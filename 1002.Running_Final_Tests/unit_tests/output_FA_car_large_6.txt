dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 50}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
res_block_channels:[32, 64, 64]
res_block_ds:[False, False, False]
reward_support:[-1, 1, 41]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64, 64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 41]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:2
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
resampling:False
resampling_use_max:False
resampling_assess_best_child:False
rs_start:1000
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
env:<class 'game_play.Car_Driving_Env.RaceWorld'>
same_env_each_time:True
channels:3
env_size:[8, 60]
observable_size:[8, 10]
game_modes:1
env_map:[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.
  0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.
  1. 1. 1. 1. 2. 1. 1. 1. 0. 0. 2. 2. 2. 1. 1. 0. 0. 0. 2. 1. 1. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 2. 1. 1. 1. 2. 2. 2. 2. 2.
  1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0. 1. 1. 1. 1. 1. 1. 1. 2. 0. 0.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.
  1. 1. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 0. 2. 2. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 2. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.
  1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 2. 2. 1. 2. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 1. 1. 2. 1. 1. 2. 2. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 2. 2.
  2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
max_steps:200
actions_size:7
optimal_score:0.86
total_frames:305000
exp_gamma:0.975
atari_env:False
reward_clipping:False
memory_size:100
image_size:[48, 48]
timesteps_in_obs:2
store_prev_actions:True
running_reward_in_obs:False
deque_length:3
PRESET_CONFIG:1
VK:True
use_two_heads:True
follow_better_policy:0.5
use_siam:True
exploration_type:rdn
rdn_beta:[0.16666666666666666, 0.6666666666666666, 4]
explorer_percentage:0.8
reward_exploration:False
train_dones:True
state_size:[6, 6]
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(1, 480)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:True
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.
  0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.
  1. 1. 1. 1. 2. 1. 1. 1. 0. 0. 2. 2. 2. 1. 1. 0. 0. 0. 2. 1. 1. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 2. 1. 1. 1. 2. 2. 2. 2. 2.
  1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0. 1. 1. 1. 1. 1. 1. 1. 2. 0. 0.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.
  1. 1. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 0. 2. 2. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 2. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.
  1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 2. 2. 1. 2. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 1. 1. 2. 1. 1. 2. 2. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 2. 2.
  2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Starting evaluation
4 3
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.0004995988830077378
rdn probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.993063024691184, 0.002312325102938685, 0.002312325102938685, 0.002312325102938685]
deleting a thread, now have 3 threads
Frames:  606 train batches done:  9 episodes:  14
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
deleting a thread, now have 2 threads
Frames:  606 train batches done:  30 episodes:  14
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
using another actor
from probs:  [0.8840967125146336, 0.05701404401728543, 0.0018751994507955612, 0.05701404401728543]
siam score:  -0.40017742
main train batch thing paused
add a thread
Adding thread: now have 3 threads
deleting a thread, now have 2 threads
Frames:  876 train batches done:  81 episodes:  21
17 6
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.0042619409161782085, 0.3319126863612739, 0.3319126863612739, 0.3319126863612739]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.005037472706229779, 0.4104926902959184, 0.17397714670193337, 0.4104926902959184]
Training Flag: False
Self play flag: True
resampling flag: False
add more workers flag:  True
expV_train_flag:  False
expV_train_start_flag:  305000
main train batch thing paused
add a thread
Adding thread: now have 3 threads
deleting a thread, now have 2 threads
Frames:  1258 train batches done:  130 episodes:  30
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.31751020803854724, 0.003914402956263169, 0.4917300997509273, 0.18684528925426228]
siam score:  -0.47325203
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.31751020803854724, 0.003914402956263169, 0.4917300997509273, 0.18684528925426228]
siam score:  -0.47173068
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.31751020803854724, 0.003914402956263169, 0.4917300997509273, 0.18684528925426228]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.31751020803854724, 0.003914402956263169, 0.4917300997509273, 0.18684528925426228]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.31751020803854724, 0.003914402956263169, 0.4917300997509273, 0.18684528925426228]
siam score:  -0.48712188
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.31751020803854724, 0.003914402956263169, 0.4917300997509273, 0.18684528925426228]
siam score:  -0.49029544
from probs:  [0.31751020803854724, 0.003914402956263169, 0.4917300997509273, 0.18684528925426228]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.3846108817880597, 0.0045330979158910555, 0.3846108817880597, 0.22624513850798947]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.45713692413056445, 0.0052018169366056955, 0.26883062946641495, 0.26883062946641495]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.4571369353093451, 0.0052018037253194205, 0.26883063048266775, 0.26883063048266775]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.4571369353093451, 0.0052018037253194205, 0.26883063048266775, 0.26883063048266775]
Printing some Q and Qe and total Qs values:  [[-0.001]
 [ 1.118]
 [ 0.025]
 [ 1.118]
 [ 1.118]
 [ 0.034]
 [ 1.118]] [[-0.231]
 [ 0.   ]
 [-0.215]
 [ 0.   ]
 [ 0.   ]
 [-0.207]
 [ 0.   ]] [[-0.001]
 [ 1.118]
 [ 0.025]
 [ 1.118]
 [ 1.118]
 [ 0.034]
 [ 1.118]]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.4044257112646001, 0.007331025155628422, 0.1838175523151714, 0.4044257112646001]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.519203876968817, 0.009133373238426827, 0.23583137489637815, 0.23583137489637815]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.519203876968817, 0.009133373238426827, 0.23583137489637815, 0.23583137489637815]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
using another actor
from probs:  [0.32921031745749485, 0.012369047627515352, 0.32921031745749485, 0.32921031745749485]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.017674672205421238, 0.017674672205421238, 0.48232532779457876, 0.48232532779457876]
Printing some Q and Qe and total Qs values:  [[0.078]
 [0.069]
 [0.078]
 [0.078]
 [0.078]
 [0.078]
 [0.063]] [[ 0.   ]
 [-0.152]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-0.156]] [[0.078]
 [0.069]
 [0.078]
 [0.078]
 [0.078]
 [0.078]
 [0.063]]
maxi score, test score, baseline:  -0.9665666666666667 -1.0 -0.9665666666666667
probs:  [0.010062810862164647, 0.23737172688748256, 0.23737172688748256, 0.5151937353628704]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.012743859421754529, 0.012743859421754529, 0.3072687235878523, 0.6672435575686387]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.012743859421754529, 0.012743859421754529, 0.3072687235878523, 0.6672435575686387]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.012743859421754529, 0.012743859421754529, 0.3072687235878523, 0.6672435575686387]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.012743859421754529, 0.012743859421754529, 0.3072687235878523, 0.6672435575686387]
first move QE:  -0.3518701958664224
from probs:  [0.019392687607864258, 0.019392687607864258, 0.4806073123921357, 0.4806073123921357]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.010984773397494369, 0.2386183225427378, 0.51177858151703, 0.2386183225427378]
from probs:  [0.010984773397494369, 0.2386183225427378, 0.51177858151703, 0.2386183225427378]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.01475942947435886, 0.3284135235085471, 0.3284135235085471, 0.3284135235085471]
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.014759394852275405, 0.32841353504924153, 0.32841353504924153, 0.32841353504924153]
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.014759331995384366, 0.32841355600153854, 0.32841355600153854, 0.32841355600153854]
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.014759331995384366, 0.32841355600153854, 0.32841355600153854, 0.32841355600153854]
from probs:  [0.014759331995384366, 0.32841355600153854, 0.32841355600153854, 0.32841355600153854]
maxi score, test score, baseline:  -0.9713285714285714 -1.0 -0.9713285714285714
probs:  [0.014759303379581984, 0.32841356554013934, 0.32841356554013934, 0.32841356554013934]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9713285714285714 -1.0 -0.9713285714285714
probs:  [0.014759303379581984, 0.32841356554013934, 0.32841356554013934, 0.32841356554013934]
using another actor
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.02108569567768791, 0.4789143043223121, 0.02108569567768791, 0.4789143043223121]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.03817564995207175, 0.8854730501437847, 0.03817564995207175, 0.03817564995207175]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.03817564995207175, 0.8854730501437847, 0.03817564995207175, 0.03817564995207175]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.03817564995207175, 0.8854730501437847, 0.03817564995207175, 0.03817564995207175]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.03817564995207175, 0.8854730501437847, 0.03817564995207175, 0.03817564995207175]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.03817564995207175, 0.8854730501437847, 0.03817564995207175, 0.03817564995207175]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.03817564995207175, 0.8854730501437847, 0.03817564995207175, 0.03817564995207175]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.3280210706194771, 0.015936788141568722, 0.3280210706194771, 0.3280210706194771]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.3280210786109543, 0.015936764167137085, 0.3280210786109543, 0.3280210786109543]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.39980000488200274, 0.19007999804719922, 0.39980000488200274, 0.01031999218879525]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.24051227492532165, 0.24051227492532165, 0.5061685770163191, 0.012806873133037515]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.024399383959879277, 0.4756006160401207, 0.4756006160401207, 0.024399383959879277]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.024399383959879277, 0.4756006160401207, 0.4756006160401207, 0.024399383959879277]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.024399383959879277, 0.4756006160401207, 0.4756006160401207, 0.024399383959879277]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.013707544446295745, 0.5037956004095349, 0.24124842757208464, 0.24124842757208464]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.013707544446295745, 0.5037956004095349, 0.24124842757208464, 0.24124842757208464]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.013707544446295745, 0.5037956004095349, 0.24124842757208464, 0.24124842757208464]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.013707544446295745, 0.5037956004095349, 0.24124842757208464, 0.24124842757208464]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.013707544446295745, 0.5037956004095349, 0.24124842757208464, 0.24124842757208464]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.013707544446295745, 0.5037956004095349, 0.24124842757208464, 0.24124842757208464]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.013707544446295745, 0.5037956004095349, 0.24124842757208464, 0.24124842757208464]
first move QE:  -0.239956815337107
siam score:  -0.55018574
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.19205634261550455, 0.39807823553815574, 0.39807823553815574, 0.011787186308183956]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.19205633760163562, 0.39807824835137506, 0.39807824835137506, 0.011787165695614296]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
siam score:  -0.56855804
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2418828062420627, 0.2418828062420627, 0.501633006496052, 0.014601381019822543]
siam score:  -0.59260225
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.47080350750410693, 0.029196492495893064, 0.029196492495893064, 0.47080350750410693]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.05165920512199063, 0.05165920512199063, 0.05165920512199063, 0.845022384634028]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2429202759997147, 0.016369107990586395, 0.2429202759997147, 0.49779034000998423]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2429202759997147, 0.016369107990586395, 0.2429202759997147, 0.49779034000998423]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.2429202759997147, 0.016369107990586395, 0.2429202759997147, 0.49779034000998423]
from probs:  [0.2429202759997147, 0.016369107990586395, 0.2429202759997147, 0.49779034000998423]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.32611477786778664, 0.02165566639664012, 0.32611477786778664, 0.32611477786778664]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.3958704046407438, 0.19430402731898877, 0.3958704046407438, 0.013955163399523603]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.32574440805565974, 0.32574440805565974, 0.32574440805565974, 0.022766775833020732]
siam score:  -0.5798428
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.4677156358218164, 0.4677156358218164, 0.03228436417818361, 0.03228436417818361]
siam score:  -0.57870865
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.4677156358218164, 0.4677156358218164, 0.03228436417818361, 0.03228436417818361]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.4677156358218164, 0.4677156358218164, 0.03228436417818361, 0.03228436417818361]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.4677156358218164, 0.4677156358218164, 0.03228436417818361, 0.03228436417818361]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.4677156358218164, 0.4677156358218164, 0.03228436417818361, 0.03228436417818361]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.4677156358218164, 0.4677156358218164, 0.03228436417818361, 0.03228436417818361]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.4677156358218164, 0.4677156358218164, 0.03228436417818361, 0.03228436417818361]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.9031383204047947, 0.032287226531735165, 0.032287226531735165, 0.032287226531735165]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.9031383204047947, 0.032287226531735165, 0.032287226531735165, 0.032287226531735165]
from probs:  [0.6023998576277183, 0.19126669039538022, 0.19126669039538022, 0.015066761581521239]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.4928755775800253, 0.24407620542487768, 0.24407620542487768, 0.018972011570219348]
first move QE:  -0.17819358537392901
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.4928755775800253, 0.24407620542487768, 0.24407620542487768, 0.018972011570219348]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.4928755775800253, 0.24407620542487768, 0.24407620542487768, 0.018972011570219348]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.4928755775800253, 0.24407620542487768, 0.24407620542487768, 0.018972011570219348]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.4928755775800253, 0.24407620542487768, 0.24407620542487768, 0.018972011570219348]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.4928755775800253, 0.24407620542487768, 0.24407620542487768, 0.018972011570219348]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.4928755775800253, 0.24407620542487768, 0.24407620542487768, 0.018972011570219348]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.6365031111971051, 0.024220954845255268, 0.31505497911238434, 0.024220954845255268]
from probs:  [0.6365031111971051, 0.024220954845255268, 0.31505497911238434, 0.024220954845255268]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.8986019228239037, 0.03379935905869879, 0.03379935905869879, 0.03379935905869879]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.8986019228239037, 0.03379935905869879, 0.03379935905869879, 0.03379935905869879]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.8986019228239037, 0.03379935905869879, 0.03379935905869879, 0.03379935905869879]
first move QE:  -0.17585772156149126
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.4632403631565828, 0.03675963684341719, 0.03675963684341719, 0.4632403631565828]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.46178854382295487, 0.46178854382295487, 0.03821145617704514, 0.03821145617704514]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.46178861247519004, 0.46178861247519004, 0.03821138752480996, 0.03821138752480996]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.46178861247519004, 0.46178861247519004, 0.03821138752480996, 0.03821138752480996]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.46178861247519004, 0.46178861247519004, 0.03821138752480996, 0.03821138752480996]
siam score:  -0.57560027
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.4617886782377788, 0.4617886782377788, 0.03821132176222121, 0.03821132176222121]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.4617886782377788, 0.4617886782377788, 0.03821132176222121, 0.03821132176222121]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.4617886782377788, 0.4617886782377788, 0.03821132176222121, 0.03821132176222121]
siam score:  -0.5742552
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.02816692696881395, 0.32394435767706203, 0.32394435767706203, 0.32394435767706203]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.02816692696881395, 0.32394435767706203, 0.32394435767706203, 0.32394435767706203]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.02816692696881395, 0.32394435767706203, 0.32394435767706203, 0.32394435767706203]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.015366864264676249, 0.3282110452451079, 0.3282110452451079, 0.3282110452451079]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.010765481191815775, 0.32974483960272805, 0.32974483960272805, 0.32974483960272805]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.012043045135890749, 0.3727356925088564, 0.3727356925088564, 0.24248556984639638]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.012043045135890749, 0.3727356925088564, 0.3727356925088564, 0.24248556984639638]
siam score:  -0.5903461
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.012043045135890749, 0.3727356925088564, 0.3727356925088564, 0.24248556984639638]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.012043045135890749, 0.3727356925088564, 0.3727356925088564, 0.24248556984639638]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.01574664004521071, 0.497364056285783, 0.16344264769231923, 0.323446655976687]
siam score:  -0.5932514
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.0295571933730438, 0.6253485626350878, 0.3155370506188247, 0.0295571933730438]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.0295571933730438, 0.6253485626350878, 0.3155370506188247, 0.0295571933730438]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.1639902722070211, 0.49621668857475115, 0.3234589520635315, 0.016334087154696184]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.19819402357740717, 0.39112662542706367, 0.39112662542706367, 0.019552725568465462]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
main train batch thing paused
add a thread
Adding thread: now have 3 threads
Printing some Q and Qe and total Qs values:  [[0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.835]
 [0.841]] [[-0.007]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.072]
 [-0.007]] [[1.339]
 [1.339]
 [1.339]
 [1.339]
 [1.339]
 [1.26 ]
 [1.339]]
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Printing some Q and Qe and total Qs values:  [[1.16 ]
 [1.171]
 [1.177]
 [1.159]
 [1.168]
 [1.157]
 [1.167]] [[ 0.052]
 [ 0.01 ]
 [-0.097]
 [-0.093]
 [-0.139]
 [-0.044]
 [ 0.06 ]] [[1.998]
 [1.992]
 [1.932]
 [1.898]
 [1.887]
 [1.927]
 [2.016]]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.224]
 [1.211]
 [1.189]
 [1.337]
 [1.34 ]
 [1.341]
 [1.341]] [[-0.022]
 [ 0.331]
 [ 0.002]
 [-0.055]
 [-0.013]
 [-0.03 ]
 [-0.042]] [[2.559]
 [2.651]
 [2.498]
 [2.773]
 [2.794]
 [2.79 ]
 [2.785]]
main train batch thing paused
add a thread
Adding thread: now have 5 threads
using another actor
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.24556883802826712, 0.48485158450185195, 0.24556883802826712, 0.024010739441613842]
main train batch thing paused
add a thread
Adding thread: now have 6 threads
main train batch thing paused
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.016918671496683097, 0.4951157273446965, 0.3234552457582299, 0.16451035540039047]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.016918671496683097, 0.4951157273446965, 0.3234552457582299, 0.16451035540039047]
Printing some Q and Qe and total Qs values:  [[0.624]
 [0.713]
 [0.964]
 [1.031]
 [1.026]
 [1.14 ]
 [1.083]] [[ 0.767]
 [ 0.122]
 [ 0.046]
 [-0.   ]
 [ 0.004]
 [ 0.098]
 [ 0.045]] [[1.894]
 [1.427]
 [1.851]
 [1.941]
 [1.934]
 [2.257]
 [2.09 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.016918671496683097, 0.4951157273446965, 0.3234552457582299, 0.16451035540039047]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.020234341583123712, 0.3906028655983872, 0.3906028655983872, 0.19855992722010182]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.02482975037976295, 0.2457515047241461, 0.4836672401719448, 0.2457515047241461]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.03230946624644497, 0.322563511251185, 0.322563511251185, 0.322563511251185]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.03230946624644497, 0.322563511251185, 0.322563511251185, 0.322563511251185]
Printing some Q and Qe and total Qs values:  [[0.348]
 [0.348]
 [0.348]
 [0.348]
 [0.348]
 [0.356]
 [0.348]] [[-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.021]
 [-0.001]] [[-0.124]
 [-0.124]
 [-0.124]
 [-0.124]
 [-0.124]
 [-0.116]
 [-0.124]]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03230940747019498, 0.32256353084326833, 0.32256353084326833, 0.32256353084326833]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03230940747019498, 0.32256353084326833, 0.32256353084326833, 0.32256353084326833]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03230940747019498, 0.32256353084326833, 0.32256353084326833, 0.32256353084326833]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03230940747019498, 0.32256353084326833, 0.32256353084326833, 0.32256353084326833]
Printing some Q and Qe and total Qs values:  [[0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.679]
 [0.672]] [[-0.007]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.093]
 [-0.007]] [[ 0.074]
 [ 0.074]
 [ 0.074]
 [ 0.074]
 [ 0.074]
 [-0.027]
 [ 0.074]]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.01770482987984423, 0.3274317233733853, 0.3274317233733853, 0.3274317233733853]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.01770482987984423, 0.3274317233733853, 0.3274317233733853, 0.3274317233733853]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.01770482987984423, 0.3274317233733853, 0.3274317233733853, 0.3274317233733853]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.01770482987984423, 0.3274317233733853, 0.3274317233733853, 0.3274317233733853]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.020912020890680023, 0.3900897713977856, 0.19890843631374883, 0.3900897713977856]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.020912020890680023, 0.3900897713977856, 0.19890843631374883, 0.3900897713977856]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.020912020890680023, 0.3900897713977856, 0.19890843631374883, 0.3900897713977856]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.020912020890680023, 0.3900897713977856, 0.19890843631374883, 0.3900897713977856]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
siam score:  -0.61711407
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.020911981701297787, 0.39008979536251603, 0.19890842757367014, 0.39008979536251603]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.020911981701297787, 0.39008979536251603, 0.19890842757367014, 0.39008979536251603]
using explorer policy with actor:  1
using another actor
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.025642844073490895, 0.48251559796020094, 0.245920778983154, 0.245920778983154]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.025642844073490895, 0.48251559796020094, 0.245920778983154, 0.245920778983154]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.03264153743997319, 0.6192475086863117, 0.31546941643374193, 0.03264153743997319]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.03264153743997319, 0.6192475086863117, 0.31546941643374193, 0.03264153743997319]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.03264153743997319, 0.6192475086863117, 0.31546941643374193, 0.03264153743997319]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.03264153743997319, 0.6192475086863117, 0.31546941643374193, 0.03264153743997319]
maxi score, test score, baseline:  -0.9817181818181818 -1.0 -0.9817181818181818
probs:  [0.04519107785774527, 0.8644267664267642, 0.04519107785774527, 0.04519107785774527]
maxi score, test score, baseline:  -0.9817181818181818 -1.0 -0.9817181818181818
probs:  [0.04519107785774527, 0.8644267664267642, 0.04519107785774527, 0.04519107785774527]
siam score:  -0.61939913
maxi score, test score, baseline:  -0.9817181818181818 -1.0 -0.9817181818181818
probs:  [0.04519107785774527, 0.8644267664267642, 0.04519107785774527, 0.04519107785774527]
Printing some Q and Qe and total Qs values:  [[0.392]
 [0.383]
 [0.377]
 [0.398]
 [0.399]
 [0.393]
 [0.385]] [[ 0.017]
 [ 0.02 ]
 [-0.015]
 [-0.148]
 [-0.156]
 [-0.036]
 [ 0.018]] [[0.159]
 [0.145]
 [0.098]
 [0.007]
 [0.001]
 [0.109]
 [0.148]]
main train batch thing paused
main train batch thing paused
main train batch thing paused
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
using explorer policy with actor:  0
siam score:  -0.6161883
main train batch thing paused
maxi score, test score, baseline:  -0.9823561403508771 -1.0 -0.9823561403508771
probs:  [0.32189191581626103, 0.32189191581626103, 0.03432425255121697, 0.32189191581626103]
from probs:  [0.45214741589726365, 0.047852584102736365, 0.047852584102736365, 0.45214741589726365]
siam score:  -0.61457956
maxi score, test score, baseline:  -0.9823561403508771 -1.0 -0.9823561403508771
probs:  [0.48029867335832704, 0.24622461191215878, 0.027252102817355465, 0.24622461191215878]
siam score:  -0.6183935
maxi score, test score, baseline:  -0.9823561403508771 -1.0 -0.9823561403508771
probs:  [0.48029867335832704, 0.24622461191215878, 0.027252102817355465, 0.24622461191215878]
maxi score, test score, baseline:  -0.9823561403508771 -1.0 -0.9823561403508771
probs:  [0.48029867335832704, 0.24622461191215878, 0.027252102817355465, 0.24622461191215878]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
using explorer policy with actor:  1
siam score:  -0.62362367
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9823561403508771 -1.0 -0.9823561403508771
probs:  [0.48029867335832704, 0.24622461191215878, 0.027252102817355465, 0.24622461191215878]
maxi score, test score, baseline:  -0.9823561403508771 -1.0 -0.9823561403508771
probs:  [0.48029867335832704, 0.24622461191215878, 0.027252102817355465, 0.24622461191215878]
maxi score, test score, baseline:  -0.9823561403508771 -1.0 -0.9823561403508771
probs:  [0.8564304591727726, 0.04785651360907575, 0.04785651360907575, 0.04785651360907575]
maxi score, test score, baseline:  -0.9823561403508771 -1.0 -0.9823561403508771
probs:  [0.8564304591727726, 0.04785651360907575, 0.04785651360907575, 0.04785651360907575]
siam score:  -0.6178572
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[1.234]
 [1.212]
 [1.212]
 [1.212]
 [1.228]
 [1.212]
 [1.212]] [[-0.165]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-0.212]
 [ 0.   ]
 [ 0.   ]] [[1.957]
 [1.97 ]
 [1.97 ]
 [1.97 ]
 [1.93 ]
 [1.97 ]
 [1.97 ]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.446]
 [0.446]
 [0.446]
 [0.462]
 [0.446]
 [0.461]
 [0.462]] [[-0.269]
 [-0.269]
 [-0.269]
 [-0.389]
 [-0.269]
 [-0.461]
 [-0.309]] [[0.041]
 [0.041]
 [0.041]
 [0.033]
 [0.041]
 [0.008]
 [0.059]]
Printing some Q and Qe and total Qs values:  [[0.702]
 [0.58 ]
 [0.725]
 [0.729]
 [0.732]
 [0.72 ]
 [0.709]] [[ 1.363]
 [ 0.072]
 [ 0.   ]
 [-0.002]
 [-0.041]
 [-0.009]
 [ 0.155]] [[0.702]
 [0.58 ]
 [0.725]
 [0.729]
 [0.732]
 [0.72 ]
 [0.709]]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.8564306841146381, 0.047856438628454, 0.047856438628454, 0.047856438628454]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.8564306841146381, 0.047856438628454, 0.047856438628454, 0.047856438628454]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.8564306841146381, 0.047856438628454, 0.047856438628454, 0.047856438628454]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.8564306841146381, 0.047856438628454, 0.047856438628454, 0.047856438628454]
Printing some Q and Qe and total Qs values:  [[ 0.003]
 [-0.007]
 [ 0.012]
 [ 0.015]
 [ 0.011]
 [ 0.009]
 [ 0.012]] [[ 0.084]
 [ 0.073]
 [-0.077]
 [-0.189]
 [-0.139]
 [-0.196]
 [-0.135]] [[-0.739]
 [-0.763]
 [-0.775]
 [-0.807]
 [-0.797]
 [-0.82 ]
 [-0.794]]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.5827598266145267, 0.19730047994792552, 0.19730047994792552, 0.022639213489622268]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.5827598266145267, 0.19730047994792552, 0.19730047994792552, 0.022639213489622268]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.5827598266145267, 0.19730047994792552, 0.19730047994792552, 0.022639213489622268]
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.384]
 [0.6  ]
 [0.605]
 [0.604]
 [0.599]
 [0.602]] [[ 0.095]
 [ 0.006]
 [-0.235]
 [-0.332]
 [-0.298]
 [-0.225]
 [-0.163]] [[0.535]
 [0.04 ]
 [0.312]
 [0.259]
 [0.278]
 [0.318]
 [0.365]]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.47922876072045706, 0.24636144824253212, 0.24636144824253212, 0.028048342794478716]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.47922876072045706, 0.24636144824253212, 0.24636144824253212, 0.028048342794478716]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.47922876072045706, 0.24636144824253212, 0.24636144824253212, 0.028048342794478716]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.47922876072045706, 0.24636144824253212, 0.24636144824253212, 0.028048342794478716]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.47922876072045706, 0.24636144824253212, 0.24636144824253212, 0.028048342794478716]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.47922876072045706, 0.24636144824253212, 0.24636144824253212, 0.028048342794478716]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.32123230172498435, 0.32123230172498435, 0.32123230172498435, 0.03630309482504699]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.32123230172498435, 0.32123230172498435, 0.32123230172498435, 0.03630309482504699]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.32123230172498435, 0.32123230172498435, 0.32123230172498435, 0.03630309482504699]
siam score:  -0.6319773
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.3212323215582402, 0.3212323215582402, 0.3212323215582402, 0.03630303532527949]
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.4495495976369388, 0.05045040236306117, 0.4495495976369388, 0.05045040236306117]
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.3209069249818891, 0.3209069249818891, 0.03727922505433274, 0.3209069249818891]
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.3209069249818891, 0.3209069249818891, 0.03727922505433274, 0.3209069249818891]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.3209069249818891, 0.3209069249818891, 0.03727922505433274, 0.3209069249818891]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.3209069249818891, 0.3209069249818891, 0.03727922505433274, 0.3209069249818891]
line 256 mcts: sample exp_bonus -0.234589710810567
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.02424331705709848, 0.38765651398957407, 0.2004436549637534, 0.38765651398957407]
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.02424331705709848, 0.38765651398957407, 0.2004436549637534, 0.38765651398957407]
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.02424331705709848, 0.38765651398957407, 0.2004436549637534, 0.38765651398957407]
Printing some Q and Qe and total Qs values:  [[1.002]
 [0.727]
 [1.02 ]
 [1.024]
 [1.025]
 [1.021]
 [1.019]] [[-0.013]
 [-0.014]
 [-0.156]
 [-0.226]
 [-0.208]
 [-0.201]
 [-0.056]] [[1.33 ]
 [0.779]
 [1.318]
 [1.303]
 [1.312]
 [1.305]
 [1.349]]
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.02424331705709848, 0.38765651398957407, 0.2004436549637534, 0.38765651398957407]
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
Printing some Q and Qe and total Qs values:  [[1.057]
 [1.038]
 [1.073]
 [1.064]
 [1.048]
 [1.045]
 [1.05 ]] [[0.839]
 [0.315]
 [0.128]
 [0.025]
 [0.006]
 [0.385]
 [0.237]] [[1.767]
 [1.028]
 [0.849]
 [0.694]
 [0.637]
 [1.136]
 [0.948]]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.02424327459470998, 0.38765653988127446, 0.2004436456427412, 0.38765653988127446]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
line 256 mcts: sample exp_bonus -0.009290422164354118
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.02424327459470998, 0.38765653988127446, 0.2004436456427412, 0.38765653988127446]
124 43
Printing some Q and Qe and total Qs values:  [[0.456]
 [0.459]
 [0.472]
 [0.458]
 [0.452]
 [0.454]
 [0.459]] [[ 0.167]
 [ 0.032]
 [-0.008]
 [-0.014]
 [-0.057]
 [-0.037]
 [-0.037]] [[ 0.033]
 [-0.008]
 [ 0.005]
 [-0.025]
 [-0.052]
 [-0.04 ]
 [-0.03 ]]
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.438]
 [0.431]
 [0.435]
 [0.435]
 [0.427]
 [0.428]] [[1.008]
 [1.136]
 [0.593]
 [0.314]
 [1.014]
 [1.023]
 [1.168]] [[ 0.188]
 [ 0.254]
 [ 0.059]
 [-0.026]
 [ 0.208]
 [ 0.195]
 [ 0.246]]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.018239803190739885, 0.42254393506944943, 0.2796081308699053, 0.2796081308699053]
siam score:  -0.6243121
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.018239803190739885, 0.42254393506944943, 0.2796081308699053, 0.2796081308699053]
Printing some Q and Qe and total Qs values:  [[0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.163]
 [0.153]] [[0.041]
 [0.041]
 [0.041]
 [0.041]
 [0.041]
 [0.095]
 [0.041]] [[-0.616]
 [-0.616]
 [-0.616]
 [-0.616]
 [-0.616]
 [-0.579]
 [-0.616]]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.018239803190739885, 0.42254393506944943, 0.2796081308699053, 0.2796081308699053]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.018239803190739885, 0.42254393506944943, 0.2796081308699053, 0.2796081308699053]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.014695959086178665, 0.4429378632310408, 0.3261446166460786, 0.21622156103670195]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.014695959086178665, 0.4429378632310408, 0.3261446166460786, 0.21622156103670195]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.014695959086178665, 0.4429378632310408, 0.3261446166460786, 0.21622156103670195]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.016287091957980736, 0.4942656821103175, 0.3639078847960441, 0.12553934113565768]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.013619020817667075, 0.3962009524422523, 0.3962009524422523, 0.19397907429782843]
line 256 mcts: sample exp_bonus 9.8582779071998e-05
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.013619020817667075, 0.3962009524422523, 0.3962009524422523, 0.19397907429782843]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.013619020817667075, 0.3962009524422523, 0.3962009524422523, 0.19397907429782843]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.013619020817667075, 0.3962009524422523, 0.3962009524422523, 0.19397907429782843]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.013619020817667075, 0.3962009524422523, 0.3962009524422523, 0.19397907429782843]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
in main func line 156:  132
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.015092074899126348, 0.3260887165934724, 0.4423197847014605, 0.2164994238059408]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.015092074899126348, 0.3260887165934724, 0.4423197847014605, 0.2164994238059408]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.015092074899126348, 0.3260887165934724, 0.4423197847014605, 0.2164994238059408]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.01683477650248711, 0.24314219930889633, 0.49688082487972024, 0.24314219930889633]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.01683477650248711, 0.24314219930889633, 0.49688082487972024, 0.24314219930889633]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.01683477650248711, 0.24314219930889633, 0.49688082487972024, 0.24314219930889633]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.01683477650248711, 0.24314219930889633, 0.49688082487972024, 0.24314219930889633]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.01683477650248711, 0.24314219930889633, 0.49688082487972024, 0.24314219930889633]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.019225021418216012, 0.27968474828230405, 0.4214054820171759, 0.27968474828230405]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.019224986817052467, 0.2796847527330762, 0.4214055077167951, 0.2796847527330762]
using another actor
line 256 mcts: sample exp_bonus -0.4501637975086956
Printing some Q and Qe and total Qs values:  [[0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]] [[0.39]
 [0.39]
 [0.39]
 [0.39]
 [0.39]
 [0.39]
 [0.39]] [[0.804]
 [0.804]
 [0.804]
 [0.804]
 [0.804]
 [0.804]
 [0.804]]
Printing some Q and Qe and total Qs values:  [[1.314]
 [1.319]
 [1.319]
 [1.319]
 [1.319]
 [1.319]
 [1.319]] [[-0.009]
 [-0.132]
 [-0.132]
 [-0.132]
 [-0.132]
 [-0.132]
 [-0.132]] [[2.639]
 [2.526]
 [2.526]
 [2.526]
 [2.526]
 [2.526]
 [2.526]]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.0222490276549728, 0.32591699078167574, 0.32591699078167574, 0.32591699078167574]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.0222490276549728, 0.32591699078167574, 0.32591699078167574, 0.32591699078167574]
Printing some Q and Qe and total Qs values:  [[-0.04 ]
 [-0.051]
 [-0.031]
 [-0.03 ]
 [-0.031]
 [-0.033]
 [-0.034]] [[0.473]
 [0.436]
 [0.196]
 [0.163]
 [0.273]
 [0.367]
 [0.461]] [[-0.407]
 [-0.476]
 [-0.757]
 [-0.798]
 [-0.654]
 [-0.532]
 [-0.408]]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.031947827121980195, 0.4741944876069778, 0.246928842635521, 0.246928842635521]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.031947827121980195, 0.4741944876069778, 0.246928842635521, 0.246928842635521]
Printing some Q and Qe and total Qs values:  [[1.21 ]
 [1.21 ]
 [1.233]
 [1.21 ]
 [1.21 ]
 [1.21 ]
 [1.21 ]] [[0.237]
 [0.237]
 [0.335]
 [0.237]
 [0.237]
 [0.237]
 [0.237]] [[1.208]
 [1.208]
 [1.384]
 [1.208]
 [1.208]
 [1.208]
 [1.208]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.031947827121980195, 0.4741944876069778, 0.246928842635521, 0.246928842635521]
first move QE:  -0.09743529804336037
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.031947827121980195, 0.4741944876069778, 0.246928842635521, 0.246928842635521]
Printing some Q and Qe and total Qs values:  [[-0.023]
 [-0.052]
 [-0.011]
 [-0.008]
 [-0.012]
 [-0.025]
 [-0.025]] [[0.676]
 [0.357]
 [0.462]
 [0.393]
 [0.522]
 [0.498]
 [0.542]] [[-0.316]
 [-0.588]
 [-0.436]
 [-0.475]
 [-0.398]
 [-0.44 ]
 [-0.41 ]]
line 256 mcts: sample exp_bonus 0.04672806463661594
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.031947827121980195, 0.4741944876069778, 0.246928842635521, 0.246928842635521]
siam score:  -0.6576514
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.05666630778130587, 0.4433336922186941, 0.4433336922186941, 0.05666630778130587]
using explorer policy with actor:  1
Starting evaluation
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.05666630778130587, 0.4433336922186941, 0.4433336922186941, 0.05666630778130587]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.05666630778130587, 0.4433336922186941, 0.4433336922186941, 0.05666630778130587]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.961]
 [0.951]
 [0.956]
 [0.961]
 [0.963]
 [0.961]
 [0.959]] [[-0.017]
 [-0.013]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]] [[0.881]
 [0.865]
 [0.871]
 [0.881]
 [0.886]
 [0.881]
 [0.878]]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.09199237210751694, 0.7240228836774493, 0.09199237210751694, 0.09199237210751694]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.09199237210751694, 0.7240228836774493, 0.09199237210751694, 0.09199237210751694]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.593]
 [0.61 ]
 [0.606]
 [0.607]
 [0.607]
 [0.604]] [[-0.016]
 [-0.018]
 [-0.016]
 [-0.015]
 [-0.016]
 [-0.016]
 [-0.015]] [[0.617]
 [0.593]
 [0.61 ]
 [0.606]
 [0.607]
 [0.607]
 [0.604]]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.09199237210751694, 0.7240228836774493, 0.09199237210751694, 0.09199237210751694]
Printing some Q and Qe and total Qs values:  [[0.639]
 [0.542]
 [0.633]
 [0.63 ]
 [0.63 ]
 [0.625]
 [0.626]] [[-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.015]
 [-0.015]
 [-0.016]] [[0.639]
 [0.542]
 [0.633]
 [0.63 ]
 [0.63 ]
 [0.625]
 [0.626]]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.24702344949655122, 0.4732412877586475, 0.24702344949655122, 0.03271181324825001]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.195]
 [0.17 ]
 [0.182]
 [0.185]
 [0.178]
 [0.181]
 [0.183]] [[-0.016]
 [-0.018]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]] [[0.195]
 [0.17 ]
 [0.182]
 [0.185]
 [0.178]
 [0.181]
 [0.183]]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.24702344949655122, 0.4732412877586475, 0.24702344949655122, 0.03271181324825001]
Printing some Q and Qe and total Qs values:  [[0.55 ]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]] [[-0.005]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]] [[0.55 ]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]]
siam score:  -0.67937255
UNIT TEST: sample policy line 217 mcts : [0.122 0.061 0.408 0.102 0.082 0.102 0.122]
using explorer policy with actor:  1
using explorer policy with actor:  0
siam score:  -0.69096327
Printing some Q and Qe and total Qs values:  [[0.54 ]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]] [[-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]] [[0.54 ]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.2470234479783225, 0.4732414016257985, 0.2470234479783225, 0.03271170241755653]
maxi score, test score, baseline:  -0.9845153846153847 -1.0 -0.9845153846153847
maxi score, test score, baseline:  -0.9845153846153847 -1.0 -0.9845153846153847
Printing some Q and Qe and total Qs values:  [[0.655]
 [0.663]
 [0.658]
 [0.663]
 [0.663]
 [0.659]
 [0.661]] [[-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.005]] [[0.655]
 [0.663]
 [0.658]
 [0.663]
 [0.663]
 [0.659]
 [0.661]]
maxi score, test score, baseline:  -0.9845153846153847 -1.0 -0.9845153846153847
probs:  [0.24702344725506498, 0.473241455870128, 0.24702344725506498, 0.03271164961974206]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9847484848484849 -1.0 -0.9847484848484849
probs:  [0.24702344655422961, 0.47324150843278306, 0.24702344655422961, 0.03271159845875773]
maxi score, test score, baseline:  -0.9847484848484849 -1.0 -0.9847484848484849
Printing some Q and Qe and total Qs values:  [[0.621]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]] [[-0.007]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]] [[0.621]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]]
Printing some Q and Qe and total Qs values:  [[0.216]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.214]
 [0.219]] [[-0.008]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.006]
 [-0.007]] [[0.228]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.227]
 [0.236]]
line 256 mcts: sample exp_bonus -0.018598777822613693
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]] [[-0.008]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]] [[0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]]
Printing some Q and Qe and total Qs values:  [[0.491]
 [0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.496]
 [0.495]] [[-0.007]
 [-0.004]
 [-0.004]
 [-0.006]
 [-0.004]
 [-0.006]
 [-0.006]] [[0.491]
 [0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.496]
 [0.495]]
maxi score, test score, baseline:  -0.9847484848484849 -1.0 -0.9847484848484849
probs:  [0.31447428138619427, 0.602712245230357, 0.04140673669172433, 0.04140673669172433]
Printing some Q and Qe and total Qs values:  [[0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]] [[-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]] [[0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]]
maxi score, test score, baseline:  -0.9849746268656716 -1.0 -0.9849746268656716
maxi score, test score, baseline:  -0.9849746268656716 -1.0 -0.9849746268656716
maxi score, test score, baseline:  -0.9849746268656716 -1.0 -0.9849746268656716
probs:  [0.3144743001382, 0.6027123478148624, 0.041406676023468765, 0.041406676023468765]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9849746268656716 -1.0 -0.9849746268656716
probs:  [0.3227640611322367, 0.48504598528268866, 0.1690232908844406, 0.02316666270063401]
Printing some Q and Qe and total Qs values:  [[0.6  ]
 [0.589]
 [0.6  ]
 [0.605]
 [0.604]
 [0.601]
 [0.597]] [[-0.007]
 [-0.007]
 [-0.008]
 [-0.008]
 [-0.007]
 [-0.007]
 [-0.007]] [[0.6  ]
 [0.589]
 [0.6  ]
 [0.605]
 [0.604]
 [0.601]
 [0.597]]
maxi score, test score, baseline:  -0.9849746268656716 -1.0 -0.9849746268656716
probs:  [0.3227640611322367, 0.48504598528268866, 0.1690232908844406, 0.02316666270063401]
Printing some Q and Qe and total Qs values:  [[0.608]
 [0.348]
 [0.61 ]
 [0.613]
 [0.614]
 [0.613]
 [0.611]] [[-0.006]
 [-0.048]
 [-0.006]
 [-0.006]
 [-0.007]
 [-0.006]
 [-0.006]] [[0.608]
 [0.348]
 [0.61 ]
 [0.613]
 [0.614]
 [0.613]
 [0.611]]
first move QE:  -0.09636758828019351
maxi score, test score, baseline:  -0.9851941176470589 -1.0 -0.9851941176470589
probs:  [0.37796785873535876, 0.5680915345707496, 0.026970303346945803, 0.026970303346945803]
STARTED EXPV TRAINING ON FRAME NO.  10624
maxi score, test score, baseline:  -0.9854072463768117 -1.0 -0.9854072463768117
probs:  [0.4669019693698064, 0.4669019693698064, 0.03309803063019364, 0.03309803063019364]
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.522]
 [0.522]
 [0.522]
 [0.522]
 [0.52 ]
 [0.511]] [[-0.012]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]] [[0.532]
 [0.522]
 [0.522]
 [0.522]
 [0.522]
 [0.52 ]
 [0.511]]
maxi score, test score, baseline:  -0.9856142857142858 -1.0 -0.9856142857142858
probs:  [0.6010040556493317, 0.3143201149095639, 0.04233791472055217, 0.04233791472055217]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10624
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.007449154862705409
Printing some Q and Qe and total Qs values:  [[0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]] [[-0.008]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]] [[0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]]
maxi score, test score, baseline:  -0.9863864864864865 -1.0 -0.9863864864864865
probs:  [0.60100442036159, 0.31432018174165266, 0.04233769894837862, 0.04233769894837862]
maxi score, test score, baseline:  -0.9863864864864865 -1.0 -0.9863864864864865
probs:  [0.60100442036159, 0.31432018174165266, 0.04233769894837862, 0.04233769894837862]
maxi score, test score, baseline:  -0.9865666666666667 -1.0 -0.9865666666666667
maxi score, test score, baseline:  -0.9865666666666667 -1.0 -0.9865666666666667
probs:  [0.6010045053380231, 0.31432019731325067, 0.04233764867436321, 0.04233764867436321]
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]] [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.6010046685387822, 0.3143202272191491, 0.04233755212103437, 0.04233755212103437]
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.546]
 [0.546]
 [0.546]
 [0.546]
 [0.549]
 [0.551]] [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.001]] [[0.546]
 [0.546]
 [0.546]
 [0.546]
 [0.546]
 [0.549]
 [0.551]]
maxi score, test score, baseline:  -0.9875543209876543 -1.0 -0.9875543209876543
maxi score, test score, baseline:  -0.9877048780487805 -1.0 -0.9877048780487805
probs:  [0.8263984128279022, 0.05786719572403255, 0.05786719572403255, 0.05786719572403255]
maxi score, test score, baseline:  -0.9877048780487805 -1.0 -0.9877048780487805
probs:  [0.7145600741412531, 0.09514664195291561, 0.09514664195291561, 0.09514664195291561]
maxi score, test score, baseline:  -0.9881352941176471 -1.0 -0.9881352941176471
probs:  [0.47138135991326846, 0.034223231476940834, 0.24719770430489527, 0.24719770430489527]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.226]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]] [[-0.027]
 [-0.031]
 [-0.031]
 [-0.031]
 [-0.031]
 [-0.031]
 [-0.031]] [[2.43]
 [1.88]
 [1.88]
 [1.88]
 [1.88]
 [1.88]
 [1.88]]
using explorer policy with actor:  0
rdn probs:  [0.47138135991326846, 0.034223231476940834, 0.24719770430489527, 0.24719770430489527]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.4834841575700699, 0.024267575335177982, 0.3225621073851925, 0.16968615970955964]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.5709676512883632, 0.028487113899580092, 0.20027261740602828, 0.20027261740602828]
maxi score, test score, baseline:  -0.9884057471264368 -1.0 -0.9884057471264368
probs:  [0.47047205404318326, 0.03497170037763586, 0.2472781227895904, 0.2472781227895904]
156 47
Printing some Q and Qe and total Qs values:  [[0.824]
 [0.824]
 [0.824]
 [0.824]
 [0.824]
 [0.824]
 [0.824]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[1.665]
 [1.665]
 [1.665]
 [1.665]
 [1.665]
 [1.665]
 [1.665]]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
Printing some Q and Qe and total Qs values:  [[0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.063]
 [0.07 ]
 [0.065]] [[ 0.]
 [ 0.]
 [ 0.]
 [ 0.]
 [-0.]
 [ 0.]
 [ 0.]] [[0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.063]
 [0.07 ]
 [0.065]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.09817984747595714, 0.09817984747595714, 0.7054604575721287, 0.09817984747595714]
Printing some Q and Qe and total Qs values:  [[0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.519]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.666]]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.199]
 [0.201]] [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.004]
 [0.003]] [[0.023]
 [0.023]
 [0.023]
 [0.023]
 [0.023]
 [0.019]
 [0.023]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.022132485285179963, 0.27979186588144295, 0.41828378295193425, 0.27979186588144295]
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.022132485285179963, 0.27979186588144295, 0.41828378295193425, 0.27979186588144295]
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.022132485285179963, 0.27979186588144295, 0.41828378295193425, 0.27979186588144295]
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.022132485285179963, 0.27979186588144295, 0.41828378295193425, 0.27979186588144295]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.022132485285179963, 0.27979186588144295, 0.41828378295193425, 0.27979186588144295]
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.022132485285179963, 0.27979186588144295, 0.41828378295193425, 0.27979186588144295]
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.022132485285179963, 0.27979186588144295, 0.41828378295193425, 0.27979186588144295]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.016189679941881027, 0.29398411961489357, 0.3958420808283317, 0.29398411961489357]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.016189679941881027, 0.29398411961489357, 0.3958420808283317, 0.29398411961489357]
deleting a thread, now have 5 threads
Frames:  11874 train batches done:  1386 episodes:  212
first move QE:  -0.08772848384858563
166 48
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.022471966521767934, 0.4151290410193191, 0.14726995143959387, 0.4151290410193191]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.025900460788103923, 0.48124315850048127, 0.17062178331684327, 0.32223459739457155]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10624
deleting a thread, now have 4 threads
Frames:  12149 train batches done:  1407 episodes:  216
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.025900460788103923, 0.48124315850048127, 0.17062178331684327, 0.32223459739457155]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
siam score:  -0.89957994
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
deleting a thread, now have 3 threads
Frames:  12229 train batches done:  1425 episodes:  217
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.03013425263606069, 0.5628858712486832, 0.03013425263606069, 0.3768456234791954]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.036826903850486495, 0.4631730961495135, 0.036826903850486495, 0.4631730961495135]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.036826903850486495, 0.4631730961495135, 0.036826903850486495, 0.4631730961495135]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.036826903850486495, 0.4631730961495135, 0.036826903850486495, 0.4631730961495135]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.022948561362264867, 0.41472359273718024, 0.14760425316337467, 0.41472359273718024]
Printing some Q and Qe and total Qs values:  [[0.158]
 [0.191]
 [0.191]
 [0.191]
 [0.191]
 [0.189]
 [0.18 ]] [[-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]] [[-0.559]
 [-0.493]
 [-0.493]
 [-0.493]
 [-0.493]
 [-0.497]
 [-0.515]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.026439757477838884, 0.4805202500725014, 0.17091991421250513, 0.32212007823715466]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.031251382573163546, 0.38284733387109227, 0.20305394968465196, 0.38284733387109227]
siam score:  -0.9056726
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.03125135316887438, 0.38284735172849216, 0.20305394337414126, 0.38284735172849216]
Printing some Q and Qe and total Qs values:  [[0.121]
 [0.134]
 [0.134]
 [0.134]
 [0.134]
 [0.13 ]
 [0.135]] [[0.009]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.009]
 [0.009]] [[-0.591]
 [-0.565]
 [-0.565]
 [-0.565]
 [-0.565]
 [-0.573]
 [-0.564]]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.03125135316887438, 0.38284735172849216, 0.20305394337414126, 0.38284735172849216]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.03125135316887438, 0.38284735172849216, 0.20305394337414126, 0.38284735172849216]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.03125135316887438, 0.38284735172849216, 0.20305394337414126, 0.38284735172849216]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.03125135316887438, 0.38284735172849216, 0.20305394337414126, 0.38284735172849216]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.03791584724496193, 0.46695965051952326, 0.24756225111775743, 0.24756225111775743]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.237]
 [0.242]
 [0.234]
 [0.232]
 [0.229]
 [0.232]
 [0.23 ]] [[-0.006]
 [-0.006]
 [-0.006]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.007]] [[0.237]
 [0.242]
 [0.234]
 [0.232]
 [0.229]
 [0.232]
 [0.23 ]]
siam score:  -0.9043612
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.04775868772482307, 0.591185725288659, 0.3132968992616949, 0.04775868772482307]
Printing some Q and Qe and total Qs values:  [[0.662]
 [0.595]
 [0.658]
 [0.659]
 [0.66 ]
 [0.661]
 [0.659]] [[-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]] [[0.733]
 [0.598]
 [0.724]
 [0.727]
 [0.728]
 [0.729]
 [0.726]]
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
probs:  [0.04775864662542708, 0.5911857946242791, 0.3132969121248667, 0.04775864662542708]
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
probs:  [0.04775864662542708, 0.5911857946242791, 0.3132969121248667, 0.04775864662542708]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9892617021276596 -1.0 -0.9892617021276596
probs:  [0.06585402215799453, 0.4341459778420055, 0.4341459778420055, 0.06585402215799453]
maxi score, test score, baseline:  -0.9892617021276596 -1.0 -0.9892617021276596
probs:  [0.06585402215799453, 0.4341459778420055, 0.4341459778420055, 0.06585402215799453]
siam score:  -0.90229994
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.06585392382001916, 0.43414607617998086, 0.43414607617998086, 0.06585392382001916]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.06585392382001916, 0.43414607617998086, 0.43414607617998086, 0.06585392382001916]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.10390674116566659, 0.6882797765030001, 0.10390674116566659, 0.10390674116566659]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.10390674116566659, 0.6882797765030001, 0.10390674116566659, 0.10390674116566659]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.9113003
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.32410199882974877, 0.32410199882974877, 0.027694003510753552, 0.32410199882974877]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.32410199882974877, 0.32410199882974877, 0.027694003510753552, 0.32410199882974877]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.20345656094754097, 0.3820313883324867, 0.0324806623874857, 0.3820313883324867]
siam score:  -0.9162971
Printing some Q and Qe and total Qs values:  [[0.694]
 [0.667]
 [0.697]
 [0.698]
 [0.698]
 [0.698]
 [0.697]] [[0.809]
 [0.899]
 [0.559]
 [0.604]
 [0.573]
 [0.585]
 [0.496]] [[1.321]
 [1.297]
 [1.243]
 [1.26 ]
 [1.25 ]
 [1.253]
 [1.223]]
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.625]
 [0.625]
 [0.676]
 [0.625]
 [0.68 ]
 [0.625]] [[0.988]
 [1.077]
 [1.077]
 [0.767]
 [1.077]
 [0.645]
 [1.077]] [[1.459]
 [1.295]
 [1.295]
 [1.294]
 [1.295]
 [1.26 ]
 [1.295]]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.032604030421779534, 0.37586082449265423, 0.032604030421779534, 0.5589311146637868]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.039721958184199255, 0.46027804181580073, 0.039721958184199255, 0.46027804181580073]
siam score:  -0.9029519
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.0690821925902151, 0.4309178074097849, 0.0690821925902151, 0.4309178074097849]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.31607039832640826, 0.31607039832640826, 0.31607039832640826, 0.05178880502077504]
Printing some Q and Qe and total Qs values:  [[0.822]
 [0.822]
 [0.822]
 [0.822]
 [0.822]
 [0.822]
 [0.822]] [[4.46]
 [4.46]
 [4.46]
 [4.46]
 [4.46]
 [4.46]
 [4.46]] [[2.18]
 [2.18]
 [2.18]
 [2.18]
 [2.18]
 [2.18]
 [2.18]]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.31607039832640826, 0.31607039832640826, 0.31607039832640826, 0.05178880502077504]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.32357354280904105, 0.32357354280904105, 0.32357354280904105, 0.029279371572876765]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.32357354280904105, 0.32357354280904105, 0.32357354280904105, 0.029279371572876765]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.32357354280904105, 0.32357354280904105, 0.32357354280904105, 0.029279371572876765]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.24785038821718966, 0.24785038821718966, 0.4628115664983311, 0.041487657067289505]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.24785038821718966, 0.24785038821718966, 0.4628115664983311, 0.041487657067289505]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.24785038821718966, 0.24785038821718966, 0.4628115664983311, 0.041487657067289505]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.312361672577023, 0.052069473994670795, 0.5834993794336355, 0.052069473994670795]
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.429]
 [0.428]
 [0.428]
 [0.428]
 [0.422]
 [0.428]] [[0.726]
 [0.74 ]
 [0.717]
 [0.717]
 [0.717]
 [0.701]
 [0.717]] [[-0.132]
 [-0.125]
 [-0.134]
 [-0.134]
 [-0.134]
 [-0.15 ]
 [-0.134]]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.827]
 [0.817]] [[5.342]
 [5.342]
 [5.342]
 [5.342]
 [5.342]
 [5.177]
 [5.342]] [[1.936]
 [1.936]
 [1.936]
 [1.936]
 [1.936]
 [1.839]
 [1.936]]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 1.7110925287235321
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.31551077216124024, 0.31551077216124024, 0.053467683516279285, 0.31551077216124024]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.4277988743900606, 0.07220112560993944, 0.07220112560993944, 0.4277988743900606]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.4277988743900606, 0.07220112560993944, 0.07220112560993944, 0.4277988743900606]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.07321741770984558, 0.4267825822901544, 0.07321741770984558, 0.4267825822901544]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.07321741770984558, 0.4267825822901544, 0.07321741770984558, 0.4267825822901544]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.07321741770984558, 0.4267825822901544, 0.07321741770984558, 0.4267825822901544]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.20457513396771237, 0.37966734485580317, 0.036090176320681316, 0.37966734485580317]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.20457513396771237, 0.37966734485580317, 0.036090176320681316, 0.37966734485580317]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.24799587628932776, 0.24799587628932776, 0.04357525780071694, 0.46043298962062756]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
siam score:  -0.8774525
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.24799587628932776, 0.24799587628932776, 0.04357525780071694, 0.46043298962062756]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.031183299485029792, 0.3210088741472695, 0.17336188328159952, 0.4744459430861013]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.031183299485029792, 0.3210088741472695, 0.17336188328159952, 0.4744459430861013]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.024479219652889784, 0.24566306191640183, 0.24566306191640183, 0.48419465651430643]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.024479219652889784, 0.24566306191640183, 0.24566306191640183, 0.48419465651430643]
Printing some Q and Qe and total Qs values:  [[0.459]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]] [[8.227]
 [6.982]
 [6.982]
 [6.982]
 [6.982]
 [6.982]
 [6.982]] [[1.597]
 [1.127]
 [1.127]
 [1.127]
 [1.127]
 [1.127]
 [1.127]]
Printing some Q and Qe and total Qs values:  [[0.068]
 [0.028]
 [0.028]
 [0.028]
 [0.028]
 [0.028]
 [0.028]] [[8.228]
 [6.697]
 [6.697]
 [6.697]
 [6.697]
 [6.697]
 [6.697]] [[1.233]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.024479219652889784, 0.24566306191640183, 0.24566306191640183, 0.48419465651430643]
Printing some Q and Qe and total Qs values:  [[0.183]
 [0.185]
 [0.185]
 [0.185]
 [0.185]
 [0.185]
 [0.179]] [[8.332]
 [9.036]
 [9.036]
 [9.036]
 [9.036]
 [9.036]
 [8.786]] [[1.507]
 [1.752]
 [1.752]
 [1.752]
 [1.752]
 [1.752]
 [1.662]]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.024479219652889784, 0.24566306191640183, 0.24566306191640183, 0.48419465651430643]
Printing some Q and Qe and total Qs values:  [[-0.054]
 [-0.059]
 [-0.059]
 [-0.059]
 [-0.059]
 [-0.059]
 [-0.059]] [[6.257]
 [5.613]
 [5.613]
 [5.613]
 [5.613]
 [5.613]
 [5.613]] [[0.823]
 [0.509]
 [0.509]
 [0.509]
 [0.509]
 [0.509]
 [0.509]]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.024479219652889784, 0.24566306191640183, 0.24566306191640183, 0.48419465651430643]
from probs:  [0.027473580073149394, 0.14985801734102266, 0.27686073526051225, 0.5458076673253158]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.90205705
siam score:  -0.9024355
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.04494457825782088, 0.24808359418932574, 0.24808359418932574, 0.4588882333635277]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.04494457825782088, 0.24808359418932574, 0.24808359418932574, 0.4588882333635277]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.04494457825782088, 0.24808359418932574, 0.24808359418932574, 0.4588882333635277]
Printing some Q and Qe and total Qs values:  [[0.884]
 [0.885]
 [0.885]
 [0.885]
 [0.885]
 [0.885]
 [0.885]] [[2.147]
 [2.128]
 [2.128]
 [2.128]
 [2.128]
 [2.128]
 [2.128]] [[1.558]
 [1.553]
 [1.553]
 [1.553]
 [1.553]
 [1.553]
 [1.553]]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.056204418811592036, 0.056204418811592036, 0.31138866236402996, 0.576202500012786]
Printing some Q and Qe and total Qs values:  [[0.643]
 [0.648]
 [0.648]
 [0.648]
 [0.648]
 [0.648]
 [0.648]] [[1.044]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]] [[0.698]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]]
siam score:  -0.9028737
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.056204418811592036, 0.056204418811592036, 0.31138866236402996, 0.576202500012786]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.056204418811592036, 0.056204418811592036, 0.31138866236402996, 0.576202500012786]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.03761129328130899, 0.20376039226419632, 0.20376039226419632, 0.5548679221902983]
line 256 mcts: sample exp_bonus 7.957803390795873
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.03761129328130899, 0.20376039226419632, 0.20376039226419632, 0.5548679221902983]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
209 65
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.04562266916001869, 0.2481249786161463, 0.2481249786161463, 0.45812737360768874]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.616828580957465
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.05754575135321243, 0.31415141621559584, 0.31415141621559584, 0.31415141621559584]
210 66
Printing some Q and Qe and total Qs values:  [[0.973]
 [0.949]
 [0.919]
 [0.919]
 [0.919]
 [0.976]
 [0.981]] [[6.393]
 [6.968]
 [6.926]
 [6.926]
 [6.926]
 [6.563]
 [6.335]] [[2.104]
 [2.322]
 [2.264]
 [2.264]
 [2.264]
 [2.181]
 [2.089]]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.07717082692476247, 0.07717082692476247, 0.42282917307523754, 0.42282917307523754]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.07717082692476247, 0.07717082692476247, 0.42282917307523754, 0.42282917307523754]
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.6468959300855928
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.052]
 [0.09 ]
 [0.066]
 [0.073]
 [0.078]
 [0.088]
 [0.077]] [[7.607]
 [7.851]
 [7.108]
 [7.104]
 [7.206]
 [7.68 ]
 [8.059]] [[1.018]
 [1.17 ]
 [0.826]
 [0.834]
 [0.882]
 [1.095]
 [1.24 ]]
start point for exploration sampling:  10624
siam score:  -0.9043996
siam score:  -0.90597993
main train batch thing paused
add a thread
Adding thread: now have 4 threads
start point for exploration sampling:  10624
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.432755720418749
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.45662768684862615, 0.248203237505664, 0.248203237505664, 0.046965838140045825]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.45662768684862615, 0.248203237505664, 0.248203237505664, 0.046965838140045825]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.45662768684862615, 0.248203237505664, 0.248203237505664, 0.046965838140045825]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
Printing some Q and Qe and total Qs values:  [[0.33 ]
 [0.347]
 [0.338]
 [0.337]
 [0.339]
 [0.337]
 [0.338]] [[5.966]
 [5.71 ]
 [5.872]
 [5.904]
 [5.912]
 [5.941]
 [5.938]] [[1.359]
 [1.224]
 [1.313]
 [1.331]
 [1.34 ]
 [1.356]
 [1.356]]
siam score:  -0.9008806
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.5719933242774848, 0.0586053666882088, 0.31079594234609764, 0.0586053666882088]
from probs:  [0.5719933242774848, 0.0586053666882088, 0.31079594234609764, 0.0586053666882088]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.5519813809853508, 0.039349573263877696, 0.20433452287538573, 0.20433452287538573]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.5519813809853508, 0.039349573263877696, 0.20433452287538573, 0.20433452287538573]
from probs:  [0.5519813809853508, 0.039349573263877696, 0.20433452287538573, 0.20433452287538573]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.76 ]
 [0.76 ]
 [0.76 ]
 [0.76 ]
 [0.76 ]
 [0.763]
 [0.76 ]] [[4.228]
 [4.228]
 [4.228]
 [4.228]
 [4.228]
 [4.302]
 [4.228]] [[2.667]
 [2.667]
 [2.667]
 [2.667]
 [2.667]
 [2.746]
 [2.667]]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9900960784313726 -1.0 -0.9900960784313726
probs:  [0.41089214993099604, 0.030004611318842665, 0.27955161937508066, 0.27955161937508066]
maxi score, test score, baseline:  -0.9900960784313726 -1.0 -0.9900960784313726
first move QE:  0.27134369230396427
siam score:  -0.89927214
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
probs:  [0.3252273860121414, 0.024317841963575754, 0.3252273860121414, 0.3252273860121414]
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
probs:  [0.3252273860121414, 0.024317841963575754, 0.3252273860121414, 0.3252273860121414]
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
probs:  [0.3629090883243591, 0.02702827095609786, 0.24715355239518402, 0.3629090883243591]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
probs:  [0.40871400524868606, 0.030322999357779132, 0.15224899014484877, 0.40871400524868606]
Printing some Q and Qe and total Qs values:  [[-0.05 ]
 [-0.04 ]
 [-0.043]
 [-0.051]
 [-0.044]
 [-0.045]
 [-0.048]] [[2.772]
 [2.724]
 [2.582]
 [2.723]
 [2.587]
 [2.655]
 [2.688]] [[0.563]
 [0.517]
 [0.323]
 [0.496]
 [0.327]
 [0.417]
 [0.454]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
probs:  [0.40871400524868606, 0.030322999357779132, 0.15224899014484877, 0.40871400524868606]
from probs:  [0.32008570032610445, 0.034741170188819115, 0.17503556417298402, 0.47013756531209244]
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
probs:  [0.3766838513192836, 0.04072667654991257, 0.20590562081152022, 0.3766838513192836]
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
probs:  [0.3766838513192836, 0.04072667654991257, 0.20590562081152022, 0.3766838513192836]
maxi score, test score, baseline:  -0.9902846153846154 -1.0 -0.9902846153846154
probs:  [0.3766838748815926, 0.04072663762654053, 0.2059056126102742, 0.3766838748815926]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.3766838979886308, 0.040726599455246044, 0.20590560456749243, 0.3766838979886308]
siam score:  -0.89864594
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.45443039430160154, 0.0489486204802436, 0.24831049260907745, 0.24831049260907745]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.5679018879261865, 0.060948711166819804, 0.31020068974017384, 0.060948711166819804]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]] [[3.766]
 [3.288]
 [3.288]
 [3.288]
 [3.288]
 [3.288]
 [3.288]] [[2.205]
 [1.839]
 [1.839]
 [1.839]
 [1.839]
 [1.839]
 [1.839]]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.5679018879261865, 0.060948711166819804, 0.31020068974017384, 0.060948711166819804]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.5679018879261865, 0.060948711166819804, 0.31020068974017384, 0.060948711166819804]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.5679018879261865, 0.060948711166819804, 0.31020068974017384, 0.060948711166819804]
using explorer policy with actor:  1
from probs:  [0.5679018879261865, 0.060948711166819804, 0.31020068974017384, 0.060948711166819804]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.418125475774278, 0.081874524225722, 0.418125475774278, 0.081874524225722]
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.3763229253109423, 0.2060615911961948, 0.3763229253109423, 0.04129255818192055]
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.3763229253109423, 0.2060615911961948, 0.3763229253109423, 0.04129255818192055]
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
probs:  [0.376322948164981, 0.2060615832469636, 0.376322948164981, 0.0412925204230744]
Printing some Q and Qe and total Qs values:  [[0.085]
 [0.08 ]
 [0.08 ]
 [0.083]
 [0.08 ]
 [0.082]
 [0.08 ]] [[2.651]
 [2.399]
 [2.399]
 [2.379]
 [2.399]
 [2.441]
 [2.399]] [[0.085]
 [0.08 ]
 [0.08 ]
 [0.083]
 [0.08 ]
 [0.082]
 [0.08 ]]
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
probs:  [0.32136468344540625, 0.32136468344540625, 0.32136468344540625, 0.03590594966378114]
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
probs:  [0.32136468344540625, 0.32136468344540625, 0.32136468344540625, 0.03590594966378114]
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.458]
 [0.431]
 [0.429]
 [0.439]
 [0.436]
 [0.438]] [[5.409]
 [5.271]
 [5.842]
 [5.94 ]
 [5.781]
 [5.683]
 [5.518]] [[0.21 ]
 [0.214]
 [0.349]
 [0.379]
 [0.345]
 [0.307]
 [0.256]]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.3759644488148805, 0.20621556591996082, 0.3759644488148805, 0.04185553645027812]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.3759644488148805, 0.20621556591996082, 0.3759644488148805, 0.04185553645027812]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.3759644488148805, 0.20621556591996082, 0.3759644488148805, 0.04185553645027812]
siam score:  -0.9043548
Printing some Q and Qe and total Qs values:  [[0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]] [[1.427]
 [1.427]
 [1.427]
 [1.427]
 [1.427]
 [1.427]
 [1.427]] [[0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.3759644488148805, 0.20621556591996082, 0.3759644488148805, 0.04185553645027812]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.3759644488148805, 0.20621556591996082, 0.3759644488148805, 0.04185553645027812]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.3759644714233845, 0.2062155580613901, 0.3759644714233845, 0.04185549909184074]
Printing some Q and Qe and total Qs values:  [[0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.56 ]
 [0.561]] [[1.811]
 [1.811]
 [1.811]
 [1.811]
 [1.811]
 [1.864]
 [1.811]] [[0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.56 ]
 [0.561]]
Printing some Q and Qe and total Qs values:  [[0.13 ]
 [0.073]
 [0.132]
 [0.134]
 [0.135]
 [0.131]
 [0.131]] [[1.651]
 [2.697]
 [1.472]
 [1.449]
 [1.468]
 [1.213]
 [1.143]] [[0.13 ]
 [0.073]
 [0.132]
 [0.134]
 [0.135]
 [0.131]
 [0.131]]
Printing some Q and Qe and total Qs values:  [[0.131]
 [0.069]
 [0.133]
 [0.131]
 [0.135]
 [0.134]
 [0.133]] [[1.459]
 [2.617]
 [1.374]
 [1.531]
 [1.453]
 [1.394]
 [1.333]] [[0.131]
 [0.069]
 [0.133]
 [0.131]
 [0.135]
 [0.134]
 [0.133]]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.2484071527547063, 0.4522916001523429, 0.05089409433824451, 0.2484071527547063]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.31208759422158444, 0.31208759422158444, 0.06373721733524672, 0.31208759422158444]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.31208759422158444, 0.31208759422158444, 0.06373721733524672, 0.31208759422158444]
first move QE:  0.43389317522322834
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.782]
 [0.771]
 [0.756]
 [0.64 ]
 [0.725]
 [0.709]] [[2.749]
 [2.88 ]
 [2.625]
 [2.453]
 [2.931]
 [2.436]
 [2.634]] [[2.024]
 [2.214]
 [1.988]
 [1.827]
 [2.08 ]
 [1.774]
 [1.919]]
Printing some Q and Qe and total Qs values:  [[0.15]
 [0.15]
 [0.15]
 [0.15]
 [0.15]
 [0.15]
 [0.15]] [[1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]] [[-1.067]
 [-1.067]
 [-1.067]
 [-1.067]
 [-1.067]
 [-1.067]
 [-1.067]]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.32103612795402964, 0.32103612795402964, 0.03689161613791111, 0.32103612795402964]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.32103612795402964, 0.32103612795402964, 0.03689161613791111, 0.32103612795402964]
Printing some Q and Qe and total Qs values:  [[0.078]
 [0.026]
 [0.024]
 [0.025]
 [0.027]
 [0.026]
 [0.026]] [[4.896]
 [4.853]
 [3.926]
 [3.866]
 [3.967]
 [3.771]
 [3.69 ]] [[-0.2  ]
 [-0.319]
 [-0.633]
 [-0.65 ]
 [-0.613]
 [-0.68 ]
 [-0.708]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[ 0.138]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]] [[4.618]
 [3.112]
 [3.112]
 [3.112]
 [3.112]
 [3.112]
 [3.112]] [[-0.244]
 [-1.026]
 [-1.026]
 [-1.026]
 [-1.026]
 [-1.026]
 [-1.026]]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.32103612795402964, 0.32103612795402964, 0.03689161613791111, 0.32103612795402964]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.32103612795402964, 0.32103612795402964, 0.03689161613791111, 0.32103612795402964]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.051219397034139594, 0.4487806029658604, 0.051219397034139594, 0.4487806029658604]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.06398737327022633, 0.5626180794777863, 0.06398737327022633, 0.309407173981761]
in main func line 156:  247
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.08546016622191384, 0.4145398337780862, 0.08546016622191384, 0.4145398337780862]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.08546016622191384, 0.4145398337780862, 0.08546016622191384, 0.4145398337780862]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.08546016622191384, 0.4145398337780862, 0.08546016622191384, 0.4145398337780862]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.08546016622191384, 0.4145398337780862, 0.08546016622191384, 0.4145398337780862]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.0435271196389383, 0.37490334737891323, 0.20666618560323508, 0.37490334737891323]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.17635698035217032, 0.037703456145350124, 0.3192767668422783, 0.4666627966602013]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.17635696862213182, 0.03770342233023896, 0.3192767778768498, 0.46666283117077945]
Printing some Q and Qe and total Qs values:  [[0.923]
 [0.829]
 [0.829]
 [0.81 ]
 [0.829]
 [0.829]
 [0.82 ]] [[2.376]
 [2.118]
 [2.118]
 [2.348]
 [2.118]
 [2.118]
 [2.325]] [[1.837]
 [1.389]
 [1.389]
 [1.582]
 [1.389]
 [1.389]
 [1.58 ]]
siam score:  -0.8899794
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.17635696862213182, 0.03770342233023896, 0.3192767778768498, 0.46666283117077945]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.17635696862213182, 0.03770342233023896, 0.3192767778768498, 0.46666283117077945]
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.667]
 [0.601]
 [0.611]
 [0.667]
 [0.602]
 [0.583]] [[3.546]
 [3.935]
 [3.82 ]
 [4.039]
 [3.935]
 [4.094]
 [3.848]] [[1.317]
 [1.798]
 [1.578]
 [1.792]
 [1.798]
 [1.825]
 [1.572]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.2057353073787004, 0.04385300293508662, 0.2057353073787004, 0.5446763823075126]
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.815]
 [0.799]
 [0.798]
 [0.792]
 [0.788]
 [0.794]] [[2.23 ]
 [1.907]
 [1.844]
 [1.827]
 [1.807]
 [1.81 ]
 [1.833]] [[0.756]
 [0.525]
 [0.473]
 [0.465]
 [0.447]
 [0.439]
 [0.459]]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.2057353073787004, 0.04385300293508662, 0.2057353073787004, 0.5446763823075126]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.2057353073787004, 0.04385300293508662, 0.2057353073787004, 0.5446763823075126]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.24546955024441686, 0.052170360672857116, 0.052170360672857116, 0.650189728409869]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.309011714942553, 0.0654713040685277, 0.0654713040685277, 0.5600456769203916]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
Printing some Q and Qe and total Qs values:  [[0.344]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.333]] [[5.255]
 [5.558]
 [5.558]
 [5.558]
 [5.558]
 [5.558]
 [5.777]] [[0.294]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.448]]
Printing some Q and Qe and total Qs values:  [[0.295]
 [0.28 ]
 [0.279]
 [0.279]
 [0.279]
 [0.279]
 [0.28 ]] [[5.274]
 [4.087]
 [4.544]
 [4.438]
 [4.391]
 [4.468]
 [4.492]] [[ 0.279]
 [-0.147]
 [ 0.003]
 [-0.032]
 [-0.047]
 [-0.021]
 [-0.012]]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.309011714942553, 0.0654713040685277, 0.0654713040685277, 0.5600456769203916]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.31914119403645874, 0.1765687295432708, 0.038189572829296116, 0.46610050359097427]
Printing some Q and Qe and total Qs values:  [[0.258]
 [0.263]
 [0.263]
 [0.262]
 [0.263]
 [0.263]
 [0.244]] [[4.867]
 [4.328]
 [4.323]
 [4.202]
 [4.328]
 [4.266]
 [4.198]] [[1.552]
 [1.253]
 [1.251]
 [1.182]
 [1.253]
 [1.219]
 [1.164]]
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.2058991249413815, 0.2058991249413815, 0.044402962754889766, 0.5437987873623471]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.2058991249413815, 0.2058991249413815, 0.044402962754889766, 0.5437987873623471]
first move QE:  0.5241192437292925
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03371218389500356, 0.2771297712616504, 0.15363114237710104, 0.535526902466245]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03371218389500356, 0.2771297712616504, 0.15363114237710104, 0.535526902466245]
siam score:  -0.90560895
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03371218389500356, 0.2771297712616504, 0.15363114237710104, 0.535526902466245]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03371218389500356, 0.2771297712616504, 0.15363114237710104, 0.535526902466245]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03371218389500356, 0.2771297712616504, 0.15363114237710104, 0.535526902466245]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03371218389500356, 0.2771297712616504, 0.15363114237710104, 0.535526902466245]
in main func line 156:  259
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03867359562441947, 0.3190054962636294, 0.17677828196873596, 0.46554262614321507]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.04517306841511937, 0.37386289373126985, 0.2071011441223409, 0.37386289373126985]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.04517306841511937, 0.37386289373126985, 0.2071011441223409, 0.37386289373126985]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.0451730300865518, 0.3738629169093122, 0.2071011360948238, 0.3738629169093122]
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.0451730300865518, 0.3738629169093122, 0.2071011360948238, 0.3738629169093122]
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.0451730300865518, 0.3738629169093122, 0.2071011360948238, 0.3738629169093122]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.0451730300865518, 0.3738629169093122, 0.2071011360948238, 0.3738629169093122]
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.0451730300865518, 0.3738629169093122, 0.2071011360948238, 0.3738629169093122]
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.275621321041146
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.25 ]
 [0.25 ]
 [0.25 ]
 [0.25 ]
 [0.23 ]
 [0.25 ]
 [0.252]] [[3.587]
 [3.587]
 [3.587]
 [3.587]
 [3.79 ]
 [3.587]
 [3.823]] [[0.937]
 [0.937]
 [0.937]
 [0.937]
 [1.118]
 [0.937]
 [1.187]]
Printing some Q and Qe and total Qs values:  [[1.06]
 [1.06]
 [1.06]
 [1.06]
 [1.06]
 [1.06]
 [1.06]] [[2.731]
 [2.731]
 [2.731]
 [2.731]
 [2.731]
 [2.731]
 [2.731]] [[1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]]
UNIT TEST: sample policy line 217 mcts : [0.224 0.449 0.245 0.    0.    0.082 0.   ]
Printing some Q and Qe and total Qs values:  [[0.668]
 [0.712]
 [0.698]
 [0.707]
 [0.702]
 [0.706]
 [0.69 ]] [[3.721]
 [3.561]
 [3.772]
 [3.786]
 [3.768]
 [3.776]
 [3.741]] [[1.651]
 [1.556]
 [1.745]
 [1.773]
 [1.748]
 [1.762]
 [1.703]]
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.20724289973024587, 0.3735205118903977, 0.3735205118903977, 0.04571607648895876]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.24761075865841856, 0.3607015154932957, 0.3607015154932957, 0.030986210354989992]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.1  ]
 [0.108]
 [0.108]
 [0.108]
 [0.108]
 [0.108]
 [0.108]] [[7.512]
 [6.426]
 [6.426]
 [6.426]
 [6.426]
 [6.426]
 [6.426]] [[1.388]
 [1.078]
 [1.078]
 [1.078]
 [1.078]
 [1.078]
 [1.078]]
siam score:  -0.89443475
line 256 mcts: sample exp_bonus 2.4028738777883407
line 256 mcts: sample exp_bonus 6.668555901188414
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.27919876696440565, 0.27919876696440565, 0.4067749180088888, 0.0348275480622999]
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.3200675028175832, 0.3200675028175832, 0.3200675028175832, 0.039797491547250305]
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.3200675028175832, 0.3200675028175832, 0.3200675028175832, 0.039797491547250305]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.8188235970872848
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.3731802305684921, 0.3731802305684921, 0.20738314297867322, 0.0462563958843426]
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
probs:  [0.37318025403317484, 0.37318025403317484, 0.20738313486055898, 0.04625635707309132]
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
Printing some Q and Qe and total Qs values:  [[0.144]
 [0.126]
 [0.125]
 [0.136]
 [0.136]
 [0.145]
 [0.128]] [[3.773]
 [3.764]
 [3.878]
 [3.885]
 [3.962]
 [3.94 ]
 [3.712]] [[1.051]
 [1.008]
 [1.113]
 [1.142]
 [1.215]
 [1.21 ]
 [0.963]]
Printing some Q and Qe and total Qs values:  [[1.284]
 [1.15 ]
 [1.15 ]
 [1.15 ]
 [1.15 ]
 [1.15 ]
 [1.15 ]] [[1.126]
 [1.088]
 [1.088]
 [1.088]
 [1.088]
 [1.088]
 [1.088]] [[2.711]
 [2.419]
 [2.419]
 [2.419]
 [2.419]
 [2.419]
 [2.419]]
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
using explorer policy with actor:  1
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 0.6158877272656424
Printing some Q and Qe and total Qs values:  [[0.277]
 [0.08 ]
 [0.273]
 [0.299]
 [0.284]
 [0.283]
 [0.276]] [[1.635]
 [1.109]
 [1.678]
 [1.531]
 [1.674]
 [1.688]
 [1.736]] [[0.892]
 [0.148]
 [0.914]
 [0.867]
 [0.933]
 [0.939]
 [0.959]]
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
probs:  [0.09138672622539276, 0.09138672622539276, 0.40861327377460727, 0.40861327377460727]
from probs:  [0.09138672622539276, 0.09138672622539276, 0.40861327377460727, 0.40861327377460727]
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
probs:  [0.20765921671476503, 0.047328784008010785, 0.3725059996386121, 0.3725059996386121]
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
probs:  [0.20765921671476503, 0.047328784008010785, 0.3725059996386121, 0.3725059996386121]
Printing some Q and Qe and total Qs values:  [[0.79 ]
 [0.846]
 [0.797]
 [0.802]
 [0.812]
 [0.811]
 [0.802]] [[0.757]
 [1.087]
 [0.741]
 [0.711]
 [0.901]
 [0.796]
 [0.772]] [[0.625]
 [0.848]
 [0.634]
 [0.633]
 [0.717]
 [0.68 ]
 [0.655]]
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.04743780328517187, 0.04743780328517187, 0.3688214003075813, 0.536302993122075]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.04743780328517187, 0.04743780328517187, 0.3688214003075813, 0.536302993122075]
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.665]
 [0.7  ]
 [0.745]
 [0.787]
 [0.789]
 [0.748]] [[3.488]
 [3.434]
 [3.064]
 [3.034]
 [3.235]
 [2.625]
 [2.61 ]] [[1.43 ]
 [1.375]
 [1.25 ]
 [1.275]
 [1.394]
 [1.141]
 [1.101]]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.05651815007200253, 0.05651815007200253, 0.2459969272428682, 0.6409667726131267]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.05651815007200253, 0.05651815007200253, 0.2459969272428682, 0.6409667726131267]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.0704880399170588, 0.0704880399170588, 0.307641455072503, 0.5513824650933793]
279 90
Printing some Q and Qe and total Qs values:  [[0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]] [[3.72 ]
 [3.178]
 [3.178]
 [3.178]
 [3.178]
 [3.178]
 [3.178]] [[2.629]
 [2.141]
 [2.141]
 [2.141]
 [2.141]
 [2.141]
 [2.141]]
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.07048798793543527, 0.07048798793543527, 0.30764147176385126, 0.5513825523652781]
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
siam score:  -0.8809327
siam score:  -0.8783841
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.07048798793543527, 0.07048798793543527, 0.30764147176385126, 0.5513825523652781]
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
Printing some Q and Qe and total Qs values:  [[0.19]
 [0.19]
 [0.19]
 [0.19]
 [0.19]
 [0.19]
 [0.19]] [[7.108]
 [7.108]
 [7.108]
 [7.108]
 [7.108]
 [7.108]
 [7.108]] [[1.51]
 [1.51]
 [1.51]
 [1.51]
 [1.51]
 [1.51]
 [1.51]]
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.13536262415468459, 0.13536262415468459, 0.5939121275359464, 0.13536262415468459]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.24869201445667907, 0.24869201445667907, 0.4448898459547984, 0.057726125131843484]
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.24869201445667907, 0.24869201445667907, 0.4448898459547984, 0.057726125131843484]
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.24869201445667907, 0.24869201445667907, 0.4448898459547984, 0.057726125131843484]
Printing some Q and Qe and total Qs values:  [[0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.518]
 [0.519]] [[2.562]
 [2.562]
 [2.562]
 [2.562]
 [2.562]
 [2.416]
 [2.562]] [[0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.518]
 [0.519]]
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.24869201445667907, 0.24869201445667907, 0.4448898459547984, 0.057726125131843484]
siam score:  -0.8801627
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.27901405219220793, 0.27901405219220793, 0.4050179359983689, 0.036953959617215267]
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
probs:  [0.27901405219220793, 0.27901405219220793, 0.4050179359983689, 0.036953959617215267]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
Printing some Q and Qe and total Qs values:  [[0.504]
 [0.361]
 [0.388]
 [0.398]
 [0.395]
 [0.408]
 [0.4  ]] [[4.953]
 [4.663]
 [5.238]
 [5.258]
 [5.128]
 [5.288]
 [5.188]] [[1.013]
 [0.74 ]
 [1.074]
 [1.093]
 [1.019]
 [1.117]
 [1.057]]
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]] [[3.683]
 [3.718]
 [3.718]
 [3.718]
 [3.718]
 [3.718]
 [3.718]] [[2.82 ]
 [2.802]
 [2.802]
 [2.802]
 [2.802]
 [2.802]
 [2.802]]
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
probs:  [0.13832388012509245, 0.35729360884816047, 0.4712778511971549, 0.0331046598295922]
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
probs:  [0.13832388012509245, 0.35729360884816047, 0.4712778511971549, 0.0331046598295922]
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
probs:  [0.13832388012509245, 0.35729360884816047, 0.4712778511971549, 0.0331046598295922]
286 92
from probs:  [0.13832388012509245, 0.35729360884816047, 0.4712778511971549, 0.0331046598295922]
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
probs:  [0.15607064893297068, 0.40333765857951004, 0.40333765857951004, 0.03725403390800917]
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
probs:  [0.17838291995919475, 0.31791929269727315, 0.46122691875259564, 0.04247086859093644]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.17838290750616542, 0.31791930450731687, 0.4612269554814732, 0.04247083250504449]
Starting evaluation
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.17838290750616542, 0.31791930450731687, 0.4612269554814732, 0.04247083250504449]
Printing some Q and Qe and total Qs values:  [[0.125]
 [0.068]
 [0.123]
 [0.123]
 [0.122]
 [0.121]
 [0.122]] [[3.878]
 [3.244]
 [3.577]
 [3.339]
 [3.579]
 [3.617]
 [3.296]] [[0.125]
 [0.068]
 [0.123]
 [0.123]
 [0.122]
 [0.121]
 [0.122]]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.20728252108766876, 0.20728252108766876, 0.5362071087126196, 0.04922784911204287]
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.24873456787575537, 0.24873456787575537, 0.4436111150094338, 0.05891974923905559]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.24873456787575537, 0.24873456787575537, 0.4436111150094338, 0.05891974923905559]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.24873456787575537, 0.24873456787575537, 0.4436111150094338, 0.05891974923905559]
Printing some Q and Qe and total Qs values:  [[0.382]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]] [[7.253]
 [7.648]
 [7.648]
 [7.648]
 [7.648]
 [7.648]
 [7.648]] [[0.382]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.31896891460200916, 0.31896891460200916, 0.31896891460200916, 0.043093256193972446]
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.1717341122365736
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.3189689267300981, 0.3189689267300981, 0.3189689267300981, 0.04309321980970567]
maxi score, test score, baseline:  -0.9921480620155039 -1.0 -0.9921480620155039
probs:  [0.20832551373368355, 0.3708560101723187, 0.3708560101723187, 0.04996246592167905]
maxi score, test score, baseline:  -0.9922076923076923 -1.0 -0.9922076923076923
probs:  [0.2083255059898163, 0.37085603262952993, 0.37085603262952993, 0.04996242875112366]
maxi score, test score, baseline:  -0.9922076923076923 -1.0 -0.9922076923076923
probs:  [0.2083255059898163, 0.37085603262952993, 0.37085603262952993, 0.04996242875112366]
Printing some Q and Qe and total Qs values:  [[0.764]
 [0.772]
 [0.775]
 [0.766]
 [0.764]
 [0.761]
 [0.763]] [[5.022]
 [5.322]
 [4.607]
 [4.591]
 [4.615]
 [4.925]
 [5.624]] [[1.011]
 [1.128]
 [0.895]
 [0.872]
 [0.875]
 [0.972]
 [1.211]]
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.605]
 [0.605]
 [0.601]
 [0.6  ]
 [0.6  ]
 [0.601]] [[4.706]
 [4.708]
 [4.527]
 [4.546]
 [4.59 ]
 [4.407]
 [4.524]] [[0.612]
 [0.605]
 [0.605]
 [0.601]
 [0.6  ]
 [0.6  ]
 [0.601]]
using explorer policy with actor:  0
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]] [[3.513]
 [3.513]
 [3.513]
 [3.513]
 [3.513]
 [3.513]
 [3.513]] [[0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]]
maxi score, test score, baseline:  -0.9924925925925926 -1.0 -0.9924925925925926
probs:  [0.05921960864333673, 0.44078039135666325, 0.44078039135666325, 0.05921960864333673]
Printing some Q and Qe and total Qs values:  [[0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]] [[2.438]
 [2.438]
 [2.438]
 [2.438]
 [2.438]
 [2.438]
 [2.438]] [[0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]]
maxi score, test score, baseline:  -0.9925470588235294 -1.0 -0.9925470588235294
probs:  [0.05921957018101586, 0.44078042981898413, 0.44078042981898413, 0.05921957018101586]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9928078014184397 -1.0 -0.9928078014184397
line 256 mcts: sample exp_bonus 3.352216530481646
maxi score, test score, baseline:  -0.9929555555555556 -1.0 -0.9929555555555556
probs:  [0.07323613504551438, 0.3068718522027485, 0.5466558777062228, 0.07323613504551438]
maxi score, test score, baseline:  -0.9929555555555556 -1.0 -0.9929555555555556
using explorer policy with actor:  1
rdn probs:  [0.09614184203380483, 0.4038581579661952, 0.4038581579661952, 0.09614184203380483]
first move QE:  0.7715655729811872
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.13867839173196841, 0.13867839173196841, 0.5839648248040948, 0.13867839173196841]
Printing some Q and Qe and total Qs values:  [[-0.055]
 [-0.036]
 [-0.054]
 [-0.05 ]
 [-0.05 ]
 [-0.049]
 [-0.051]] [[7.755]
 [4.878]
 [7.38 ]
 [7.536]
 [7.633]
 [7.662]
 [7.763]] [[-0.11 ]
 [-1.033]
 [-0.234]
 [-0.172]
 [-0.139]
 [-0.129]
 [-0.098]]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.13867839173196841, 0.13867839173196841, 0.5839648248040948, 0.13867839173196841]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.127]
 [-0.121]
 [-0.121]
 [-0.121]
 [-0.121]
 [-0.121]
 [-0.121]] [[6.46 ]
 [1.838]
 [1.838]
 [1.838]
 [1.838]
 [1.838]
 [1.838]] [[ 0.368]
 [-0.756]
 [-0.756]
 [-0.756]
 [-0.756]
 [-0.756]
 [-0.756]]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.13867839173196841, 0.13867839173196841, 0.5839648248040948, 0.13867839173196841]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.13867839173196841, 0.13867839173196841, 0.5839648248040948, 0.13867839173196841]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
UNIT TEST: sample policy line 217 mcts : [0.429 0.061 0.082 0.122 0.102 0.082 0.122]
siam score:  -0.8975679
Printing some Q and Qe and total Qs values:  [[0.927]
 [0.927]
 [0.932]
 [0.927]
 [0.936]
 [0.934]
 [0.927]] [[2.965]
 [2.965]
 [3.294]
 [2.965]
 [3.252]
 [3.286]
 [2.965]] [[1.381]
 [1.381]
 [1.611]
 [1.381]
 [1.591]
 [1.61 ]
 [1.381]]
Printing some Q and Qe and total Qs values:  [[1.199]
 [1.086]
 [1.065]
 [1.063]
 [1.12 ]
 [1.118]
 [1.05 ]] [[4.38 ]
 [2.572]
 [4.633]
 [4.575]
 [4.539]
 [4.512]
 [4.489]] [[1.585]
 [0.793]
 [1.606]
 [1.582]
 [1.601]
 [1.589]
 [1.54 ]]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
Printing some Q and Qe and total Qs values:  [[-0.051]
 [-0.051]
 [-0.055]
 [-0.051]
 [-0.051]
 [-0.051]
 [-0.051]] [[5.959]
 [5.959]
 [6.796]
 [5.959]
 [5.959]
 [5.959]
 [5.959]] [[0.004]
 [0.004]
 [0.51 ]
 [0.004]
 [0.004]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.0509971918726215, 0.20858317191257772, 0.3702098181074004, 0.3702098181074004]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.06068274568864625, 0.24879415761585127, 0.4417289390796512, 0.24879415761585127]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.07458012423889215, 0.07458012423889215, 0.5443486050906707, 0.30649114643154507]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.862215969723843
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.17914273617956372, 0.044320299970974024, 0.45915856522817783, 0.3173783986212845]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.17914273617956372, 0.044320299970974024, 0.45915856522817783, 0.3173783986212845]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.2488129793249939, 0.06126371267415498, 0.4411103286758572, 0.2488129793249939]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.2488129793249939, 0.06126371267415498, 0.4411103286758572, 0.2488129793249939]
from probs:  [0.2488129793249939, 0.06126371267415498, 0.4411103286758572, 0.2488129793249939]
Printing some Q and Qe and total Qs values:  [[0.705]
 [0.704]
 [0.703]
 [0.703]
 [0.714]
 [0.704]
 [0.722]] [[1.992]
 [2.143]
 [2.03 ]
 [2.021]
 [1.893]
 [1.972]
 [1.834]] [[0.705]
 [0.704]
 [0.703]
 [0.703]
 [0.714]
 [0.704]
 [0.722]]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.14104449450792816, 0.14104449450792816, 0.14104449450792816, 0.5768665164762156]
maxi score, test score, baseline:  -0.9930506849315068 -1.0 -0.9930506849315068
maxi score, test score, baseline:  -0.9930506849315068 -1.0 -0.9930506849315068
probs:  [0.14104444700948146, 0.14104444700948146, 0.14104444700948146, 0.5768666589715556]
maxi score, test score, baseline:  -0.9930972789115646 -1.0 -0.9930972789115646
probs:  [0.061841167564687036, 0.24883131159978064, 0.24883131159978064, 0.4404962092357517]
Printing some Q and Qe and total Qs values:  [[0.404]
 [0.548]
 [0.418]
 [0.403]
 [0.393]
 [0.399]
 [0.44 ]] [[8.87 ]
 [6.005]
 [9.157]
 [9.349]
 [9.454]
 [9.3  ]
 [8.513]] [[1.832]
 [1.035]
 [1.925]
 [1.975]
 [2.003]
 [1.959]
 [1.741]]
siam score:  -0.9040099
maxi score, test score, baseline:  -0.9930972789115646 -1.0 -0.9930972789115646
maxi score, test score, baseline:  -0.9930972789115646 -1.0 -0.9930972789115646
probs:  [0.061841167564687036, 0.24883131159978064, 0.24883131159978064, 0.4404962092357517]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 9.13266954397346
maxi score, test score, baseline:  -0.9930972789115646 -1.0 -0.9930972789115646
probs:  [0.061841167564687036, 0.24883131159978064, 0.24883131159978064, 0.4404962092357517]
Printing some Q and Qe and total Qs values:  [[0.412]
 [0.419]
 [0.419]
 [0.413]
 [0.419]
 [0.419]
 [0.419]] [[3.763]
 [3.757]
 [3.757]
 [3.762]
 [3.757]
 [3.757]
 [3.757]] [[1.744]
 [1.748]
 [1.748]
 [1.746]
 [1.748]
 [1.748]
 [1.748]]
Printing some Q and Qe and total Qs values:  [[0.492]
 [0.5  ]
 [0.483]
 [0.49 ]
 [0.491]
 [0.489]
 [0.496]] [[1.91 ]
 [2.031]
 [1.81 ]
 [1.683]
 [1.633]
 [1.599]
 [1.836]] [[0.492]
 [0.5  ]
 [0.483]
 [0.49 ]
 [0.491]
 [0.489]
 [0.496]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.8617740454067646
using explorer policy with actor:  1
first move QE:  0.842902185026537
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
Printing some Q and Qe and total Qs values:  [[0.098]
 [0.062]
 [0.104]
 [0.092]
 [0.106]
 [0.1  ]
 [0.083]] [[9.305]
 [5.837]
 [9.443]
 [9.465]
 [9.274]
 [9.191]
 [9.41 ]] [[1.819]
 [0.885]
 [1.858]
 [1.859]
 [1.814]
 [1.789]
 [1.841]]
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
probs:  [0.09916017433633646, 0.40083982566366355, 0.09916017433633646, 0.40083982566366355]
maxi score, test score, baseline:  -0.9931885906040269 -1.0 -0.9931885906040269
probs:  [0.09916012956525236, 0.4008398704347476, 0.09916012956525236, 0.4008398704347476]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.629]
 [0.629]
 [0.632]
 [0.629]
 [0.629]
 [0.629]] [[1.762]
 [1.545]
 [1.545]
 [1.667]
 [1.545]
 [1.545]
 [1.545]] [[1.262]
 [1.14 ]
 [1.14 ]
 [1.229]
 [1.14 ]
 [1.14 ]
 [1.14 ]]
from probs:  [0.09916012956525236, 0.4008398704347476, 0.09916012956525236, 0.4008398704347476]
maxi score, test score, baseline:  -0.9931885906040269 -1.0 -0.9931885906040269
probs:  [0.14181111702506335, 0.14181111702506335, 0.14181111702506335, 0.57456664892481]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9931885906040269 -1.0 -0.9931885906040269
probs:  [0.14181111702506335, 0.14181111702506335, 0.14181111702506335, 0.57456664892481]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.158]
 [0.157]
 [0.157]
 [0.157]
 [0.158]
 [0.157]
 [0.157]] [[1.217]
 [2.743]
 [1.27 ]
 [0.931]
 [1.315]
 [1.355]
 [1.275]] [[0.158]
 [0.157]
 [0.157]
 [0.157]
 [0.158]
 [0.157]
 [0.157]]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.686]
 [0.741]
 [0.736]
 [0.709]
 [0.703]
 [0.698]] [[3.803]
 [3.664]
 [3.808]
 [3.775]
 [2.981]
 [3.11 ]
 [2.855]] [[1.603]
 [1.427]
 [1.585]
 [1.564]
 [1.244]
 [1.276]
 [1.181]]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.30766964087261617, 0.30766964087261617, 0.30766964087261617, 0.07699107738215166]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.30766964087261617, 0.30766964087261617, 0.30766964087261617, 0.07699107738215166]
Printing some Q and Qe and total Qs values:  [[1.232]
 [1.392]
 [1.232]
 [1.232]
 [1.232]
 [1.232]
 [1.232]] [[1.61 ]
 [1.412]
 [1.61 ]
 [1.61 ]
 [1.61 ]
 [1.61 ]
 [1.61 ]] [[1.316]
 [1.449]
 [1.316]
 [1.316]
 [1.316]
 [1.316]
 [1.316]]
Printing some Q and Qe and total Qs values:  [[0.415]
 [0.392]
 [0.413]
 [0.415]
 [0.415]
 [0.407]
 [0.42 ]] [[8.189]
 [4.247]
 [5.918]
 [6.391]
 [5.902]
 [5.346]
 [5.018]] [[1.887]
 [0.316]
 [0.988]
 [1.177]
 [0.983]
 [0.759]
 [0.637]]
siam score:  -0.89292145
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.708]
 [0.699]
 [0.699]
 [0.706]
 [0.697]
 [0.696]] [[4.667]
 [2.434]
 [4.53 ]
 [4.418]
 [4.407]
 [4.2  ]
 [4.413]] [[ 1.387]
 [-0.071]
 [ 1.308]
 [ 1.233]
 [ 1.24 ]
 [ 1.083]
 [ 1.224]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.091831802946017
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3179030424746035, 0.04629087257618947, 0.3179030424746035, 0.3179030424746035]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3179030424746035, 0.04629087257618947, 0.3179030424746035, 0.3179030424746035]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
Printing some Q and Qe and total Qs values:  [[0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]] [[4.198]
 [4.198]
 [4.198]
 [4.198]
 [4.198]
 [4.198]
 [4.198]] [[1.542]
 [1.542]
 [1.542]
 [1.542]
 [1.542]
 [1.542]
 [1.542]]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3179030424746035, 0.04629087257618947, 0.3179030424746035, 0.3179030424746035]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3179030424746035, 0.04629087257618947, 0.3179030424746035, 0.3179030424746035]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3179030424746035, 0.04629087257618947, 0.3179030424746035, 0.3179030424746035]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3222851511585177, 0.0331445465244468, 0.3222851511585177, 0.3222851511585177]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.35761530585650997, 0.03667971916017312, 0.35761530585650997, 0.24808966912680702]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.45370540401626364, 0.04629459598373638, 0.45370540401626364, 0.04629459598373638]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.45370540401626364, 0.04629459598373638, 0.45370540401626364, 0.04629459598373638]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
Printing some Q and Qe and total Qs values:  [[0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]] [[2.897]
 [2.897]
 [2.897]
 [2.897]
 [2.897]
 [2.897]
 [2.897]] [[0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.45370540401626364, 0.04629459598373638, 0.45370540401626364, 0.04629459598373638]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.45370540401626364, 0.04629459598373638, 0.45370540401626364, 0.04629459598373638]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.45370540401626364, 0.04629459598373638, 0.45370540401626364, 0.04629459598373638]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.45370540401626364, 0.04629459598373638, 0.45370540401626364, 0.04629459598373638]
Printing some Q and Qe and total Qs values:  [[0.152]
 [0.196]
 [0.196]
 [0.196]
 [0.196]
 [0.196]
 [0.196]] [[4.245]
 [4.506]
 [4.506]
 [4.506]
 [4.506]
 [4.506]
 [4.506]] [[1.261]
 [1.537]
 [1.537]
 [1.537]
 [1.537]
 [1.537]
 [1.537]]
Printing some Q and Qe and total Qs values:  [[0.756]
 [0.756]
 [0.756]
 [0.76 ]
 [0.756]
 [0.756]
 [0.756]] [[1.323]
 [1.323]
 [1.323]
 [1.719]
 [1.323]
 [1.323]
 [1.323]] [[1.199]
 [1.199]
 [1.199]
 [1.469]
 [1.199]
 [1.199]
 [1.199]]
Printing some Q and Qe and total Qs values:  [[0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]] [[3.565]
 [3.565]
 [3.565]
 [3.565]
 [3.565]
 [3.565]
 [3.565]] [[2.697]
 [2.697]
 [2.697]
 [2.697]
 [2.697]
 [2.697]
 [2.697]]
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
probs:  [0.06411863655165542, 0.06411863655165542, 0.6250238034484148, 0.24673892344827436]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
probs:  [0.07913094366580048, 0.07913094366580048, 0.5365547209340056, 0.30518339173439335]
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
probs:  [0.20956984597332948, 0.05503681280471967, 0.3676966706109754, 0.3676966706109754]
siam score:  -0.8820212
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
probs:  [0.20956984597332948, 0.05503681280471967, 0.3676966706109754, 0.3676966706109754]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
siam score:  -0.8827211
using explorer policy with actor:  1
using explorer policy with actor:  1
first move QE:  0.9577933532661309
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
probs:  [0.3163055530402893, 0.18059149956512635, 0.04792720010064122, 0.4551757472939431]
Printing some Q and Qe and total Qs values:  [[0.421]
 [0.421]
 [0.418]
 [0.417]
 [0.416]
 [0.416]
 [0.418]] [[2.861]
 [2.891]
 [2.694]
 [2.467]
 [2.506]
 [2.506]
 [2.554]] [[1.017]
 [1.048]
 [0.843]
 [0.615]
 [0.65 ]
 [0.65 ]
 [0.704]]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.3568297569410207, 0.24818932615354222, 0.038151159964416315, 0.3568297569410207]
Printing some Q and Qe and total Qs values:  [[0.95 ]
 [1.324]
 [0.95 ]
 [0.95 ]
 [0.95 ]
 [0.95 ]
 [0.95 ]] [[1.755]
 [4.658]
 [1.755]
 [1.755]
 [1.755]
 [1.755]
 [1.755]] [[1.437]
 [2.996]
 [1.437]
 [1.437]
 [1.437]
 [1.437]
 [1.437]]
line 256 mcts: sample exp_bonus 2.161773254335022
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.27845293783126174, 0.27845293783126174, 0.042700024372233816, 0.40039409996524267]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
Printing some Q and Qe and total Qs values:  [[0.5  ]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.501]] [[2.611]
 [2.505]
 [2.505]
 [2.505]
 [2.505]
 [2.505]
 [2.505]] [[1.931]
 [1.791]
 [1.791]
 [1.791]
 [1.791]
 [1.791]
 [1.791]]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 2.051088956466165
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.08162980826680874, 0.5322860835378044, 0.08162980826680874, 0.30445429992857825]
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.75 ]
 [0.735]
 [0.75 ]
 [0.743]
 [0.747]
 [0.718]] [[9.213]
 [8.392]
 [9.074]
 [8.392]
 [8.926]
 [9.171]
 [9.315]] [[1.947]
 [1.705]
 [1.903]
 [1.705]
 [1.868]
 [1.958]
 [1.949]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
332 123
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9935708860759493 -1.0 -0.9935708860759493
probs:  [0.0569981354632796, 0.3664813015045404, 0.2100392615276396, 0.3664813015045404]
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.692]
 [2.989]
 [0.737]
 [0.736]
 [0.733]
 [0.732]] [[2.287]
 [2.078]
 [0.   ]
 [1.422]
 [1.451]
 [1.333]
 [1.284]] [[3.068]
 [2.879]
 [6.089]
 [2.531]
 [2.548]
 [2.464]
 [2.43 ]]
maxi score, test score, baseline:  -0.9935708860759493 -1.0 -0.9935708860759493
probs:  [0.0569981354632796, 0.3664813015045404, 0.2100392615276396, 0.3664813015045404]
deleting a thread, now have 3 threads
Frames:  23575 train batches done:  2762 episodes:  458
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.06743325690474979, 0.4345840551736503, 0.24899134396079994, 0.24899134396079994]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.06743325690474979, 0.4345840551736503, 0.24899134396079994, 0.24899134396079994]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.075]
 [-0.075]
 [-0.075]
 [-0.075]
 [-0.075]
 [-0.075]
 [-0.075]] [[3.581]
 [3.581]
 [3.581]
 [3.581]
 [3.581]
 [3.581]
 [3.581]] [[1.159]
 [1.159]
 [1.159]
 [1.159]
 [1.159]
 [1.159]
 [1.159]]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.06743322132319629, 0.43458409114836943, 0.2489913437642171, 0.2489913437642171]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.08224333679596246, 0.5312391118420635, 0.3042742145660115, 0.08224333679596246]
using explorer policy with actor:  1
deleting a thread, now have 2 threads
Frames:  23841 train batches done:  2784 episodes:  461
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.10622131601742102, 0.393778683982579, 0.393778683982579, 0.10622131601742102]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.10622131601742102, 0.393778683982579, 0.393778683982579, 0.10622131601742102]
line 256 mcts: sample exp_bonus 6.505053412666477
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.10622131601742102, 0.393778683982579, 0.393778683982579, 0.10622131601742102]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.10622131601742102, 0.393778683982579, 0.393778683982579, 0.10622131601742102]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.10622131601742102, 0.393778683982579, 0.393778683982579, 0.10622131601742102]
Printing some Q and Qe and total Qs values:  [[0.204]
 [0.227]
 [0.22 ]
 [0.222]
 [0.227]
 [0.231]
 [0.226]] [[8.408]
 [8.032]
 [8.36 ]
 [8.398]
 [8.414]
 [8.476]
 [8.318]] [[1.554]
 [1.403]
 [1.546]
 [1.565]
 [1.577]
 [1.609]
 [1.532]]
from probs:  [0.2490053269252055, 0.4340145188369218, 0.2490053269252055, 0.06797482731266707]
Printing some Q and Qe and total Qs values:  [[0.07 ]
 [0.066]
 [0.082]
 [0.079]
 [0.072]
 [0.071]
 [0.07 ]] [[2.15 ]
 [3.156]
 [2.184]
 [2.238]
 [2.228]
 [2.266]
 [2.134]] [[0.07 ]
 [0.066]
 [0.082]
 [0.079]
 [0.072]
 [0.071]
 [0.07 ]]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.10689201452400786, 0.3931079854759921, 0.3931079854759921, 0.10689201452400786]
Printing some Q and Qe and total Qs values:  [[0.16 ]
 [0.158]
 [0.158]
 [0.158]
 [0.158]
 [0.159]
 [0.158]] [[1.619]
 [1.23 ]
 [1.23 ]
 [1.23 ]
 [1.23 ]
 [1.551]
 [1.23 ]] [[0.16 ]
 [0.158]
 [0.158]
 [0.158]
 [0.158]
 [0.159]
 [0.158]]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.10689201452400786, 0.3931079854759921, 0.3931079854759921, 0.10689201452400786]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
line 256 mcts: sample exp_bonus 4.331314846241098
start point for exploration sampling:  10624
using explorer policy with actor:  0
siam score:  -0.88421714
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05796457654919431, 0.3658834451858311, 0.3658834451858311, 0.2102685330791435]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05796457654919431, 0.3658834451858311, 0.3658834451858311, 0.2102685330791435]
Printing some Q and Qe and total Qs values:  [[0.304]
 [0.33 ]
 [0.305]
 [0.33 ]
 [0.33 ]
 [0.306]
 [0.33 ]] [[4.635]
 [4.062]
 [4.476]
 [4.062]
 [4.062]
 [4.53 ]
 [4.062]] [[1.497]
 [1.014]
 [1.352]
 [1.014]
 [1.014]
 [1.403]
 [1.014]]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05796457654919431, 0.3658834451858311, 0.3658834451858311, 0.2102685330791435]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.06851329947776477, 0.4334487189062589, 0.24901899080798817, 0.24901899080798817]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.06851329947776477, 0.4334487189062589, 0.24901899080798817, 0.24901899080798817]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.08345762913915805, 0.5291681468386782, 0.3039165948830058, 0.08345762913915805]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.08345762913915805, 0.5291681468386782, 0.3039165948830058, 0.08345762913915805]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.08345762913915805, 0.5291681468386782, 0.3039165948830058, 0.08345762913915805]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.08345762913915805, 0.5291681468386782, 0.3039165948830058, 0.08345762913915805]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.08345762913915805, 0.5291681468386782, 0.3039165948830058, 0.08345762913915805]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
Printing some Q and Qe and total Qs values:  [[0.247]
 [0.246]
 [0.246]
 [0.246]
 [0.246]
 [0.259]
 [0.246]] [[1.954]
 [1.99 ]
 [1.99 ]
 [1.99 ]
 [1.99 ]
 [1.859]
 [1.99 ]] [[0.247]
 [0.246]
 [0.246]
 [0.246]
 [0.246]
 [0.259]
 [0.246]]
Printing some Q and Qe and total Qs values:  [[1.039]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]] [[4.755]
 [4.21 ]
 [4.21 ]
 [4.21 ]
 [4.21 ]
 [4.21 ]
 [4.21 ]] [[1.754]
 [1.378]
 [1.378]
 [1.378]
 [1.378]
 [1.378]
 [1.378]]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.05825041560493411, 0.5223996241835491, 0.2096749801057584, 0.2096749801057584]
maxi score, test score, baseline:  -0.9937271604938271 -1.0 -0.9937271604938271
probs:  [0.08405836351452005, 0.5281441664934564, 0.08405836351452005, 0.3037391064775035]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.483]
 [0.599]
 [0.601]
 [0.601]
 [0.603]
 [0.603]] [[7.633]
 [5.561]
 [7.33 ]
 [7.308]
 [7.096]
 [7.745]
 [7.721]] [[1.457]
 [0.528]
 [1.351]
 [1.348]
 [1.277]
 [1.498]
 [1.489]]
maxi score, test score, baseline:  -0.9937271604938271 -1.0 -0.9937271604938271
maxi score, test score, baseline:  -0.9937271604938271 -1.0 -0.9937271604938271
maxi score, test score, baseline:  -0.9937271604938271 -1.0 -0.9937271604938271
probs:  [0.08405836351452005, 0.5281441664934564, 0.08405836351452005, 0.3037391064775035]
Printing some Q and Qe and total Qs values:  [[0.446]
 [0.468]
 [0.442]
 [0.445]
 [0.446]
 [0.442]
 [0.446]] [[5.662]
 [4.761]
 [3.928]
 [4.723]
 [4.187]
 [4.394]
 [4.637]] [[0.446]
 [0.468]
 [0.442]
 [0.445]
 [0.446]
 [0.442]
 [0.446]]
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [0.08405832331508274, 0.5281442338740072, 0.08405832331508274, 0.3037391194958273]
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [0.08405832331508274, 0.5281442338740072, 0.08405832331508274, 0.3037391194958273]
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [0.08405832331508274, 0.5281442338740072, 0.08405832331508274, 0.3037391194958273]
Printing some Q and Qe and total Qs values:  [[ 0.003]
 [-0.008]
 [-0.   ]
 [ 0.002]
 [ 0.005]
 [ 0.005]
 [ 0.006]] [[8.229]
 [6.136]
 [7.808]
 [7.45 ]
 [6.944]
 [7.072]
 [7.182]] [[ 0.568]
 [-0.152]
 [ 0.421]
 [ 0.306]
 [ 0.142]
 [ 0.187]
 [ 0.224]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [0.08405832331508274, 0.5281442338740072, 0.08405832331508274, 0.3037391194958273]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.08405828361037469, 0.5281443004253161, 0.08405828361037469, 0.3037391323539345]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.08405828361037469, 0.5281443004253161, 0.08405828361037469, 0.3037391323539345]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.08405828361037469, 0.5281443004253161, 0.08405828361037469, 0.3037391323539345]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.05098548060036593, 0.4518425141491948, 0.18179145996893178, 0.31538054528150755]
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.744]
 [0.719]
 [0.717]
 [0.717]
 [0.716]
 [0.736]] [[1.74 ]
 [2.536]
 [1.73 ]
 [1.599]
 [1.612]
 [1.706]
 [2.203]] [[1.043]
 [1.644]
 [1.057]
 [0.966]
 [0.974]
 [1.035]
 [1.405]]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.05098548060036593, 0.4518425141491948, 0.18179145996893178, 0.31538054528150755]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.05098548060036593, 0.4518425141491948, 0.18179145996893178, 0.31538054528150755]
Printing some Q and Qe and total Qs values:  [[0.565]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]] [[9.245]
 [5.967]
 [5.967]
 [5.967]
 [5.967]
 [5.967]
 [5.967]] [[2.01 ]
 [1.053]
 [1.053]
 [1.053]
 [1.053]
 [1.053]
 [1.053]]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.05098548060036593, 0.4518425141491948, 0.18179145996893178, 0.31538054528150755]
siam score:  -0.8788569
maxi score, test score, baseline:  -0.9938393939393939 -1.0 -0.9938393939393939
from probs:  [0.0509854519977968, 0.4518425431582073, 0.18179145016592885, 0.3153805546780671]
maxi score, test score, baseline:  -0.9938393939393939 -1.0 -0.9938393939393939
maxi score, test score, baseline:  -0.9938393939393939 -1.0 -0.9938393939393939
probs:  [0.05892172855800355, 0.3652919528109948, 0.21049436582000686, 0.3652919528109948]
siam score:  -0.8768276
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.06958094799055874, 0.24904540184122043, 0.24904540184122043, 0.4323282483270003]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.18195824677227962, 0.05141514733656322, 0.3152496219855898, 0.45137698390556735]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.24716622813692427, 0.0695831913841187, 0.0695831913841187, 0.6136673890948384]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.24716622813692427, 0.0695831913841187, 0.0695831913841187, 0.6136673890948384]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.24716622813692427, 0.0695831913841187, 0.0695831913841187, 0.6136673890948384]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.08446519198030407, 0.08446519198030407, 0.08446519198030407, 0.7466044240590879]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
probs:  [0.08446515281311721, 0.08446515281311721, 0.08446515281311721, 0.7466045415606483]
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
probs:  [0.08446515281311721, 0.08446515281311721, 0.08446515281311721, 0.7466045415606483]
Printing some Q and Qe and total Qs values:  [[0.381]
 [0.394]
 [0.368]
 [0.368]
 [0.394]
 [0.369]
 [0.37 ]] [[4.071]
 [3.888]
 [4.146]
 [4.11 ]
 [3.888]
 [4.151]
 [4.155]] [[1.348]
 [1.212]
 [1.393]
 [1.364]
 [1.212]
 [1.399]
 [1.404]]
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
probs:  [0.08446515281311721, 0.08446515281311721, 0.08446515281311721, 0.7466045415606483]
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
probs:  [0.08446515281311721, 0.08446515281311721, 0.08446515281311721, 0.7466045415606483]
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
probs:  [0.10887367779602362, 0.10887367779602362, 0.10887367779602362, 0.6733789666119292]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
probs:  [0.10887367779602362, 0.10887367779602362, 0.10887367779602362, 0.6733789666119292]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
probs:  [0.10887367779602362, 0.10887367779602362, 0.10887367779602362, 0.6733789666119292]
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
maxi score, test score, baseline:  -0.9939119760479042 -1.0 -0.9939119760479042
probs:  [0.10887367779602362, 0.10887367779602362, 0.10887367779602362, 0.6733789666119292]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.10887363515784883, 0.10887363515784883, 0.10887363515784883, 0.6733790945264535]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.10887363515784883, 0.10887363515784883, 0.10887363515784883, 0.6733790945264535]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.24907065608101298, 0.24907065608101298, 0.07063662363551683, 0.43122206420245723]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
Printing some Q and Qe and total Qs values:  [[0.033]
 [0.033]
 [0.033]
 [0.033]
 [0.033]
 [0.033]
 [0.033]] [[7.79]
 [7.79]
 [7.79]
 [7.79]
 [7.79]
 [7.79]
 [7.79]] [[1.687]
 [1.687]
 [1.687]
 [1.687]
 [1.687]
 [1.687]
 [1.687]]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.24907065608101298, 0.24907065608101298, 0.07063662363551683, 0.43122206420245723]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
Printing some Q and Qe and total Qs values:  [[0.716]
 [0.862]
 [0.716]
 [0.716]
 [0.716]
 [0.716]
 [0.716]] [[7.023]
 [8.594]
 [7.023]
 [7.023]
 [7.023]
 [7.023]
 [7.023]] [[1.533]
 [2.05 ]
 [1.533]
 [1.533]
 [1.533]
 [1.533]
 [1.533]]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.3045923595827216, 0.3045923595827216, 0.08622292125183527, 0.3045923595827216]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.38984467309325127, 0.38984467309325127, 0.11015532690674874, 0.11015532690674874]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.5416704299388003, 0.15277652335373326, 0.15277652335373326, 0.15277652335373326]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.1901747295848986
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.08680442432885335, 0.3043985252237155, 0.3043985252237155, 0.3043985252237155]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.08680442432885335, 0.3043985252237155, 0.3043985252237155, 0.3043985252237155]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.060808946726905615, 0.3641273965088708, 0.21093626025535275, 0.3641273965088708]
siam score:  -0.88575524
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.07168045944626601, 0.4301298912192517, 0.24909482466724117, 0.24909482466724117]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.07168045944626601, 0.4301298912192517, 0.24909482466724117, 0.24909482466724117]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.3040148568555675, 0.3040148568555675, 0.3040148568555675, 0.08795542943329757]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.3154405876352037, 0.3154405876352037, 0.3154405876352037, 0.053678237094388626]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.3154405876352037, 0.3154405876352037, 0.3154405876352037, 0.053678237094388626]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.3204048174582332, 0.3204048174582332, 0.3204048174582332, 0.03878554762530052]
Printing some Q and Qe and total Qs values:  [[0.97 ]
 [0.924]
 [0.854]
 [0.851]
 [0.738]
 [0.628]
 [0.794]] [[3.524]
 [3.064]
 [3.64 ]
 [3.819]
 [4.139]
 [4.378]
 [3.916]] [[2.85 ]
 [2.596]
 [2.751]
 [2.824]
 [2.816]
 [2.776]
 [2.793]]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.455]
 [0.633]
 [0.582]
 [0.67 ]
 [0.599]
 [0.606]] [[4.259]
 [4.016]
 [4.096]
 [3.894]
 [4.05 ]
 [4.051]
 [3.808]] [[1.45 ]
 [0.964]
 [1.374]
 [1.137]
 [1.417]
 [1.277]
 [1.128]]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.24845759733503497, 0.354369246995999, 0.354369246995999, 0.04280390867296702]
line 256 mcts: sample exp_bonus 5.191984814865347
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.2779025339659382, 0.2779025339659382, 0.3964163895738351, 0.047778542494288506]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.3144708869707377, 0.1829367410266762, 0.44863571583367756, 0.05395665616890845]
maxi score, test score, baseline:  -0.9939828402366864 -1.0 -0.9939828402366864
probs:  [0.3144708869707377, 0.1829367410266762, 0.44863571583367756, 0.05395665616890845]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.31447089687856916, 0.18293673072044964, 0.4486357463598507, 0.053956626041130454]
siam score:  -0.89012605
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.31447089687856916, 0.18293673072044964, 0.4486357463598507, 0.053956626041130454]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.24912918424068692, 0.24912918424068692, 0.4285172306590419, 0.07322440085958427]
siam score:  -0.88552165
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.15576750161642844, 0.5326974951507146, 0.15576750161642844, 0.15576750161642844]
Printing some Q and Qe and total Qs values:  [[0.595]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]] [[5.561]
 [5.708]
 [5.708]
 [5.708]
 [5.708]
 [5.708]
 [5.708]] [[1.341]
 [1.427]
 [1.427]
 [1.427]
 [1.427]
 [1.427]
 [1.427]]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.15576750161642844, 0.5326974951507146, 0.15576750161642844, 0.15576750161642844]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.15576750161642844, 0.5326974951507146, 0.15576750161642844, 0.15576750161642844]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.743]
 [0.79 ]
 [0.786]
 [0.801]
 [0.772]
 [0.772]] [[7.685]
 [7.462]
 [7.77 ]
 [7.684]
 [7.442]
 [7.716]
 [7.81 ]] [[1.704]
 [1.591]
 [1.748]
 [1.71 ]
 [1.618]
 [1.715]
 [1.754]]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.15576750161642844, 0.5326974951507146, 0.15576750161642844, 0.15576750161642844]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.15576750161642844, 0.5326974951507146, 0.15576750161642844, 0.15576750161642844]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.15576750161642844, 0.5326974951507146, 0.15576750161642844, 0.15576750161642844]
Printing some Q and Qe and total Qs values:  [[-0.022]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]] [[9.049]
 [9.876]
 [9.876]
 [9.876]
 [9.876]
 [9.876]
 [9.876]] [[0.801]
 [1.147]
 [1.147]
 [1.147]
 [1.147]
 [1.147]
 [1.147]]
siam score:  -0.8793193
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.15576750161642844, 0.5326974951507146, 0.15576750161642844, 0.15576750161642844]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.15576750161642844, 0.5326974951507146, 0.15576750161642844, 0.15576750161642844]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.724]
 [0.716]
 [0.715]
 [0.716]
 [0.717]
 [0.72 ]] [[2.51 ]
 [3.868]
 [2.004]
 [1.902]
 [1.906]
 [1.927]
 [2.066]] [[1.348]
 [1.891]
 [1.173]
 [1.134]
 [1.136]
 [1.145]
 [1.201]]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.089652661853906, 0.3034491127153647, 0.3034491127153647, 0.3034491127153647]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.1138843213771128, 0.3861156786228872, 0.3861156786228872, 0.1138843213771128]
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.1138843213771128, 0.3861156786228872, 0.3861156786228872, 0.1138843213771128]
siam score:  -0.878615
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.1138843213771128, 0.3861156786228872, 0.3861156786228872, 0.1138843213771128]
Printing some Q and Qe and total Qs values:  [[0.29 ]
 [0.255]
 [0.255]
 [0.255]
 [0.255]
 [0.255]
 [0.255]] [[6.233]
 [5.668]
 [5.668]
 [5.668]
 [5.668]
 [5.668]
 [5.668]] [[1.483]
 [1.169]
 [1.169]
 [1.169]
 [1.169]
 [1.169]
 [1.169]]
siam score:  -0.8762649
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.1138843213771128, 0.3861156786228872, 0.3861156786228872, 0.1138843213771128]
rdn beta is 0 so we're just using the maxi policy
line 256 mcts: sample exp_bonus 1.2261217659962331
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.15634406286912986, 0.15634406286912986, 0.5309678113926104, 0.15634406286912986]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.11448695614082467, 0.11448695614082467, 0.38551304385917534, 0.38551304385917534]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.11448695614082467, 0.11448695614082467, 0.38551304385917534, 0.38551304385917534]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.11448695614082467, 0.11448695614082467, 0.38551304385917534, 0.38551304385917534]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.11448695614082467, 0.11448695614082467, 0.38551304385917534, 0.38551304385917534]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.11448695614082467, 0.11448695614082467, 0.38551304385917534, 0.38551304385917534]
using explorer policy with actor:  1
using explorer policy with actor:  1
first move QE:  1.2738594724026753
Printing some Q and Qe and total Qs values:  [[1.244]
 [0.788]
 [0.712]
 [0.715]
 [0.705]
 [0.666]
 [0.546]] [[2.953]
 [2.514]
 [2.752]
 [2.603]
 [2.916]
 [2.755]
 [3.201]] [[3.015]
 [1.788]
 [1.924]
 [1.767]
 [2.091]
 [1.853]
 [2.142]]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.384915560154137, 0.11508443984586297, 0.11508443984586297, 0.384915560154137]
Printing some Q and Qe and total Qs values:  [[0.795]
 [0.653]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]] [[4.001]
 [3.712]
 [4.001]
 [4.001]
 [4.001]
 [4.001]
 [4.001]] [[2.008]
 [1.672]
 [2.008]
 [2.008]
 [2.008]
 [2.008]
 [2.008]]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.384915560154137, 0.11508443984586297, 0.11508443984586297, 0.384915560154137]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.3621463532812298, 0.06402689377501458, 0.21168039966252586, 0.3621463532812298]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.3621463532812298, 0.06402689377501458, 0.21168039966252586, 0.3621463532812298]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.3621463532812298, 0.06402689377501458, 0.21168039966252586, 0.3621463532812298]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.3621463532812298, 0.06402689377501458, 0.21168039966252586, 0.3621463532812298]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.4264131985585516, 0.07524326339974491, 0.2491717690208517, 0.2491717690208517]
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
probs:  [0.5164185070699207, 0.09095166338763595, 0.3016781661548074, 0.09095166338763595]
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
probs:  [0.5164185070699207, 0.09095166338763595, 0.3016781661548074, 0.09095166338763595]
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
probs:  [0.5164185070699207, 0.09095166338763595, 0.3016781661548074, 0.09095166338763595]
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
probs:  [0.5164185070699207, 0.09095166338763595, 0.3016781661548074, 0.09095166338763595]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.77 ]
 [0.765]
 [0.758]
 [0.758]
 [0.763]
 [0.759]
 [0.763]] [[1.648]
 [1.62 ]
 [1.509]
 [1.397]
 [1.295]
 [1.25 ]
 [1.256]] [[0.818]
 [0.8  ]
 [0.748]
 [0.711]
 [0.687]
 [0.665]
 [0.675]]
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
probs:  [0.44641622849575063, 0.183724796640923, 0.3138314020407209, 0.05602757282260544]
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
probs:  [0.5119208914285581, 0.06412065769586198, 0.35983779317971787, 0.06412065769586198]
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
probs:  [0.5119208914285581, 0.06412065769586198, 0.35983779317971787, 0.06412065769586198]
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
probs:  [0.45818410312999913, 0.04471430283381695, 0.35189115918593344, 0.14521043485025048]
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
probs:  [0.3938117098674531, 0.04993721542424416, 0.3938117098674531, 0.16243936484084964]
line 256 mcts: sample exp_bonus 1.2006220821983837
Training Flag: False
Self play flag: True
resampling flag: False
add more workers flag:  True
expV_train_flag:  True
expV_train_start_flag:  10624
main train batch thing paused
add a thread
Adding thread: now have 3 threads
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]] [[1.868]
 [1.321]
 [1.321]
 [1.321]
 [1.321]
 [1.321]
 [1.321]] [[0.429]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]]
main train batch thing paused
add a thread
Adding thread: now have 4 threads
main train batch thing paused
add a thread
Adding thread: now have 5 threads
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]] [[5.787]
 [5.674]
 [5.674]
 [5.674]
 [5.674]
 [5.674]
 [5.674]] [[2.071]
 [2.014]
 [2.014]
 [2.014]
 [2.014]
 [2.014]
 [2.014]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.814]
 [0.822]
 [0.834]
 [0.825]
 [0.84 ]
 [0.823]
 [0.815]] [[1.912]
 [2.107]
 [1.875]
 [1.609]
 [1.394]
 [1.76 ]
 [1.783]] [[0.774]
 [0.856]
 [0.801]
 [0.694]
 [0.654]
 [0.741]
 [0.733]]
Printing some Q and Qe and total Qs values:  [[0.058]
 [0.058]
 [0.058]
 [0.058]
 [0.06 ]
 [0.058]
 [0.058]] [[1.761]
 [1.559]
 [1.559]
 [1.559]
 [1.728]
 [1.559]
 [1.822]] [[0.058]
 [0.058]
 [0.058]
 [0.058]
 [0.06 ]
 [0.058]
 [0.058]]
maxi score, test score, baseline:  -0.9941528735632184 -1.0 -0.9941528735632184
probs:  [0.5145595052386219, 0.09204672792592379, 0.3013470389095304, 0.09204672792592379]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.209957115179872
Printing some Q and Qe and total Qs values:  [[0.533]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.529]] [[2.384]
 [1.902]
 [1.902]
 [2.016]
 [1.902]
 [1.964]
 [2.018]] [[0.533]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.529]]
maxi score, test score, baseline:  -0.9941528735632184 -1.0 -0.9941528735632184
probs:  [0.6511895588030634, 0.11627014706564548, 0.11627014706564548, 0.11627014706564548]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.3689166600907505
387 158
maxi score, test score, baseline:  -0.9941528735632184 -1.0 -0.9941528735632184
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.496]
 [0.486]
 [0.486]
 [0.487]
 [0.48 ]
 [0.487]] [[2.197]
 [2.61 ]
 [3.243]
 [3.243]
 [2.233]
 [2.238]
 [2.095]] [[0.467]
 [0.496]
 [0.486]
 [0.486]
 [0.487]
 [0.48 ]
 [0.487]]
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.652]
 [0.652]
 [0.652]
 [0.655]
 [0.652]
 [0.65 ]] [[5.444]
 [6.081]
 [6.081]
 [6.229]
 [5.794]
 [6.371]
 [6.304]] [[1.636]
 [1.892]
 [1.892]
 [1.952]
 [1.777]
 [2.01 ]
 [1.982]]
line 256 mcts: sample exp_bonus 4.748428778781256
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.4451112396179371, 0.05725021615460753, 0.1841865511062429, 0.3134519931212125]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.4451112396179371, 0.05725021615460753, 0.1841865511062429, 0.3134519931212125]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.5113456993341987, 0.06563985550843328, 0.211507222578684, 0.211507222578684]
UNIT TEST: sample policy line 217 mcts : [0.735 0.041 0.02  0.082 0.041 0.041 0.041]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.5989108230087394, 0.07673136000246299, 0.07673136000246299, 0.24762645698633462]
first move QE:  1.316756193441035
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.5989108230087394, 0.07673136000246299, 0.07673136000246299, 0.24762645698633462]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.5989108230087394, 0.07673136000246299, 0.07673136000246299, 0.24762645698633462]
Printing some Q and Qe and total Qs values:  [[0.841]
 [0.922]
 [0.819]
 [0.811]
 [0.807]
 [0.793]
 [0.79 ]] [[5.462]
 [5.814]
 [5.504]
 [5.507]
 [5.517]
 [5.539]
 [5.517]] [[1.176]
 [1.456]
 [1.146]
 [1.13 ]
 [1.126]
 [1.106]
 [1.093]]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.38200400437389764, 0.11799599562610233, 0.11799599562610233, 0.38200400437389764]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.36077362305494753, 0.2121910388375337, 0.06626171505257118, 0.36077362305494753]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
from probs:  [0.4238543589210133, 0.24922038404071317, 0.0777048729975604, 0.24922038404071317]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.38143637606368863, 0.38143637606368863, 0.11856362393631137, 0.11856362393631137]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.38143637606368863, 0.38143637606368863, 0.11856362393631137, 0.11856362393631137]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.38143637606368863, 0.38143637606368863, 0.11856362393631137, 0.11856362393631137]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.38143637606368863, 0.38143637606368863, 0.11856362393631137, 0.11856362393631137]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.38143637606368863, 0.38143637606368863, 0.11856362393631137, 0.11856362393631137]
Printing some Q and Qe and total Qs values:  [[0.464]
 [0.362]
 [0.475]
 [0.474]
 [0.475]
 [0.468]
 [0.464]] [[0.836]
 [1.388]
 [0.634]
 [0.584]
 [0.743]
 [0.58 ]
 [0.722]] [[0.464]
 [0.362]
 [0.475]
 [0.474]
 [0.475]
 [0.468]
 [0.464]]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [0.3605031604788731, 0.3605031604788731, 0.21229120636477572, 0.06670247267747803]
from probs:  [0.3605031604788731, 0.3605031604788731, 0.21229120636477572, 0.06670247267747803]
maxi score, test score, baseline:  -0.9943444444444445 -1.0 -0.9943444444444445
probs:  [0.24922954758597232, 0.42335179315614174, 0.24922954758597232, 0.07818911167191364]
maxi score, test score, baseline:  -0.9943444444444445 -1.0 -0.9943444444444445
probs:  [0.42156596593701995, 0.42156596593701995, 0.07843403406298005, 0.07843403406298005]
maxi score, test score, baseline:  -0.9943444444444445 -1.0 -0.9943444444444445
probs:  [0.42156596593701995, 0.42156596593701995, 0.07843403406298005, 0.07843403406298005]
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.769]
 [0.629]
 [0.762]
 [0.776]
 [0.765]
 [0.754]
 [0.749]] [[3.101]
 [3.318]
 [3.202]
 [2.831]
 [3.246]
 [2.605]
 [2.663]] [[1.691]
 [1.636]
 [1.771]
 [1.463]
 [1.814]
 [1.222]
 [1.264]]
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.4215660034821388, 0.4215660034821388, 0.07843399651786122, 0.07843399651786122]
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.4215660034821388, 0.4215660034821388, 0.07843399651786122, 0.07843399651786122]
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.4215660034821388, 0.4215660034821388, 0.07843399651786122, 0.07843399651786122]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.3921686028746324, 0.3921686028746324, 0.05215697921642086, 0.16350581503431433]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.3921686028746324, 0.3921686028746324, 0.05215697921642086, 0.16350581503431433]
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.21193194554528375, 0.5087337260396766, 0.06740238286975576, 0.21193194554528375]
line 256 mcts: sample exp_bonus 2.7858410974950196
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.21193194554528375, 0.5087337260396766, 0.06740238286975576, 0.21193194554528375]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.24924735654280586, 0.4223553516974875, 0.0791499352169007, 0.24924735654280586]
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.24924735654280586, 0.4223553516974875, 0.0791499352169007, 0.24924735654280586]
using explorer policy with actor:  1
406 167
from probs:  [0.09524568787997313, 0.5091340534326566, 0.09524568787997313, 0.30037457080739716]
line 256 mcts: sample exp_bonus 1.4044257700818354
siam score:  -0.8774634
maxi score, test score, baseline:  -0.9944355191256831 -1.0 -0.9944355191256831
Printing some Q and Qe and total Qs values:  [[0.5  ]
 [0.749]
 [0.749]
 [0.747]
 [0.749]
 [0.749]
 [0.749]] [[4.722]
 [2.465]
 [2.465]
 [2.058]
 [2.465]
 [2.465]
 [2.465]] [[2.36 ]
 [1.353]
 [1.353]
 [1.079]
 [1.353]
 [1.353]
 [1.353]]
maxi score, test score, baseline:  -0.9944355191256831 -1.0 -0.9944355191256831
probs:  [0.16225642307977423, 0.16225642307977423, 0.16225642307977423, 0.5132307307606774]
start point for exploration sampling:  10624
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.3478745410115323
start point for exploration sampling:  10624
from probs:  [0.12078708543893563, 0.3792129145610644, 0.3792129145610644, 0.12078708543893563]
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.12078704286241286, 0.3792129571375872, 0.3792129571375872, 0.12078704286241286]
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
line 256 mcts: sample exp_bonus 5.989346469062135
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.02689903687338
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.21268567670648275, 0.3594344439448517, 0.3594344439448517, 0.0684454354038139]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.21268566980019388, 0.3594344641994372, 0.3594344641994372, 0.06844540180093171]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.21268566980019388, 0.3594344641994372, 0.3594344641994372, 0.06844540180093171]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.389]
 [0.314]
 [0.314]
 [0.314]
 [0.314]
 [0.314]
 [0.314]] [[7.925]
 [8.186]
 [8.186]
 [8.186]
 [8.186]
 [8.186]
 [8.186]] [[1.681]
 [1.72 ]
 [1.72 ]
 [1.72 ]
 [1.72 ]
 [1.72 ]
 [1.72 ]]
Printing some Q and Qe and total Qs values:  [[0.781]
 [0.781]
 [0.781]
 [0.781]
 [0.781]
 [0.781]
 [0.781]] [[1.539]
 [1.539]
 [1.539]
 [1.539]
 [1.539]
 [1.539]
 [1.539]] [[1.857]
 [1.857]
 [1.857]
 [1.857]
 [1.857]
 [1.857]
 [1.857]]
Printing some Q and Qe and total Qs values:  [[0.479]
 [0.533]
 [0.489]
 [0.49 ]
 [0.485]
 [0.492]
 [0.495]] [[1.796]
 [2.109]
 [1.743]
 [1.522]
 [1.633]
 [1.754]
 [1.848]] [[0.479]
 [0.533]
 [0.489]
 [0.49 ]
 [0.485]
 [0.492]
 [0.495]]
first move QE:  1.3686268037293519
Printing some Q and Qe and total Qs values:  [[1.049]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]] [[7.787]
 [4.421]
 [4.421]
 [4.421]
 [4.421]
 [4.421]
 [4.421]] [[1.95 ]
 [1.009]
 [1.009]
 [1.009]
 [1.009]
 [1.009]
 [1.009]]
maxi score, test score, baseline:  -0.9945524064171123 -1.0 -0.9945524064171123
probs:  [0.09628406476313717, 0.5073745198058149, 0.30005735066791067, 0.09628406476313717]
line 256 mcts: sample exp_bonus 9.564124954279972
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9945524064171123 -1.0 -0.9945524064171123
probs:  [0.16325329180242665, 0.5102401245927202, 0.16325329180242665, 0.16325329180242665]
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.537]
 [0.518]
 [0.517]
 [0.511]
 [0.512]
 [0.514]] [[1.471]
 [3.158]
 [1.656]
 [1.591]
 [1.544]
 [1.554]
 [1.653]] [[0.511]
 [0.537]
 [0.518]
 [0.517]
 [0.511]
 [0.512]
 [0.514]]
maxi score, test score, baseline:  -0.9945524064171123 -1.0 -0.9945524064171123
probs:  [0.12187149432730021, 0.12187149432730021, 0.3781285056726998, 0.3781285056726998]
maxi score, test score, baseline:  -0.9945524064171123 -1.0 -0.9945524064171123
probs:  [0.16374349856330292, 0.16374349856330292, 0.16374349856330292, 0.5087695043100913]
using explorer policy with actor:  1
siam score:  -0.86409867
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.87209
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.30078500721766405, 0.30078500721766405, 0.09764497834700786, 0.30078500721766405]
Printing some Q and Qe and total Qs values:  [[0.463]
 [0.5  ]
 [0.446]
 [0.5  ]
 [0.447]
 [0.5  ]
 [0.491]] [[6.53 ]
 [5.82 ]
 [5.819]
 [5.82 ]
 [5.515]
 [5.82 ]
 [6.731]] [[1.529]
 [1.233]
 [1.182]
 [1.233]
 [1.042]
 [1.233]
 [1.648]]
using explorer policy with actor:  1
first move QE:  1.3944746599502367
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.37759300426965553, 0.12240699573034444, 0.12240699573034444, 0.37759300426965553]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.3586464067250277, 0.06973193967970237, 0.21297524687024225, 0.3586464067250277]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.2492890589759644, 0.08150697730360106, 0.2492890589759644, 0.41991490474447013]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.09781673887747942, 0.09781673887747942, 0.2995878041859883, 0.5047787180590528]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.09781673887747942, 0.09781673887747942, 0.2995878041859883, 0.5047787180590528]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.12293826647194388, 0.12293826647194388, 0.3770617335280561, 0.3770617335280561]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
Printing some Q and Qe and total Qs values:  [[-0.019]
 [-0.   ]
 [-0.   ]
 [-0.   ]
 [-0.   ]
 [-0.   ]
 [-0.   ]] [[8.19 ]
 [8.014]
 [8.014]
 [8.014]
 [8.014]
 [8.014]
 [8.014]] [[1.496]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.45 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.16470764515322048, 0.16470764515322048, 0.5058770645403385, 0.16470764515322048]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
UNIT TEST: sample policy line 217 mcts : [0.531 0.    0.061 0.    0.327 0.082 0.   ]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.16470764515322048, 0.16470764515322048, 0.5058770645403385, 0.16470764515322048]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.24929694953664264, 0.08197093925762157, 0.4194351616690931, 0.24929694953664264]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.24929694953664264, 0.08197093925762157, 0.4194351616690931, 0.24929694953664264]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.29943295730695135, 0.09832109681028783, 0.5039248490724729, 0.09832109681028783]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.5044543754203064, 0.16518187485989788, 0.16518187485989788, 0.16518187485989788]
Printing some Q and Qe and total Qs values:  [[0.6  ]
 [0.494]
 [0.714]
 [0.638]
 [0.232]
 [0.683]
 [0.676]] [[0.707]
 [2.118]
 [0.721]
 [0.996]
 [3.059]
 [0.794]
 [1.153]] [[1.412]
 [1.672]
 [1.645]
 [1.584]
 [1.463]
 [1.608]
 [1.713]]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
Starting evaluation
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.12398795314053856, 0.37601204685946144, 0.37601204685946144, 0.12398795314053856]
Printing some Q and Qe and total Qs values:  [[0.35 ]
 [0.3  ]
 [0.35 ]
 [0.351]
 [0.35 ]
 [0.349]
 [0.35 ]] [[2.804]
 [3.791]
 [3.454]
 [3.262]
 [3.609]
 [3.642]
 [3.678]] [[0.35 ]
 [0.3  ]
 [0.35 ]
 [0.351]
 [0.35 ]
 [0.349]
 [0.35 ]]
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.16565091465202603, 0.5030472560439221, 0.16565091465202603, 0.16565091465202603]
rdn beta is 0 so we're just using the maxi policy
using another actor
from probs:  [0.16565091465202603, 0.5030472560439221, 0.16565091465202603, 0.16565091465202603]
Printing some Q and Qe and total Qs values:  [[0.345]
 [0.326]
 [0.343]
 [0.353]
 [0.353]
 [0.343]
 [0.353]] [[3.61 ]
 [3.515]
 [3.349]
 [3.111]
 [3.111]
 [3.276]
 [3.111]] [[0.345]
 [0.326]
 [0.343]
 [0.353]
 [0.353]
 [0.343]
 [0.353]]
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.3001175971669689, 0.3001175971669689, 0.3001175971669689, 0.09964720849909353]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.3001175971669689, 0.3001175971669689, 0.3001175971669689, 0.09964720849909353]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.361]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]] [[3.126]
 [3.602]
 [3.602]
 [3.602]
 [3.602]
 [3.602]
 [3.602]] [[0.361]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.3001175971669689, 0.3001175971669689, 0.3001175971669689, 0.09964720849909353]
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.349]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.346]] [[3.462]
 [3.415]
 [3.415]
 [3.294]
 [3.415]
 [3.415]
 [3.393]] [[0.349]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.346]]
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.31249636602066194, 0.31249636602066194, 0.31249636602066194, 0.06251090193801422]
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.165480219041635
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.31249636602066194, 0.31249636602066194, 0.31249636602066194, 0.06251090193801422]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 3.0431476104211397
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.31249636602066194, 0.31249636602066194, 0.31249636602066194, 0.06251090193801422]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.447]
 [0.439]
 [0.41 ]
 [0.396]
 [0.416]
 [0.426]] [[4.917]
 [3.968]
 [3.229]
 [4.323]
 [4.379]
 [4.318]
 [3.955]] [[0.427]
 [0.447]
 [0.439]
 [0.41 ]
 [0.396]
 [0.416]
 [0.426]]
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.31249636602066194, 0.31249636602066194, 0.31249636602066194, 0.06251090193801422]
using explorer policy with actor:  1
first move QE:  1.4401135311250353
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.31249636602066194, 0.31249636602066194, 0.31249636602066194, 0.06251090193801422]
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.28 ]
 [0.345]
 [0.343]
 [0.343]
 [0.343]
 [0.338]] [[2.947]
 [3.787]
 [2.946]
 [3.012]
 [3.061]
 [2.977]
 [2.921]] [[0.347]
 [0.28 ]
 [0.345]
 [0.343]
 [0.343]
 [0.343]
 [0.338]]
line 256 mcts: sample exp_bonus 3.008643349531036
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.479]
 [0.461]
 [0.461]
 [0.461]
 [0.478]
 [0.477]] [[3.395]
 [3.037]
 [4.172]
 [4.172]
 [4.172]
 [3.036]
 [3.073]] [[0.475]
 [0.479]
 [0.461]
 [0.461]
 [0.461]
 [0.478]
 [0.477]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
siam score:  -0.85452485
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.26782862273277735, 0.34664990218294967, 0.34664990218294967, 0.03887157290132341]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.267828624526264, 0.34664991190553235, 0.34664991190553235, 0.03887155166267119]
maxi score, test score, baseline:  -0.9948238578680203 -1.0 -0.9948238578680203
probs:  [0.2483780263102492, 0.45274671121876753, 0.2483780263102492, 0.05049723616073416]
line 256 mcts: sample exp_bonus 5.7763999147531395
using explorer policy with actor:  1
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [0.18561899322878678, 0.5658693144712652, 0.18561899322878678, 0.06289269907116117]
Printing some Q and Qe and total Qs values:  [[0.339]
 [0.34 ]
 [0.34 ]
 [0.34 ]
 [0.34 ]
 [0.34 ]
 [0.34 ]] [[2.602]
 [2.734]
 [2.734]
 [2.734]
 [2.734]
 [2.734]
 [2.734]] [[0.339]
 [0.34 ]
 [0.34 ]
 [0.34 ]
 [0.34 ]
 [0.34 ]
 [0.34 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
437 189
Printing some Q and Qe and total Qs values:  [[-0.022]
 [-0.018]
 [-0.019]
 [-0.019]
 [-0.019]
 [-0.019]
 [-0.021]] [[4.166]
 [3.674]
 [3.728]
 [3.732]
 [3.704]
 [3.656]
 [4.142]] [[1.059]
 [0.709]
 [0.745]
 [0.749]
 [0.728]
 [0.694]
 [1.043]]
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.3  ]
 [0.358]
 [0.351]
 [0.357]
 [0.359]
 [0.357]] [[2.903]
 [2.947]
 [2.718]
 [2.728]
 [2.689]
 [2.781]
 [2.682]] [[0.356]
 [0.3  ]
 [0.358]
 [0.351]
 [0.357]
 [0.359]
 [0.357]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.582984481924599
Printing some Q and Qe and total Qs values:  [[0.526]
 [0.752]
 [0.801]
 [0.729]
 [0.645]
 [0.652]
 [0.722]] [[4.234]
 [4.095]
 [4.529]
 [3.299]
 [2.952]
 [3.12 ]
 [3.249]] [[2.027]
 [2.168]
 [2.527]
 [1.582]
 [1.247]
 [1.374]
 [1.539]]
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.24933435289222422, 0.4170774240514701, 0.24933435289222422, 0.08425387016408137]
Printing some Q and Qe and total Qs values:  [[0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]] [[2.537]
 [2.537]
 [2.537]
 [2.537]
 [2.537]
 [2.537]
 [2.537]] [[0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[-0.094]
 [-0.089]
 [-0.094]
 [-0.093]
 [-0.092]
 [-0.093]
 [-0.093]] [[4.919]
 [4.062]
 [4.472]
 [4.329]
 [4.129]
 [4.498]
 [4.481]] [[0.76 ]
 [0.428]
 [0.585]
 [0.53 ]
 [0.452]
 [0.596]
 [0.589]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.3568509642518463, 0.21363120214119277, 0.3568509642518463, 0.07266686935511474]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.3568509642518463, 0.21363120214119277, 0.3568509642518463, 0.07266686935511474]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.4098559595647515
Printing some Q and Qe and total Qs values:  [[0.325]
 [0.326]
 [0.325]
 [0.325]
 [0.323]
 [0.323]
 [0.323]] [[1.893]
 [3.149]
 [2.347]
 [2.21 ]
 [2.308]
 [2.292]
 [2.012]] [[0.325]
 [0.326]
 [0.325]
 [0.325]
 [0.323]
 [0.323]
 [0.323]]
using explorer policy with actor:  1
siam score:  -0.8726659
Printing some Q and Qe and total Qs values:  [[0.325]
 [0.325]
 [0.325]
 [0.325]
 [0.325]
 [0.325]
 [0.325]] [[2.064]
 [2.114]
 [2.114]
 [2.114]
 [2.114]
 [2.114]
 [2.114]] [[0.325]
 [0.325]
 [0.325]
 [0.325]
 [0.325]
 [0.325]
 [0.325]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.357871906514521
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
440 192
from probs:  [0.24934144769333932, 0.24934144769333932, 0.41661373358508935, 0.08470337102823203]
line 256 mcts: sample exp_bonus 6.871240369307198
line 256 mcts: sample exp_bonus 1.8951527266629453
maxi score, test score, baseline:  -0.9949495049504951 -1.0 -0.9949495049504951
probs:  [0.12604305191578363, 0.12604305191578363, 0.621870844252649, 0.12604305191578363]
Printing some Q and Qe and total Qs values:  [[-0.009]
 [-0.003]
 [-0.014]
 [-0.015]
 [-0.015]
 [-0.014]
 [-0.016]] [[6.157]
 [4.06 ]
 [5.796]
 [5.524]
 [5.28 ]
 [5.404]
 [5.7  ]] [[0.965]
 [0.008]
 [0.796]
 [0.671]
 [0.56 ]
 [0.616]
 [0.751]]
Printing some Q and Qe and total Qs values:  [[-0.021]
 [-0.018]
 [-0.028]
 [-0.028]
 [-0.027]
 [-0.026]
 [-0.027]] [[6.315]
 [3.373]
 [5.964]
 [5.607]
 [5.073]
 [5.513]
 [5.971]] [[ 1.11 ]
 [-0.122]
 [ 0.958]
 [ 0.809]
 [ 0.585]
 [ 0.771]
 [ 0.962]]
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.555]
 [0.555]
 [0.555]
 [0.592]
 [0.555]
 [0.555]] [[6.068]
 [5.405]
 [5.405]
 [5.405]
 [4.178]
 [5.405]
 [5.405]] [[0.732]
 [0.555]
 [0.555]
 [0.555]
 [0.592]
 [0.555]
 [0.555]]
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.225]] [[1.428]
 [1.181]
 [1.181]
 [1.181]
 [1.181]
 [1.181]
 [1.402]] [[0.225]
 [0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.225]]
maxi score, test score, baseline:  -0.9950219512195122 -1.0 -0.9950219512195122
probs:  [0.08470703170643143, 0.2480400043285367, 0.5825459322586003, 0.08470703170643143]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9950219512195122 -1.0 -0.9950219512195122
probs:  [0.10176217706159704, 0.29837234222200704, 0.4981033036547989, 0.10176217706159704]
Printing some Q and Qe and total Qs values:  [[0.34 ]
 [0.407]
 [0.349]
 [0.338]
 [0.342]
 [0.343]
 [0.348]] [[2.835]
 [2.554]
 [1.774]
 [1.718]
 [1.615]
 [1.604]
 [1.697]] [[0.34 ]
 [0.407]
 [0.349]
 [0.338]
 [0.342]
 [0.343]
 [0.348]]
rdn probs:  [0.21381376443325908, 0.3563488602534015, 0.3563488602534015, 0.07348851505993788]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.27674539453183405, 0.38890350063307366, 0.27674539453183405, 0.05760571030325807]
from probs:  [0.27674539453183405, 0.38890350063307366, 0.27674539453183405, 0.05760571030325807]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.3545282223554945, 0.49832366051649546, 0.07357405856400498, 0.07357405856400498]
line 256 mcts: sample exp_bonus 1.7387377862257665
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.3545282573246483, 0.49832374359136306, 0.07357399954199427, 0.07357399954199427]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.4141798892024162, 0.4141798892024162, 0.0858201107975838, 0.0858201107975838]
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.6173877282538723, 0.12753742391537592, 0.12753742391537592, 0.12753742391537592]
maxi score, test score, baseline:  -0.9952488372093024 -1.0 -0.9952488372093024
probs:  [0.6173878338938796, 0.12753738870204012, 0.12753738870204012, 0.12753738870204012]
maxi score, test score, baseline:  -0.9952488372093024 -1.0 -0.9952488372093024
probs:  [0.6173878338938796, 0.12753738870204012, 0.12753738870204012, 0.12753738870204012]
maxi score, test score, baseline:  -0.9952488372093024 -1.0 -0.9952488372093024
maxi score, test score, baseline:  -0.9952488372093024 -1.0 -0.9952488372093024
probs:  [0.6173878338938796, 0.12753738870204012, 0.12753738870204012, 0.12753738870204012]
maxi score, test score, baseline:  -0.9952488372093024 -1.0 -0.9952488372093024
probs:  [0.6173878338938796, 0.12753738870204012, 0.12753738870204012, 0.12753738870204012]
Printing some Q and Qe and total Qs values:  [[0.796]
 [0.703]
 [0.7  ]
 [0.706]
 [0.707]
 [0.702]
 [0.715]] [[5.78 ]
 [4.919]
 [4.465]
 [4.303]
 [4.277]
 [4.413]
 [4.452]] [[1.512]
 [1.074]
 [0.897]
 [0.842]
 [0.832]
 [0.879]
 [0.909]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.414785174430132, 0.24936863917842875, 0.08647754721301039, 0.24936863917842875]
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]] [[6.127]
 [5.077]
 [5.077]
 [5.077]
 [5.077]
 [5.077]
 [5.077]] [[1.519]
 [1.076]
 [1.076]
 [1.076]
 [1.076]
 [1.076]
 [1.076]]
siam score:  -0.8673071
Printing some Q and Qe and total Qs values:  [[-0.01 ]
 [-0.011]
 [-0.011]
 [-0.011]
 [-0.011]
 [-0.011]
 [-0.011]] [[7.131]
 [6.801]
 [6.801]
 [6.801]
 [6.801]
 [6.801]
 [6.801]] [[0.958]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]]
Printing some Q and Qe and total Qs values:  [[-0.058]
 [-0.055]
 [-0.056]
 [-0.057]
 [-0.057]
 [-0.058]
 [-0.052]] [[4.909]
 [3.996]
 [3.893]
 [3.921]
 [3.892]
 [3.804]
 [5.006]] [[0.984]
 [0.327]
 [0.251]
 [0.27 ]
 [0.248]
 [0.183]
 [1.063]]
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
using another actor
line 256 mcts: sample exp_bonus 1.452157794594756
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.3878629624205521, 0.2765759927557689, 0.05898505206791004, 0.2765759927557689]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.31124024540787826, 0.31124024540787826, 0.06627926377636531, 0.31124024540787826]
Printing some Q and Qe and total Qs values:  [[1.1  ]
 [1.043]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [1.223]] [[3.184]
 [3.629]
 [4.721]
 [4.721]
 [4.721]
 [4.721]
 [2.811]] [[1.499]
 [1.78 ]
 [2.514]
 [2.514]
 [2.514]
 [2.514]
 [1.393]]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.35511365058435046, 0.21426135880132174, 0.07551134002997728, 0.35511365058435046]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.2493878664523644, 0.2493878664523644, 0.08778460987651883, 0.41343965721875237]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.27653378492213654, 0.27653378492213654, 0.05932698741998892, 0.3876054427357381]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.3111172468836352, 0.3111172468836352, 0.06664825934909459, 0.3111172468836352]
Printing some Q and Qe and total Qs values:  [[0.437]
 [0.474]
 [0.419]
 [0.421]
 [0.421]
 [0.433]
 [0.431]] [[4.148]
 [3.502]
 [3.828]
 [3.712]
 [3.766]
 [4.01 ]
 [4.102]] [[0.591]
 [0.449]
 [0.447]
 [0.413]
 [0.43 ]
 [0.536]
 [0.563]]
Printing some Q and Qe and total Qs values:  [[-0.068]
 [-0.075]
 [-0.065]
 [-0.07 ]
 [-0.065]
 [-0.065]
 [-0.066]] [[4.739]
 [4.103]
 [5.072]
 [4.66 ]
 [5.072]
 [5.072]
 [4.633]] [[-0.975]
 [-1.201]
 [-0.856]
 [-1.005]
 [-0.856]
 [-0.856]
 [-1.007]]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.3111172468836352, 0.3111172468836352, 0.06664825934909459, 0.3111172468836352]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.2143494098100045, 0.3548699842815226, 0.07591062162695025, 0.3548699842815226]
Printing some Q and Qe and total Qs values:  [[0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]] [[5.647]
 [5.647]
 [5.647]
 [5.647]
 [5.647]
 [5.647]
 [5.647]] [[1.2]
 [1.2]
 [1.2]
 [1.2]
 [1.2]
 [1.2]
 [1.2]]
Printing some Q and Qe and total Qs values:  [[0.67 ]
 [0.566]
 [0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.694]] [[3.351]
 [3.608]
 [2.861]
 [2.861]
 [2.861]
 [2.861]
 [2.861]] [[1.387]
 [1.265]
 [1.27 ]
 [1.27 ]
 [1.27 ]
 [1.27 ]
 [1.27 ]]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.2143494098100045, 0.3548699842815226, 0.07591062162695025, 0.3548699842815226]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.2143494098100045, 0.3548699842815226, 0.07591062162695025, 0.3548699842815226]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.10505494778808422, 0.49253897764138477, 0.10505494778808422, 0.29735112678244685]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.06689355377962733, 0.43493069517995636, 0.18775513354813167, 0.3104206174922846]
Printing some Q and Qe and total Qs values:  [[0.149]
 [0.159]
 [0.159]
 [0.159]
 [0.159]
 [0.159]
 [0.159]] [[4.338]
 [4.213]
 [4.213]
 [4.213]
 [4.213]
 [4.213]
 [4.213]] [[0.345]
 [0.289]
 [0.289]
 [0.289]
 [0.289]
 [0.289]
 [0.289]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.06689355377962733, 0.43493069517995636, 0.18775513354813167, 0.3104206174922846]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.06689355377962733, 0.43493069517995636, 0.18775513354813167, 0.3104206174922846]
Printing some Q and Qe and total Qs values:  [[1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.237]] [[1.587]
 [1.605]
 [1.605]
 [1.605]
 [1.605]
 [1.605]
 [1.605]] [[1.477]
 [1.488]
 [1.488]
 [1.488]
 [1.488]
 [1.488]
 [1.488]]
Printing some Q and Qe and total Qs values:  [[0.724]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[9.172]
 [8.872]
 [8.872]
 [8.872]
 [8.872]
 [8.872]
 [8.872]] [[2.141]
 [2.012]
 [2.012]
 [2.012]
 [2.012]
 [2.012]
 [2.012]]
Printing some Q and Qe and total Qs values:  [[0.735]
 [0.722]
 [0.738]
 [0.732]
 [0.735]
 [0.722]
 [0.737]] [[8.81 ]
 [8.784]
 [8.697]
 [8.831]
 [8.971]
 [8.784]
 [8.931]] [[2.038]
 [2.018]
 [1.99 ]
 [2.046]
 [2.11 ]
 [2.018]
 [2.094]]
from probs:  [0.06726023073355018, 0.31030422388151996, 0.18788868321508012, 0.4345468621698497]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.07654567717131551, 0.2140775071064859, 0.2140775071064859, 0.49529930861571264]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.131350390267829, 0.131350390267829, 0.36864960973217104, 0.36864960973217104]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.0819454600941927
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.17212053622361007, 0.17212053622361007, 0.48363839132916986, 0.17212053622361007]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.17212053622361007, 0.17212053622361007, 0.48363839132916986, 0.17212053622361007]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.17212053622361007, 0.17212053622361007, 0.48363839132916986, 0.17212053622361007]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.17212053622361007, 0.17212053622361007, 0.48363839132916986, 0.17212053622361007]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.2494120746423145, 0.2494120746423145, 0.41167947336329974, 0.08949637735207129]
using explorer policy with actor:  1
UNIT TEST: sample policy line 217 mcts : [0.286 0.061 0.102 0.224 0.204 0.    0.122]
siam score:  -0.8520726
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
probs:  [0.29692508164274284, 0.10642325766026425, 0.49022840303672877, 0.10642325766026425]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
probs:  [0.31007257427001844, 0.18815385141850274, 0.43378421951641005, 0.06798935479506876]
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
probs:  [0.31007257427001844, 0.18815385141850274, 0.43378421951641005, 0.06798935479506876]
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]] [[7.85]
 [7.85]
 [7.85]
 [7.85]
 [7.85]
 [7.85]
 [7.85]] [[1.585]
 [1.585]
 [1.585]
 [1.585]
 [1.585]
 [1.585]
 [1.585]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.3100725832632712, 0.18815384215973407, 0.4337842470301033, 0.06798932754689141]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
UNIT TEST: sample policy line 217 mcts : [0.286 0.    0.143 0.184 0.082 0.102 0.204]
Printing some Q and Qe and total Qs values:  [[0.332]
 [0.206]
 [0.206]
 [0.206]
 [0.206]
 [0.206]
 [0.206]] [[5.247]
 [4.59 ]
 [4.59 ]
 [4.59 ]
 [4.59 ]
 [4.59 ]
 [4.59 ]] [[0.759]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.3100725832632712, 0.18815384215973407, 0.4337842470301033, 0.06798932754689141]
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.536]
 [0.576]
 [0.574]
 [0.576]
 [0.578]
 [0.58 ]] [[4.98 ]
 [4.776]
 [4.371]
 [4.32 ]
 [4.386]
 [4.418]
 [4.396]] [[1.16 ]
 [1.009]
 [0.843]
 [0.816]
 [0.852]
 [0.869]
 [0.86 ]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.3100725832632712, 0.18815384215973407, 0.4337842470301033, 0.06798932754689141]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
Printing some Q and Qe and total Qs values:  [[-0.075]
 [-0.074]
 [-0.062]
 [-0.062]
 [-0.062]
 [-0.062]
 [-0.062]] [[5.437]
 [7.834]
 [6.503]
 [6.503]
 [6.503]
 [6.503]
 [6.503]] [[0.383]
 [1.231]
 [0.769]
 [0.769]
 [0.769]
 [0.769]
 [0.769]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.3100725832632712, 0.18815384215973407, 0.4337842470301033, 0.06798932754689141]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
Printing some Q and Qe and total Qs values:  [[0.163]
 [0.184]
 [0.165]
 [0.163]
 [0.169]
 [0.168]
 [0.172]] [[6.74 ]
 [6.294]
 [6.516]
 [6.563]
 [6.562]
 [6.552]
 [6.5  ]] [[1.167]
 [0.95 ]
 [1.049]
 [1.072]
 [1.078]
 [1.072]
 [1.048]]
Printing some Q and Qe and total Qs values:  [[0.079]
 [0.108]
 [0.074]
 [0.081]
 [0.084]
 [0.077]
 [0.069]] [[7.278]
 [6.913]
 [7.376]
 [7.251]
 [7.273]
 [7.268]
 [7.358]] [[1.25 ]
 [1.091]
 [1.295]
 [1.239]
 [1.251]
 [1.244]
 [1.282]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.29761022116745767, 0.29761022116745767, 0.29761022116745767, 0.10716933649762697]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.29761022116745767, 0.29761022116745767, 0.29761022116745767, 0.10716933649762697]
siam score:  -0.84852326
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4108135414740987, 0.24942360737823033, 0.24942360737823033, 0.09033924376944068]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4108135414740987, 0.24942360737823033, 0.24942360737823033, 0.09033924376944068]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4108135414740987, 0.24942360737823033, 0.24942360737823033, 0.09033924376944068]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4108135414740987, 0.24942360737823033, 0.24942360737823033, 0.09033924376944068]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4887118576288897, 0.10732164831376786, 0.29664484574357464, 0.10732164831376786]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4887118576288897, 0.10732164831376786, 0.29664484574357464, 0.10732164831376786]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
line 256 mcts: sample exp_bonus 5.917595793853816
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4930103280665379, 0.2144375129658718, 0.2144375129658718, 0.07811464600171852]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4930103280665379, 0.2144375129658718, 0.2144375129658718, 0.07811464600171852]
Printing some Q and Qe and total Qs values:  [[0.245]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]] [[6.608]
 [6.176]
 [6.176]
 [6.176]
 [6.176]
 [6.176]
 [6.176]] [[1.523]
 [1.34 ]
 [1.34 ]
 [1.34 ]
 [1.34 ]
 [1.34 ]
 [1.34 ]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4930103280665379, 0.2144375129658718, 0.2144375129658718, 0.07811464600171852]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4930103280665379, 0.2144375129658718, 0.2144375129658718, 0.07811464600171852]
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]] [[7.959]
 [7.959]
 [7.959]
 [7.959]
 [7.959]
 [7.959]
 [7.959]] [[1.786]
 [1.786]
 [1.786]
 [1.786]
 [1.786]
 [1.786]
 [1.786]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4930103280665379, 0.2144375129658718, 0.2144375129658718, 0.07811464600171852]
Printing some Q and Qe and total Qs values:  [[0.36 ]
 [0.309]
 [0.352]
 [0.345]
 [0.418]
 [0.37 ]
 [0.352]] [[4.517]
 [4.183]
 [3.78 ]
 [3.907]
 [3.971]
 [3.81 ]
 [3.78 ]] [[0.36 ]
 [0.309]
 [0.352]
 [0.345]
 [0.418]
 [0.37 ]
 [0.352]]
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.555]
 [0.555]
 [0.555]
 [0.555]
 [0.555]
 [0.555]] [[7.029]
 [6.489]
 [6.489]
 [6.489]
 [6.489]
 [6.489]
 [6.489]] [[1.381]
 [1.17 ]
 [1.17 ]
 [1.17 ]
 [1.17 ]
 [1.17 ]
 [1.17 ]]
Printing some Q and Qe and total Qs values:  [[ 1.05 ]
 [-0.025]
 [-0.025]
 [-0.025]
 [-0.025]
 [-0.025]
 [-0.025]] [[1.625]
 [2.891]
 [2.891]
 [2.891]
 [2.891]
 [2.891]
 [2.891]] [[1.535]
 [1.073]
 [1.073]
 [1.073]
 [1.073]
 [1.073]
 [1.073]]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
Printing some Q and Qe and total Qs values:  [[0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]] [[7.813]
 [7.813]
 [7.813]
 [7.813]
 [7.813]
 [7.813]
 [7.813]] [[2.187]
 [2.187]
 [2.187]
 [2.187]
 [2.187]
 [2.187]
 [2.187]]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.4954504098553059, 0.2753743656053808, 0.16767757799371616, 0.06149764654559708]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.5544513194239631, 0.3081146393202439, 0.06871702062789647, 0.06871702062789647]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.49148797376430486, 0.35180857549737643, 0.07835172536915934, 0.07835172536915934]
deleting a thread, now have 4 threads
Frames:  33858 train batches done:  3961 episodes:  704
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]] [[4.201]
 [3.816]
 [3.816]
 [3.816]
 [3.816]
 [3.816]
 [3.816]] [[1.502]
 [1.355]
 [1.355]
 [1.355]
 [1.355]
 [1.355]
 [1.355]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.43227837302710664, 0.30961371768274526, 0.06943117574973054, 0.18867673354041753]
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.673]
 [0.683]
 [0.685]
 [0.665]
 [0.691]
 [0.669]] [[4.936]
 [4.542]
 [4.076]
 [4.078]
 [4.718]
 [4.074]
 [4.702]] [[0.941]
 [0.858]
 [0.721]
 [0.727]
 [0.901]
 [0.737]
 [0.904]]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.40653040555953907, 0.31582208688126867, 0.05125615740297987, 0.2263913501562124]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.40653040555953907, 0.31582208688126867, 0.05125615740297987, 0.2263913501562124]
Printing some Q and Qe and total Qs values:  [[0.557]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]] [[4.757]
 [4.753]
 [4.753]
 [4.753]
 [4.753]
 [4.753]
 [4.753]] [[0.8  ]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.40653040555953907, 0.31582208688126867, 0.05125615740297987, 0.2263913501562124]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.40653040555953907, 0.31582208688126867, 0.05125615740297987, 0.2263913501562124]
deleting a thread, now have 3 threads
Frames:  34070 train batches done:  3980 episodes:  708
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.34736644044359544, 0.34736644044359544, 0.05629202901221484, 0.24897509010059418]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
siam score:  -0.8440902
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.34736644044359544, 0.34736644044359544, 0.05629202901221484, 0.24897509010059418]
from probs:  [0.34736644044359544, 0.34736644044359544, 0.05629202901221484, 0.24897509010059418]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.34736644044359544, 0.34736644044359544, 0.05629202901221484, 0.24897509010059418]
maxi score, test score, baseline:  -0.9954752212389381 -1.0 -0.9954752212389381
probs:  [0.3100311088824169, 0.3100311088824169, 0.06990667335274922, 0.3100311088824169]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.21512093296382004, 0.3527260193531339, 0.07942702832991202, 0.3527260193531339]
Printing some Q and Qe and total Qs values:  [[0.205]
 [0.262]
 [0.197]
 [0.197]
 [0.195]
 [0.197]
 [0.201]] [[4.016]
 [4.781]
 [3.955]
 [3.901]
 [3.851]
 [3.884]
 [3.978]] [[0.205]
 [0.262]
 [0.197]
 [0.197]
 [0.195]
 [0.197]
 [0.201]]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.21512093296382004, 0.3527260193531339, 0.07942702832991202, 0.3527260193531339]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.21512093296382004, 0.3527260193531339, 0.07942702832991202, 0.3527260193531339]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
Printing some Q and Qe and total Qs values:  [[-0.022]
 [-0.019]
 [-0.019]
 [-0.019]
 [-0.019]
 [-0.019]
 [-0.018]] [[7.51 ]
 [6.813]
 [6.813]
 [6.813]
 [6.813]
 [6.472]
 [6.601]] [[1.155]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.766]
 [0.815]]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.519]
 [0.533]
 [0.519]
 [0.511]
 [0.519]
 [0.519]] [[7.027]
 [7.822]
 [6.287]
 [7.822]
 [7.053]
 [7.822]
 [6.025]] [[1.518]
 [1.875]
 [1.194]
 [1.875]
 [1.524]
 [1.875]
 [1.067]]
from probs:  [0.21512093296382004, 0.3527260193531339, 0.07942702832991202, 0.3527260193531339]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.2960933304738862, 0.48573446156642747, 0.10908610397984311, 0.10908610397984311]
Printing some Q and Qe and total Qs values:  [[0.495]
 [0.512]
 [0.49 ]
 [0.49 ]
 [0.492]
 [0.489]
 [0.491]] [[6.597]
 [6.5  ]
 [6.253]
 [6.168]
 [6.092]
 [6.121]
 [6.203]] [[0.495]
 [0.512]
 [0.49 ]
 [0.49 ]
 [0.492]
 [0.489]
 [0.491]]
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
probs:  [0.29609334159772766, 0.48573451845694304, 0.10908606997266468, 0.10908606997266468]
first move QE:  1.6827344026828088
Printing some Q and Qe and total Qs values:  [[1.116]
 [1.088]
 [1.088]
 [1.087]
 [1.088]
 [1.097]
 [1.088]] [[4.936]
 [4.68 ]
 [4.68 ]
 [5.009]
 [4.68 ]
 [5.489]
 [4.68 ]] [[1.951]
 [1.806]
 [1.806]
 [1.945]
 [1.806]
 [2.161]
 [1.806]]
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
probs:  [0.47554730399783207, 0.17481756533405599, 0.17481756533405599, 0.17481756533405599]
line 256 mcts: sample exp_bonus 4.683441602769418
start point for exploration sampling:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.823]
 [0.829]
 [0.84 ]
 [0.836]
 [0.862]
 [0.834]
 [0.87 ]] [[1.439]
 [3.377]
 [1.7  ]
 [1.073]
 [1.198]
 [1.085]
 [1.183]] [[0.769]
 [1.428]
 [0.889]
 [0.672]
 [0.767]
 [0.673]
 [0.777]]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
line 256 mcts: sample exp_bonus 3.005682503811472
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.29673151847038476, 0.29673151847038476, 0.10980544458884557, 0.29673151847038476]
siam score:  -0.8411742
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.29673151847038476, 0.29673151847038476, 0.10980544458884557, 0.29673151847038476]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.29673151847038476, 0.29673151847038476, 0.10980544458884557, 0.29673151847038476]
Printing some Q and Qe and total Qs values:  [[0.228]
 [0.628]
 [0.812]
 [0.772]
 [0.221]
 [0.786]
 [0.581]] [[6.974]
 [6.296]
 [6.11 ]
 [6.579]
 [4.668]
 [6.086]
 [5.703]] [[1.921]
 [1.893]
 [1.925]
 [2.072]
 [1.09 ]
 [1.903]
 [1.655]]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.3650560383623089, 0.13494396163769112, 0.13494396163769112, 0.3650560383623089]
using explorer policy with actor:  1
siam score:  -0.84035146
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
probs:  [0.3650560724020669, 0.1349439275979331, 0.1349439275979331, 0.3650560724020669]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
probs:  [0.17518793942886662, 0.17518793942886662, 0.17518793942886662, 0.47443618171340013]
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
probs:  [0.17518793942886662, 0.17518793942886662, 0.17518793942886662, 0.47443618171340013]
first move QE:  1.702060358971077
Printing some Q and Qe and total Qs values:  [[0.332]
 [0.305]
 [0.394]
 [0.364]
 [0.435]
 [0.437]
 [0.435]] [[4.853]
 [5.942]
 [5.522]
 [4.917]
 [5.32 ]
 [5.127]
 [5.32 ]] [[0.773]
 [1.168]
 [1.075]
 [0.822]
 [1.03 ]
 [0.957]
 [1.03 ]]
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
probs:  [0.2965881161824791, 0.2965881161824791, 0.11023565145256263, 0.2965881161824791]
Printing some Q and Qe and total Qs values:  [[0.819]
 [0.822]
 [0.883]
 [0.883]
 [0.883]
 [0.883]
 [0.883]] [[3.665]
 [3.282]
 [3.877]
 [3.877]
 [3.877]
 [3.877]
 [3.877]] [[0.864]
 [0.736]
 [1.001]
 [1.001]
 [1.001]
 [1.001]
 [1.001]]
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.3646217447999425, 0.13537825520005747, 0.13537825520005747, 0.3646217447999425]
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.3646217447999425, 0.13537825520005747, 0.13537825520005747, 0.3646217447999425]
Printing some Q and Qe and total Qs values:  [[0.64 ]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]] [[9.723]
 [8.923]
 [8.923]
 [8.923]
 [8.923]
 [8.923]
 [8.923]] [[1.942]
 [1.629]
 [1.629]
 [1.629]
 [1.629]
 [1.629]
 [1.629]]
line 256 mcts: sample exp_bonus 9.15237475379955
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
Printing some Q and Qe and total Qs values:  [[0.324]
 [0.32 ]
 [0.306]
 [0.285]
 [0.3  ]
 [0.291]
 [0.3  ]] [[6.532]
 [5.292]
 [6.505]
 [6.438]
 [6.272]
 [6.506]
 [6.552]] [[1.251]
 [0.639]
 [1.224]
 [1.176]
 [1.105]
 [1.214]
 [1.243]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.09322330039625833, 0.24946124845497045, 0.24946124845497045, 0.4078542026938006]
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.09322330039625833, 0.24946124845497045, 0.24946124845497045, 0.4078542026938006]
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.09322330039625833, 0.24946124845497045, 0.24946124845497045, 0.4078542026938006]
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.11066330904058072, 0.29644556365313973, 0.29644556365313973, 0.29644556365313973]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.11066327542341278, 0.2964455748588624, 0.2964455748588624, 0.2964455748588624]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.11066327542341278, 0.2964455748588624, 0.2964455748588624, 0.2964455748588624]
Printing some Q and Qe and total Qs values:  [[0.818]
 [0.719]
 [0.815]
 [0.814]
 [0.814]
 [0.814]
 [0.815]] [[2.621]
 [3.315]
 [2.597]
 [2.614]
 [2.509]
 [2.417]
 [2.443]] [[1.757]
 [2.117]
 [1.735]
 [1.746]
 [1.67 ]
 [1.603]
 [1.624]]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
Printing some Q and Qe and total Qs values:  [[0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]] [[5.455]
 [5.455]
 [5.455]
 [5.455]
 [5.455]
 [5.455]
 [5.455]] [[1.439]
 [1.439]
 [1.439]
 [1.439]
 [1.439]
 [1.439]
 [1.439]]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.017233213823499
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.13580939959604654, 0.36419060040395346, 0.36419060040395346, 0.13580939959604654]
Printing some Q and Qe and total Qs values:  [[0.825]
 [0.863]
 [0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]] [[6.464]
 [7.686]
 [6.464]
 [6.464]
 [6.464]
 [6.464]
 [6.464]] [[1.794]
 [2.277]
 [1.794]
 [1.794]
 [1.794]
 [1.794]
 [1.794]]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.24901784250976702, 0.3465788198729292, 0.3465788198729292, 0.05782451774437442]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.24901784250976702, 0.3465788198729292, 0.3465788198729292, 0.05782451774437442]
siam score:  -0.8446628
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.27594991246879225, 0.38410479240866047, 0.27594991246879225, 0.06399538265375518]
maxi score, test score, baseline:  -0.9956081545064378 -1.0 -0.9956081545064378
probs:  [0.27594991608210084, 0.3841048110816359, 0.27594991608210084, 0.0639953567541624]
maxi score, test score, baseline:  -0.9956081545064378 -1.0 -0.9956081545064378
Printing some Q and Qe and total Qs values:  [[-0.048]
 [-0.047]
 [-0.047]
 [-0.047]
 [-0.047]
 [-0.047]
 [-0.047]] [[9.121]
 [8.974]
 [8.974]
 [8.974]
 [8.974]
 [8.974]
 [8.974]] [[-0.096]
 [-0.143]
 [-0.143]
 [-0.143]
 [-0.143]
 [-0.143]
 [-0.143]]
maxi score, test score, baseline:  -0.9956081545064378 -1.0 -0.9956081545064378
Printing some Q and Qe and total Qs values:  [[0.675]
 [0.652]
 [0.611]
 [0.615]
 [0.652]
 [0.652]
 [0.652]] [[7.156]
 [5.57 ]
 [6.51 ]
 [6.386]
 [5.57 ]
 [5.57 ]
 [5.57 ]] [[2.053]
 [1.226]
 [1.66 ]
 [1.602]
 [1.226]
 [1.226]
 [1.226]]
Printing some Q and Qe and total Qs values:  [[0.674]
 [0.669]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]] [[7.426]
 [6.21 ]
 [6.079]
 [6.079]
 [6.079]
 [6.079]
 [6.079]] [[1.8  ]
 [1.296]
 [1.199]
 [1.199]
 [1.199]
 [1.199]
 [1.199]]
Printing some Q and Qe and total Qs values:  [[0.86 ]
 [0.851]
 [0.832]
 [0.833]
 [0.826]
 [0.821]
 [0.815]] [[6.264]
 [5.685]
 [6.125]
 [6.135]
 [6.263]
 [6.276]
 [6.309]] [[1.9  ]
 [1.562]
 [1.776]
 [1.783]
 [1.844]
 [1.842]
 [1.85 ]]
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
probs:  [0.18944303147207744, 0.4300669657397712, 0.30893654984991037, 0.07155345293824104]
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2155340566082606, 0.35157181992929837, 0.35157181992929837, 0.08132230353314267]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2155340566082606, 0.35157181992929837, 0.35157181992929837, 0.08132230353314267]
Printing some Q and Qe and total Qs values:  [[-0.034]
 [-0.032]
 [-0.034]
 [-0.036]
 [-0.033]
 [-0.034]
 [-0.036]] [[5.955]
 [5.19 ]
 [5.786]
 [5.827]
 [5.653]
 [5.655]
 [5.852]] [[0.639]
 [0.329]
 [0.57 ]
 [0.585]
 [0.517]
 [0.517]
 [0.595]]
first move QE:  1.7462199172010635
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2494712844575757, 0.4070285160998329, 0.2494712844575757, 0.09402891498501559]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2494712844575757, 0.4070285160998329, 0.2494712844575757, 0.09402891498501559]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2494712844575757, 0.4070285160998329, 0.2494712844575757, 0.09402891498501559]
siam score:  -0.84963286
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2494712844575757, 0.4070285160998329, 0.2494712844575757, 0.09402891498501559]
Printing some Q and Qe and total Qs values:  [[0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]] [[5.944]
 [5.944]
 [5.944]
 [5.944]
 [5.944]
 [5.944]
 [5.944]] [[1.498]
 [1.498]
 [1.498]
 [1.498]
 [1.498]
 [1.498]
 [1.498]]
Printing some Q and Qe and total Qs values:  [[0.035]
 [0.046]
 [0.028]
 [0.028]
 [0.029]
 [0.022]
 [0.025]] [[5.316]
 [3.52 ]
 [5.286]
 [4.953]
 [4.926]
 [5.173]
 [4.993]] [[ 0.891]
 [-0.275]
 [ 0.862]
 [ 0.642]
 [ 0.626]
 [ 0.779]
 [ 0.666]]
line 256 mcts: sample exp_bonus 6.29904152783856
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2494712844575757, 0.4070285160998329, 0.2494712844575757, 0.09402891498501559]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2494712844575757, 0.4070285160998329, 0.2494712844575757, 0.09402891498501559]
siam score:  -0.8522105
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.2954203673464512, 0.4821137393360197, 0.11123294665876461, 0.11123294665876461]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.3633377557742695, 0.3633377557742695, 0.13666224422573053, 0.13666224422573053]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.35134399475797873, 0.35134399475797873, 0.08169658013406941, 0.2156154303499731]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.4066188131092363, 0.2494761912605035, 0.09442880436975677, 0.2494761912605035]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.4066188131092363, 0.2494761912605035, 0.09442880436975677, 0.2494761912605035]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.4066188131092363, 0.2494761912605035, 0.09442880436975677, 0.2494761912605035]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.4066188131092363, 0.2494761912605035, 0.09442880436975677, 0.2494761912605035]
Printing some Q and Qe and total Qs values:  [[0.22 ]
 [0.213]
 [0.215]
 [0.213]
 [0.212]
 [0.211]
 [0.214]] [[4.687]
 [4.494]
 [4.687]
 [4.494]
 [4.458]
 [4.79 ]
 [4.847]] [[0.498]
 [0.345]
 [0.49 ]
 [0.345]
 [0.317]
 [0.559]
 [0.606]]
Printing some Q and Qe and total Qs values:  [[-0.056]
 [-0.044]
 [-0.044]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]] [[4.851]
 [4.438]
 [4.438]
 [4.18 ]
 [4.381]
 [4.654]
 [4.65 ]] [[0.857]
 [0.622]
 [0.622]
 [0.434]
 [0.556]
 [0.721]
 [0.72 ]]
Printing some Q and Qe and total Qs values:  [[-0.069]
 [-0.071]
 [-0.071]
 [-0.07 ]
 [-0.067]
 [-0.071]
 [-0.07 ]] [[5.32 ]
 [5.156]
 [5.278]
 [5.321]
 [5.412]
 [5.17 ]
 [5.17 ]] [[1.04 ]
 [0.921]
 [1.008]
 [1.04 ]
 [1.109]
 [0.931]
 [0.933]]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.4066188131092363, 0.2494761912605035, 0.09442880436975677, 0.2494761912605035]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.38361996139979965, 0.27586768278100354, 0.06464467303819321, 0.27586768278100354]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.38361996139979965, 0.27586768278100354, 0.06464467303819321, 0.27586768278100354]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.38361996139979965, 0.27586768278100354, 0.06464467303819321, 0.27586768278100354]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.42934197001831065, 0.3087137314129969, 0.07225042924627824, 0.18969386932241414]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.40462569780561913, 0.3150877816688762, 0.05354281611154828, 0.22674370441395622]
Printing some Q and Qe and total Qs values:  [[0.308]
 [0.321]
 [0.308]
 [0.308]
 [0.308]
 [0.298]
 [0.308]] [[4.275]
 [3.413]
 [3.709]
 [3.709]
 [3.709]
 [3.632]
 [3.709]] [[1.527]
 [0.891]
 [1.099]
 [1.099]
 [1.099]
 [1.03 ]
 [1.099]]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.44391114159664824, 0.2487158202543268, 0.05865721789469805, 0.2487158202543268]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.44391114159664824, 0.2487158202543268, 0.05865721789469805, 0.2487158202543268]
from probs:  [0.44391114159664824, 0.2487158202543268, 0.05865721789469805, 0.2487158202543268]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.5483581466758083, 0.07225472112930618, 0.07225472112930618, 0.30713241106557926]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.6220734919580716, 0.08185140267279449, 0.08185140267279449, 0.21422370269633942]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.6220734919580716, 0.08185140267279449, 0.08185140267279449, 0.21422370269633942]
from probs:  [0.6220734919580716, 0.08185140267279449, 0.08185140267279449, 0.21422370269633942]
Printing some Q and Qe and total Qs values:  [[0.041]
 [0.033]
 [0.033]
 [0.033]
 [0.033]
 [0.032]
 [0.033]] [[2.035]
 [2.008]
 [2.008]
 [2.008]
 [2.008]
 [1.643]
 [2.008]] [[0.041]
 [0.033]
 [0.033]
 [0.033]
 [0.033]
 [0.032]
 [0.033]]
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.7172672160183432, 0.09424426132721889, 0.09424426132721889, 0.09424426132721889]
Printing some Q and Qe and total Qs values:  [[0.58 ]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]] [[9.108]
 [6.526]
 [6.526]
 [6.526]
 [6.526]
 [6.526]
 [6.526]] [[2.583]
 [1.763]
 [1.763]
 [1.763]
 [1.763]
 [1.763]
 [1.763]]
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.736]
 [0.736]
 [0.736]
 [0.736]
 [0.736]
 [0.736]] [[5.195]
 [5.614]
 [5.614]
 [5.614]
 [5.614]
 [5.614]
 [5.614]] [[1.564]
 [1.709]
 [1.709]
 [1.709]
 [1.709]
 [1.709]
 [1.709]]
Printing some Q and Qe and total Qs values:  [[0.608]
 [0.662]
 [0.604]
 [0.634]
 [0.634]
 [0.634]
 [0.634]] [[2.272]
 [2.224]
 [2.433]
 [3.726]
 [3.726]
 [3.726]
 [3.726]] [[0.549]
 [0.641]
 [0.594]
 [1.086]
 [1.086]
 [1.086]
 [1.086]]
maxi score, test score, baseline:  -0.9956627118644068 -1.0 -0.9956627118644068
probs:  [0.6641698974473452, 0.11194336751755164, 0.11194336751755164, 0.11194336751755164]
siam score:  -0.8511382
Printing some Q and Qe and total Qs values:  [[1.081]
 [1.414]
 [1.081]
 [1.081]
 [1.081]
 [1.081]
 [1.081]] [[3.45 ]
 [5.569]
 [3.45 ]
 [3.45 ]
 [3.45 ]
 [3.45 ]
 [3.45 ]] [[1.623]
 [2.69 ]
 [1.623]
 [1.623]
 [1.623]
 [1.623]
 [1.623]]
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
probs:  [0.466948528540545, 0.17768382381981837, 0.17768382381981837, 0.17768382381981837]
using another actor
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
probs:  [0.29560768939877835, 0.11317693180366484, 0.29560768939877835, 0.29560768939877835]
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
probs:  [0.29560768939877835, 0.11317693180366484, 0.29560768939877835, 0.29560768939877835]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
probs:  [0.29560768939877835, 0.11317693180366484, 0.29560768939877835, 0.29560768939877835]
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
probs:  [0.1383313348166537, 0.1383313348166537, 0.3616686651833463, 0.3616686651833463]
line 256 mcts: sample exp_bonus 5.266166612046012
Printing some Q and Qe and total Qs values:  [[0.748]
 [0.53 ]
 [0.575]
 [0.794]
 [0.755]
 [0.752]
 [0.701]] [[3.421]
 [4.03 ]
 [3.161]
 [3.262]
 [3.759]
 [3.062]
 [3.389]] [[1.631]
 [1.762]
 [1.173]
 [1.58 ]
 [1.898]
 [1.366]
 [1.537]]
line 256 mcts: sample exp_bonus 3.7534441107226875
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
using explorer policy with actor:  1
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
probs:  [0.31508993884180897, 0.31508993884180897, 0.31508993884180897, 0.054730183474573035]
from probs:  [0.31508993884180897, 0.31508993884180897, 0.31508993884180897, 0.054730183474573035]
maxi score, test score, baseline:  -0.995750622406639 -1.0 -0.995750622406639
probs:  [0.3188005745937803, 0.3188005745937803, 0.3188005745937803, 0.0435982762186591]
Printing some Q and Qe and total Qs values:  [[0.966]
 [0.966]
 [0.949]
 [0.949]
 [0.887]
 [0.949]
 [0.949]] [[4.447]
 [3.773]
 [3.972]
 [3.972]
 [4.637]
 [3.972]
 [3.972]] [[2.9  ]
 [2.458]
 [2.555]
 [2.555]
 [2.868]
 [2.555]
 [2.555]]
maxi score, test score, baseline:  -0.995750622406639 -1.0 -0.995750622406639
probs:  [0.34287626329082954, 0.26742180876736177, 0.34287626329082954, 0.04682566465097911]
maxi score, test score, baseline:  -0.995750622406639 -1.0 -0.995750622406639
maxi score, test score, baseline:  -0.995750622406639 -1.0 -0.995750622406639
probs:  [0.34287626329082954, 0.26742180876736177, 0.34287626329082954, 0.04682566465097911]
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]] [[6.094]
 [6.292]
 [6.292]
 [6.292]
 [6.292]
 [6.292]
 [6.292]] [[0.996]
 [1.051]
 [1.051]
 [1.051]
 [1.051]
 [1.051]
 [1.051]]
maxi score, test score, baseline:  -0.995750622406639 -1.0 -0.995750622406639
probs:  [0.34287626329082954, 0.26742180876736177, 0.34287626329082954, 0.04682566465097911]
maxi score, test score, baseline:  -0.995750622406639 -1.0 -0.995750622406639
probs:  [0.34287626329082954, 0.26742180876736177, 0.34287626329082954, 0.04682566465097911]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.3428762724668934, 0.2674218104886147, 0.3428762724668934, 0.04682564457759849]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.3428762724668934, 0.2674218104886147, 0.3428762724668934, 0.04682564457759849]
line 256 mcts: sample exp_bonus 6.564454229811573
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.3428762724668934, 0.2674218104886147, 0.3428762724668934, 0.04682564457759849]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.3428762724668934, 0.2674218104886147, 0.3428762724668934, 0.04682564457759849]
Printing some Q and Qe and total Qs values:  [[0.286]
 [0.256]
 [0.292]
 [0.308]
 [0.298]
 [0.333]
 [0.307]] [[7.764]
 [8.477]
 [7.745]
 [7.686]
 [7.739]
 [6.883]
 [7.702]] [[0.4  ]
 [0.578]
 [0.405]
 [0.417]
 [0.415]
 [0.2  ]
 [0.422]]
line 256 mcts: sample exp_bonus 3.2798714685747132
Printing some Q and Qe and total Qs values:  [[0.859]
 [0.883]
 [0.859]
 [0.859]
 [0.859]
 [0.86 ]
 [0.875]] [[4.976]
 [4.991]
 [5.156]
 [5.156]
 [5.156]
 [4.933]
 [4.827]] [[2.23 ]
 [2.28 ]
 [2.331]
 [2.331]
 [2.331]
 [2.208]
 [2.173]]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.289259590341646, 0.289259590341646, 0.3708987384693089, 0.050582080847399145]
line 256 mcts: sample exp_bonus 9.211864952754157
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.22695582554499652, 0.31463556491594535, 0.4034614446708277, 0.054947164868230446]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.22695582554499652, 0.31463556491594535, 0.4034614446708277, 0.054947164868230446]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.22695582554499652, 0.31463556491594535, 0.4034614446708277, 0.054947164868230446]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.22695582554499652, 0.31463556491594535, 0.4034614446708277, 0.054947164868230446]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 7.517685104213111
from probs:  [0.2748642274420259, 0.1699569060728732, 0.4887928827830467, 0.06638598370205419]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3080539806258118, 0.19043306944544808, 0.4272024361072172, 0.07431051382152293]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
siam score:  -0.8449762
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
Printing some Q and Qe and total Qs values:  [[0.415]
 [0.425]
 [0.421]
 [0.425]
 [0.424]
 [0.432]
 [0.427]] [[7.983]
 [7.084]
 [7.324]
 [7.084]
 [7.464]
 [7.349]
 [7.409]] [[0.907]
 [0.625]
 [0.698]
 [0.625]
 [0.751]
 [0.728]
 [0.738]]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.3497769125832715, 0.21617371193871965, 0.3497769125832715, 0.08427246289473715]
Printing some Q and Qe and total Qs values:  [[0.372]
 [0.189]
 [0.349]
 [0.353]
 [0.347]
 [0.345]
 [0.344]] [[0.442]
 [2.562]
 [1.482]
 [0.651]
 [1.371]
 [1.277]
 [1.126]] [[0.372]
 [0.189]
 [0.349]
 [0.353]
 [0.347]
 [0.345]
 [0.344]]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
siam score:  -0.8466213
Printing some Q and Qe and total Qs values:  [[-0.022]
 [-0.09 ]
 [-0.022]
 [-0.017]
 [-0.015]
 [-0.015]
 [-0.018]] [[9.439]
 [7.128]
 [9.124]
 [9.073]
 [8.962]
 [8.919]
 [8.808]] [[0.94 ]
 [0.309]
 [0.868]
 [0.862]
 [0.839]
 [0.829]
 [0.8  ]]
535 247
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.3497769302009904, 0.21617370596597632, 0.3497769302009904, 0.08427243363204294]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.4038093604376258, 0.2495085962925316, 0.2495085962925316, 0.09717344697731109]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.4038093604376258, 0.2495085962925316, 0.2495085962925316, 0.09717344697731109]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.2950651958635277, 0.2950651958635277, 0.2950651958635277, 0.11480441240941688]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.578]
 [0.621]
 [0.578]
 [0.578]
 [0.578]
 [0.582]
 [0.578]] [[3.949]
 [5.241]
 [3.949]
 [3.949]
 [3.949]
 [3.855]
 [3.949]] [[0.578]
 [0.621]
 [0.578]
 [0.578]
 [0.578]
 [0.582]
 [0.578]]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
Printing some Q and Qe and total Qs values:  [[0.197]
 [0.168]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]] [[9.753]
 [9.126]
 [9.029]
 [9.029]
 [9.029]
 [9.029]
 [9.029]] [[1.688]
 [1.502]
 [1.738]
 [1.738]
 [1.738]
 [1.738]
 [1.738]]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.13995312356553954, 0.3600468764344605, 0.3600468764344605, 0.13995312356553954]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.13995312356553954, 0.3600468764344605, 0.3600468764344605, 0.13995312356553954]
maxi score, test score, baseline:  -0.9958183673469387 -1.0 -0.9958183673469387
probs:  [0.13995309140862316, 0.36004690859137684, 0.36004690859137684, 0.13995309140862316]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.24951296452947405, 0.4034161732158684, 0.24951296452947405, 0.09755789772518338]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.24951296452947405, 0.4034161732158684, 0.24951296452947405, 0.09755789772518338]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
Printing some Q and Qe and total Qs values:  [[0.895]
 [0.838]
 [0.822]
 [0.812]
 [0.822]
 [0.811]
 [0.807]] [[5.214]
 [4.245]
 [4.307]
 [4.098]
 [4.064]
 [4.144]
 [4.266]] [[1.598]
 [1.159]
 [1.149]
 [1.06 ]
 [1.067]
 [1.072]
 [1.104]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.29493153445404907, 0.29493153445404907, 0.29493153445404907, 0.11520539663785284]
Printing some Q and Qe and total Qs values:  [[0.812]
 [0.794]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]] [[6.845]
 [7.063]
 [6.845]
 [6.845]
 [6.845]
 [6.845]
 [6.845]] [[1.911]
 [1.949]
 [1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]]
Printing some Q and Qe and total Qs values:  [[0.714]
 [0.739]
 [0.739]
 [0.739]
 [0.739]
 [0.739]
 [0.739]] [[8.73 ]
 [7.147]
 [7.147]
 [7.147]
 [7.147]
 [7.147]
 [7.147]] [[2.033]
 [1.55 ]
 [1.55 ]
 [1.55 ]
 [1.55 ]
 [1.55 ]
 [1.55 ]]
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]] [[8.33 ]
 [7.446]
 [7.446]
 [7.446]
 [7.446]
 [7.446]
 [7.446]] [[1.351]
 [0.973]
 [0.973]
 [0.973]
 [0.973]
 [0.973]
 [0.973]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.29493153445404907, 0.29493153445404907, 0.29493153445404907, 0.11520539663785284]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.1403513814769839, 0.3596486185230161, 0.3596486185230161, 0.1403513814769839]
Printing some Q and Qe and total Qs values:  [[0.995]
 [0.957]
 [0.995]
 [0.995]
 [0.995]
 [0.995]
 [0.995]] [[5.017]
 [5.882]
 [5.017]
 [5.017]
 [5.017]
 [5.017]
 [5.017]] [[2.204]
 [2.632]
 [2.204]
 [2.204]
 [2.204]
 [2.204]
 [2.204]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.179696702584543, 0.46090989224637097, 0.179696702584543, 0.179696702584543]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.179696702584543, 0.46090989224637097, 0.179696702584543, 0.179696702584543]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.179696702584543, 0.46090989224637097, 0.179696702584543, 0.179696702584543]
siam score:  -0.84647834
from probs:  [0.179696702584543, 0.46090989224637097, 0.179696702584543, 0.179696702584543]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]] [[6.546]
 [5.931]
 [5.931]
 [5.931]
 [5.931]
 [5.931]
 [5.931]] [[1.527]
 [1.195]
 [1.195]
 [1.195]
 [1.195]
 [1.195]
 [1.195]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.18002159688053737, 0.18002159688053737, 0.18002159688053737, 0.45993520935838783]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.18002159688053737, 0.18002159688053737, 0.18002159688053737, 0.45993520935838783]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.18002159688053737, 0.18002159688053737, 0.18002159688053737, 0.45993520935838783]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.24952151870433556, 0.09832142927424026, 0.24952151870433556, 0.4026355333170885]
maxi score, test score, baseline:  -0.9958677419354839 -1.0 -0.9958677419354839
probs:  [0.294666446645542, 0.11600066006337408, 0.294666446645542, 0.294666446645542]
maxi score, test score, baseline:  -0.9958677419354839 -1.0 -0.9958677419354839
probs:  [0.294666446645542, 0.11600066006337408, 0.294666446645542, 0.294666446645542]
maxi score, test score, baseline:  -0.9958677419354839 -1.0 -0.9958677419354839
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.2946664572973508, 0.11600062810794766, 0.2946664572973508, 0.2946664572973508]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.2946664572973508, 0.11600062810794766, 0.2946664572973508, 0.2946664572973508]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.2946664572973508, 0.11600062810794766, 0.2946664572973508, 0.2946664572973508]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
Printing some Q and Qe and total Qs values:  [[0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]] [[7.641]
 [7.641]
 [7.641]
 [7.641]
 [7.641]
 [7.641]
 [7.641]] [[1.591]
 [1.591]
 [1.591]
 [1.591]
 [1.591]
 [1.591]
 [1.591]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.2946664572973508, 0.11600062810794766, 0.2946664572973508, 0.2946664572973508]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.2946664572973508, 0.11600062810794766, 0.2946664572973508, 0.2946664572973508]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.2946664572973508, 0.11600062810794766, 0.2946664572973508, 0.2946664572973508]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.2946664572973508, 0.11600062810794766, 0.2946664572973508, 0.2946664572973508]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3588603351235496, 0.1411396648764504, 0.3588603351235496, 0.1411396648764504]
UNIT TEST: sample policy line 217 mcts : [0.143 0.286 0.245 0.02  0.02  0.184 0.102]
siam score:  -0.8484327
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.40224820414126755, 0.24952570652915468, 0.24952570652915468, 0.09870038280042318]
UNIT TEST: sample policy line 217 mcts : [0.408 0.041 0.082 0.102 0.061 0.102 0.204]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.40224823492677736, 0.24952570643324945, 0.24952570643324945, 0.09870035220672371]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.772]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]] [[9.307]
 [9.221]
 [9.221]
 [9.221]
 [9.221]
 [9.221]
 [9.221]] [[2.109]
 [2.088]
 [2.088]
 [2.088]
 [2.088]
 [2.088]
 [2.088]]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.4738522131894996, 0.2938761516488789, 0.11613581758081074, 0.11613581758081074]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.4738522131894996, 0.2938761516488789, 0.11613581758081074, 0.11613581758081074]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.4738522131894996, 0.2938761516488789, 0.11613581758081074, 0.11613581758081074]
line 256 mcts: sample exp_bonus 4.363778641409634
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.4738522131894996, 0.2938761516488789, 0.11613581758081074, 0.11613581758081074]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.4738522131894996, 0.2938761516488789, 0.11613581758081074, 0.11613581758081074]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.4738522131894996, 0.2938761516488789, 0.11613581758081074, 0.11613581758081074]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.47385226610366776, 0.2938761620203184, 0.11613578593800689, 0.11613578593800689]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.4011073257752018, 0.4011073257752018, 0.0988926742247982, 0.0988926742247982]
siam score:  -0.83826876
siam score:  -0.8372104
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.4011073257752018, 0.4011073257752018, 0.0988926742247982, 0.0988926742247982]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.4731895946091177, 0.2937518063873981, 0.11652929950174208, 0.11652929950174208]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.4731895946091177, 0.2937518063873981, 0.11652929950174208, 0.11652929950174208]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.804]
 [0.826]
 [0.79 ]
 [0.785]
 [0.783]
 [0.784]
 [0.784]] [[6.935]
 [6.448]
 [6.387]
 [6.268]
 [6.131]
 [6.139]
 [6.229]] [[1.309]
 [1.19 ]
 [1.097]
 [1.047]
 [0.999]
 [1.002]
 [1.033]]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.18097877387758146, 0.45706367836725564, 0.18097877387758146, 0.18097877387758146]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.18097877387758146, 0.45706367836725564, 0.18097877387758146, 0.18097877387758146]
rdn beta is 0 so we're just using the maxi policy
560 255
Printing some Q and Qe and total Qs values:  [[0.456]
 [0.462]
 [0.462]
 [0.45 ]
 [0.455]
 [0.452]
 [0.462]] [[2.854]
 [2.758]
 [2.758]
 [2.589]
 [2.684]
 [2.675]
 [2.758]] [[0.456]
 [0.462]
 [0.462]
 [0.45 ]
 [0.455]
 [0.452]
 [0.462]]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.11692058240834458, 0.47253073745738894, 0.2936280977259219, 0.11692058240834458]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.11692055060550009, 0.4725307906369891, 0.29362810815201074, 0.11692055060550009]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.11692055060550009, 0.4725307906369891, 0.29362810815201074, 0.11692055060550009]
Printing some Q and Qe and total Qs values:  [[0.354]
 [0.38 ]
 [0.379]
 [0.38 ]
 [0.362]
 [0.38 ]
 [0.354]] [[3.667]
 [3.303]
 [3.383]
 [3.303]
 [3.602]
 [3.303]
 [3.678]] [[0.805]
 [0.616]
 [0.667]
 [0.616]
 [0.778]
 [0.616]
 [0.813]]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.1423016224734006, 0.3576983775265994, 0.3576983775265994, 0.1423016224734006]
Printing some Q and Qe and total Qs values:  [[ 0.11 ]
 [-0.005]
 [ 0.191]
 [ 0.187]
 [ 0.158]
 [ 0.107]
 [ 0.191]] [[3.756]
 [2.773]
 [3.223]
 [3.425]
 [3.384]
 [3.492]
 [3.223]] [[ 0.305]
 [-0.579]
 [ 0.113]
 [ 0.239]
 [ 0.155]
 [ 0.125]
 [ 0.113]]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.1423016224734006, 0.3576983775265994, 0.3576983775265994, 0.1423016224734006]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.1423016224734006, 0.3576983775265994, 0.3576983775265994, 0.1423016224734006]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.03 ]
 [0.032]] [[8.168]
 [8.047]
 [8.047]
 [8.047]
 [8.047]
 [7.412]
 [8.047]] [[1.26 ]
 [1.224]
 [1.224]
 [1.224]
 [1.224]
 [0.946]
 [1.224]]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.18129216978747842, 0.45612349063756474, 0.18129216978747842, 0.18129216978747842]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.18129216978747842, 0.45612349063756474, 0.18129216978747842, 0.18129216978747842]
siam score:  -0.8399126
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.18129216978747842, 0.45612349063756474, 0.18129216978747842, 0.18129216978747842]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9959474308300396 -1.0 -0.9959474308300396
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9959474308300396 -1.0 -0.9959474308300396
probs:  [0.11756416922996077, 0.29414527692334635, 0.29414527692334635, 0.29414527692334635]
maxi score, test score, baseline:  -0.9959474308300396 -1.0 -0.9959474308300396
maxi score, test score, baseline:  -0.9959474308300396 -1.0 -0.9959474308300396
probs:  [0.11756416922996077, 0.29414527692334635, 0.29414527692334635, 0.29414527692334635]
maxi score, test score, baseline:  -0.9959629921259843 -1.0 -0.9959629921259843
probs:  [0.07709694204745159, 0.30763435265084943, 0.30763435265084943, 0.30763435265084943]
maxi score, test score, baseline:  -0.9959629921259843 -1.0 -0.9959629921259843
probs:  [0.07709694204745159, 0.30763435265084943, 0.30763435265084943, 0.30763435265084943]
siam score:  -0.83711106
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.0770969152420636, 0.3076343615859788, 0.3076343615859788, 0.3076343615859788]
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]] [[6.928]
 [6.799]
 [6.799]
 [6.799]
 [6.799]
 [6.799]
 [6.799]] [[2.082]
 [1.997]
 [1.997]
 [1.997]
 [1.997]
 [1.997]
 [1.997]]
Printing some Q and Qe and total Qs values:  [[1.402]
 [1.205]
 [1.205]
 [1.205]
 [1.205]
 [1.205]
 [1.205]] [[4.66 ]
 [5.021]
 [5.021]
 [5.021]
 [5.021]
 [5.021]
 [5.021]] [[2.309]
 [2.293]
 [2.293]
 [2.293]
 [2.293]
 [2.293]
 [2.293]]
first move QE:  1.9162900922621435
siam score:  -0.83740187
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.10019822686892664, 0.2495418906020464, 0.2495418906020464, 0.40071799192698054]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.06938121327038972, 0.27526136877337193, 0.27526136877337193, 0.3800960491828665]
Printing some Q and Qe and total Qs values:  [[0.991]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]] [[5.614]
 [5.919]
 [5.919]
 [5.919]
 [5.919]
 [5.919]
 [5.919]] [[1.589]
 [1.25 ]
 [1.25 ]
 [1.25 ]
 [1.25 ]
 [1.25 ]
 [1.25 ]]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.06938121327038972, 0.27526136877337193, 0.27526136877337193, 0.3800960491828665]
using explorer policy with actor:  1
siam score:  -0.8408723
siam score:  -0.84124815
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.07731692499671658, 0.3070882971362475, 0.19150633418120877, 0.4240884436858271]
Starting evaluation
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.06315787495635773, 0.3438463480871714, 0.2491494288692993, 0.3438463480871714]
Printing some Q and Qe and total Qs values:  [[0.428]
 [0.28 ]
 [0.428]
 [0.423]
 [0.425]
 [0.429]
 [0.432]] [[4.966]
 [2.896]
 [4.324]
 [5.297]
 [5.339]
 [5.246]
 [4.734]] [[0.428]
 [0.28 ]
 [0.428]
 [0.423]
 [0.425]
 [0.429]
 [0.432]]
Printing some Q and Qe and total Qs values:  [[0.365]
 [0.377]
 [0.366]
 [0.366]
 [0.367]
 [0.367]
 [0.367]] [[1.373]
 [1.219]
 [1.448]
 [1.282]
 [1.372]
 [1.266]
 [1.476]] [[0.365]
 [0.377]
 [0.366]
 [0.366]
 [0.367]
 [0.367]
 [0.367]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.338]
 [0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.351]] [[5.957]
 [5.582]
 [5.582]
 [5.582]
 [5.582]
 [5.582]
 [5.582]] [[1.689]
 [1.444]
 [1.444]
 [1.444]
 [1.444]
 [1.444]
 [1.444]]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.07764498392439483, 0.30698273036031254, 0.19162308079766832, 0.42374920491762424]
Printing some Q and Qe and total Qs values:  [[0.355]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]] [[1.178]
 [1.156]
 [1.156]
 [1.156]
 [1.156]
 [1.156]
 [1.156]] [[0.355]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.07764498392439483, 0.30698273036031254, 0.19162308079766832, 0.42374920491762424]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.189]
 [0.199]
 [0.199]
 [0.199]
 [0.191]
 [0.199]
 [0.199]] [[1.099]
 [1.399]
 [1.399]
 [1.399]
 [1.281]
 [1.399]
 [1.399]] [[0.189]
 [0.199]
 [0.199]
 [0.199]
 [0.191]
 [0.199]
 [0.199]]
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.307]
 [0.353]
 [0.353]
 [0.355]
 [0.353]
 [0.355]] [[1.261]
 [4.528]
 [1.306]
 [1.237]
 [1.281]
 [1.161]
 [1.251]] [[0.347]
 [0.307]
 [0.353]
 [0.353]
 [0.355]
 [0.353]
 [0.355]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.43 ]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]] [[5.426]
 [6.886]
 [6.886]
 [6.886]
 [6.886]
 [6.886]
 [6.886]] [[0.43 ]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.492298670776548
Printing some Q and Qe and total Qs values:  [[0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]] [[4.542]
 [4.542]
 [4.542]
 [4.542]
 [4.542]
 [4.542]
 [4.542]] [[0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.07764498392439483, 0.30698273036031254, 0.19162308079766832, 0.42374920491762424]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.07764498392439483, 0.30698273036031254, 0.19162308079766832, 0.42374920491762424]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.07764498392439483, 0.30698273036031254, 0.19162308079766832, 0.42374920491762424]
Printing some Q and Qe and total Qs values:  [[0.633]
 [0.562]
 [0.639]
 [0.634]
 [0.633]
 [0.642]
 [0.643]] [[8.39 ]
 [8.337]
 [7.785]
 [7.95 ]
 [7.893]
 [7.698]
 [7.356]] [[1.738]
 [1.636]
 [1.512]
 [1.57 ]
 [1.547]
 [1.482]
 [1.351]]
Printing some Q and Qe and total Qs values:  [[0.33 ]
 [0.114]
 [0.114]
 [0.114]
 [0.114]
 [0.114]
 [0.114]] [[9.122]
 [9.487]
 [9.487]
 [9.487]
 [9.487]
 [9.487]
 [9.487]] [[1.556]
 [1.57 ]
 [1.57 ]
 [1.57 ]
 [1.57 ]
 [1.57 ]
 [1.57 ]]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.07764498392439483, 0.30698273036031254, 0.19162308079766832, 0.42374920491762424]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.882]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]] [[2.068]
 [2.339]
 [2.339]
 [2.339]
 [2.339]
 [2.339]
 [2.339]] [[0.882]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]]
maxi score, test score, baseline:  -0.995978431372549 -1.0 -0.995978431372549
probs:  [0.07764498392439483, 0.30698273036031254, 0.19162308079766832, 0.42374920491762424]
line 256 mcts: sample exp_bonus 3.5394758992528765
Printing some Q and Qe and total Qs values:  [[0.188]
 [0.134]
 [0.185]
 [0.185]
 [0.185]
 [0.186]
 [0.187]] [[0.512]
 [4.093]
 [0.753]
 [0.423]
 [0.587]
 [0.758]
 [0.811]] [[0.188]
 [0.134]
 [0.185]
 [0.185]
 [0.185]
 [0.186]
 [0.187]]
Printing some Q and Qe and total Qs values:  [[0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]] [[3.892]
 [3.892]
 [3.892]
 [3.892]
 [3.892]
 [3.892]
 [3.892]] [[0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]]
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.437]
 [0.437]
 [0.437]
 [0.437]
 [0.437]
 [0.437]] [[5.167]
 [5.466]
 [5.466]
 [5.466]
 [5.466]
 [5.466]
 [5.466]] [[0.451]
 [0.437]
 [0.437]
 [0.437]
 [0.437]
 [0.437]
 [0.437]]
Printing some Q and Qe and total Qs values:  [[0.386]
 [0.376]
 [0.361]
 [0.363]
 [0.365]
 [0.368]
 [0.372]] [[7.738]
 [7.144]
 [7.673]
 [7.514]
 [7.477]
 [7.429]
 [7.494]] [[1.131]
 [0.86 ]
 [1.071]
 [1.004]
 [0.99 ]
 [0.974]
 [1.006]]
Printing some Q and Qe and total Qs values:  [[0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]] [[5.563]
 [5.563]
 [5.563]
 [5.563]
 [5.563]
 [5.563]
 [5.563]] [[0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]]
Printing some Q and Qe and total Qs values:  [[0.366]
 [0.314]
 [0.363]
 [0.364]
 [0.364]
 [0.364]
 [0.365]] [[0.562]
 [5.087]
 [0.752]
 [0.494]
 [0.608]
 [0.718]
 [0.779]] [[0.366]
 [0.314]
 [0.363]
 [0.364]
 [0.364]
 [0.364]
 [0.365]]
Printing some Q and Qe and total Qs values:  [[0.844]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]] [[3.291]
 [3.454]
 [3.454]
 [3.454]
 [3.454]
 [3.454]
 [3.454]] [[0.844]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]]
line 256 mcts: sample exp_bonus 4.026543582429294
maxi score, test score, baseline:  -0.99599375 -1.0 -0.99599375
line 256 mcts: sample exp_bonus 3.512911146779887
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.357]
 [0.355]
 [0.355]
 [0.357]
 [0.354]
 [0.355]] [[0.361]
 [0.63 ]
 [0.743]
 [0.707]
 [0.63 ]
 [0.702]
 [0.757]] [[0.358]
 [0.357]
 [0.355]
 [0.355]
 [0.357]
 [0.354]
 [0.355]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]] [[4.815]
 [4.939]
 [4.939]
 [4.939]
 [4.939]
 [4.939]
 [4.939]] [[0.591]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]]
maxi score, test score, baseline:  -0.99599375 -1.0 -0.99599375
probs:  [0.07764495690473003, 0.30698273929335473, 0.19162307164606324, 0.423749232155852]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.8582454608462871
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.319]
 [0.354]
 [0.353]
 [0.353]
 [0.353]
 [0.351]] [[0.366]
 [4.374]
 [0.569]
 [0.565]
 [0.756]
 [0.653]
 [0.988]] [[0.356]
 [0.319]
 [0.354]
 [0.353]
 [0.353]
 [0.353]
 [0.351]]
maxi score, test score, baseline:  -0.9960089494163424 -1.0 -0.9960089494163424
probs:  [0.07764493009655814, 0.30698274815646903, 0.19162306256609413, 0.42374925918087875]
Printing some Q and Qe and total Qs values:  [[0.354]
 [0.324]
 [0.355]
 [0.353]
 [0.353]
 [0.353]
 [0.353]] [[0.546]
 [4.991]
 [0.606]
 [0.615]
 [0.753]
 [0.652]
 [0.974]] [[0.354]
 [0.324]
 [0.355]
 [0.353]
 [0.353]
 [0.353]
 [0.353]]
Printing some Q and Qe and total Qs values:  [[0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]] [[0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]] [[0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]]
maxi score, test score, baseline:  -0.9960089494163424 -1.0 -0.9960089494163424
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]] [[3.738]
 [4.907]
 [4.907]
 [4.907]
 [4.907]
 [4.907]
 [4.907]] [[0.739]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]]
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.319]
 [0.354]
 [0.353]
 [0.354]
 [0.351]
 [0.353]] [[0.369]
 [4.374]
 [0.645]
 [0.617]
 [0.718]
 [0.691]
 [0.972]] [[0.356]
 [0.319]
 [0.354]
 [0.353]
 [0.354]
 [0.351]
 [0.353]]
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.339]
 [0.43 ]
 [0.43 ]
 [0.431]
 [0.43 ]
 [0.438]] [[3.668]
 [3.194]
 [5.138]
 [4.999]
 [4.943]
 [5.066]
 [5.058]] [[0.703]
 [0.339]
 [0.43 ]
 [0.43 ]
 [0.431]
 [0.43 ]
 [0.438]]
Printing some Q and Qe and total Qs values:  [[0.609]
 [0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]] [[5.135]
 [5.32 ]
 [5.32 ]
 [5.32 ]
 [5.32 ]
 [5.32 ]
 [5.32 ]] [[0.609]
 [0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]]
maxi score, test score, baseline:  -0.9960089494163424 -1.0 -0.9960089494163424
probs:  [0.07764493009655814, 0.30698274815646903, 0.19162306256609413, 0.42374925918087875]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]] [[4.657]
 [4.657]
 [4.657]
 [4.657]
 [4.657]
 [4.657]
 [4.657]] [[0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]]
line 256 mcts: sample exp_bonus 0.23873521433204248
Printing some Q and Qe and total Qs values:  [[0.491]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]] [[5.105]
 [5.144]
 [5.144]
 [5.144]
 [5.144]
 [5.144]
 [5.144]] [[0.491]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]]
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.08768536265111213, 0.21659383977080998, 0.21659383977080998, 0.47912695780726794]
Printing some Q and Qe and total Qs values:  [[0.421]
 [0.421]
 [0.421]
 [0.421]
 [0.421]
 [0.421]
 [0.421]] [[4.552]
 [4.552]
 [4.552]
 [4.552]
 [4.552]
 [4.552]
 [4.552]] [[0.421]
 [0.421]
 [0.421]
 [0.421]
 [0.421]
 [0.421]
 [0.421]]
Printing some Q and Qe and total Qs values:  [[0.492]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]] [[4.535]
 [4.846]
 [4.846]
 [4.846]
 [4.846]
 [4.846]
 [4.846]] [[0.492]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]]
Printing some Q and Qe and total Qs values:  [[0.463]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]] [[3.66 ]
 [4.851]
 [4.851]
 [4.851]
 [4.851]
 [4.851]
 [4.851]] [[0.463]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]]
Printing some Q and Qe and total Qs values:  [[0.473]
 [0.45 ]
 [0.45 ]
 [0.45 ]
 [0.45 ]
 [0.45 ]
 [0.45 ]] [[4.556]
 [4.79 ]
 [4.79 ]
 [4.79 ]
 [4.79 ]
 [4.79 ]
 [4.79 ]] [[0.473]
 [0.45 ]
 [0.45 ]
 [0.45 ]
 [0.45 ]
 [0.45 ]
 [0.45 ]]
Printing some Q and Qe and total Qs values:  [[0.376]
 [0.377]
 [0.368]
 [0.377]
 [0.377]
 [0.377]
 [0.367]] [[0.654]
 [0.79 ]
 [0.513]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.611]] [[0.376]
 [0.377]
 [0.368]
 [0.377]
 [0.377]
 [0.377]
 [0.367]]
Printing some Q and Qe and total Qs values:  [[0.483]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]] [[4.838]
 [4.776]
 [4.776]
 [4.776]
 [4.776]
 [4.776]
 [4.776]] [[0.483]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]]
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.08768536265111213, 0.21659383977080998, 0.21659383977080998, 0.47912695780726794]
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.446]
 [0.449]
 [0.448]
 [0.447]
 [0.446]
 [0.458]] [[3.646]
 [4.811]
 [3.794]
 [3.765]
 [3.8  ]
 [3.728]
 [3.856]] [[0.513]
 [0.446]
 [0.449]
 [0.448]
 [0.447]
 [0.446]
 [0.458]]
Printing some Q and Qe and total Qs values:  [[0.482]
 [0.496]
 [0.496]
 [0.496]
 [0.442]
 [0.44 ]
 [0.439]] [[4.311]
 [3.829]
 [3.829]
 [3.829]
 [3.946]
 [3.956]
 [4.378]] [[0.482]
 [0.496]
 [0.496]
 [0.496]
 [0.442]
 [0.44 ]
 [0.439]]
Printing some Q and Qe and total Qs values:  [[0.383]
 [0.374]
 [0.374]
 [0.374]
 [0.374]
 [0.374]
 [0.369]] [[0.164]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.47 ]] [[0.383]
 [0.374]
 [0.374]
 [0.374]
 [0.374]
 [0.374]
 [0.369]]
Printing some Q and Qe and total Qs values:  [[0.381]
 [0.374]
 [0.369]
 [0.369]
 [0.368]
 [0.368]
 [0.368]] [[0.278]
 [0.57 ]
 [0.49 ]
 [0.504]
 [0.493]
 [0.465]
 [0.45 ]] [[0.381]
 [0.374]
 [0.369]
 [0.369]
 [0.368]
 [0.368]
 [0.368]]
Printing some Q and Qe and total Qs values:  [[0.47 ]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]] [[4.514]
 [4.396]
 [4.396]
 [4.396]
 [4.396]
 [4.396]
 [4.396]] [[0.47 ]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]]
Printing some Q and Qe and total Qs values:  [[0.528]
 [0.463]
 [0.466]
 [0.465]
 [0.464]
 [0.463]
 [0.475]] [[3.606]
 [4.716]
 [3.781]
 [3.764]
 [3.799]
 [3.726]
 [3.785]] [[0.528]
 [0.463]
 [0.466]
 [0.465]
 [0.464]
 [0.463]
 [0.475]]
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.11846355912082242, 0.11846355912082242, 0.2931397180348205, 0.46993316372353466]
line 256 mcts: sample exp_bonus 3.7157747753721946
Printing some Q and Qe and total Qs values:  [[0.621]
 [0.521]
 [0.521]
 [0.521]
 [0.521]
 [0.521]
 [0.521]] [[2.764]
 [4.018]
 [4.018]
 [4.018]
 [4.018]
 [4.018]
 [4.018]] [[0.621]
 [0.521]
 [0.521]
 [0.521]
 [0.521]
 [0.521]
 [0.521]]
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.11846355912082242, 0.11846355912082242, 0.2931397180348205, 0.46993316372353466]
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.11846355912082242, 0.11846355912082242, 0.2931397180348205, 0.46993316372353466]
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]] [[4.098]
 [3.729]
 [3.729]
 [3.729]
 [3.729]
 [3.729]
 [3.729]] [[0.451]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.11846355912082242, 0.11846355912082242, 0.2931397180348205, 0.46993316372353466]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.6673082045864178
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.11846355912082242, 0.11846355912082242, 0.2931397180348205, 0.46993316372353466]
line 256 mcts: sample exp_bonus 2.418560220367348
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.11846355912082242, 0.11846355912082242, 0.2931397180348205, 0.46993316372353466]
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.07797178121421262, 0.19173931136627112, 0.3068775346526904, 0.4234113727668259]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9960240310077519 -1.0 -0.9960240310077519
probs:  [0.07797178121421262, 0.19173931136627112, 0.3068775346526904, 0.4234113727668259]
Printing some Q and Qe and total Qs values:  [[0.489]
 [0.489]
 [0.489]
 [0.489]
 [0.489]
 [0.489]
 [0.489]] [[4.9]
 [4.9]
 [4.9]
 [4.9]
 [4.9]
 [4.9]
 [4.9]] [[0.489]
 [0.489]
 [0.489]
 [0.489]
 [0.489]
 [0.489]
 [0.489]]
maxi score, test score, baseline:  -0.9960832061068703 -1.0 -0.9960832061068703
probs:  [0.08789783365703824, 0.08789783365703824, 0.3463215771023413, 0.47788275558358223]
maxi score, test score, baseline:  -0.9960832061068703 -1.0 -0.9960832061068703
probs:  [0.08789783365703824, 0.08789783365703824, 0.3463215771023413, 0.47788275558358223]
Printing some Q and Qe and total Qs values:  [[0.474]
 [0.469]
 [0.47 ]
 [0.469]
 [0.47 ]
 [0.468]
 [0.469]] [[3.448]
 [3.817]
 [3.497]
 [3.468]
 [3.477]
 [3.481]
 [3.486]] [[0.474]
 [0.469]
 [0.47 ]
 [0.469]
 [0.47 ]
 [0.468]
 [0.469]]
UNIT TEST: sample policy line 217 mcts : [0.755 0.02  0.02  0.02  0.02  0.143 0.02 ]
maxi score, test score, baseline:  -0.9961546816479401 -1.0 -0.9961546816479401
probs:  [0.10112325904893282, 0.10112325904893282, 0.3988767409510672, 0.3988767409510672]
maxi score, test score, baseline:  -0.9961825278810409 -1.0 -0.9961825278810409
probs:  [0.1011232033317535, 0.1011232033317535, 0.3988767966682465, 0.3988767966682465]
maxi score, test score, baseline:  -0.9961962962962964 -1.0 -0.9961962962962964
probs:  [0.10112317578441475, 0.10112317578441475, 0.3988768242155853, 0.3988768242155853]
rdn probs:  [0.10112317578441475, 0.10112317578441475, 0.3988768242155853, 0.3988768242155853]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.10112304106919046, 0.10112304106919046, 0.39887695893080954, 0.39887695893080954]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.10112304106919046, 0.10112304106919046, 0.39887695893080954, 0.39887695893080954]
Printing some Q and Qe and total Qs values:  [[0.463]
 [0.408]
 [0.398]
 [0.401]
 [0.396]
 [0.396]
 [0.399]] [[3.474]
 [4.562]
 [3.331]
 [3.277]
 [3.393]
 [3.38 ]
 [3.315]] [[0.463]
 [0.408]
 [0.398]
 [0.401]
 [0.396]
 [0.396]
 [0.399]]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.191854939027417, 0.07829705532021843, 0.4230752082625654, 0.30677279738979923]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.191854939027417, 0.07829705532021843, 0.4230752082625654, 0.30677279738979923]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.191854939027417, 0.07829705532021843, 0.4230752082625654, 0.30677279738979923]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.191854939027417, 0.07829705532021843, 0.4230752082625654, 0.30677279738979923]
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.21674784787438156, 0.08837907455221913, 0.4781252296990176, 0.21674784787438156]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.428]
 [0.309]
 [0.419]
 [0.42 ]
 [0.421]
 [0.422]
 [0.422]] [[5.184]
 [2.995]
 [5.192]
 [5.094]
 [5.192]
 [5.294]
 [5.327]] [[1.652]
 [0.008]
 [1.649]
 [1.581]
 [1.651]
 [1.722]
 [1.745]]
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
Printing some Q and Qe and total Qs values:  [[0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]] [[0.279]
 [0.279]
 [0.279]
 [0.279]
 [0.279]
 [0.279]
 [0.279]] [[0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]]
line 256 mcts: sample exp_bonus 4.457984442750105
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.35544591527609326, 0.1445540847239068, 0.35544591527609326, 0.1445540847239068]
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.35544591527609326, 0.1445540847239068, 0.35544591527609326, 0.1445540847239068]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.3469888807398315, 0.21716124510383525, 0.3469888807398315, 0.08886099341650187]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.3469888807398315, 0.21716124510383525, 0.3469888807398315, 0.08886099341650187]
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]] [[5.743]
 [6.343]
 [6.343]
 [6.343]
 [6.343]
 [6.343]
 [6.343]] [[0.584]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]]
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.3469888807398315, 0.21716124510383525, 0.3469888807398315, 0.08886099341650187]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.34698889587187776, 0.21716123998038678, 0.34698889587187776, 0.08886096827585777]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2495609213881437, 0.2495609213881437, 0.39884764941947387, 0.1020305078042387]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2495609213881437, 0.2495609213881437, 0.39884764941947387, 0.1020305078042387]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2495609213881437, 0.2495609213881437, 0.39884764941947387, 0.1020305078042387]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2495609213881437, 0.2495609213881437, 0.39884764941947387, 0.1020305078042387]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2495609213881437, 0.2495609213881437, 0.39884764941947387, 0.1020305078042387]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.2495609213099398, 0.2495609213099398, 0.3988476759300406, 0.10203048145007984]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.30698277005157487, 0.30698277005157487, 0.30698277005157487, 0.07905168984527536]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.30698277005157487, 0.30698277005157487, 0.30698277005157487, 0.07905168984527536]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.31363020708739087, 0.31363020708739087, 0.31363020708739087, 0.05910937873782726]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.31363020708739087, 0.31363020708739087, 0.31363020708739087, 0.05910937873782726]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.31363020708739087, 0.31363020708739087, 0.31363020708739087, 0.05910937873782726]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3431145842143856, 0.3431145842143856, 0.24918081010955084, 0.06459002146167812]
Printing some Q and Qe and total Qs values:  [[0.825]
 [0.761]
 [0.761]
 [0.798]
 [0.8  ]
 [0.808]
 [0.832]] [[5.158]
 [4.79 ]
 [4.79 ]
 [5.223]
 [5.234]
 [5.268]
 [5.222]] [[2.122]
 [1.777]
 [1.777]
 [2.13 ]
 [2.14 ]
 [2.175]
 [2.176]]
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.646]
 [0.624]
 [0.621]
 [0.615]
 [0.611]
 [0.573]] [[4.676]
 [4.252]
 [4.367]
 [4.536]
 [4.587]
 [4.613]
 [4.909]] [[1.403]
 [1.146]
 [1.18 ]
 [1.285]
 [1.308]
 [1.316]
 [1.437]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.2750242813257001, 0.3787393750129416, 0.2750242813257001, 0.07121206233565824]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.2750242813257001, 0.3787393750129416, 0.2750242813257001, 0.07121206233565824]
Printing some Q and Qe and total Qs values:  [[-0.016]
 [-0.018]
 [-0.018]
 [-0.018]
 [-0.018]
 [-0.018]
 [-0.018]] [[3.738]
 [3.64 ]
 [3.64 ]
 [3.64 ]
 [3.64 ]
 [3.64 ]
 [3.64 ]] [[1.538]
 [1.443]
 [1.443]
 [1.443]
 [1.443]
 [1.443]
 [1.443]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.2750242813257001, 0.3787393750129416, 0.2750242813257001, 0.07121206233565824]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3064602331315335, 0.4220733063284973, 0.1921993596210807, 0.07926710091888847]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3064602331315335, 0.4220733063284973, 0.1921993596210807, 0.07926710091888847]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3064602331315335, 0.4220733063284973, 0.1921993596210807, 0.07926710091888847]
Printing some Q and Qe and total Qs values:  [[-0.056]
 [-0.056]
 [-0.056]
 [-0.056]
 [-0.056]
 [-0.056]
 [-0.056]] [[4.019]
 [4.019]
 [4.019]
 [4.019]
 [4.019]
 [4.019]
 [4.019]] [[0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]]
Printing some Q and Qe and total Qs values:  [[-0.051]
 [-0.067]
 [-0.065]
 [-0.068]
 [-0.068]
 [-0.072]
 [-0.071]] [[3.717]
 [3.744]
 [3.731]
 [3.753]
 [3.754]
 [3.711]
 [3.681]] [[0.797]
 [0.799]
 [0.793]
 [0.805]
 [0.805]
 [0.773]
 [0.754]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3064602331315335, 0.4220733063284973, 0.1921993596210807, 0.07926710091888847]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.34296952998040453, 0.34296952998040453, 0.24918685542291116, 0.06487408461627991]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.34296952998040453, 0.34296952998040453, 0.24918685542291116, 0.06487408461627991]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.34296952998040453, 0.34296952998040453, 0.24918685542291116, 0.06487408461627991]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.34296952998040453, 0.34296952998040453, 0.24918685542291116, 0.06487408461627991]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3409366372995168, 0.3409366372995168, 0.26716985459501535, 0.05095687080595095]
Printing some Q and Qe and total Qs values:  [[0.959]
 [0.938]
 [0.936]
 [0.936]
 [0.936]
 [0.936]
 [0.936]] [[8.63 ]
 [6.123]
 [5.902]
 [5.902]
 [5.902]
 [5.902]
 [5.902]] [[2.352]
 [1.471]
 [1.394]
 [1.394]
 [1.394]
 [1.394]
 [1.394]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3409366372995168, 0.3409366372995168, 0.26716985459501535, 0.05095687080595095]
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]] [[6.384]
 [6.387]
 [6.387]
 [6.387]
 [6.387]
 [6.387]
 [6.387]] [[1.809]
 [1.812]
 [1.812]
 [1.812]
 [1.812]
 [1.812]
 [1.812]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3409366372995168, 0.3409366372995168, 0.26716985459501535, 0.05095687080595095]
siam score:  -0.83172345
Printing some Q and Qe and total Qs values:  [[0.928]
 [0.889]
 [0.889]
 [0.889]
 [0.889]
 [0.889]
 [0.889]] [[6.772]
 [4.946]
 [4.946]
 [4.946]
 [4.946]
 [4.946]
 [4.946]] [[2.428]
 [1.401]
 [1.401]
 [1.401]
 [1.401]
 [1.401]
 [1.401]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3681270400795026, 0.2884599665375125, 0.2884599665375125, 0.05495302684547243]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3996422904234791, 0.22763646827362, 0.31313643834810934, 0.0595848029547916]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3996422904234791, 0.22763646827362, 0.31313643834810934, 0.0595848029547916]
Printing some Q and Qe and total Qs values:  [[0.823]
 [0.796]
 [0.823]
 [0.823]
 [0.823]
 [0.823]
 [0.823]] [[4.698]
 [4.914]
 [4.698]
 [4.698]
 [4.698]
 [4.698]
 [4.698]] [[2.592]
 [2.672]
 [2.592]
 [2.592]
 [2.592]
 [2.592]
 [2.592]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.3996422904234791, 0.22763646827362, 0.31313643834810934, 0.0595848029547916]
using explorer policy with actor:  1
siam score:  -0.82206833
Printing some Q and Qe and total Qs values:  [[-0.005]
 [-0.013]
 [-0.013]
 [ 0.009]
 [-0.013]
 [-0.013]
 [-0.013]] [[6.85 ]
 [6.298]
 [6.298]
 [7.283]
 [6.298]
 [6.298]
 [6.298]] [[-0.26 ]
 [-0.462]
 [-0.462]
 [-0.088]
 [-0.462]
 [-0.462]
 [-0.462]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.48169324401594993, 0.17237847410638538, 0.274284502952558, 0.0716437789251067]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.757]
 [0.773]
 [0.755]
 [0.74 ]
 [0.728]
 [0.722]
 [0.655]] [[4.743]
 [4.633]
 [4.589]
 [3.756]
 [4.315]
 [4.515]
 [4.883]] [[1.524]
 [1.52 ]
 [1.468]
 [1.16 ]
 [1.322]
 [1.377]
 [1.367]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.124]
 [0.137]
 [0.107]
 [0.114]
 [0.104]
 [0.101]
 [0.11 ]] [[3.446]
 [3.428]
 [2.838]
 [3.02 ]
 [2.836]
 [2.802]
 [3.131]] [[0.124]
 [0.137]
 [0.107]
 [0.114]
 [0.104]
 [0.101]
 [0.11 ]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[-0.052]
 [-0.049]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.065]] [[6.139]
 [6.392]
 [6.058]
 [6.058]
 [6.058]
 [6.058]
 [6.058]] [[-0.285]
 [-0.193]
 [-0.337]
 [-0.337]
 [-0.337]
 [-0.337]
 [-0.337]]
siam score:  -0.82620347
using explorer policy with actor:  1
first move QE:  2.037488925052808
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.30615068915851557, 0.08022687305444774, 0.42108286304867, 0.19253957473836664]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.30615068915851557, 0.08022687305444774, 0.42108286304867, 0.19253957473836664]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.3061506971695729, 0.08022684883280606, 0.421082887457169, 0.19253956654045212]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.3061506971695729, 0.08022684883280606, 0.421082887457169, 0.19253956654045212]
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.3061507051231002, 0.08022682478509899, 0.4210829116903973, 0.1925395584014035]
in main func line 156:  600
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.24893439833874376, 0.06565091260283057, 0.4364802907196819, 0.24893439833874376]
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.24893439833874376, 0.06565091260283057, 0.4364802907196819, 0.24893439833874376]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.27486794665336733, 0.0724136044871291, 0.37785050220613625, 0.27486794665336733]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.27486794665336733, 0.0724136044871291, 0.37785050220613625, 0.27486794665336733]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.2748679498234348, 0.0724135818491149, 0.3778505185040154, 0.2748679498234348]
Printing some Q and Qe and total Qs values:  [[0.842]
 [0.898]
 [0.841]
 [0.819]
 [0.851]
 [0.837]
 [0.825]] [[4.287]
 [4.449]
 [4.211]
 [4.381]
 [4.342]
 [4.275]
 [4.395]] [[1.156]
 [1.321]
 [1.128]
 [1.141]
 [1.191]
 [1.142]
 [1.157]]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.21759709864926452, 0.09089811359244628, 0.34575239387914464, 0.34575239387914464]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.21759709864926452, 0.09089811359244628, 0.34575239387914464, 0.34575239387914464]
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]] [[3.087]
 [5.13 ]
 [5.13 ]
 [5.13 ]
 [5.13 ]
 [5.13 ]
 [5.13 ]] [[0.81 ]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2175970883607096, 0.0908980630744961, 0.34575242428239716, 0.34575242428239716]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2175970883607096, 0.0908980630744961, 0.34575242428239716, 0.34575242428239716]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2175970883607096, 0.0908980630744961, 0.34575242428239716, 0.34575242428239716]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2175970883607096, 0.0908980630744961, 0.34575242428239716, 0.34575242428239716]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2495821596807964, 0.10417372859799678, 0.39666195204041044, 0.2495821596807964]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2495821596807964, 0.10417372859799678, 0.39666195204041044, 0.2495821596807964]
Printing some Q and Qe and total Qs values:  [[0.27]
 [0.27]
 [0.27]
 [0.27]
 [0.27]
 [0.27]
 [0.27]] [[6.432]
 [6.432]
 [6.432]
 [6.432]
 [6.432]
 [6.432]
 [6.432]] [[0.411]
 [0.411]
 [0.411]
 [0.411]
 [0.411]
 [0.411]
 [0.411]]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2495821596807964, 0.10417372859799678, 0.39666195204041044, 0.2495821596807964]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2495821596807964, 0.10417372859799678, 0.39666195204041044, 0.2495821596807964]
Printing some Q and Qe and total Qs values:  [[0.069]
 [0.054]
 [0.054]
 [0.054]
 [0.054]
 [0.049]
 [0.049]] [[5.378]
 [5.651]
 [5.651]
 [5.651]
 [5.651]
 [5.429]
 [5.613]] [[0.967]
 [1.144]
 [1.144]
 [1.144]
 [1.144]
 [0.982]
 [1.112]]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2495821596807964, 0.10417372859799678, 0.39666195204041044, 0.2495821596807964]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.021]
 [-0.026]
 [-0.026]
 [-0.026]
 [-0.036]
 [-0.026]
 [-0.027]] [[7.001]
 [6.38 ]
 [6.38 ]
 [6.38 ]
 [6.414]
 [6.38 ]
 [6.8  ]] [[1.213]
 [0.868]
 [0.868]
 [0.868]
 [0.878]
 [0.868]
 [1.098]]
Printing some Q and Qe and total Qs values:  [[-0.058]
 [-0.063]
 [-0.063]
 [-0.063]
 [-0.063]
 [-0.063]
 [-0.063]] [[6.794]
 [6.915]
 [6.915]
 [6.915]
 [6.915]
 [6.915]
 [6.915]] [[1.184]
 [1.241]
 [1.241]
 [1.241]
 [1.241]
 [1.241]
 [1.241]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.24958554180670242, 0.24958554180670242, 0.3963037422343347, 0.10452517415226047]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2925299726491326, 0.2925299726491326, 0.2925299726491326, 0.12241008205260223]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.30623986309527973, 0.30623986309527973, 0.30623986309527973, 0.08128041071416078]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.30623986309527973, 0.30623986309527973, 0.30623986309527973, 0.08128041071416078]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.34210850044917585, 0.24922161830606282, 0.34210850044917585, 0.06656138079558538]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.34210850044917585, 0.24922161830606282, 0.34210850044917585, 0.06656138079558538]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.34210850044917585, 0.24922161830606282, 0.34210850044917585, 0.06656138079558538]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.34210850044917585, 0.24922161830606282, 0.34210850044917585, 0.06656138079558538]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.34210850044917585, 0.24922161830606282, 0.34210850044917585, 0.06656138079558538]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.34210850044917585, 0.24922161830606282, 0.34210850044917585, 0.06656138079558538]
Printing some Q and Qe and total Qs values:  [[0.596]
 [0.571]
 [0.62 ]
 [0.62 ]
 [0.533]
 [0.62 ]
 [0.62 ]] [[5.516]
 [4.049]
 [4.797]
 [4.797]
 [4.251]
 [4.797]
 [4.797]] [[1.197]
 [0.602]
 [0.934]
 [0.934]
 [0.652]
 [0.934]
 [0.934]]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.34210850044917585, 0.24922161830606282, 0.34210850044917585, 0.06656138079558538]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.34210852182955115, 0.2492216181253853, 0.34210852182955115, 0.06656133821551243]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.34210852182955115, 0.2492216181253853, 0.34210852182955115, 0.06656133821551243]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.27475164404242103, 0.27475164404242103, 0.3771919742989144, 0.07330473761624368]
Printing some Q and Qe and total Qs values:  [[-0.064]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.065]] [[6.114]
 [4.872]
 [4.872]
 [4.872]
 [4.872]
 [4.872]
 [4.872]] [[0.912]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.30613524131669245, 0.30613524131669245, 0.30613524131669245, 0.08159427604992257]
siam score:  -0.8194553
maxi score, test score, baseline:  -0.9964034965034965 -1.0 -0.9964034965034965
probs:  [0.3061352492411383, 0.3061352492411383, 0.3061352492411383, 0.08159425227658526]
Printing some Q and Qe and total Qs values:  [[0.792]
 [0.711]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]] [[4.819]
 [5.187]
 [4.589]
 [4.589]
 [4.589]
 [4.589]
 [4.589]] [[0.878]
 [0.839]
 [0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.595]]
maxi score, test score, baseline:  -0.9964034965034965 -1.0 -0.9964034965034965
Printing some Q and Qe and total Qs values:  [[1.069]
 [1.073]
 [1.073]
 [1.073]
 [1.073]
 [1.073]
 [1.073]] [[4.113]
 [3.927]
 [3.927]
 [3.927]
 [3.927]
 [3.927]
 [3.927]] [[1.901]
 [1.827]
 [1.827]
 [1.827]
 [1.827]
 [1.827]
 [1.827]]
maxi score, test score, baseline:  -0.9964034965034965 -1.0 -0.9964034965034965
maxi score, test score, baseline:  -0.9964034965034965 -1.0 -0.9964034965034965
probs:  [0.24959217783217014, 0.3955925139155031, 0.24959217783217014, 0.1052231304201566]
from probs:  [0.29229153908918837, 0.29229153908918837, 0.29229153908918837, 0.12312538273243483]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.12348014981352923, 0.29217328339549026, 0.29217328339549026, 0.29217328339549026]
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]] [[3.713]
 [3.713]
 [3.713]
 [3.713]
 [3.713]
 [3.713]
 [3.713]] [[1.511]
 [1.511]
 [1.511]
 [1.511]
 [1.511]
 [1.511]
 [1.511]]
siam score:  -0.82438874
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.12348014981352923, 0.29217328339549026, 0.29217328339549026, 0.29217328339549026]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.08221874415206132, 0.30592708528264617, 0.30592708528264617, 0.30592708528264617]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
Printing some Q and Qe and total Qs values:  [[1.048]
 [0.966]
 [0.966]
 [0.966]
 [0.966]
 [0.966]
 [0.966]] [[2.922]
 [2.93 ]
 [2.93 ]
 [2.93 ]
 [2.93 ]
 [2.93 ]
 [2.93 ]] [[0.87 ]
 [0.788]
 [0.788]
 [0.788]
 [0.788]
 [0.788]
 [0.788]]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.10591473966862776, 0.24959864829991313, 0.24959864829991313, 0.394887963731546]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.12360166427769574, 0.2915074312112199, 0.12360166427769574, 0.4612892402333886]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.19331741562449298, 0.3054401414987021, 0.0824268076170352, 0.4188156352597697]
Printing some Q and Qe and total Qs values:  [[0.778]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]] [[10.]
 [10.]
 [10.]
 [10.]
 [10.]
 [10.]
 [10.]] [[1.968]
 [1.822]
 [1.822]
 [1.822]
 [1.822]
 [1.822]
 [1.822]]
Printing some Q and Qe and total Qs values:  [[0.755]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]] [[10.]
 [10.]
 [10.]
 [10.]
 [10.]
 [10.]
 [10.]] [[1.932]
 [1.788]
 [1.788]
 [1.788]
 [1.788]
 [1.788]
 [1.788]]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.2180211710844921, 0.3445461028806339, 0.09288662315424005, 0.3445461028806339]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.2180211710844921, 0.3445461028806339, 0.09288662315424005, 0.3445461028806339]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.2180211710844921, 0.3445461028806339, 0.09288662315424005, 0.3445461028806339]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
using explorer policy with actor:  1
first move QE:  2.0842392214964365
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.10609013140164737, 0.39390986859835264, 0.10609013140164737, 0.39390986859835264]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.10609013140164737, 0.39390986859835264, 0.10609013140164737, 0.39390986859835264]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.10609013140164737, 0.39390986859835264, 0.10609013140164737, 0.39390986859835264]
siam score:  -0.8194297
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.10609013140164737, 0.39390986859835264, 0.10609013140164737, 0.39390986859835264]
Printing some Q and Qe and total Qs values:  [[0.931]
 [0.809]
 [0.809]
 [0.887]
 [0.875]
 [0.809]
 [0.809]] [[4.063]
 [3.732]
 [3.732]
 [4.014]
 [3.775]
 [3.732]
 [3.732]] [[2.085]
 [1.725]
 [1.725]
 [2.005]
 [1.824]
 [1.725]
 [1.725]]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.12395391920762355, 0.2913952073450955, 0.12395391920762355, 0.4606969542396574]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.09321346488559866, 0.3443478929676326, 0.2180907491791361, 0.3443478929676326]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.106432789459641, 0.393567210540359, 0.106432789459641, 0.393567210540359]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.106432789459641, 0.393567210540359, 0.106432789459641, 0.393567210540359]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.106432789459641, 0.393567210540359, 0.106432789459641, 0.393567210540359]
from probs:  [0.106432789459641, 0.393567210540359, 0.106432789459641, 0.393567210540359]
624 289
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.12430422957079007, 0.4601079758917628, 0.12430422957079007, 0.29128356496665714]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.506921722044939
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.504]
 [0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]] [[6.962]
 [5.603]
 [5.603]
 [5.603]
 [5.603]
 [5.603]
 [5.603]] [[1.866]
 [1.285]
 [1.285]
 [1.285]
 [1.285]
 [1.285]
 [1.285]]
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.24882141185202183, 0.5379683708231117, 0.10660510866243329, 0.10660510866243329]
using another actor
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.28741410036420617, 0.4446946372430172, 0.05783525217820251, 0.21005601021457412]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.22766047737569062, 0.48205749011781884, 0.06262155513079991, 0.22766047737569062]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.22766047737569062, 0.48205749011781884, 0.06262155513079991, 0.22766047737569062]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.22766047737569062, 0.48205749011781884, 0.06262155513079991, 0.22766047737569062]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.22766047737569062, 0.48205749011781884, 0.06262155513079991, 0.22766047737569062]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.22766047495776193, 0.4820575152346723, 0.06262153484980376, 0.22766047495776193]
Printing some Q and Qe and total Qs values:  [[0.873]
 [0.883]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.873]] [[4.546]
 [5.235]
 [4.546]
 [4.546]
 [4.546]
 [4.546]
 [4.546]] [[1.425]
 [1.676]
 [1.425]
 [1.425]
 [1.425]
 [1.425]
 [1.425]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.499818768028444
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.22766047495776193, 0.4820575152346723, 0.06262153484980376, 0.22766047495776193]
from probs:  [0.22766047495776193, 0.4820575152346723, 0.06262153484980376, 0.22766047495776193]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.15775232425396032, 0.5257698625811956, 0.0682211758168222, 0.24825663734802197]
Printing some Q and Qe and total Qs values:  [[1.014]
 [0.724]
 [0.975]
 [0.974]
 [0.976]
 [0.92 ]
 [0.975]] [[3.266]
 [4.06 ]
 [2.799]
 [2.806]
 [2.858]
 [3.846]
 [2.849]] [[1.702]
 [1.877]
 [1.255]
 [1.259]
 [1.304]
 [2.022]
 [1.297]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 8.166793402746194
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.19459765049889063, 0.48543634438134736, 0.05384416495684374, 0.2661218401629183]
line 256 mcts: sample exp_bonus 5.4081903418296156
start point for exploration sampling:  10624
siam score:  -0.81368196
siam score:  -0.80853635
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.19498342358467358, 0.41198837356859364, 0.05416106242489583, 0.338867140421837]
siam score:  -0.8111255
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.19498342358467358, 0.41198837356859364, 0.05416106242489583, 0.338867140421837]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.13362152161258303, 0.44343273229250274, 0.05822863390722906, 0.3647171121876852]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.13362152161258303, 0.44343273229250274, 0.05822863390722906, 0.3647171121876852]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.13362152161258303, 0.44343273229250274, 0.05822863390722906, 0.3647171121876852]
Printing some Q and Qe and total Qs values:  [[0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]] [[3.916]
 [3.916]
 [3.916]
 [3.916]
 [3.916]
 [3.916]
 [3.916]] [[1.057]
 [1.057]
 [1.057]
 [1.057]
 [1.057]
 [1.057]
 [1.057]]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.1336215101113202, 0.4434327514087571, 0.05822861495516134, 0.3647171235247615]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.1336215101113202, 0.4434327514087571, 0.05822861495516134, 0.3647171235247615]
Printing some Q and Qe and total Qs values:  [[-0.046]
 [-0.046]
 [-0.046]
 [-0.046]
 [-0.046]
 [-0.046]
 [-0.046]] [[7.522]
 [7.522]
 [7.522]
 [7.522]
 [7.522]
 [7.522]
 [7.522]] [[0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]]
using explorer policy with actor:  1
from probs:  [0.14486893476734114, 0.48095399781945436, 0.0630822771363081, 0.31109479027689646]
Printing some Q and Qe and total Qs values:  [[0.628]
 [0.62 ]
 [0.635]
 [0.634]
 [0.64 ]
 [0.64 ]
 [0.649]] [[5.603]
 [5.673]
 [5.632]
 [5.595]
 [5.531]
 [5.462]
 [5.38 ]] [[1.585]
 [1.611]
 [1.613]
 [1.592]
 [1.565]
 [1.525]
 [1.495]]
Printing some Q and Qe and total Qs values:  [[0.853]
 [0.877]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.838]] [[5.24 ]
 [5.519]
 [5.833]
 [5.833]
 [5.833]
 [5.833]
 [5.276]] [[1.126]
 [1.267]
 [1.279]
 [1.279]
 [1.279]
 [1.279]
 [1.108]]
Printing some Q and Qe and total Qs values:  [[0.506]
 [0.424]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]] [[5.058]
 [5.112]
 [4.135]
 [4.135]
 [4.135]
 [4.135]
 [4.135]] [[1.292]
 [1.144]
 [1.256]
 [1.256]
 [1.256]
 [1.256]
 [1.256]]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.158360186948429, 0.4325621913016432, 0.06890421389702309, 0.34017340785290473]
siam score:  -0.8027657
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.575]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]] [[5.249]
 [5.303]
 [4.868]
 [4.868]
 [4.868]
 [4.868]
 [4.868]] [[0.545]
 [0.585]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.158360186948429, 0.4325621913016432, 0.06890421389702309, 0.34017340785290473]
Printing some Q and Qe and total Qs values:  [[-0.006]
 [-0.009]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.008]] [[6.891]
 [7.064]
 [6.987]
 [6.954]
 [6.773]
 [6.684]
 [6.807]] [[-0.228]
 [-0.174]
 [-0.197]
 [-0.208]
 [-0.267]
 [-0.299]
 [-0.258]]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.158360186948429, 0.4325621913016432, 0.06890421389702309, 0.34017340785290473]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.0756051428739452, 0.47514754000484366, 0.0756051428739452, 0.373642174247266]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.05847249875829436, 0.4431778184844653, 0.13377651878979746, 0.3645731639674428]
Printing some Q and Qe and total Qs values:  [[0.905]
 [0.905]
 [0.905]
 [0.905]
 [0.905]
 [0.905]
 [0.905]] [[5.219]
 [5.219]
 [5.219]
 [5.219]
 [5.219]
 [5.219]
 [5.219]] [[1.013]
 [1.013]
 [1.013]
 [1.013]
 [1.013]
 [1.013]
 [1.013]]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 8.559643577505566
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.06339711749059504, 0.39572480878028676, 0.14515326494883132, 0.39572480878028676]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.06339711749059504, 0.39572480878028676, 0.14515326494883132, 0.39572480878028676]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.06339711749059504, 0.39572480878028676, 0.14515326494883132, 0.39572480878028676]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.06339711749059504, 0.39572480878028676, 0.14515326494883132, 0.39572480878028676]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.06339711749059504, 0.39572480878028676, 0.14515326494883132, 0.39572480878028676]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.06339711749059504, 0.39572480878028676, 0.14515326494883132, 0.39572480878028676]
siam score:  -0.7912944
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.06339711749059504, 0.39572480878028676, 0.14515326494883132, 0.39572480878028676]
siam score:  -0.7938609
siam score:  -0.7959267
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.19849815335727
Printing some Q and Qe and total Qs values:  [[0.867]
 [0.867]
 [0.867]
 [0.867]
 [0.867]
 [0.867]
 [0.867]] [[4.52]
 [4.52]
 [4.52]
 [4.52]
 [4.52]
 [4.52]
 [4.52]] [[2.367]
 [2.367]
 [2.367]
 [2.367]
 [2.367]
 [2.367]
 [2.367]]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.07589316929502522, 0.3734429492527186, 0.07589316929502522, 0.47477071215723093]
from probs:  [0.08437563416246643, 0.4156243658375336, 0.08437563416246643, 0.4156243658375336]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.09489658807709675, 0.46794273636755246, 0.09489658807709675, 0.3422640874782541]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.09489658807709675, 0.46794273636755246, 0.09489658807709675, 0.3422640874782541]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.09489658807709675, 0.46794273636755246, 0.09489658807709675, 0.3422640874782541]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.09489658807709675, 0.46794273636755246, 0.09489658807709675, 0.3422640874782541]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.09489658807709675, 0.46794273636755246, 0.09489658807709675, 0.3422640874782541]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.09489658807709675, 0.46794273636755246, 0.09489658807709675, 0.3422640874782541]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.09489658807709675, 0.46794273636755246, 0.09489658807709675, 0.3422640874782541]
using explorer policy with actor:  1
644 300
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
Printing some Q and Qe and total Qs values:  [[1.112]
 [1.051]
 [1.051]
 [1.051]
 [1.051]
 [1.051]
 [1.051]] [[6.869]
 [6.313]
 [6.313]
 [6.313]
 [6.313]
 [6.313]
 [6.313]] [[2.172]
 [1.921]
 [1.921]
 [1.921]
 [1.921]
 [1.921]
 [1.921]]
Printing some Q and Qe and total Qs values:  [[0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]] [[5.285]
 [5.285]
 [5.285]
 [5.285]
 [5.285]
 [5.285]
 [5.285]] [[0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]]
first move QE:  2.122641476389397
Printing some Q and Qe and total Qs values:  [[1.015]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]] [[9.202]
 [8.29 ]
 [8.29 ]
 [8.29 ]
 [8.29 ]
 [8.29 ]
 [8.29 ]] [[2.097]
 [1.784]
 [1.784]
 [1.784]
 [1.784]
 [1.784]
 [1.784]]
from probs:  [0.10845598893192286, 0.3915440110680771, 0.10845598893192286, 0.3915440110680771]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.12636729344400457, 0.456640101010999, 0.12636729344400457, 0.29062531210099174]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.18856354005393547, 0.18856354005393547, 0.18856354005393547, 0.4343093798381936]
Printing some Q and Qe and total Qs values:  [[0.104]
 [0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.085]] [[7.113]
 [7.403]
 [7.403]
 [7.403]
 [7.403]
 [7.403]
 [7.403]] [[0.61 ]
 [0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.703]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.18856354005393547, 0.18856354005393547, 0.18856354005393547, 0.4343093798381936]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.18856354005393547, 0.18856354005393547, 0.18856354005393547, 0.4343093798381936]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.18856354005393547, 0.18856354005393547, 0.18856354005393547, 0.4343093798381936]
maxi score, test score, baseline:  -0.9965666666666667 -1.0 -0.9965666666666667
probs:  [0.3740221973684942, 0.07699097859253777, 0.17496462667047388, 0.3740221973684942]
maxi score, test score, baseline:  -0.9965666666666667 -1.0 -0.9965666666666667
probs:  [0.41471820501161466, 0.08528179498838537, 0.08528179498838537, 0.41471820501161466]
siam score:  -0.78783065
maxi score, test score, baseline:  -0.9965666666666667 -1.0 -0.9965666666666667
probs:  [0.41471820501161466, 0.08528179498838537, 0.08528179498838537, 0.41471820501161466]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
probs:  [0.3395104250667492, 0.1590723667276924, 0.070255705887224, 0.43116150231833433]
line 256 mcts: sample exp_bonus 2.2202776013922216
siam score:  -0.78825605
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
probs:  [0.3395104250667492, 0.1590723667276924, 0.070255705887224, 0.43116150231833433]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.114567205031594
siam score:  -0.78966993
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
probs:  [0.3395104250667492, 0.1590723667276924, 0.070255705887224, 0.43116150231833433]
Printing some Q and Qe and total Qs values:  [[-0.094]
 [-0.093]
 [-0.093]
 [-0.093]
 [-0.093]
 [-0.093]
 [-0.093]] [[7.251]
 [7.769]
 [7.769]
 [7.769]
 [7.769]
 [7.769]
 [7.769]] [[-0.51 ]
 [-0.335]
 [-0.335]
 [-0.335]
 [-0.335]
 [-0.335]
 [-0.335]]
using explorer policy with actor:  0
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.528]] [[2.354]
 [2.493]
 [2.493]
 [2.493]
 [2.493]
 [2.493]
 [2.493]] [[0.532]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.528]]
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
probs:  [0.24963429393225686, 0.24963429393225686, 0.10993457605437434, 0.39079683608111193]
line 256 mcts: sample exp_bonus 3.8449095492293783
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.24963429386492395, 0.24963429386492395, 0.1099345502661828, 0.39079686200396935]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
Printing some Q and Qe and total Qs values:  [[0.523]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]] [[7.838]
 [6.279]
 [6.279]
 [6.279]
 [6.279]
 [6.279]
 [6.279]] [[1.546]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.24963429386492395, 0.24963429386492395, 0.1099345502661828, 0.39079686200396935]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
first move QE:  2.1538848132934723
line 256 mcts: sample exp_bonus 2.6091659261752014
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.24963429379803814, 0.24963429379803814, 0.10993452464904697, 0.39079688775487686]
siam score:  -0.78804207
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.274182268894648, 0.274182268894648, 0.0776370195806948, 0.3739984426300093]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.22840470942268853, 0.3113645709581762, 0.06503759747588704, 0.3951931221432481]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.6548289795617785
siam score:  -0.79286253
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.19470601740586804, 0.3041625806186162, 0.086372085610689, 0.4147593163648268]
Printing some Q and Qe and total Qs values:  [[1.031]
 [1.031]
 [1.031]
 [1.031]
 [1.031]
 [1.031]
 [1.031]] [[5.28]
 [5.28]
 [5.28]
 [5.28]
 [5.28]
 [5.28]
 [5.28]] [[2.662]
 [2.662]
 [2.662]
 [2.662]
 [2.662]
 [2.662]
 [2.662]]
Printing some Q and Qe and total Qs values:  [[1.059]
 [1.083]
 [0.991]
 [0.989]
 [0.992]
 [0.99 ]
 [1.025]] [[5.113]
 [4.862]
 [4.687]
 [4.565]
 [5.017]
 [4.847]
 [4.958]] [[2.252]
 [2.153]
 [1.901]
 [1.831]
 [2.086]
 [1.99 ]
 [2.109]]
siam score:  -0.794138
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.24891678317118424, 0.11026502908273846, 0.11026502908273846, 0.5305531586633389]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.24891678317118424, 0.11026502908273846, 0.11026502908273846, 0.5305531586633389]
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.24891678317118424, 0.11026502908273846, 0.11026502908273846, 0.5305531586633389]
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.2735451501868567, 0.07804050991275967, 0.17529153610038692, 0.4731228037999967]
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.30406649661197915, 0.08666831824270027, 0.19480997620075113, 0.41445520894456944]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.582]
 [0.555]
 [0.557]
 [0.582]
 [0.582]
 [0.582]] [[4.372]
 [3.972]
 [4.176]
 [4.375]
 [3.972]
 [3.972]
 [3.972]] [[1.428]
 [1.112]
 [1.252]
 [1.424]
 [1.112]
 [1.112]
 [1.112]]
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.30406649661197915, 0.08666831824270027, 0.19480997620075113, 0.41445520894456944]
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.38980902394427774, 0.11090611172807359, 0.2496424321638244, 0.2496424321638244]
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.38980902394427774, 0.11090611172807359, 0.2496424321638244, 0.2496424321638244]
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.3898090496214586, 0.11090608618223266, 0.24964243209815437, 0.24964243209815437]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.3898090496214586, 0.11090608618223266, 0.24964243209815437, 0.24964243209815437]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.4527319281617413, 0.1286931905261716, 0.2898816907859155, 0.1286931905261716]
Printing some Q and Qe and total Qs values:  [[0.873]
 [0.966]
 [0.884]
 [0.884]
 [0.884]
 [0.884]
 [0.884]] [[3.654]
 [4.993]
 [3.852]
 [3.852]
 [3.852]
 [3.852]
 [3.852]] [[1.178]
 [1.679]
 [1.247]
 [1.247]
 [1.247]
 [1.247]
 [1.247]]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.4141522266123822, 0.0869635137219993, 0.3039707284253638, 0.19491353124025476]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.4141522266123822, 0.0869635137219993, 0.3039707284253638, 0.19491353124025476]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.4141522266123822, 0.0869635137219993, 0.3039707284253638, 0.19491353124025476]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.4141522266123822, 0.0869635137219993, 0.3039707284253638, 0.19491353124025476]
from probs:  [0.4141522266123822, 0.0869635137219993, 0.3039707284253638, 0.19491353124025476]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.29025636896106793, 0.12923089311679603, 0.29025636896106793, 0.29025636896106793]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.29025636896106793, 0.12923089311679603, 0.29025636896106793, 0.29025636896106793]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.29025636896106793, 0.12923089311679603, 0.29025636896106793, 0.29025636896106793]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]] [[5.153]
 [4.672]
 [4.672]
 [4.672]
 [4.672]
 [4.672]
 [4.672]] [[0.739]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.29025636896106793, 0.12923089311679603, 0.29025636896106793, 0.29025636896106793]
maxi score, test score, baseline:  -0.996642671009772 -1.0 -0.996642671009772
maxi score, test score, baseline:  -0.996642671009772 -1.0 -0.996642671009772
probs:  [0.1539605907982392, 0.1539605907982392, 0.34603940920176085, 0.34603940920176085]
Printing some Q and Qe and total Qs values:  [[0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]] [[5.132]
 [5.132]
 [5.132]
 [5.132]
 [5.132]
 [5.132]
 [5.132]] [[1.795]
 [1.795]
 [1.795]
 [1.795]
 [1.795]
 [1.795]
 [1.795]]
maxi score, test score, baseline:  -0.9966532467532467 -1.0 -0.9966532467532467
probs:  [0.1539605664489175, 0.1539605664489175, 0.3460394335510825, 0.3460394335510825]
Printing some Q and Qe and total Qs values:  [[0.233]
 [0.261]
 [0.292]
 [0.282]
 [0.231]
 [0.293]
 [0.277]] [[3.992]
 [1.971]
 [2.698]
 [1.47 ]
 [3.104]
 [1.89 ]
 [3.079]] [[0.233]
 [0.261]
 [0.292]
 [0.282]
 [0.231]
 [0.293]
 [0.277]]
maxi score, test score, baseline:  -0.9966532467532467 -1.0 -0.9966532467532467
probs:  [0.21909846447434073, 0.09796444521376466, 0.3414685451559473, 0.3414685451559473]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.21909845951551346, 0.09796442081631578, 0.34146855983408536, 0.34146855983408536]
Printing some Q and Qe and total Qs values:  [[0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]] [[3.307]
 [3.307]
 [3.307]
 [3.307]
 [3.307]
 [3.307]
 [3.307]] [[0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.21909845951551346, 0.09796442081631578, 0.34146855983408536, 0.34146855983408536]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.21909845951551346, 0.09796442081631578, 0.34146855983408536, 0.34146855983408536]
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.5  ]
 [0.489]
 [0.463]
 [0.459]
 [0.459]
 [0.471]] [[3.508]
 [3.632]
 [3.299]
 [3.27 ]
 [3.438]
 [3.37 ]
 [3.385]] [[0.475]
 [0.5  ]
 [0.489]
 [0.463]
 [0.459]
 [0.459]
 [0.471]]
siam score:  -0.7763263
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.21909845951551346, 0.09796442081631578, 0.34146855983408536, 0.34146855983408536]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.21909845951551346, 0.09796442081631578, 0.34146855983408536, 0.34146855983408536]
from probs:  [0.21909845951551346, 0.09796442081631578, 0.34146855983408536, 0.34146855983408536]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.21909845458882363, 0.09796439657702426, 0.3414685744170761, 0.3414685744170761]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.21909845458882363, 0.09796439657702426, 0.3414685744170761, 0.3414685744170761]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.24964770126399274, 0.11154659674951072, 0.3891580007225037, 0.24964770126399274]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.7822284
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.2496477011371626, 0.11154654690436246, 0.3891580508213123, 0.2496477011371626]
Printing some Q and Qe and total Qs values:  [[0.695]
 [0.703]
 [0.703]
 [0.694]
 [0.696]
 [0.709]
 [0.695]] [[6.879]
 [6.363]
 [6.363]
 [6.866]
 [6.742]
 [6.667]
 [6.693]] [[0.577]
 [0.42 ]
 [0.42 ]
 [0.568]
 [0.532]
 [0.534]
 [0.514]]
Printing some Q and Qe and total Qs values:  [[0.691]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]] [[7.069]
 [6.704]
 [6.704]
 [6.704]
 [6.704]
 [6.704]
 [6.704]] [[1.337]
 [1.206]
 [1.206]
 [1.206]
 [1.206]
 [1.206]
 [1.206]]
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.585]
 [0.567]
 [0.659]
 [0.685]
 [0.42 ]
 [0.554]] [[7.686]
 [8.282]
 [5.77 ]
 [5.881]
 [6.722]
 [5.166]
 [8.489]] [[0.535]
 [0.585]
 [0.567]
 [0.659]
 [0.685]
 [0.42 ]
 [0.554]]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.2496477011371626, 0.11154654690436246, 0.3891580508213123, 0.2496477011371626]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.2496477011371626, 0.11154654690436246, 0.3891580508213123, 0.2496477011371626]
in main func line 156:  680
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
probs:  [0.24964770107435652, 0.11154652222179863, 0.3891580756294884, 0.24964770107435652]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.24964770101195172, 0.11154649769719145, 0.3891581002789051, 0.24964770101195172]
siam score:  -0.77059054
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.24964770101195172, 0.11154649769719145, 0.3891581002789051, 0.24964770101195172]
Printing some Q and Qe and total Qs values:  [[-0.023]
 [-0.023]
 [-0.023]
 [-0.023]
 [-0.023]
 [-0.023]
 [-0.023]] [[6.874]
 [6.874]
 [6.874]
 [6.874]
 [6.874]
 [6.874]
 [6.874]] [[-0.27]
 [-0.27]
 [-0.27]
 [-0.27]
 [-0.27]
 [-0.27]
 [-0.27]]
Printing some Q and Qe and total Qs values:  [[0.412]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.404]
 [0.404]] [[1.625]
 [1.387]
 [1.387]
 [1.387]
 [1.387]
 [1.451]
 [1.505]] [[0.412]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.404]
 [0.404]]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.24964770101195172, 0.11154649769719145, 0.3891581002789051, 0.24964770101195172]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.24964770101195172, 0.11154649769719145, 0.3891581002789051, 0.24964770101195172]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.24964770101195172, 0.11154649769719145, 0.3891581002789051, 0.24964770101195172]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
siam score:  -0.7662518
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.12934215264053292, 0.12934215264053292, 0.45164175846853605, 0.28967393625039806]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.12934215264053292, 0.12934215264053292, 0.45164175846853605, 0.28967393625039806]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.12934215264053292, 0.12934215264053292, 0.45164175846853605, 0.28967393625039806]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.12934215264053292, 0.12934215264053292, 0.45164175846853605, 0.28967393625039806]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.12934215264053292, 0.12934215264053292, 0.45164175846853605, 0.28967393625039806]
Printing some Q and Qe and total Qs values:  [[0.824]
 [0.676]
 [0.769]
 [0.783]
 [0.815]
 [0.752]
 [0.752]] [[4.185]
 [4.163]
 [4.083]
 [3.778]
 [3.563]
 [4.903]
 [4.903]] [[1.69 ]
 [1.604]
 [1.625]
 [1.525]
 [1.466]
 [1.905]
 [1.905]]
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
probs:  [0.12934212798601416, 0.12934212798601416, 0.4516417996708297, 0.28967394435714205]
from probs:  [0.15426628401678893, 0.15426628401678893, 0.34573371598321107, 0.34573371598321107]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.2895708009654181, 0.12966417962824625, 0.45110083977808935, 0.12966417962824625]
first move QE:  2.1756329376983095
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.585]
 [0.563]
 [0.559]
 [0.559]
 [0.559]
 [0.563]] [[2.788]
 [3.652]
 [3.159]
 [3.2  ]
 [3.2  ]
 [3.2  ]
 [3.178]] [[0.626]
 [0.585]
 [0.563]
 [0.559]
 [0.559]
 [0.559]
 [0.563]]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.30368531297809, 0.08784290858047607, 0.4132499852611415, 0.19522179318029242]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.30368531297809, 0.08784290858047607, 0.4132499852611415, 0.19522179318029242]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.30368531297809, 0.08784290858047607, 0.4132499852611415, 0.19522179318029242]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.21895719296596505, 0.09845605039050506, 0.46362956367756486, 0.21895719296596505]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.21895719296596505, 0.09845605039050506, 0.46362956367756486, 0.21895719296596505]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.21895719296596505, 0.09845605039050506, 0.46362956367756486, 0.21895719296596505]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.21895719296596505, 0.09845605039050506, 0.46362956367756486, 0.21895719296596505]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.21895719296596505, 0.09845605039050506, 0.46362956367756486, 0.21895719296596505]
Printing some Q and Qe and total Qs values:  [[0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]] [[4.742]
 [4.742]
 [4.742]
 [4.742]
 [4.742]
 [4.742]
 [4.742]] [[0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]] [[3.63]
 [3.63]
 [3.63]
 [3.63]
 [3.63]
 [3.63]
 [3.63]] [[0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.21895719296596505, 0.09845605039050506, 0.46362956367756486, 0.21895719296596505]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.21895719296596505, 0.09845605039050506, 0.46362956367756486, 0.21895719296596505]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.24965284994837675, 0.11218142950558352, 0.38851287059766304, 0.24965284994837675]
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]] [[3.925]
 [4.901]
 [4.901]
 [4.901]
 [4.901]
 [4.901]
 [4.901]] [[0.535]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]]
Printing some Q and Qe and total Qs values:  [[0.896]
 [0.787]
 [0.905]
 [0.918]
 [0.752]
 [0.781]
 [0.722]] [[4.833]
 [4.292]
 [3.985]
 [3.594]
 [4.142]
 [3.802]
 [3.845]] [[2.224]
 [1.706]
 [1.611]
 [1.337]
 [1.558]
 [1.339]
 [1.306]]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.24965284982621824, 0.11218138100840909, 0.3885129193391544, 0.24965284982621824]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.24965284982621824, 0.11218138100840909, 0.3885129193391544, 0.24965284982621824]
Printing some Q and Qe and total Qs values:  [[0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]] [[3.296]
 [3.296]
 [3.296]
 [3.296]
 [3.296]
 [3.296]
 [3.296]] [[6.048]
 [6.048]
 [6.048]
 [6.048]
 [6.048]
 [6.048]
 [6.048]]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.2894681668924144, 0.1299845537353152, 0.45056272563695515, 0.1299845537353152]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
siam score:  -0.76485056
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.439]
 [0.442]
 [0.447]
 [0.448]
 [0.447]
 [0.447]] [[4.808]
 [5.08 ]
 [5.091]
 [5.021]
 [5.056]
 [5.077]
 [5.06 ]] [[0.518]
 [0.573]
 [0.583]
 [0.57 ]
 [0.583]
 [0.588]
 [0.582]]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
Printing some Q and Qe and total Qs values:  [[0.788]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]] [[4.397]
 [3.717]
 [3.717]
 [3.717]
 [3.717]
 [3.717]
 [3.717]] [[2.162]
 [1.566]
 [1.566]
 [1.566]
 [1.566]
 [1.566]
 [1.566]]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.2893660146241894, 0.13030333624421322, 0.4500273128873842, 0.13030333624421322]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.2893660146241894, 0.13030333624421322, 0.4500273128873842, 0.13030333624421322]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.2893660146241894, 0.13030333624421322, 0.4500273128873842, 0.13030333624421322]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.3407291966315471, 0.21935636405159714, 0.3407291966315471, 0.09918524268530864]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.38787342984979023, 0.24965788230806582, 0.24965788230806582, 0.11281080553407818]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.2897242386137345, 0.2897242386137345, 0.2897242386137345, 0.13082728415879663]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.155471084576777, 0.34452891542322306, 0.34452891542322306, 0.155471084576777]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.155471084576777, 0.34452891542322306, 0.34452891542322306, 0.155471084576777]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.155471084576777, 0.34452891542322306, 0.34452891542322306, 0.155471084576777]
siam score:  -0.7485365
from probs:  [0.155471084576777, 0.34452891542322306, 0.34452891542322306, 0.155471084576777]
Printing some Q and Qe and total Qs values:  [[0.191]
 [0.13 ]
 [0.144]
 [0.149]
 [0.157]
 [0.149]
 [0.152]] [[8.979]
 [6.983]
 [6.91 ]
 [6.678]
 [6.822]
 [7.121]
 [6.934]] [[1.291]
 [0.503]
 [0.508]
 [0.44 ]
 [0.503]
 [0.588]
 [0.53 ]]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.19166220924767563, 0.19166220924767563, 0.42501337225697305, 0.19166220924767563]
Printing some Q and Qe and total Qs values:  [[0.363]
 [0.291]
 [0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]] [[3.414]
 [3.885]
 [3.414]
 [3.414]
 [3.414]
 [3.414]
 [3.414]] [[0.363]
 [0.291]
 [0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.11312345723627479, 0.24966035597329034, 0.38755583081714456, 0.24966035597329034]
start point for exploration sampling:  10624
siam score:  -0.74796426
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.11312345723627479, 0.24966035597329034, 0.38755583081714456, 0.24966035597329034]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.08041559252448417, 0.2738139806242196, 0.3719564462270767, 0.2738139806242196]
Printing some Q and Qe and total Qs values:  [[0.562]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]] [[2.744]
 [2.794]
 [2.794]
 [2.794]
 [2.794]
 [2.794]
 [2.794]] [[0.562]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]]
Printing some Q and Qe and total Qs values:  [[0.538]
 [0.609]
 [0.554]
 [0.552]
 [0.523]
 [0.521]
 [0.565]] [[3.213]
 [2.997]
 [2.976]
 [3.004]
 [3.106]
 [3.022]
 [2.982]] [[0.538]
 [0.609]
 [0.554]
 [0.552]
 [0.523]
 [0.521]
 [0.565]]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.08041559252448417, 0.2738139806242196, 0.3719564462270767, 0.2738139806242196]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.08041559252448417, 0.2738139806242196, 0.3719564462270767, 0.2738139806242196]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.08041559252448417, 0.2738139806242196, 0.3719564462270767, 0.2738139806242196]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.08041559252448417, 0.2738139806242196, 0.3719564462270767, 0.2738139806242196]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.08041557099912577, 0.2738139836469317, 0.3719564617070109, 0.2738139836469317]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.08041554960892926, 0.27381398665066164, 0.3719564770897475, 0.27381398665066164]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.0890017665684749, 0.30330892547353516, 0.4120618120820719, 0.19562749587591802]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.0997887360283422, 0.3403637781289062, 0.3403637781289062, 0.21948370771384543]
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.11343469824675213, 0.38723969830511706, 0.2496628017240654, 0.2496628017240654]
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.11343469824675213, 0.38723969830511706, 0.2496628017240654, 0.2496628017240654]
using explorer policy with actor:  1
Starting evaluation
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.11343469824675213, 0.38723969830511706, 0.2496628017240654, 0.2496628017240654]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.11343469824675213, 0.38723969830511706, 0.2496628017240654, 0.2496628017240654]
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.11343469824675213, 0.38723969830511706, 0.2496628017240654, 0.2496628017240654]
line 256 mcts: sample exp_bonus -0.5152002805137152
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
Printing some Q and Qe and total Qs values:  [[0.34 ]
 [0.328]
 [0.32 ]
 [0.319]
 [0.319]
 [0.335]
 [0.326]] [[-1.306]
 [-0.927]
 [-0.327]
 [-0.36 ]
 [-0.403]
 [-0.33 ]
 [-0.158]] [[0.34 ]
 [0.328]
 [0.32 ]
 [0.319]
 [0.319]
 [0.335]
 [0.326]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.51 ]
 [0.344]
 [0.395]
 [0.431]
 [0.431]
 [0.452]
 [0.429]] [[-0.438]
 [ 2.763]
 [-0.008]
 [-0.152]
 [-0.15 ]
 [-0.104]
 [ 0.038]] [[0.51 ]
 [0.344]
 [0.395]
 [0.431]
 [0.431]
 [0.452]
 [0.429]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.402]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.402]
 [0.395]] [[-0.011]
 [-0.11 ]
 [-0.11 ]
 [-0.11 ]
 [-0.11 ]
 [-0.037]
 [ 0.122]] [[0.402]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.402]
 [0.395]]
siam score:  -0.7346666
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.385]
 [0.214]
 [0.371]
 [0.333]
 [0.315]
 [0.356]
 [0.343]] [[-0.579]
 [ 2.297]
 [-0.484]
 [-0.61 ]
 [-0.549]
 [-0.323]
 [-0.415]] [[0.385]
 [0.214]
 [0.371]
 [0.333]
 [0.315]
 [0.356]
 [0.343]]
Printing some Q and Qe and total Qs values:  [[0.57 ]
 [0.392]
 [0.387]
 [0.386]
 [0.386]
 [0.386]
 [0.385]] [[-1.219]
 [-0.321]
 [-0.277]
 [-0.312]
 [-0.271]
 [-0.179]
 [-0.056]] [[0.57 ]
 [0.392]
 [0.387]
 [0.386]
 [0.386]
 [0.386]
 [0.385]]
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.15606251219085818, 0.34393748780914185, 0.15606251219085818, 0.34393748780914185]
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]] [[-1.078]
 [-0.498]
 [-0.498]
 [-0.498]
 [-0.498]
 [-0.498]
 [-0.498]] [[0.582]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]]
Printing some Q and Qe and total Qs values:  [[0.551]
 [0.395]
 [0.395]
 [0.395]
 [0.395]
 [0.395]
 [0.395]] [[-0.533]
 [-0.506]
 [-0.506]
 [-0.506]
 [-0.506]
 [-0.506]
 [-0.506]] [[0.551]
 [0.395]
 [0.395]
 [0.395]
 [0.395]
 [0.395]
 [0.395]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.561]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]] [[-1.052]
 [-0.429]
 [-0.429]
 [-0.429]
 [-0.429]
 [-0.429]
 [-0.429]] [[0.561]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]]
Printing some Q and Qe and total Qs values:  [[0.403]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.366]
 [0.366]] [[-0.16 ]
 [-0.375]
 [-0.375]
 [-0.375]
 [-0.375]
 [-0.137]
 [-0.18 ]] [[0.403]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.366]
 [0.366]]
Printing some Q and Qe and total Qs values:  [[0.522]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]] [[-0.768]
 [-0.525]
 [-0.525]
 [-0.525]
 [-0.525]
 [-0.525]
 [-0.525]] [[0.522]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]]
Printing some Q and Qe and total Qs values:  [[0.45 ]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]] [[-0.242]
 [-0.297]
 [-0.297]
 [-0.297]
 [-0.297]
 [-0.297]
 [-0.297]] [[0.45 ]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus -0.32611141649947833
maxi score, test score, baseline:  -0.9967847352024922 -1.0 -0.9967847352024922
probs:  [0.249665220173614, 0.249665220173614, 0.11374461066087031, 0.38692494899190166]
Printing some Q and Qe and total Qs values:  [[0.35 ]
 [0.501]
 [0.394]
 [0.358]
 [0.351]
 [0.501]
 [0.391]] [[-0.532]
 [ 0.   ]
 [-0.051]
 [-0.353]
 [-0.367]
 [ 0.   ]
 [-0.111]] [[0.35 ]
 [0.501]
 [0.394]
 [0.358]
 [0.351]
 [0.501]
 [0.391]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9967847352024922 -1.0 -0.9967847352024922
probs:  [0.249665220173614, 0.249665220173614, 0.11374461066087031, 0.38692494899190166]
Printing some Q and Qe and total Qs values:  [[0.355]
 [0.238]
 [0.352]
 [0.351]
 [0.328]
 [0.455]
 [0.385]] [[-0.554]
 [ 2.998]
 [-0.199]
 [-0.721]
 [-0.403]
 [-0.212]
 [-0.28 ]] [[0.355]
 [0.238]
 [0.352]
 [0.351]
 [0.328]
 [0.455]
 [0.385]]
maxi score, test score, baseline:  -0.9967847352024922 -1.0 -0.9967847352024922
probs:  [0.249665220173614, 0.249665220173614, 0.11374461066087031, 0.38692494899190166]
maxi score, test score, baseline:  -0.9967847352024922 -1.0 -0.9967847352024922
probs:  [0.249665220173614, 0.249665220173614, 0.11374461066087031, 0.38692494899190166]
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.5987420200789214
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9967847352024922 -1.0 -0.9967847352024922
probs:  [0.249665220173614, 0.249665220173614, 0.11374461066087031, 0.38692494899190166]
Printing some Q and Qe and total Qs values:  [[0.365]
 [0.241]
 [0.393]
 [0.353]
 [0.351]
 [0.46 ]
 [0.4  ]] [[-0.662]
 [ 2.972]
 [-0.291]
 [-0.643]
 [-0.245]
 [ 0.169]
 [-0.3  ]] [[0.365]
 [0.241]
 [0.393]
 [0.353]
 [0.351]
 [0.46 ]
 [0.4  ]]
Printing some Q and Qe and total Qs values:  [[0.402]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]] [[-0.793]
 [-0.726]
 [-0.726]
 [-0.726]
 [-0.726]
 [-0.726]
 [-0.726]] [[0.402]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]]
Printing some Q and Qe and total Qs values:  [[0.357]
 [0.35 ]
 [0.396]
 [0.353]
 [0.331]
 [0.403]
 [0.474]] [[-0.34 ]
 [ 4.719]
 [ 0.329]
 [-0.384]
 [-0.307]
 [-0.142]
 [ 0.627]] [[0.357]
 [0.35 ]
 [0.396]
 [0.353]
 [0.331]
 [0.403]
 [0.474]]
Printing some Q and Qe and total Qs values:  [[0.386]
 [0.354]
 [0.354]
 [0.354]
 [0.354]
 [0.354]
 [0.354]] [[-0.36 ]
 [ 0.215]
 [ 0.215]
 [ 0.215]
 [ 0.215]
 [ 0.215]
 [-0.148]] [[0.386]
 [0.354]
 [0.354]
 [0.354]
 [0.354]
 [0.354]
 [0.354]]
Printing some Q and Qe and total Qs values:  [[0.501]
 [0.495]
 [0.446]
 [0.457]
 [0.454]
 [0.456]
 [0.476]] [[-0.027]
 [ 3.785]
 [ 0.332]
 [ 0.056]
 [ 0.321]
 [ 0.128]
 [ 0.417]] [[0.501]
 [0.495]
 [0.446]
 [0.457]
 [0.454]
 [0.456]
 [0.476]]
Printing some Q and Qe and total Qs values:  [[0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]] [[-0.078]
 [-0.078]
 [-0.078]
 [-0.078]
 [-0.078]
 [-0.078]
 [-0.078]] [[0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.1315622132911275, 0.2889623488191199, 0.1315622132911275, 0.44791322459862515]
Printing some Q and Qe and total Qs values:  [[0.495]
 [0.495]
 [0.446]
 [0.457]
 [0.454]
 [0.456]
 [0.475]] [[-0.037]
 [ 3.717]
 [ 0.31 ]
 [ 0.071]
 [ 0.306]
 [ 0.135]
 [ 0.45 ]] [[0.495]
 [0.495]
 [0.446]
 [0.457]
 [0.454]
 [0.456]
 [0.475]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.1315622132911275, 0.2889623488191199, 0.1315622132911275, 0.44791322459862515]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
line 256 mcts: sample exp_bonus -0.2398601995361338
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.1315622132911275, 0.2889623488191199, 0.1315622132911275, 0.44791322459862515]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.1315622132911275, 0.2889623488191199, 0.1315622132911275, 0.44791322459862515]
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.367]
 [0.356]
 [0.354]
 [0.336]
 [0.429]
 [0.476]] [[-0.391]
 [ 5.236]
 [ 0.258]
 [-0.498]
 [-0.374]
 [-0.249]
 [ 0.276]] [[0.358]
 [0.367]
 [0.356]
 [0.354]
 [0.336]
 [0.429]
 [0.476]]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.1315622132911275, 0.2889623488191199, 0.1315622132911275, 0.44791322459862515]
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.316]
 [0.362]
 [0.357]
 [0.353]
 [0.386]
 [0.379]] [[-0.577]
 [ 4.511]
 [-0.105]
 [-1.137]
 [-0.235]
 [-0.655]
 [-0.558]] [[0.368]
 [0.316]
 [0.362]
 [0.357]
 [0.353]
 [0.386]
 [0.379]]
Printing some Q and Qe and total Qs values:  [[0.777]
 [0.793]
 [0.793]
 [0.793]
 [0.793]
 [0.793]
 [0.793]] [[9.33 ]
 [9.283]
 [9.283]
 [9.283]
 [9.283]
 [9.283]
 [9.283]] [[1.883]
 [1.883]
 [1.883]
 [1.883]
 [1.883]
 [1.883]
 [1.883]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.333]
 [0.363]
 [0.359]
 [0.359]
 [0.36 ]
 [0.36 ]] [[-0.918]
 [ 3.682]
 [-0.291]
 [-0.781]
 [-0.733]
 [-0.56 ]
 [-0.337]] [[0.368]
 [0.333]
 [0.363]
 [0.359]
 [0.359]
 [0.36 ]
 [0.36 ]]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.1315622132911275, 0.2889623488191199, 0.1315622132911275, 0.44791322459862515]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.1315622132911275, 0.2889623488191199, 0.1315622132911275, 0.44791322459862515]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
using explorer policy with actor:  0
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus -0.03576939402839022
siam score:  -0.7309851
Printing some Q and Qe and total Qs values:  [[0.31]
 [0.31]
 [0.31]
 [0.31]
 [0.31]
 [0.31]
 [0.31]] [[4.604]
 [4.604]
 [4.604]
 [4.604]
 [4.604]
 [4.604]
 [4.604]] [[0.31]
 [0.31]
 [0.31]
 [0.31]
 [0.31]
 [0.31]
 [0.31]]
Printing some Q and Qe and total Qs values:  [[0.638]
 [0.617]
 [0.614]
 [0.575]
 [0.614]
 [0.567]
 [0.614]] [[5.434]
 [5.899]
 [5.148]
 [5.082]
 [5.148]
 [5.29 ]
 [5.148]] [[0.638]
 [0.617]
 [0.614]
 [0.575]
 [0.614]
 [0.567]
 [0.614]]
Printing some Q and Qe and total Qs values:  [[0.528]
 [0.532]
 [0.532]
 [0.532]
 [0.532]
 [0.532]
 [0.532]] [[9.437]
 [8.237]
 [8.237]
 [8.237]
 [8.237]
 [8.237]
 [8.237]] [[1.832]
 [1.491]
 [1.491]
 [1.491]
 [1.491]
 [1.491]
 [1.491]]
Printing some Q and Qe and total Qs values:  [[0.725]
 [0.618]
 [0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]] [[5.258]
 [4.579]
 [5.529]
 [5.529]
 [5.529]
 [5.529]
 [5.529]] [[0.725]
 [0.618]
 [0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]]
Printing some Q and Qe and total Qs values:  [[0.396]
 [0.396]
 [0.396]
 [0.396]
 [0.396]
 [0.396]
 [0.396]] [[9.634]
 [9.634]
 [9.634]
 [9.634]
 [9.634]
 [9.634]
 [9.634]] [[1.58]
 [1.58]
 [1.58]
 [1.58]
 [1.58]
 [1.58]
 [1.58]]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.1315622132911275, 0.2889623488191199, 0.1315622132911275, 0.44791322459862515]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.10038764820106151, 0.3400011803790488, 0.2196099910408409, 0.3400011803790488]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.10038764820106151, 0.3400011803790488, 0.2196099910408409, 0.3400011803790488]
maxi score, test score, baseline:  -0.9968040247678018 -1.0 -0.9968040247678018
probs:  [0.10038762480111929, 0.3400011944555781, 0.21960998628772457, 0.3400011944555781]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]] [[7.374]
 [5.673]
 [5.673]
 [5.673]
 [5.673]
 [5.673]
 [5.673]] [[0.699]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]]
maxi score, test score, baseline:  -0.9968040247678018 -1.0 -0.9968040247678018
probs:  [0.10038762480111929, 0.3400011944555781, 0.21960998628772457, 0.3400011944555781]
Printing some Q and Qe and total Qs values:  [[ 0.036]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]] [[6.951]
 [7.197]
 [7.197]
 [7.197]
 [7.197]
 [7.197]
 [7.197]] [[0.212]
 [0.206]
 [0.206]
 [0.206]
 [0.206]
 [0.206]
 [0.206]]
maxi score, test score, baseline:  -0.9968418960244648 -1.0 -0.9968418960244648
probs:  [0.10038753263905789, 0.3400012498968171, 0.2196099675673078, 0.3400012498968171]
Printing some Q and Qe and total Qs values:  [[-0.071]
 [-0.053]
 [-0.05 ]
 [-0.057]
 [-0.034]
 [-0.037]
 [-0.054]] [[6.602]
 [6.644]
 [6.049]
 [9.665]
 [7.443]
 [6.99 ]
 [6.784]] [[ 0.006]
 [ 0.056]
 [-0.137]
 [ 1.057]
 [ 0.36 ]
 [ 0.203]
 [ 0.101]]
maxi score, test score, baseline:  -0.996869696969697 -1.0 -0.996869696969697
probs:  [0.10038746499033807, 0.3400012905917498, 0.2196099538261623, 0.3400012905917498]
maxi score, test score, baseline:  -0.9968788519637463 -1.0 -0.9968788519637463
probs:  [0.10038744271449464, 0.34000130399206097, 0.21960994930138344, 0.34000130399206097]
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
probs:  [0.10038739856596303, 0.3400013305501629, 0.2196099403337112, 0.3400013305501629]
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
probs:  [0.08123257745455276, 0.2737052773805974, 0.2737052773805974, 0.37135686778425236]
707 332
line 256 mcts: sample exp_bonus 2.655144182845896
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.505]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]] [[9.799]
 [8.906]
 [8.906]
 [8.906]
 [8.906]
 [8.906]
 [8.906]] [[1.523]
 [0.94 ]
 [0.94 ]
 [0.94 ]
 [0.94 ]
 [0.94 ]
 [0.94 ]]
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
probs:  [0.13177779836838494, 0.13177779836838494, 0.13177779836838494, 0.6046666048948451]
Printing some Q and Qe and total Qs values:  [[0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]] [[-0.757]
 [-0.757]
 [-0.757]
 [-0.757]
 [-0.757]
 [-0.757]
 [-0.757]] [[0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]]
maxi score, test score, baseline:  -0.9969059880239521 -1.0 -0.9969059880239521
probs:  [0.13177777551555686, 0.13177777551555686, 0.13177777551555686, 0.6046666734533296]
rdn probs:  [0.1317776193150375, 0.1317776193150375, 0.1317776193150375, 0.6046671420548876]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.13177759752491414, 0.13177759752491414, 0.13177759752491414, 0.6046672074252575]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.3128],
        [-0.0000],
        [-0.0000],
        [-0.2062],
        [-0.0000],
        [-0.4368],
        [-0.2527],
        [-0.0000],
        [-0.2098],
        [-0.0000]], dtype=torch.float64)
-0.0727797758985 -0.385544591723113
-0.932455422954 -0.932455422954
-0.887971095 -0.887971095
-0.0727797758985 -0.27901424157278837
-0.004949999999999235 -0.004949999999999235
-0.024259925299500003 -0.4610717270638166
-0.0727797758985 -0.32546725138301236
-0.9355500000000001 -0.9355500000000001
-0.0727797758985 -0.2826044908581572
-0.22123013714999942 -0.22123013714999942
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.13177759752491414, 0.13177759752491414, 0.13177759752491414, 0.6046672074252575]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.13177759752491414, 0.13177759752491414, 0.13177759752491414, 0.6046672074252575]
Printing some Q and Qe and total Qs values:  [[0.103]
 [0.089]
 [0.089]
 [0.089]
 [0.089]
 [0.089]
 [0.089]] [[6.301]
 [6.288]
 [6.288]
 [6.288]
 [6.288]
 [6.288]
 [6.288]] [[-0.479]
 [-0.513]
 [-0.513]
 [-0.513]
 [-0.513]
 [-0.513]
 [-0.513]]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.13177759752491414, 0.13177759752491414, 0.13177759752491414, 0.6046672074252575]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.08995697880117007, 0.19561644910719483, 0.19561644910719483, 0.5188101229844402]
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[5.63 ]
 [5.339]
 [5.339]
 [5.339]
 [5.339]
 [5.339]
 [5.339]] [[0.589]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
siam score:  -0.7265062
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.08995697880117007, 0.19561644910719483, 0.19561644910719483, 0.5188101229844402]
Printing some Q and Qe and total Qs values:  [[0.723]
 [0.641]
 [0.641]
 [0.641]
 [0.641]
 [0.641]
 [0.641]] [[5.376]
 [4.979]
 [4.979]
 [4.979]
 [4.979]
 [4.979]
 [4.979]] [[1.652]
 [1.348]
 [1.348]
 [1.348]
 [1.348]
 [1.348]
 [1.348]]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.08995697880117007, 0.19561644910719483, 0.19561644910719483, 0.5188101229844402]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.10086431510436686, 0.21947853587490082, 0.21947853587490082, 0.46017861314583147]
Printing some Q and Qe and total Qs values:  [[0.36 ]
 [0.282]
 [0.282]
 [0.282]
 [0.282]
 [0.282]
 [0.282]] [[6.116]
 [6.025]
 [6.025]
 [6.025]
 [6.025]
 [6.025]
 [6.025]] [[1.299]
 [1.191]
 [1.191]
 [1.191]
 [1.191]
 [1.191]
 [1.191]]
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.10086431510436686, 0.21947853587490082, 0.21947853587490082, 0.46017861314583147]
Printing some Q and Qe and total Qs values:  [[-0.002]
 [-0.002]
 [-0.01 ]
 [-0.002]
 [-0.011]
 [-0.012]
 [-0.004]] [[4.815]
 [4.612]
 [4.741]
 [4.612]
 [4.771]
 [4.794]
 [4.724]] [[0.803]
 [0.678]
 [0.749]
 [0.678]
 [0.767]
 [0.78 ]
 [0.744]]
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.11466588291969916, 0.24967231448649094, 0.24967231448649094, 0.38598948810731903]
first move QE:  2.2409320788447085
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.11466588291969916, 0.24967231448649094, 0.24967231448649094, 0.38598948810731903]
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.11466588291969916, 0.24967231448649094, 0.24967231448649094, 0.38598948810731903]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.11466588291969916, 0.24967231448649094, 0.24967231448649094, 0.38598948810731903]
712 336
using another actor
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.09052122189407696, 0.30315959270197435, 0.30315959270197435, 0.30315959270197435]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.09052122189407696, 0.30315959270197435, 0.30315959270197435, 0.30315959270197435]
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.09052122189407696, 0.30315959270197435, 0.30315959270197435, 0.30315959270197435]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.09052122189407696, 0.30315959270197435, 0.30315959270197435, 0.30315959270197435]
line 256 mcts: sample exp_bonus 4.625008282535437
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.09052122189407696, 0.30315959270197435, 0.30315959270197435, 0.30315959270197435]
siam score:  -0.6990923
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]] [[10.]
 [10.]
 [10.]
 [10.]
 [10.]
 [10.]
 [10.]] [[1.974]
 [1.93 ]
 [1.93 ]
 [1.93 ]
 [1.93 ]
 [1.93 ]
 [1.93 ]]
siam score:  -0.69531554
Printing some Q and Qe and total Qs values:  [[0.824]
 [0.704]
 [0.699]
 [0.699]
 [0.699]
 [0.698]
 [0.696]] [[4.201]
 [4.307]
 [4.022]
 [3.973]
 [3.934]
 [3.922]
 [3.926]] [[1.243]
 [1.2  ]
 [1.032]
 [1.003]
 [0.981]
 [0.973]
 [0.974]]
Printing some Q and Qe and total Qs values:  [[0.761]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]] [[6.251]
 [4.789]
 [4.789]
 [4.789]
 [4.789]
 [4.789]
 [4.789]] [[1.267]
 [0.729]
 [0.729]
 [0.729]
 [0.729]
 [0.729]
 [0.729]]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.15750975293675096, 0.34249024706324904, 0.15750975293675096, 0.34249024706324904]
line 256 mcts: sample exp_bonus 7.141142498820082
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.19320731546491188, 0.19320731546491188, 0.19320731546491188, 0.42037805360526437]
siam score:  -0.69490236
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.2889005264958371, 0.2889005264958371, 0.2889005264958371, 0.13329842051248875]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.2889005264958371, 0.2889005264958371, 0.2889005264958371, 0.13329842051248875]
Printing some Q and Qe and total Qs values:  [[0.915]
 [0.943]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[4.789]
 [4.021]
 [4.382]
 [4.382]
 [4.382]
 [4.382]
 [4.382]] [[1.609]
 [1.409]
 [1.309]
 [1.309]
 [1.309]
 [1.309]
 [1.309]]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.2889005264958371, 0.2889005264958371, 0.2889005264958371, 0.13329842051248875]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.2889005264958371, 0.2889005264958371, 0.2889005264958371, 0.13329842051248875]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.2889005264958371, 0.2889005264958371, 0.2889005264958371, 0.13329842051248875]
using explorer policy with actor:  1
siam score:  -0.6963562
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.24967917844588874, 0.3850658742805807, 0.24967917844588874, 0.11557576882764177]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.28879984748736737, 0.28879984748736737, 0.28879984748736737, 0.13360045753789795]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.28879984748736737, 0.28879984748736737, 0.28879984748736737, 0.13360045753789795]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.564]
 [0.754]
 [0.766]
 [0.769]
 [0.765]
 [0.594]] [[3.709]
 [3.772]
 [2.539]
 [2.175]
 [2.249]
 [2.503]
 [3.7  ]] [[1.955]
 [2.085]
 [1.689]
 [1.492]
 [1.542]
 [1.688]
 [2.096]]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.34192318250987114, 0.34192318250987114, 0.1580768174901289, 0.1580768174901289]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.34192318250987114, 0.34192318250987114, 0.1580768174901289, 0.1580768174901289]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.34192318250987114, 0.34192318250987114, 0.1580768174901289, 0.1580768174901289]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.34192318250987114, 0.34192318250987114, 0.1580768174901289, 0.1580768174901289]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.34192318250987114, 0.34192318250987114, 0.1580768174901289, 0.1580768174901289]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.34192318250987114, 0.34192318250987114, 0.1580768174901289, 0.1580768174901289]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.4190969926733199, 0.19363433577556, 0.19363433577556, 0.19363433577556]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.4190969926733199, 0.19363433577556, 0.19363433577556, 0.19363433577556]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.44431642836843305, 0.1337045618098002, 0.1337045618098002, 0.2882744480119665]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.44431642836843305, 0.1337045618098002, 0.1337045618098002, 0.2882744480119665]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.44431642836843305, 0.1337045618098002, 0.1337045618098002, 0.2882744480119665]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.44431642836843305, 0.1337045618098002, 0.1337045618098002, 0.2882744480119665]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.44431642836843305, 0.1337045618098002, 0.1337045618098002, 0.2882744480119665]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.45807602623224747, 0.10233314267388649, 0.21979541554693297, 0.21979541554693297]
Printing some Q and Qe and total Qs values:  [[1.045]
 [1.168]
 [1.14 ]
 [0.948]
 [0.932]
 [0.95 ]
 [0.987]] [[3.773]
 [3.645]
 [3.548]
 [3.634]
 [3.592]
 [3.636]
 [3.577]] [[1.539]
 [1.574]
 [1.487]
 [1.361]
 [1.32 ]
 [1.364]
 [1.362]]
Printing some Q and Qe and total Qs values:  [[1.168]
 [0.989]
 [0.989]
 [0.989]
 [0.989]
 [0.989]
 [0.989]] [[5.336]
 [4.532]
 [4.532]
 [4.532]
 [4.532]
 [4.532]
 [4.532]] [[1.243]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.42585809084139525, 0.07579315883786478, 0.24917437516037005, 0.24917437516037005]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
siam score:  -0.70291275
start point for exploration sampling:  10624
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.471]
 [0.744]
 [0.705]
 [0.7  ]
 [0.685]
 [0.674]] [[3.271]
 [3.686]
 [3.25 ]
 [3.374]
 [3.506]
 [3.5  ]
 [3.493]] [[1.663]
 [1.556]
 [1.529]
 [1.596]
 [1.725]
 [1.696]
 [1.672]]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.42585809084139525, 0.07579315883786478, 0.24917437516037005, 0.24917437516037005]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.15]
 [0.15]
 [0.15]
 [0.15]
 [0.15]
 [0.15]
 [0.15]] [[7.847]
 [7.847]
 [7.847]
 [7.847]
 [7.847]
 [7.847]
 [7.847]] [[0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.064]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.4665707363260499, 0.08296063680797566, 0.27295620496551565, 0.1775124219004588]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.817146737675421
siam score:  -0.69939387
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.42524560735560607, 0.07598421339218386, 0.3366946643106327, 0.1620755149415774]
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.908]
 [0.913]
 [0.849]
 [0.825]
 [0.839]
 [0.832]] [[4.841]
 [5.04 ]
 [4.868]
 [4.125]
 [4.234]
 [4.101]
 [4.124]] [[0.944]
 [1.075]
 [1.028]
 [0.652]
 [0.641]
 [0.624]
 [0.618]]
first move QE:  2.255873101984797
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.6518742076885868, 0.11604193077047102, 0.11604193077047102, 0.11604193077047102]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.6518742076885868, 0.11604193077047102, 0.11604193077047102, 0.11604193077047102]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.6518742076885868, 0.11604193077047102, 0.11604193077047102, 0.11604193077047102]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.597363281101591, 0.134212239632803, 0.134212239632803, 0.134212239632803]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.597363281101591, 0.134212239632803, 0.134212239632803, 0.134212239632803]
Printing some Q and Qe and total Qs values:  [[-0.005]
 [ 0.015]
 [ 0.065]
 [ 0.065]
 [-0.009]
 [-0.014]
 [-0.01 ]] [[7.616]
 [8.083]
 [7.246]
 [7.246]
 [6.82 ]
 [6.734]
 [6.426]] [[-0.125]
 [ 0.072]
 [-0.109]
 [-0.109]
 [-0.399]
 [-0.437]
 [-0.532]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.5232382456367349, 0.1589205847877551, 0.1589205847877551, 0.1589205847877551]
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.429]
 [0.536]
 [0.536]
 [0.543]
 [0.543]
 [0.543]] [[2.934]
 [4.255]
 [2.582]
 [2.492]
 [2.506]
 [2.506]
 [2.506]] [[0.607]
 [0.429]
 [0.536]
 [0.536]
 [0.543]
 [0.543]
 [0.543]]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.4165903783382671, 0.19446987388724424, 0.19446987388724424, 0.19446987388724424]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.4165904246596488, 0.19446985844678374, 0.19446985844678374, 0.19446985844678374]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.4165904246596488, 0.19446985844678374, 0.19446985844678374, 0.19446985844678374]
Printing some Q and Qe and total Qs values:  [[0.879]
 [0.881]
 [0.854]
 [0.834]
 [0.833]
 [0.934]
 [0.834]] [[4.658]
 [4.044]
 [4.243]
 [4.246]
 [4.215]
 [4.336]
 [4.061]] [[1.424]
 [1.113]
 [1.194]
 [1.181]
 [1.164]
 [1.303]
 [1.086]]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.4165904246596488, 0.19446985844678374, 0.19446985844678374, 0.19446985844678374]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.4165904246596488, 0.19446985844678374, 0.19446985844678374, 0.19446985844678374]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.4165904246596488, 0.19446985844678374, 0.19446985844678374, 0.19446985844678374]
Printing some Q and Qe and total Qs values:  [[0.958]
 [0.991]
 [0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]] [[4.881]
 [4.988]
 [4.881]
 [4.881]
 [4.881]
 [4.881]
 [4.881]] [[1.908]
 [2.027]
 [1.908]
 [1.908]
 [1.908]
 [1.908]
 [1.908]]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.2883038936548363, 0.2883038936548363, 0.2883038936548363, 0.1350883190354912]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.34053458028136474, 0.34053458028136474, 0.15946541971863523, 0.15946541971863523]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.34053458028136474, 0.34053458028136474, 0.15946541971863523, 0.15946541971863523]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.122]
 [1.021]
 [0.974]
 [0.983]
 [0.818]
 [1.102]
 [1.05 ]] [[4.185]
 [3.906]
 [3.688]
 [3.879]
 [4.178]
 [4.565]
 [4.066]] [[1.442]
 [1.141]
 [0.955]
 [1.068]
 [0.967]
 [1.609]
 [1.269]]
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
Printing some Q and Qe and total Qs values:  [[0.668]
 [0.631]
 [0.625]
 [0.613]
 [0.631]
 [0.631]
 [0.631]] [[4.467]
 [4.122]
 [4.556]
 [4.602]
 [4.122]
 [4.122]
 [4.122]] [[1.222]
 [0.916]
 [1.241]
 [1.263]
 [0.916]
 [0.916]
 [0.916]]
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
probs:  [0.38325464607284976, 0.2496922525494845, 0.11736084882818118, 0.2496922525494845]
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
probs:  [0.38325464607284976, 0.2496922525494845, 0.11736084882818118, 0.2496922525494845]
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
probs:  [0.38325464607284976, 0.2496922525494845, 0.11736084882818118, 0.2496922525494845]
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
probs:  [0.38325464607284976, 0.2496922525494845, 0.11736084882818118, 0.2496922525494845]
using another actor
from probs:  [0.4418232775639888, 0.13518995320638547, 0.13518995320638547, 0.28779681602324025]
line 256 mcts: sample exp_bonus 1.8269353121858054
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
probs:  [0.5215867844550349, 0.15947107184832174, 0.15947107184832174, 0.15947107184832174]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.4560140689137167, 0.10377464970733723, 0.22010564068947303, 0.22010564068947303]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.4560140689137167, 0.10377464970733723, 0.22010564068947303, 0.22010564068947303]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.4560140689137167, 0.10377464970733723, 0.22010564068947303, 0.22010564068947303]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.4560140689137167, 0.10377464970733723, 0.22010564068947303, 0.22010564068947303]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.3829573530454842, 0.11765394512943633, 0.24969435091253978, 0.24969435091253978]
using another actor
from probs:  [0.3829573530454842, 0.11765394512943633, 0.24969435091253978, 0.24969435091253978]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.4413320733547654, 0.13548264486132636, 0.28770263692258197, 0.13548264486132636]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.4413320733547654, 0.13548264486132636, 0.28770263692258197, 0.13548264486132636]
siam score:  -0.6926184
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.4413320733547654, 0.13548264486132636, 0.28770263692258197, 0.13548264486132636]
siam score:  -0.6939419
Printing some Q and Qe and total Qs values:  [[0.695]
 [0.695]
 [0.695]
 [0.695]
 [0.695]
 [0.695]
 [0.695]] [[2.482]
 [2.482]
 [2.482]
 [2.482]
 [2.482]
 [2.482]
 [2.482]] [[0.695]
 [0.695]
 [0.695]
 [0.695]
 [0.695]
 [0.695]
 [0.695]]
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.33999050462969327, 0.1600094953703068, 0.33999050462969327, 0.1600094953703068]
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.33999050462969327, 0.1600094953703068, 0.33999050462969327, 0.1600094953703068]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
line 256 mcts: sample exp_bonus 5.367620262512196
using explorer policy with actor:  1
siam score:  -0.6966304
maxi score, test score, baseline:  -0.997034670487106 -1.0 -0.997034670487106
probs:  [0.3399905249982211, 0.16000947500177892, 0.3399905249982211, 0.16000947500177892]
maxi score, test score, baseline:  -0.997034670487106 -1.0 -0.997034670487106
probs:  [0.3399905249982211, 0.16000947500177892, 0.3399905249982211, 0.16000947500177892]
747 348
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.514]
 [0.515]
 [0.538]
 [0.538]
 [0.538]
 [0.538]
 [0.538]] [[3.643]
 [4.437]
 [4.001]
 [4.001]
 [4.001]
 [4.001]
 [4.001]] [[0.514]
 [0.515]
 [0.538]
 [0.538]
 [0.538]
 [0.538]
 [0.538]]
maxi score, test score, baseline:  -0.997034670487106 -1.0 -0.997034670487106
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.997034670487106 -1.0 -0.997034670487106
probs:  [0.1359635108234759, 0.28801216305884136, 0.28801216305884136, 0.28801216305884136]
Printing some Q and Qe and total Qs values:  [[0.943]
 [1.032]
 [0.939]
 [0.877]
 [0.878]
 [0.885]
 [0.933]] [[3.769]
 [3.749]
 [3.813]
 [3.881]
 [3.931]
 [3.983]
 [3.822]] [[1.724]
 [1.821]
 [1.756]
 [1.735]
 [1.78 ]
 [1.833]
 [1.756]]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.19528152748623395, 0.19528152748623395, 0.4141554175412982, 0.19528152748623395]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.24969848149563242, 0.11823641359169916, 0.38236662341703603, 0.24969848149563242]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.33945270410184675, 0.16054729589815325, 0.33945270410184675, 0.16054729589815325]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.33945270410184675, 0.16054729589815325, 0.33945270410184675, 0.16054729589815325]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.33945270410184675, 0.16054729589815325, 0.33945270410184675, 0.16054729589815325]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.33945270410184675, 0.16054729589815325, 0.33945270410184675, 0.16054729589815325]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.33945270410184675, 0.16054729589815325, 0.33945270410184675, 0.16054729589815325]
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.11852580144602075, 0.24970051435409213, 0.3820731698457951, 0.24970051435409213]
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.925]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[4.416]
 [4.626]
 [4.416]
 [4.416]
 [4.416]
 [4.416]
 [4.416]] [[1.462]
 [1.563]
 [1.462]
 [1.462]
 [1.462]
 [1.462]
 [1.462]]
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.13653987062693235, 0.2878200431243559, 0.2878200431243559, 0.2878200431243559]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.811958952846642
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.13653987062693235, 0.2878200431243559, 0.2878200431243559, 0.2878200431243559]
Printing some Q and Qe and total Qs values:  [[0.78 ]
 [0.76 ]
 [0.851]
 [0.772]
 [0.765]
 [0.775]
 [0.758]] [[3.429]
 [3.584]
 [3.046]
 [3.249]
 [3.343]
 [3.355]
 [3.338]] [[1.16 ]
 [1.223]
 [1.047]
 [1.023]
 [1.072]
 [1.101]
 [1.055]]
in main func line 156:  754
line 256 mcts: sample exp_bonus 8.692763342675606
line 256 mcts: sample exp_bonus 2.2657156328281567
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.16081384906885202, 0.33918615093114796, 0.16081384906885202, 0.33918615093114796]
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.22058372168487322, 0.3371982535769863, 0.10501977116115412, 0.3371982535769863]
from probs:  [0.2497025261217276, 0.2497025261217276, 0.11881401968182731, 0.3817809280747174]
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.28772467137687263, 0.28772467137687263, 0.13682598586938216, 0.28772467137687263]
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.16107890923274065, 0.33892109076725935, 0.16107890923274065, 0.33892109076725935]
Printing some Q and Qe and total Qs values:  [[0.503]
 [0.255]
 [0.478]
 [0.482]
 [0.489]
 [0.501]
 [0.498]] [[1.79 ]
 [3.28 ]
 [1.787]
 [1.628]
 [1.742]
 [1.704]
 [1.737]] [[0.503]
 [0.255]
 [0.478]
 [0.482]
 [0.489]
 [0.501]
 [0.498]]
siam score:  -0.69737655
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.19587529668216724, 0.19587529668216724, 0.19587529668216724, 0.41237410995349827]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  2.2648235502428666
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1371106728416578, 0.2876297757194474, 0.2876297757194474, 0.2876297757194474]
from probs:  [0.1371106728416578, 0.2876297757194474, 0.2876297757194474, 0.2876297757194474]
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.557]
 [0.557]
 [0.557]
 [0.557]
 [0.557]
 [0.557]] [[2.569]
 [2.271]
 [2.271]
 [2.271]
 [2.271]
 [2.271]
 [2.271]] [[0.62 ]
 [0.557]
 [0.557]
 [0.557]
 [0.557]
 [0.557]
 [0.557]]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.16134240883064158, 0.3386575911693584, 0.16134240883064158, 0.3386575911693584]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.22070107855228846, 0.3368596343803867, 0.10557965268693814, 0.3368596343803867]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.22070107855228846, 0.3368596343803867, 0.10557965268693814, 0.3368596343803867]
line 256 mcts: sample exp_bonus 1.082884673622478
siam score:  -0.7028732
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.24970648709840815, 0.3812002670119402, 0.11938675879124352, 0.24970648709840815]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.24970648709840815, 0.3812002670119402, 0.11938675879124352, 0.24970648709840815]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.24970648709840815, 0.3812002670119402, 0.11938675879124352, 0.24970648709840815]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.13720900324755114, 0.4384352580475004, 0.13720900324755114, 0.28714673545739733]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
line 256 mcts: sample exp_bonus -0.18380099869636932
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.09483701915520101, 0.40609141022238027, 0.19766213048989634, 0.30140944013252235]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.09483701915520101, 0.40609141022238027, 0.19766213048989634, 0.30140944013252235]
siam score:  -0.701718
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.09483701915520101, 0.40609141022238027, 0.19766213048989634, 0.30140944013252235]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.09483701915520101, 0.40609141022238027, 0.19766213048989634, 0.30140944013252235]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.11939217954884822, 0.5120922034556684, 0.11939217954884822, 0.2491234374466352]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.11939217954884822, 0.5120922034556684, 0.11939217954884822, 0.2491234374466352]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.17892036052379653, 0.4624101319602858, 0.08609627607113662, 0.2725732314447811]
Printing some Q and Qe and total Qs values:  [[0.963]
 [0.879]
 [0.947]
 [0.944]
 [0.959]
 [0.967]
 [1.003]] [[3.88 ]
 [4.202]
 [3.806]
 [3.804]
 [3.848]
 [3.786]
 [3.757]] [[1.546]
 [1.593]
 [1.464]
 [1.456]
 [1.516]
 [1.49 ]
 [1.544]]
first move QE:  2.2470760111453902
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.2497103669412576, 0.3806245094936097, 0.119954756623875, 0.2497103669412576]
Printing some Q and Qe and total Qs values:  [[0.735]
 [0.69 ]
 [0.693]
 [0.69 ]
 [0.69 ]
 [0.69 ]
 [0.711]] [[4.014]
 [3.791]
 [3.908]
 [4.011]
 [4.011]
 [4.011]
 [3.733]] [[1.513]
 [1.283]
 [1.379]
 [1.457]
 [1.457]
 [1.457]
 [1.263]]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.33787606342065946, 0.16212393657934057, 0.16212393657934057, 0.33787606342065946]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.33787606342065946, 0.16212393657934057, 0.16212393657934057, 0.33787606342065946]
Printing some Q and Qe and total Qs values:  [[0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]] [[1.63]
 [1.63]
 [1.63]
 [1.63]
 [1.63]
 [1.63]
 [1.63]] [[0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]]
Printing some Q and Qe and total Qs values:  [[0.504]
 [0.562]
 [0.521]
 [0.521]
 [0.521]
 [0.521]
 [0.521]] [[3.749]
 [3.47 ]
 [3.266]
 [3.266]
 [3.266]
 [3.266]
 [3.266]] [[0.974]
 [0.797]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.33787606342065946, 0.16212393657934057, 0.16212393657934057, 0.33787606342065946]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.41005696931496183, 0.19664767689501275, 0.19664767689501275, 0.19664767689501275]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.41005696931496183, 0.19664767689501275, 0.19664767689501275, 0.19664767689501275]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.41005696931496183, 0.19664767689501275, 0.19664767689501275, 0.19664767689501275]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.3803384254971163, 0.249712277206408, 0.249712277206408, 0.12023702009006772]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.3803384254971163, 0.249712277206408, 0.249712277206408, 0.12023702009006772]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]] [[ 4.739]
 [10.   ]
 [10.   ]
 [10.   ]
 [10.   ]
 [10.   ]
 [10.   ]] [[0.831]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.38033844711964504, 0.24971227715867675, 0.24971227715867675, 0.12023699856300137]
siam score:  -0.70146835
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.38033844711964504, 0.24971227715867675, 0.24971227715867675, 0.12023699856300137]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.38033844711964504, 0.24971227715867675, 0.24971227715867675, 0.12023699856300137]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.2872547278276145, 0.2872547278276145, 0.2872547278276145, 0.13823581651715652]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.3361898507020756, 0.3361898507020756, 0.2209330415520852, 0.10668725704376368]
Printing some Q and Qe and total Qs values:  [[0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]] [[1.783]
 [1.783]
 [1.783]
 [1.783]
 [1.783]
 [1.783]
 [1.783]] [[0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.38005357081910907, 0.24971416797622173, 0.24971416797622173, 0.12051809322844749]
Printing some Q and Qe and total Qs values:  [[0.935]
 [1.013]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]] [[3.96 ]
 [4.009]
 [3.191]
 [3.191]
 [3.191]
 [3.191]
 [3.191]] [[1.675]
 [1.848]
 [1.369]
 [1.369]
 [1.369]
 [1.369]
 [1.369]]
line 256 mcts: sample exp_bonus 5.518904783100953
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.3373623650407168, 0.3373623650407168, 0.16263763495928318, 0.16263763495928318]
Printing some Q and Qe and total Qs values:  [[0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]] [[1.715]
 [1.715]
 [1.715]
 [1.715]
 [1.715]
 [1.715]
 [1.715]] [[0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.735]
 [0.821]
 [0.672]
 [0.676]
 [0.66 ]
 [0.695]
 [0.663]] [[1.543]
 [1.06 ]
 [1.286]
 [1.261]
 [1.291]
 [1.299]
 [1.516]] [[0.97 ]
 [0.98 ]
 [0.759]
 [0.758]
 [0.737]
 [0.809]
 [0.818]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.3373623650407168, 0.3373623650407168, 0.16263763495928318, 0.16263763495928318]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.19702589601817727, 0.4089223119454682, 0.19702589601817727, 0.19702589601817727]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.2870698737989596, 0.2870698737989596, 0.13879037860312118, 0.2870698737989596]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.2870698737989596, 0.2870698737989596, 0.13879037860312118, 0.2870698737989596]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.2870698737989596, 0.2870698737989596, 0.13879037860312118, 0.2870698737989596]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.2870698737989596, 0.2870698737989596, 0.13879037860312118, 0.2870698737989596]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.2870698737989596, 0.2870698737989596, 0.13879037860312118, 0.2870698737989596]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.2870698737989596, 0.2870698737989596, 0.13879037860312118, 0.2870698737989596]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.2870698737989596, 0.2870698737989596, 0.13879037860312118, 0.2870698737989596]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.16289230173331884, 0.33710769826668113, 0.16289230173331884, 0.33710769826668113]
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.844]
 [0.843]
 [0.777]
 [0.777]
 [0.777]
 [0.777]] [[3.68 ]
 [3.451]
 [2.508]
 [2.94 ]
 [2.94 ]
 [2.94 ]
 [3.34 ]] [[1.758]
 [2.026]
 [1.797]
 [1.807]
 [1.807]
 [1.807]
 [1.903]]
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.08005959461321195, 0.33524879352189685, 0.24944281834299445, 0.33524879352189685]
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.07401927220912455, 0.3086602425969585, 0.3086602425969585, 0.3086602425969585]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.07401927220912455, 0.3086602425969585, 0.3086602425969585, 0.3086602425969585]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.07401927220912455, 0.3086602425969585, 0.3086602425969585, 0.3086602425969585]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.07401927220912455, 0.3086602425969585, 0.3086602425969585, 0.3086602425969585]
Printing some Q and Qe and total Qs values:  [[0.952]
 [0.911]
 [0.935]
 [0.947]
 [0.972]
 [0.944]
 [0.95 ]] [[5.162]
 [4.402]
 [4.653]
 [4.94 ]
 [4.655]
 [4.413]
 [5.495]] [[1.255]
 [0.929]
 [1.043]
 [1.164]
 [1.066]
 [0.953]
 [1.386]]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.07401927220912455, 0.3086602425969585, 0.3086602425969585, 0.3086602425969585]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.07401927220912455, 0.3086602425969585, 0.3086602425969585, 0.3086602425969585]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 7.776474744113147
line 256 mcts: sample exp_bonus 5.188449656538468
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.07401927220912455, 0.3086602425969585, 0.3086602425969585, 0.3086602425969585]
start point for exploration sampling:  10624
line 256 mcts: sample exp_bonus 5.6530351827202665
Printing some Q and Qe and total Qs values:  [[0.957]
 [1.044]
 [0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.957]] [[4.328]
 [4.709]
 [4.328]
 [4.328]
 [4.328]
 [4.328]
 [4.328]] [[1.727]
 [2.082]
 [1.727]
 [1.727]
 [1.727]
 [1.727]
 [1.727]]
Printing some Q and Qe and total Qs values:  [[-0.003]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]] [[6.044]
 [5.678]
 [5.678]
 [5.678]
 [5.678]
 [5.678]
 [5.678]] [[0.961]
 [0.76 ]
 [0.76 ]
 [0.76 ]
 [0.76 ]
 [0.76 ]
 [0.76 ]]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.06416798404027624, 0.33478999382728986, 0.2662520283051441, 0.33478999382728986]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.06416798404027624, 0.33478999382728986, 0.2662520283051441, 0.33478999382728986]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.06879283500056352, 0.3592272156761561, 0.21275273364712424, 0.3592272156761561]
from probs:  [0.06879283500056352, 0.3592272156761561, 0.21275273364712424, 0.3592272156761561]
first move QE:  2.239923761213465
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.07419885646167707, 0.3877920595812565, 0.22963791168761527, 0.30837117226945115]
Printing some Q and Qe and total Qs values:  [[1.021]
 [1.039]
 [1.039]
 [1.039]
 [1.042]
 [1.085]
 [1.018]] [[5.593]
 [4.911]
 [4.911]
 [4.911]
 [5.925]
 [5.428]
 [5.633]] [[1.181]
 [0.853]
 [0.853]
 [0.853]
 [1.363]
 [1.147]
 [1.198]]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.08054171698113695, 0.335004534168725, 0.24944921468141296, 0.335004534168725]
786 378
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.08801656843698372, 0.27279618038735526, 0.27279618038735526, 0.3663910707883057]
Printing some Q and Qe and total Qs values:  [[0.288]
 [0.264]
 [0.264]
 [0.264]
 [0.264]
 [0.264]
 [0.264]] [[0.429]
 [0.713]
 [0.713]
 [0.713]
 [0.713]
 [0.713]
 [0.713]] [[0.288]
 [0.264]
 [0.264]
 [0.264]
 [0.264]
 [0.264]
 [0.264]]
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
probs:  [0.1079426805924722, 0.2209986787368708, 0.2209986787368708, 0.45005996193378617]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.10794265961865794, 0.22099867445502164, 0.22099867445502164, 0.4500599914712988]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.10794265961865794, 0.22099867445502164, 0.22099867445502164, 0.4500599914712988]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.10794265961865794, 0.22099867445502164, 0.22099867445502164, 0.4500599914712988]
Printing some Q and Qe and total Qs values:  [[0.46 ]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]] [[5.346]
 [3.956]
 [3.956]
 [3.956]
 [3.956]
 [3.956]
 [3.956]] [[1.743]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]]
line 256 mcts: sample exp_bonus 3.620436296555564
Printing some Q and Qe and total Qs values:  [[1.042]
 [1.093]
 [1.042]
 [1.042]
 [1.042]
 [1.042]
 [1.042]] [[3.063]
 [3.15 ]
 [3.063]
 [3.063]
 [3.063]
 [3.063]
 [3.063]] [[1.745]
 [1.877]
 [1.745]
 [1.745]
 [1.745]
 [1.745]
 [1.745]]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.13988371380603618, 0.28670542873132127, 0.28670542873132127, 0.28670542873132127]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
Printing some Q and Qe and total Qs values:  [[0.782]
 [1.017]
 [0.88 ]
 [0.821]
 [0.802]
 [0.92 ]
 [0.849]] [[3.091]
 [2.857]
 [2.783]
 [2.778]
 [3.073]
 [3.033]
 [2.934]] [[1.876]
 [2.154]
 [1.867]
 [1.759]
 [1.9  ]
 [2.086]
 [1.902]]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.22111370605424285, 0.4492911540291268, 0.10848143386238762, 0.22111370605424285]
line 256 mcts: sample exp_bonus 2.8508003047942423
using another actor
maxi score, test score, baseline:  -0.997175204359673 -1.0 -0.997175204359673
probs:  [0.3778172695348344, 0.24972862575470317, 0.12272547895575933, 0.24972862575470317]
Printing some Q and Qe and total Qs values:  [[1.008]
 [1.263]
 [1.067]
 [1.005]
 [0.993]
 [0.981]
 [0.998]] [[2.882]
 [2.833]
 [2.813]
 [3.021]
 [2.993]
 [3.222]
 [3.146]] [[1.207]
 [1.472]
 [1.223]
 [1.315]
 [1.277]
 [1.445]
 [1.406]]
line 256 mcts: sample exp_bonus 4.144157748945723
maxi score, test score, baseline:  -0.997175204359673 -1.0 -0.997175204359673
actor:  1 policy actor:  1  step number:  85 total reward:  0.09999999999999931  reward:  1.0 rdn_beta:  0.667
maxi score, test score, baseline:  -0.997175204359673 -1.0 -0.997175204359673
probs:  [0.011139535742727252, 0.007691562246646238, 0.004272808864938689, 0.9768960931456879]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.8506085020260117
maxi score, test score, baseline:  -0.997175204359673 -1.0 -0.997175204359673
probs:  [0.011139535742727252, 0.007691562246646238, 0.004272808864938689, 0.9768960931456879]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.011139548067563038, 0.0076915699985546275, 0.004272812082673506, 0.9768960698512087]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.011139548067563038, 0.0076915699985546275, 0.004272812082673506, 0.9768960698512087]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
Printing some Q and Qe and total Qs values:  [[0.359]
 [0.858]
 [0.831]
 [0.835]
 [0.747]
 [0.869]
 [0.83 ]] [[3.314]
 [2.725]
 [2.177]
 [2.687]
 [1.294]
 [1.749]
 [3.331]] [[1.49 ]
 [1.581]
 [1.241]
 [1.539]
 [0.659]
 [1.027]
 [1.908]]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008079967574287977, 0.008079967574287977, 0.004462893391494124, 0.97937717145993]
795 398
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
Printing some Q and Qe and total Qs values:  [[0.901]
 [0.901]
 [0.877]
 [0.901]
 [0.901]
 [0.901]
 [0.901]] [[2.039]
 [2.039]
 [2.589]
 [2.039]
 [2.039]
 [2.039]
 [2.039]] [[1.484]
 [1.484]
 [2.169]
 [1.484]
 [1.484]
 [1.484]
 [1.484]]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.00818753070360416, 0.00818753070360416, 0.004515534658275104, 0.9791094039345166]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008351686399780104, 0.008351686399780104, 0.004595872259560526, 0.9787007549408793]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008351686399780104, 0.008351686399780104, 0.004595872259560526, 0.9787007549408793]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008407170292313842, 0.008407170292313842, 0.004623026010176443, 0.9785626334051959]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008463043562100835, 0.008463043562100835, 0.00465037032155415, 0.9784235425542441]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008463043562100835, 0.008463043562100835, 0.00465037032155415, 0.9784235425542441]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008463043562100835, 0.008463043562100835, 0.00465037032155415, 0.9784235425542441]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008463043562100835, 0.008463043562100835, 0.00465037032155415, 0.9784235425542441]
Printing some Q and Qe and total Qs values:  [[0.71 ]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]] [[2.53 ]
 [2.338]
 [2.338]
 [2.338]
 [2.338]
 [2.338]
 [2.338]] [[0.71 ]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]]
Printing some Q and Qe and total Qs values:  [[-0.052]
 [-0.057]
 [-0.057]
 [-0.057]
 [-0.057]
 [-0.052]
 [-0.057]] [[6.428]
 [6.486]
 [6.486]
 [6.486]
 [6.486]
 [6.271]
 [6.486]] [[1.253]
 [1.28 ]
 [1.28 ]
 [1.28 ]
 [1.28 ]
 [1.166]
 [1.28 ]]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008519310322457148, 0.008519310322457148, 0.004677907206745579, 0.9782834721483401]
Printing some Q and Qe and total Qs values:  [[0.568]
 [0.649]
 [0.528]
 [0.511]
 [0.506]
 [0.508]
 [0.508]] [[1.853]
 [1.102]
 [2.443]
 [2.379]
 [2.344]
 [2.327]
 [2.299]] [[0.568]
 [0.649]
 [0.528]
 [0.511]
 [0.506]
 [0.508]
 [0.508]]
Printing some Q and Qe and total Qs values:  [[0.763]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]] [[2.782]
 [2.405]
 [2.405]
 [2.405]
 [2.405]
 [2.405]
 [2.405]] [[0.763]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]]
siam score:  -0.6942397
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008575974744839662, 0.008575974744839662, 0.004705638707256929, 0.9781424118030637]
Printing some Q and Qe and total Qs values:  [[0.243]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]] [[-1.837]
 [-1.713]
 [-1.713]
 [-1.713]
 [-1.713]
 [-1.713]
 [-1.713]] [[0.243]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.00869051355842695, 0.00869051355842695, 0.004761693865573338, 0.9778572790175727]
Printing some Q and Qe and total Qs values:  [[0.742]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]] [[1.52 ]
 [1.953]
 [1.953]
 [1.953]
 [1.953]
 [1.953]
 [1.953]] [[0.742]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.008865411989804914, 0.008865411989804914, 0.0048472889486121775, 0.9774218870717779]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]] [[3.474]
 [3.474]
 [3.474]
 [3.474]
 [3.474]
 [3.474]
 [3.474]] [[1.024]
 [1.024]
 [1.024]
 [1.024]
 [1.024]
 [1.024]
 [1.024]]
800 407
maxi score, test score, baseline:  -0.997189972899729 -1.0 -0.997189972899729
maxi score, test score, baseline:  -0.997189972899729 -1.0 -0.997189972899729
probs:  [0.008865421877600905, 0.008865421877600905, 0.004847293114341043, 0.9774218631304572]
Printing some Q and Qe and total Qs values:  [[0.508]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]] [[2.524]
 [2.701]
 [2.701]
 [2.701]
 [2.701]
 [2.701]
 [2.701]] [[0.508]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
probs:  [0.009104588432355624, 0.009104588432355624, 0.004964340229549501, 0.9768264829057391]
using another actor
from probs:  [0.009226804676112314, 0.009226804676112314, 0.005024152692146072, 0.9765222379556294]
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
probs:  [0.009386769586723152, 0.0051024393006898995, 0.0051024393006898995, 0.980408351811897]
in main func line 156:  804
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]] [[2.407]
 [2.407]
 [2.407]
 [2.407]
 [2.407]
 [2.407]
 [2.407]] [[0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]]
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
probs:  [0.009450017340876712, 0.005133392665098382, 0.005133392665098382, 0.9802831973289267]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.009450028301992973, 0.005133397313904754, 0.005133397313904754, 0.9802831770701974]
Printing some Q and Qe and total Qs values:  [[0.199]
 [0.199]
 [0.199]
 [0.199]
 [0.199]
 [0.199]
 [0.199]] [[5.424]
 [5.424]
 [5.424]
 [5.424]
 [5.424]
 [5.424]
 [5.424]] [[1.276]
 [1.276]
 [1.276]
 [1.276]
 [1.276]
 [1.276]
 [1.276]]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
Printing some Q and Qe and total Qs values:  [[0.15 ]
 [0.116]
 [0.116]
 [0.116]
 [0.116]
 [0.116]
 [0.116]] [[5.974]
 [5.376]
 [5.376]
 [5.376]
 [5.376]
 [5.376]
 [5.376]] [[1.305]
 [0.94 ]
 [0.94 ]
 [0.94 ]
 [0.94 ]
 [0.94 ]
 [0.94 ]]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.00527869460313799, 0.00527869460313799, 0.00527869460313799, 0.984163916190586]
Printing some Q and Qe and total Qs values:  [[1.394]
 [1.407]
 [1.328]
 [1.328]
 [1.328]
 [1.328]
 [1.328]] [[2.25 ]
 [2.243]
 [2.228]
 [2.228]
 [2.228]
 [2.228]
 [2.228]] [[2.659]
 [2.674]
 [2.516]
 [2.516]
 [2.516]
 [2.516]
 [2.516]]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.005311130143809139, 0.005311130143809139, 0.005311130143809139, 0.9840666095685726]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.005311130143809139, 0.005311130143809139, 0.005311130143809139, 0.9840666095685726]
using another actor
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.005343816774300342, 0.005343816774300342, 0.005343816774300342, 0.9839685496770989]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.005343816774300342, 0.005343816774300342, 0.005343816774300342, 0.9839685496770989]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.005343816774300342, 0.005343816774300342, 0.005343816774300342, 0.9839685496770989]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.005343816774300342, 0.005343816774300342, 0.005343816774300342, 0.9839685496770989]
siam score:  -0.68873215
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.005343816774300342, 0.005343816774300342, 0.005343816774300342, 0.9839685496770989]
siam score:  -0.69131666
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.005477133423524865, 0.005477133423524865, 0.005477133423524865, 0.9835685997294253]
Printing some Q and Qe and total Qs values:  [[0.338]
 [0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]] [[-0.799]
 [-1.091]
 [-1.091]
 [-1.091]
 [-1.091]
 [-1.091]
 [-1.091]] [[0.338]
 [0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]]
siam score:  -0.6876352
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.0055453765991681885, 0.0055453765991681885, 0.0055453765991681885, 0.9833638702024954]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.005720818368284478, 0.005720818368284478, 0.005720818368284478, 0.9828375448951465]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.0058663579130793534, 0.0058663579130793534, 0.0058663579130793534, 0.9824009262607619]
line 256 mcts: sample exp_bonus 3.558823502229959
first move QE:  2.211799427600408
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.006093864712943699, 0.006093864712943699, 0.006093864712943699, 0.981718405861169]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.00613290549143834, 0.00613290549143834, 0.00613290549143834, 0.981601283525685]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.006172278026925819, 0.006172278026925819, 0.006172278026925819, 0.9814831659192226]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.006172278026925819, 0.006172278026925819, 0.006172278026925819, 0.9814831659192226]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.006211986566209431, 0.006211986566209431, 0.006211986566209431, 0.9813640403013718]
using another actor
Printing some Q and Qe and total Qs values:  [[0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]] [[-1.273]
 [-1.273]
 [-1.273]
 [-1.273]
 [-1.273]
 [-1.273]
 [-1.273]] [[0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]
 [0.107]]
siam score:  -0.68517435
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.19 ]
 [0.507]
 [0.404]
 [0.39 ]
 [0.386]
 [0.339]] [[-0.265]
 [ 1.745]
 [ 0.181]
 [ 0.188]
 [ 0.187]
 [-0.05 ]
 [ 0.01 ]] [[0.452]
 [0.19 ]
 [0.507]
 [0.404]
 [0.39 ]
 [0.386]
 [0.339]]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.006292435993352684, 0.006292435993352684, 0.006292435993352684, 0.9811226920199418]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.006292442940366585, 0.006292442940366585, 0.006292442940366585, 0.9811226711789003]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.006292442940366585, 0.006292442940366585, 0.006292442940366585, 0.9811226711789003]
Printing some Q and Qe and total Qs values:  [[0.57 ]
 [0.541]
 [0.498]
 [0.513]
 [0.513]
 [0.498]
 [0.513]] [[3.022]
 [4.158]
 [3.506]
 [3.671]
 [3.671]
 [3.603]
 [3.671]] [[0.57 ]
 [0.541]
 [0.498]
 [0.513]
 [0.513]
 [0.498]
 [0.513]]
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.0062924498502600155, 0.0062924498502600155, 0.0062924498502600155, 0.9811226504492201]
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.0062924498502600155, 0.0062924498502600155, 0.0062924498502600155, 0.9811226504492201]
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.0062924498502600155, 0.0062924498502600155, 0.0062924498502600155, 0.9811226504492201]
Printing some Q and Qe and total Qs values:  [[0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]] [[2.758]
 [2.758]
 [2.758]
 [2.758]
 [2.758]
 [2.758]
 [2.758]] [[0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.0062924498502600155, 0.0062924498502600155, 0.0062924498502600155, 0.9811226504492201]
from probs:  [0.0062924498502600155, 0.0062924498502600155, 0.0062924498502600155, 0.9811226504492201]
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
Printing some Q and Qe and total Qs values:  [[0.469]
 [0.326]
 [0.326]
 [0.326]
 [0.326]
 [0.326]
 [0.326]] [[1.645]
 [1.718]
 [1.718]
 [1.718]
 [1.718]
 [1.718]
 [1.718]] [[0.469]
 [0.326]
 [0.326]
 [0.326]
 [0.326]
 [0.326]
 [0.326]]
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
probs:  [0.006374296728471018, 0.006374296728471018, 0.006374296728471018, 0.9808771098145869]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
probs:  [0.006374296728471018, 0.006374296728471018, 0.006374296728471018, 0.9808771098145869]
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
probs:  [0.006374296728471018, 0.006374296728471018, 0.006374296728471018, 0.9808771098145869]
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
probs:  [0.006457570283866294, 0.006457570283866294, 0.006457570283866294, 0.9806272891484011]
Printing some Q and Qe and total Qs values:  [[0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]] [[2.738]
 [2.738]
 [2.738]
 [2.738]
 [2.738]
 [2.738]
 [2.738]] [[0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]]
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
maxi score, test score, baseline:  -0.9972404255319149 -1.0 -0.9972404255319149
maxi score, test score, baseline:  -0.9972474801061008 -1.0 -0.9972474801061008
probs:  [0.006542322786321138, 0.006542322786321138, 0.006542322786321138, 0.9803730316410367]
Printing some Q and Qe and total Qs values:  [[0.845]
 [0.455]
 [0.631]
 [0.631]
 [0.741]
 [0.885]
 [0.631]] [[4.022]
 [3.526]
 [3.482]
 [3.482]
 [2.842]
 [3.052]
 [3.482]] [[1.931]
 [1.463]
 [1.558]
 [1.558]
 [1.352]
 [1.537]
 [1.558]]
using explorer policy with actor:  1
siam score:  -0.69186366
maxi score, test score, baseline:  -0.9972474801061008 -1.0 -0.9972474801061008
maxi score, test score, baseline:  -0.9972474801061008 -1.0 -0.9972474801061008
probs:  [0.006628578992862098, 0.006628578992862098, 0.006628578992862098, 0.9801142630214137]
Printing some Q and Qe and total Qs values:  [[0.927]
 [0.936]
 [0.951]
 [0.951]
 [0.951]
 [0.886]
 [0.926]] [[4.498]
 [4.132]
 [4.589]
 [4.589]
 [4.589]
 [3.741]
 [3.932]] [[1.844]
 [1.556]
 [1.947]
 [1.947]
 [1.947]
 [1.177]
 [1.382]]
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.824]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]] [[2.929]
 [3.506]
 [2.929]
 [2.929]
 [2.929]
 [2.929]
 [2.929]] [[1.312]
 [1.887]
 [1.312]
 [1.312]
 [1.312]
 [1.312]
 [1.312]]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.006628586549189835, 0.006628586549189835, 0.006628586549189835, 0.9801142403524306]
siam score:  -0.6907313
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.006760893709218165, 0.006760893709218165, 0.006760893709218165, 0.9797173188723456]
Printing some Q and Qe and total Qs values:  [[0.858]
 [0.849]
 [0.849]
 [0.837]
 [0.832]
 [0.861]
 [0.852]] [[-2.565]
 [ 3.728]
 [-2.386]
 [-2.643]
 [-2.668]
 [-2.507]
 [-2.608]] [[0.308]
 [1.775]
 [0.347]
 [0.282]
 [0.275]
 [0.323]
 [0.296]]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.006989559335404145, 0.006989559335404145, 0.006989559335404145, 0.9790313219937875]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.006989559335404145, 0.006989559335404145, 0.006989559335404145, 0.9790313219937875]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
Printing some Q and Qe and total Qs values:  [[0.533]
 [0.571]
 [0.581]
 [0.571]
 [0.57 ]
 [0.571]
 [0.571]] [[3.759]
 [3.427]
 [3.608]
 [3.427]
 [3.717]
 [3.427]
 [3.427]] [[1.395]
 [1.132]
 [1.318]
 [1.132]
 [1.407]
 [1.132]
 [1.132]]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
Printing some Q and Qe and total Qs values:  [[0.149]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]] [[3.892]
 [3.895]
 [3.895]
 [3.895]
 [3.895]
 [3.895]
 [3.895]] [[0.476]
 [0.411]
 [0.411]
 [0.411]
 [0.411]
 [0.411]
 [0.411]]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007229043971956807, 0.007229043971956807, 0.007229043971956807, 0.9783128680841295]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007278307070823144, 0.007278307070823144, 0.007278307070823144, 0.9781650787875305]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007278307070823144, 0.007278307070823144, 0.007278307070823144, 0.9781650787875305]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
line 256 mcts: sample exp_bonus 0.7331470745652728
siam score:  -0.6989609
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007378251895543328, 0.007378251895543328, 0.007378251895543328, 0.9778652443133701]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007378251895543328, 0.007378251895543328, 0.007378251895543328, 0.9778652443133701]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007480134054102134, 0.007480134054102134, 0.007480134054102134, 0.9775595978376938]
siam score:  -0.71241915
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.007584020292241511, 0.007584020292241511, 0.007584020292241511, 0.9772479391232753]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.007636724835645164, 0.007636724835645164, 0.007636724835645164, 0.9770898254930646]
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.007689950290679551, 0.007689950290679551, 0.007689950290679551, 0.9769301491279615]
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.00779799513495546, 0.00779799513495546, 0.00779799513495546, 0.9766060145951336]
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.007852830515107628, 0.007852830515107628, 0.007852830515107628, 0.976441508454677]
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.007964168384108697, 0.007964168384108697, 0.007964168384108697, 0.976107494847674]
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.007964168384108697, 0.007964168384108697, 0.007964168384108697, 0.976107494847674]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.008135482925487152, 0.008135482925487152, 0.008135482925487152, 0.9755935512235384]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 3.804145390673988
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.008193765437976282, 0.008193765437976282, 0.008193765437976282, 0.9754187036860711]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.008193765437976282, 0.008193765437976282, 0.008193765437976282, 0.9754187036860711]
Printing some Q and Qe and total Qs values:  [[0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.606]] [[1.676]
 [1.676]
 [1.676]
 [1.676]
 [1.676]
 [1.676]
 [1.676]] [[0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.606]]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.008193776842523872, 0.008193776842523872, 0.008193776842523872, 0.9754186694724283]
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]] [[1.585]
 [1.674]
 [1.674]
 [1.674]
 [1.674]
 [1.674]
 [1.674]] [[0.732]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]]
line 256 mcts: sample exp_bonus 1.8733520519361158
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.008494473150873599, 0.008494473150873599, 0.008494473150873599, 0.9745165805473793]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.008494473150873599, 0.008494473150873599, 0.008494473150873599, 0.9745165805473793]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.008556538365659547, 0.008556538365659547, 0.008556538365659547, 0.9743303849030214]
using explorer policy with actor:  1
siam score:  -0.70488787
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.008682690619551165, 0.008682690619551165, 0.008682690619551165, 0.9739519281413466]
line 256 mcts: sample exp_bonus 2.457500619757446
maxi score, test score, baseline:  -0.9972890339425587 -1.0 -0.9972890339425587
probs:  [0.008746799766128525, 0.008746799766128525, 0.008746799766128525, 0.9737596007016144]
maxi score, test score, baseline:  -0.9972890339425587 -1.0 -0.9972890339425587
probs:  [0.008746799766128525, 0.008746799766128525, 0.008746799766128525, 0.9737596007016144]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.008746812566905958, 0.008746812566905958, 0.008746812566905958, 0.9737595622992822]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.008746812566905958, 0.008746812566905958, 0.008746812566905958, 0.9737595622992822]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.008811608382413625, 0.008811608382413625, 0.008811608382413625, 0.9735651748527591]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.008811608382413625, 0.008811608382413625, 0.008811608382413625, 0.9735651748527591]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.008811608382413625, 0.008811608382413625, 0.008811608382413625, 0.9735651748527591]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.008943343757886118, 0.008943343757886118, 0.008943343757886118, 0.9731699687263415]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.884]
 [0.883]
 [0.883]
 [0.883]
 [0.883]
 [0.883]
 [0.883]] [[2.385]
 [2.409]
 [2.409]
 [2.409]
 [2.409]
 [2.409]
 [2.409]] [[2.   ]
 [2.031]
 [2.031]
 [2.031]
 [2.031]
 [2.031]
 [2.031]]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.00907801714358155, 0.00907801714358155, 0.00907801714358155, 0.9727659485692552]
using explorer policy with actor:  1
Starting evaluation
maxi score, test score, baseline:  -0.9973025974025974 -1.0 -0.9973025974025974
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.39 ]
 [0.306]
 [0.454]
 [0.409]
 [0.358]
 [0.373]
 [0.393]] [[-2.29 ]
 [ 2.425]
 [-1.413]
 [-1.744]
 [-0.423]
 [-2.188]
 [-0.211]] [[0.39 ]
 [0.306]
 [0.454]
 [0.409]
 [0.358]
 [0.373]
 [0.393]]
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.009215756143887978, 0.009215756143887978, 0.009215756143887978, 0.9723527315683361]
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -1.8485008269023484
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.009215756143887978, 0.009215756143887978, 0.009215756143887978, 0.9723527315683361]
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]] [[2.06 ]
 [2.779]
 [2.779]
 [2.779]
 [2.779]
 [2.779]
 [2.779]] [[0.513]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.009215784061728039, 0.009215784061728039, 0.009215784061728039, 0.9723526478148158]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.795]
 [0.783]
 [0.758]
 [0.739]
 [0.745]
 [0.735]
 [0.717]] [[6.519]
 [6.476]
 [6.988]
 [6.78 ]
 [6.738]
 [6.807]
 [7.102]] [[1.43 ]
 [1.393]
 [1.513]
 [1.406]
 [1.405]
 [1.407]
 [1.469]]
Printing some Q and Qe and total Qs values:  [[0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]] [[-1.525]
 [-1.525]
 [-1.525]
 [-1.525]
 [-1.525]
 [-1.525]
 [-1.525]] [[0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]]
Printing some Q and Qe and total Qs values:  [[0.417]
 [0.417]
 [0.417]
 [0.417]
 [0.417]
 [0.417]
 [0.417]] [[-2.149]
 [-2.149]
 [-2.149]
 [-2.149]
 [-2.149]
 [-2.149]
 [-2.149]] [[0.417]
 [0.417]
 [0.417]
 [0.417]
 [0.417]
 [0.417]
 [0.417]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]] [[1.622]
 [1.622]
 [1.622]
 [1.622]
 [1.622]
 [1.622]
 [1.622]] [[0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.852]
 [0.686]
 [0.991]
 [0.969]
 [0.875]
 [0.877]
 [0.944]] [[-2.405]
 [ 2.474]
 [-1.415]
 [-1.646]
 [-2.41 ]
 [-2.413]
 [-1.972]] [[0.152]
 [1.641]
 [0.538]
 [0.453]
 [0.162]
 [0.162]
 [0.336]]
line 256 mcts: sample exp_bonus 3.555431740504948
Printing some Q and Qe and total Qs values:  [[0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]] [[8.735]
 [8.735]
 [8.735]
 [8.735]
 [8.735]
 [8.735]
 [8.735]] [[1.499]
 [1.499]
 [1.499]
 [1.499]
 [1.499]
 [1.499]
 [1.499]]
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]] [[-2.083]
 [-2.083]
 [-2.083]
 [-2.083]
 [-2.083]
 [-2.083]
 [-2.083]] [[0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
Printing some Q and Qe and total Qs values:  [[0.481]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]] [[-1.768]
 [-1.662]
 [-1.662]
 [-1.662]
 [-1.662]
 [-1.662]
 [-1.662]] [[0.481]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]]
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]] [[1.366]
 [1.366]
 [1.366]
 [1.366]
 [1.366]
 [1.366]
 [1.366]] [[0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.0095007419107608, 0.0095007419107608, 0.0095007419107608, 0.9714977742677176]
Printing some Q and Qe and total Qs values:  [[0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]] [[1.64]
 [1.64]
 [1.64]
 [1.64]
 [1.64]
 [1.64]
 [1.64]] [[0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.2018533412107804
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[1.473]
 [1.473]
 [1.473]
 [1.473]
 [1.473]
 [1.473]
 [1.473]] [[2.137]
 [2.137]
 [2.165]
 [2.165]
 [2.165]
 [2.165]
 [2.165]] [[2.877]
 [2.877]
 [2.908]
 [2.908]
 [2.908]
 [2.908]
 [2.908]]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.009723242295277039, 0.009723242295277039, 0.009723242295277039, 0.9708302731141688]
line 256 mcts: sample exp_bonus 2.857008255560652
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]] [[2.919]
 [2.919]
 [2.919]
 [2.919]
 [2.919]
 [2.919]
 [2.919]] [[0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.476]
 [0.727]
 [0.727]
 [0.727]
 [0.661]
 [0.655]
 [0.669]] [[4.935]
 [3.892]
 [4.392]
 [4.392]
 [3.316]
 [3.841]
 [3.35 ]] [[1.861]
 [1.296]
 [1.721]
 [1.721]
 [0.722]
 [1.16 ]
 [0.761]]
Printing some Q and Qe and total Qs values:  [[0.679]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]] [[2.039]
 [1.888]
 [1.888]
 [1.888]
 [1.888]
 [1.888]
 [1.888]] [[0.679]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.753]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]] [[1.92 ]
 [1.888]
 [1.888]
 [1.888]
 [1.888]
 [1.888]
 [1.888]] [[0.753]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]]
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.452]
 [0.452]
 [0.452]
 [0.452]
 [0.452]
 [0.452]] [[2.183]
 [2.183]
 [2.183]
 [2.183]
 [2.183]
 [2.183]
 [2.183]] [[0.452]
 [0.452]
 [0.452]
 [0.452]
 [0.452]
 [0.452]
 [0.452]]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.009799160871096144, 0.009799160871096144, 0.009799160871096144, 0.9706025173867114]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 1.3476159510046357
Printing some Q and Qe and total Qs values:  [[0.444]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]] [[2.164]
 [2.27 ]
 [2.27 ]
 [2.27 ]
 [2.27 ]
 [2.27 ]
 [2.27 ]] [[0.444]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]]
Printing some Q and Qe and total Qs values:  [[0.569]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]] [[2.421]
 [2.293]
 [2.293]
 [2.293]
 [2.293]
 [2.293]
 [2.293]] [[0.569]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.009530028769525304, 0.018395222998162968, 0.018395222998162968, 0.9536795252341488]
Printing some Q and Qe and total Qs values:  [[0.498]
 [0.508]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]] [[2.309]
 [2.461]
 [2.433]
 [2.433]
 [2.433]
 [2.433]
 [2.433]] [[0.498]
 [0.508]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]]
Printing some Q and Qe and total Qs values:  [[0.501]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]] [[1.167]
 [1.749]
 [1.749]
 [1.749]
 [1.749]
 [1.749]
 [1.749]] [[0.501]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]]
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]] [[1.747]
 [1.917]
 [1.917]
 [1.917]
 [1.917]
 [1.917]
 [1.917]] [[0.734]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]]
using explorer policy with actor:  0
siam score:  -0.69219184
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.415]
 [0.455]
 [0.497]
 [0.459]
 [0.447]
 [0.462]] [[1.378]
 [2.494]
 [1.83 ]
 [1.408]
 [1.78 ]
 [1.821]
 [1.59 ]] [[0.477]
 [0.415]
 [0.455]
 [0.497]
 [0.459]
 [0.447]
 [0.462]]
Printing some Q and Qe and total Qs values:  [[0.633]
 [0.464]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]] [[1.317]
 [2.567]
 [2.875]
 [2.875]
 [2.875]
 [2.875]
 [2.875]] [[0.633]
 [0.464]
 [0.449]
 [0.449]
 [0.449]
 [0.449]
 [0.449]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]] [[1.762]
 [1.762]
 [1.762]
 [1.762]
 [1.762]
 [1.762]
 [1.762]] [[0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
Printing some Q and Qe and total Qs values:  [[0.815]
 [0.747]
 [0.823]
 [0.75 ]
 [0.712]
 [0.708]
 [0.825]] [[2.527]
 [3.54 ]
 [2.697]
 [2.41 ]
 [2.377]
 [2.629]
 [2.301]] [[1.117]
 [1.888]
 [1.271]
 [0.936]
 [0.859]
 [1.067]
 [0.939]]
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.563]
 [0.563]
 [0.563]
 [0.563]
 [0.558]
 [0.557]] [[1.154]
 [1.829]
 [1.829]
 [1.829]
 [1.829]
 [1.702]
 [1.721]] [[0.701]
 [0.563]
 [0.563]
 [0.563]
 [0.563]
 [0.558]
 [0.557]]
Printing some Q and Qe and total Qs values:  [[0.602]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]] [[1.474]
 [1.438]
 [1.438]
 [1.438]
 [1.438]
 [1.438]
 [1.438]] [[0.602]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]]
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.566]
 [0.57 ]
 [0.628]
 [0.698]
 [0.538]
 [0.563]] [[1.536]
 [2.168]
 [1.877]
 [1.635]
 [1.43 ]
 [1.746]
 [1.691]] [[0.703]
 [0.566]
 [0.57 ]
 [0.628]
 [0.698]
 [0.538]
 [0.563]]
Printing some Q and Qe and total Qs values:  [[0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]] [[1.698]
 [1.698]
 [1.698]
 [1.698]
 [1.698]
 [1.698]
 [1.698]] [[0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.009602594315694749, 0.018543186534336432, 0.018543186534336432, 0.9533110326156323]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.009602594315694749, 0.018543186534336432, 0.018543186534336432, 0.9533110326156323]
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
probs:  [0.009602608791381763, 0.018543218728294633, 0.018543218728294633, 0.953310953752029]
Printing some Q and Qe and total Qs values:  [[0.56]
 [0.56]
 [0.56]
 [0.56]
 [0.56]
 [0.56]
 [0.56]] [[1.665]
 [1.665]
 [1.665]
 [1.665]
 [1.665]
 [1.665]
 [1.665]] [[0.56]
 [0.56]
 [0.56]
 [0.56]
 [0.56]
 [0.56]
 [0.56]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]] [[1.294]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]] [[0.536]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.607]
 [0.726]
 [0.513]
 [0.613]
 [0.462]
 [0.472]] [[1.036]
 [1.584]
 [2.504]
 [1.682]
 [1.121]
 [1.625]
 [1.64 ]] [[0.581]
 [0.607]
 [0.726]
 [0.513]
 [0.613]
 [0.462]
 [0.472]]
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
maxi score, test score, baseline:  -0.9973937343358396 -1.0 -0.9973937343358396
probs:  [0.009675977527204336, 0.018692814278347084, 0.018692814278347084, 0.9529383939161016]
from probs:  [0.009675977527204336, 0.018692814278347084, 0.018692814278347084, 0.9529383939161016]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9974000000000001 -1.0 -0.9974000000000001
probs:  [0.009750150074710426, 0.018844040718603704, 0.018844040718603704, 0.952561768488082]
maxi score, test score, baseline:  -0.9974000000000001 -1.0 -0.9974000000000001
probs:  [0.009750150074710426, 0.018844040718603704, 0.018844040718603704, 0.952561768488082]
Printing some Q and Qe and total Qs values:  [[-0.004]
 [-0.019]
 [-0.019]
 [-0.019]
 [-0.019]
 [-0.019]
 [-0.019]] [[9.111]
 [4.241]
 [4.241]
 [4.241]
 [4.241]
 [4.241]
 [4.241]] [[1.52 ]
 [0.294]
 [0.294]
 [0.294]
 [0.294]
 [0.294]
 [0.294]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.417]
 [0.488]
 [0.469]
 [0.433]
 [0.432]
 [0.468]] [[1.712]
 [2.667]
 [1.75 ]
 [1.653]
 [1.585]
 [1.652]
 [1.725]] [[0.601]
 [0.417]
 [0.488]
 [0.469]
 [0.433]
 [0.432]
 [0.468]]
Printing some Q and Qe and total Qs values:  [[0.787]
 [0.691]
 [0.691]
 [0.691]
 [0.691]
 [0.691]
 [0.691]] [[1.203]
 [1.891]
 [1.891]
 [1.891]
 [1.891]
 [1.891]
 [1.891]] [[0.787]
 [0.691]
 [0.691]
 [0.691]
 [0.691]
 [0.691]
 [0.691]]
using another actor
maxi score, test score, baseline:  -0.9974000000000001 -1.0 -0.9974000000000001
probs:  [0.009977852531713767, 0.019308282987606906, 0.019308282987606906, 0.9514055814930724]
Printing some Q and Qe and total Qs values:  [[0.82 ]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]] [[2.137]
 [2.242]
 [2.242]
 [2.242]
 [2.242]
 [2.242]
 [2.242]] [[0.82 ]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]]
Printing some Q and Qe and total Qs values:  [[0.686]
 [0.501]
 [0.521]
 [0.515]
 [0.498]
 [0.502]
 [0.516]] [[1.16 ]
 [2.683]
 [1.695]
 [1.594]
 [1.552]
 [1.62 ]
 [1.669]] [[0.686]
 [0.501]
 [0.521]
 [0.515]
 [0.498]
 [0.502]
 [0.516]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.5289642003261237
Printing some Q and Qe and total Qs values:  [[0.527]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]] [[1.771]
 [1.856]
 [1.856]
 [1.856]
 [1.856]
 [1.856]
 [1.856]] [[0.527]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]] [[2.469]
 [2.302]
 [2.302]
 [2.302]
 [2.302]
 [2.302]
 [2.302]] [[0.614]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]]
Printing some Q and Qe and total Qs values:  [[0.726]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]] [[1.115]
 [1.585]
 [1.585]
 [1.585]
 [1.585]
 [1.585]
 [1.585]] [[0.726]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]] [[3.517]
 [3.517]
 [3.517]
 [3.517]
 [3.517]
 [3.517]
 [3.517]] [[0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]]
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.558]
 [0.747]
 [0.554]
 [0.5  ]
 [0.486]
 [0.671]] [[1.385]
 [3.049]
 [2.353]
 [1.726]
 [1.629]
 [1.558]
 [1.767]] [[0.635]
 [0.558]
 [0.747]
 [0.554]
 [0.5  ]
 [0.486]
 [0.671]]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.010213740849386683, 0.019789217464666917, 0.019789217464666917, 0.9502078242212795]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.010213740849386683, 0.019789217464666917, 0.019789217464666917, 0.9502078242212795]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.697]
 [0.629]
 [0.629]
 [0.629]
 [0.599]
 [0.629]
 [0.629]] [[1.977]
 [2.2  ]
 [2.2  ]
 [2.2  ]
 [1.865]
 [2.2  ]
 [2.2  ]] [[0.697]
 [0.629]
 [0.629]
 [0.629]
 [0.599]
 [0.629]
 [0.629]]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.010213740849386683, 0.019789217464666917, 0.019789217464666917, 0.9502078242212795]
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.603]] [[2.788]
 [2.465]
 [2.465]
 [2.465]
 [2.465]
 [2.465]
 [2.465]] [[0.622]
 [0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.603]]
Printing some Q and Qe and total Qs values:  [[0.472]
 [0.355]
 [0.457]
 [0.452]
 [0.452]
 [0.445]
 [0.456]] [[1.587]
 [2.721]
 [1.368]
 [1.223]
 [1.425]
 [1.421]
 [1.298]] [[0.472]
 [0.355]
 [0.457]
 [0.452]
 [0.452]
 [0.445]
 [0.456]]
rdn probs:  [0.010213834556629525, 0.01978942494050929, 0.01978942494050929, 0.9502073155623519]
Printing some Q and Qe and total Qs values:  [[0.572]
 [0.298]
 [0.511]
 [0.507]
 [0.505]
 [0.504]
 [0.505]] [[1.167]
 [2.403]
 [1.822]
 [1.467]
 [1.558]
 [1.564]
 [1.499]] [[0.572]
 [0.298]
 [0.511]
 [0.507]
 [0.505]
 [0.504]
 [0.505]]
maxi score, test score, baseline:  -0.9974550122249389 -1.0 -0.9974550122249389
from probs:  [0.010375876592358462, 0.020119803821214297, 0.020119803821214297, 0.9493845157652129]
maxi score, test score, baseline:  -0.9974609756097561 -1.0 -0.9974609756097561
probs:  [0.010375892278536013, 0.020119838513211197, 0.020119838513211197, 0.9493844306950416]
rdn beta is 0 so we're just using the maxi policy
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9974609756097561 -1.0 -0.9974609756097561
probs:  [0.010375892278536013, 0.020119838513211197, 0.020119838513211197, 0.9493844306950416]
maxi score, test score, baseline:  -0.9974669099756691 -1.0 -0.9974669099756691
probs:  [0.010375907888261418, 0.02011987303610734, 0.02011987303610734, 0.9493843460395239]
start point for exploration sampling:  10624
from probs:  [0.010375907888261418, 0.02011987303610734, 0.02011987303610734, 0.9493843460395239]
maxi score, test score, baseline:  -0.9974728155339806 -1.0 -0.9974728155339806
probs:  [0.010458409693746564, 0.02028808159839965, 0.02028808159839965, 0.9489654271094541]
using explorer policy with actor:  1
siam score:  -0.7196176
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.818]
 [0.867]
 [0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]] [[5.376]
 [4.332]
 [3.737]
 [3.737]
 [3.737]
 [3.737]
 [3.737]] [[2.129]
 [1.862]
 [1.696]
 [1.696]
 [1.696]
 [1.696]
 [1.696]]
Printing some Q and Qe and total Qs values:  [[0.971]
 [0.973]
 [0.973]
 [0.973]
 [0.973]
 [0.973]
 [0.973]] [[3.11 ]
 [3.207]
 [3.207]
 [3.207]
 [3.207]
 [3.207]
 [3.207]] [[2.388]
 [2.507]
 [2.507]
 [2.507]
 [2.507]
 [2.507]
 [2.507]]
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.010798684812324398, 0.020981845016516544, 0.020981845016516544, 0.9472376251546424]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.010798684812324398, 0.020981845016516544, 0.020981845016516544, 0.9472376251546424]
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.01088641694484189, 0.021160714610859343, 0.021160714610859343, 0.9467921538334394]
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.77 ]
 [0.778]
 [0.767]
 [0.782]
 [0.769]
 [0.805]] [[3.039]
 [3.142]
 [2.778]
 [2.509]
 [2.505]
 [2.532]
 [2.515]] [[1.545]
 [1.623]
 [1.295]
 [1.03 ]
 [1.047]
 [1.055]
 [1.088]]
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.011065229351346852, 0.021525280040847746, 0.021525280040847746, 0.9458842105669577]
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.011342143968502779, 0.022089857736807206, 0.022089857736807206, 0.9444781405578828]
Printing some Q and Qe and total Qs values:  [[0.458]
 [0.336]
 [0.301]
 [0.3  ]
 [0.298]
 [0.298]
 [0.303]] [[1.141]
 [2.754]
 [2.278]
 [2.26 ]
 [2.259]
 [2.258]
 [2.254]] [[0.458]
 [0.336]
 [0.301]
 [0.3  ]
 [0.298]
 [0.298]
 [0.303]]
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.011342143968502779, 0.022089857736807206, 0.022089857736807206, 0.9444781405578828]
867 495
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.011436858584615342, 0.02228296332396537, 0.02228296332396537, 0.9439972147674539]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.011436858584615342, 0.02228296332396537, 0.02228296332396537, 0.9439972147674539]
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.011436858584615342, 0.02228296332396537, 0.02228296332396537, 0.9439972147674539]
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.011436858584615342, 0.02228296332396537, 0.02228296332396537, 0.9439972147674539]
maxi score, test score, baseline:  -0.9974845410628019 -1.0 -0.9974845410628019
probs:  [0.011436858584615342, 0.02228296332396537, 0.02228296332396537, 0.9439972147674539]
Printing some Q and Qe and total Qs values:  [[0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.683]] [[2.743]
 [2.743]
 [2.743]
 [2.743]
 [2.743]
 [2.743]
 [2.346]] [[0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.683]]
maxi score, test score, baseline:  -0.9974903614457832 -1.0 -0.9974903614457832
maxi score, test score, baseline:  -0.9974903614457832 -1.0 -0.9974903614457832
probs:  [0.011532836564161684, 0.02247864764742262, 0.02247864764742262, 0.9435098681409931]
Printing some Q and Qe and total Qs values:  [[ 0.024]
 [-0.005]
 [ 0.031]
 [ 0.031]
 [ 0.031]
 [ 0.031]
 [ 0.031]] [[4.709]
 [4.875]
 [4.313]
 [4.313]
 [4.313]
 [4.313]
 [4.313]] [[0.872]
 [0.955]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]]
siam score:  -0.70545024
maxi score, test score, baseline:  -0.9974903614457832 -1.0 -0.9974903614457832
probs:  [0.011929622392969678, 0.02328762068867535, 0.02328762068867535, 0.9414951362296797]
maxi score, test score, baseline:  -0.9974903614457832 -1.0 -0.9974903614457832
maxi score, test score, baseline:  -0.9974903614457832 -1.0 -0.9974903614457832
maxi score, test score, baseline:  -0.9974903614457832 -1.0 -0.9974903614457832
probs:  [0.011929622392969678, 0.02328762068867535, 0.02328762068867535, 0.9414951362296797]
maxi score, test score, baseline:  -0.9974903614457832 -1.0 -0.9974903614457832
probs:  [0.011929622392969678, 0.02328762068867535, 0.02328762068867535, 0.9414951362296797]
siam score:  -0.7078032
Printing some Q and Qe and total Qs values:  [[0.646]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]] [[2.106]
 [2.075]
 [2.075]
 [2.075]
 [2.075]
 [2.075]
 [2.075]] [[0.646]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]]
maxi score, test score, baseline:  -0.9974961538461539 -1.0 -0.9974961538461539
probs:  [0.012032208346570459, 0.023496777604014477, 0.023496777604014477, 0.9409742364454007]
maxi score, test score, baseline:  -0.9974961538461539 -1.0 -0.9974961538461539
probs:  [0.012032208346570459, 0.023496777604014477, 0.023496777604014477, 0.9409742364454007]
maxi score, test score, baseline:  -0.9974961538461539 -1.0 -0.9974961538461539
probs:  [0.012136177068425805, 0.02370875065997389, 0.02370875065997389, 0.9404463216116264]
maxi score, test score, baseline:  -0.9974961538461539 -1.0 -0.9974961538461539
maxi score, test score, baseline:  -0.9974961538461539 -1.0 -0.9974961538461539
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]] [[1.629]
 [2.303]
 [2.303]
 [2.303]
 [2.303]
 [2.303]
 [2.303]] [[0.774]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]]
maxi score, test score, baseline:  -0.9974961538461539 -1.0 -0.9974961538461539
probs:  [0.0122415776812235, 0.023923643077578056, 0.023923643077578056, 0.9399111361636204]
Printing some Q and Qe and total Qs values:  [[0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]] [[2.794]
 [2.794]
 [2.794]
 [2.794]
 [2.794]
 [2.794]
 [2.794]] [[0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.332]
 [0.299]
 [0.337]
 [0.337]
 [0.337]
 [0.337]
 [0.297]] [[1.504]
 [1.993]
 [1.227]
 [1.227]
 [1.227]
 [1.227]
 [1.349]] [[0.332]
 [0.299]
 [0.337]
 [0.337]
 [0.337]
 [0.337]
 [0.297]]
maxi score, test score, baseline:  -0.9974961538461539 -1.0 -0.9974961538461539
probs:  [0.0122415776812235, 0.023923643077578056, 0.023923643077578056, 0.9399111361636204]
Printing some Q and Qe and total Qs values:  [[0.348]
 [0.29 ]
 [0.307]
 [0.295]
 [0.273]
 [0.273]
 [0.307]] [[2.27 ]
 [2.603]
 [2.284]
 [2.291]
 [2.299]
 [2.282]
 [2.222]] [[0.348]
 [0.29 ]
 [0.307]
 [0.295]
 [0.273]
 [0.273]
 [0.307]]
maxi score, test score, baseline:  -0.9975019184652278 -1.0 -0.9975019184652278
maxi score, test score, baseline:  -0.9975019184652278 -1.0 -0.9975019184652278
probs:  [0.012456816408045093, 0.024362478361091625, 0.024362478361091625, 0.9388182268697718]
maxi score, test score, baseline:  -0.9975019184652278 -1.0 -0.9975019184652278
probs:  [0.012456816408045093, 0.024362478361091625, 0.024362478361091625, 0.9388182268697718]
maxi score, test score, baseline:  -0.9975076555023924 -1.0 -0.9975076555023924
probs:  [0.012456838156596711, 0.024362525888433836, 0.024362525888433836, 0.9388181100665355]
Printing some Q and Qe and total Qs values:  [[0.146]
 [0.082]
 [0.136]
 [0.14 ]
 [0.133]
 [0.137]
 [0.141]] [[1.069]
 [3.172]
 [1.381]
 [0.975]
 [1.141]
 [1.227]
 [0.902]] [[0.146]
 [0.082]
 [0.136]
 [0.14 ]
 [0.133]
 [0.137]
 [0.141]]
maxi score, test score, baseline:  -0.9975076555023924 -1.0 -0.9975076555023924
probs:  [0.012456838156596711, 0.024362525888433836, 0.024362525888433836, 0.9388181100665355]
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
probs:  [0.012456859801185627, 0.024362573188566338, 0.024362573188566338, 0.9388179938216816]
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
probs:  [0.012456859801185627, 0.024362573188566338, 0.024362573188566338, 0.9388179938216816]
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
probs:  [0.012456859801185627, 0.024362573188566338, 0.024362573188566338, 0.9388179938216816]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
probs:  [0.012456859801185627, 0.024362573188566338, 0.024362573188566338, 0.9388179938216816]
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
probs:  [0.012566739313626176, 0.024586597348441125, 0.024586597348441125, 0.9382600659894915]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
maxi score, test score, baseline:  -0.9975133651551312 -1.0 -0.9975133651551312
probs:  [0.012678174996490306, 0.024813794254208238, 0.024813794254208238, 0.9376942364950932]
maxi score, test score, baseline:  -0.997524703087886 -1.0 -0.997524703087886
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
probs:  [0.01279126795746247, 0.025044379742702187, 0.025044379742702187, 0.9371199725571332]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
probs:  [0.01279126795746247, 0.025044379742702187, 0.025044379742702187, 0.9371199725571332]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.7868780943498406
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
probs:  [0.012905918041715371, 0.025278130317220798, 0.025278130317220798, 0.9365378213238431]
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
probs:  [0.012905918041715371, 0.025278130317220798, 0.025278130317220798, 0.9365378213238431]
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
probs:  [0.012905918041715371, 0.025278130317220798, 0.025278130317220798, 0.9365378213238431]
Printing some Q and Qe and total Qs values:  [[0.974]
 [0.862]
 [0.907]
 [0.907]
 [0.907]
 [0.969]
 [0.907]] [[0.677]
 [3.45 ]
 [3.078]
 [3.078]
 [3.078]
 [0.712]
 [3.078]] [[1.061]
 [2.497]
 [2.357]
 [2.357]
 [2.357]
 [1.073]
 [2.357]]
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.798]
 [0.836]
 [0.836]
 [0.924]
 [0.836]
 [0.836]] [[3.328]
 [4.204]
 [3.73 ]
 [3.73 ]
 [2.089]
 [3.73 ]
 [3.73 ]] [[1.067]
 [1.766]
 [1.466]
 [1.466]
 [0.382]
 [1.466]
 [1.466]]
maxi score, test score, baseline:  -0.9975359338061466 -1.0 -0.9975359338061466
probs:  [0.01302225031890036, 0.025515313840080593, 0.025515313840080593, 0.9359471220009384]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9975359338061466 -1.0 -0.9975359338061466
probs:  [0.013140255071268167, 0.025755904001997718, 0.025755904001997718, 0.9353479369247364]
maxi score, test score, baseline:  -0.9975359338061466 -1.0 -0.9975359338061466
probs:  [0.013140255071268167, 0.025755904001997718, 0.025755904001997718, 0.9353479369247364]
maxi score, test score, baseline:  -0.9975359338061466 -1.0 -0.9975359338061466
probs:  [0.013140255071268167, 0.025755904001997718, 0.025755904001997718, 0.9353479369247364]
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]] [[4.493]
 [4.493]
 [4.493]
 [4.493]
 [4.493]
 [4.493]
 [4.493]] [[4.28]
 [4.28]
 [4.28]
 [4.28]
 [4.28]
 [4.28]
 [4.28]]
using explorer policy with actor:  1
first move QE:  2.180483444396563
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.013260016373618757, 0.026000078761954114, 0.026000078761954114, 0.9347398261024731]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.394]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]] [[4.684]
 [4.936]
 [4.936]
 [4.936]
 [4.936]
 [4.936]
 [4.936]] [[0.729]
 [0.856]
 [0.856]
 [0.856]
 [0.856]
 [0.856]
 [0.856]]
882 509
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.013504844699605622, 0.02649923911960014, 0.02649923911960014, 0.933496677061194]
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.013670196777627971, 0.013670196777627971, 0.026836361885401536, 0.9458232445593425]
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.013670196777627971, 0.013670196777627971, 0.026836361885401536, 0.9458232445593425]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.013670222198683748, 0.013670222198683748, 0.026836417122031303, 0.9458231384806012]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.013670222198683748, 0.013670222198683748, 0.026836417122031303, 0.9458231384806012]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.013670222198683748, 0.013670222198683748, 0.026836417122031303, 0.9458231384806012]
line 256 mcts: sample exp_bonus 2.1376926026133063
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.013670222198683748, 0.013670222198683748, 0.026836417122031303, 0.9458231384806012]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.01392924002364131, 0.01392924002364131, 0.027364507352897114, 0.9447770125998202]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.751]
 [0.718]] [[2.303]
 [2.082]
 [2.082]
 [2.082]
 [2.082]
 [2.135]
 [2.082]] [[1.522]
 [1.227]
 [1.227]
 [1.227]
 [1.227]
 [1.364]
 [1.227]]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.014196358996806628, 0.014196358996806628, 0.027909114351395238, 0.9436981676549915]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.014333076119416909, 0.014333076119416909, 0.028187855696144543, 0.9431459920650216]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.014521214316272717, 0.014521214316272717, 0.014521214316272717, 0.9564363570511819]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.014521214316272717, 0.014521214316272717, 0.014521214316272717, 0.9564363570511819]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.014521214316272717, 0.014521214316272717, 0.014521214316272717, 0.9564363570511819]
maxi score, test score, baseline:  -0.9975470588235295 -1.0 -0.9975470588235295
probs:  [0.015259386635771014, 0.015259386635771014, 0.015259386635771014, 0.9542218400926871]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.01573271470797619, 0.01573271470797619, 0.01573271470797619, 0.9528018558760715]
from probs:  [0.015895939789568523, 0.015895939789568523, 0.015895939789568523, 0.9523121806312944]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.016062013786494717, 0.016062013786494717, 0.016062013786494717, 0.9518139586405158]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.0162310119424564, 0.0162310119424564, 0.0162310119424564, 0.9513069641726309]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.0162310119424564, 0.0162310119424564, 0.0162310119424564, 0.9513069641726309]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.0162310119424564, 0.0162310119424564, 0.0162310119424564, 0.9513069641726309]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.0162310119424564, 0.0162310119424564, 0.0162310119424564, 0.9513069641726309]
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.655]
 [0.63 ]
 [0.672]
 [0.702]
 [0.605]
 [0.624]] [[1.297]
 [1.916]
 [1.321]
 [0.961]
 [1.042]
 [1.201]
 [1.18 ]] [[0.767]
 [0.655]
 [0.63 ]
 [0.672]
 [0.702]
 [0.605]
 [0.624]]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.0162310119424564, 0.0162310119424564, 0.0162310119424564, 0.9513069641726309]
Printing some Q and Qe and total Qs values:  [[0.748]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[4.443]
 [4.175]
 [4.175]
 [4.175]
 [4.175]
 [4.175]
 [4.175]] [[0.748]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]]
maxi score, test score, baseline:  -0.9975635514018691 -1.0 -0.9975635514018691
probs:  [0.0162310830090547, 0.0162310830090547, 0.0162310830090547, 0.9513067509728359]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.016231118293562646, 0.016231118293562646, 0.016231118293562646, 0.9513066451193121]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.016578206133276634, 0.016578206133276634, 0.016578206133276634, 0.95026538160017]
Printing some Q and Qe and total Qs values:  [[0.195]
 [0.074]
 [0.069]
 [0.069]
 [0.069]
 [0.069]
 [0.069]] [[3.428]
 [3.539]
 [3.526]
 [3.526]
 [3.526]
 [3.526]
 [3.526]] [[0.711]
 [0.638]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.016578206133276634, 0.016578206133276634, 0.016578206133276634, 0.95026538160017]
Printing some Q and Qe and total Qs values:  [[-0.03 ]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]] [[5.026]
 [4.929]
 [4.929]
 [4.929]
 [4.929]
 [4.929]
 [4.929]] [[1.155]
 [1.093]
 [1.093]
 [1.093]
 [1.093]
 [1.093]
 [1.093]]
Printing some Q and Qe and total Qs values:  [[0.474]
 [0.474]
 [0.474]
 [0.474]
 [0.474]
 [0.474]
 [0.474]] [[2.663]
 [2.663]
 [2.663]
 [2.663]
 [2.663]
 [2.663]
 [2.663]] [[0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.01675645796117829, 0.01675645796117829, 0.01675645796117829, 0.9497306261164651]
Printing some Q and Qe and total Qs values:  [[0.183]
 [0.071]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.262]] [[2.609]
 [3.325]
 [2.227]
 [2.227]
 [2.227]
 [2.227]
 [2.148]] [[0.183]
 [0.071]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.262]]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.01693796295604276, 0.01693796295604276, 0.01693796295604276, 0.9491861111318718]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
Printing some Q and Qe and total Qs values:  [[0.064]
 [0.055]
 [0.054]
 [0.06 ]
 [0.058]
 [0.062]
 [0.054]] [[3.606]
 [3.537]
 [3.634]
 [3.639]
 [3.627]
 [3.57 ]
 [3.579]] [[1.174]
 [1.068]
 [1.192]
 [1.209]
 [1.19 ]
 [1.124]
 [1.12 ]]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.017311095298417838, 0.017311095298417838, 0.017311095298417838, 0.9480667141047465]
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]] [[1.697]
 [1.995]
 [1.995]
 [1.995]
 [1.995]
 [1.995]
 [1.995]] [[0.625]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.01663830811099966, 0.03281766968404375, 0.03281766968404375, 0.9177263525209128]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.018663259955719918, 0.036937103607262926, 0.018663259955719918, 0.9257363764812973]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.018663259955719918, 0.036937103607262926, 0.018663259955719918, 0.9257363764812973]
UNIT TEST: sample policy line 217 mcts : [0.612 0.082 0.02  0.    0.204 0.041 0.041]
Printing some Q and Qe and total Qs values:  [[0.038]
 [0.033]
 [0.033]
 [0.033]
 [0.027]
 [0.033]
 [0.029]] [[-0.942]
 [-0.884]
 [-1.297]
 [-1.228]
 [-0.887]
 [-0.884]
 [-1.282]] [[0.038]
 [0.033]
 [0.033]
 [0.033]
 [0.027]
 [0.033]
 [0.029]]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.01887895967367763, 0.03737590902961335, 0.01887895967367763, 0.9248661716230313]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.01887895967367763, 0.03737590902961335, 0.01887895967367763, 0.9248661716230313]
siam score:  -0.72181964
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]] [[3.253]
 [3.253]
 [3.253]
 [3.253]
 [3.253]
 [3.253]
 [3.253]] [[1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.01909896742249722, 0.037823478428661086, 0.01909896742249722, 0.9239785867263446]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.01909896742249722, 0.037823478428661086, 0.01909896742249722, 0.9239785867263446]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.558]
 [0.558]
 [0.558]
 [0.558]
 [0.558]
 [0.558]] [[-0.132]
 [ 1.774]
 [ 1.774]
 [ 1.774]
 [ 1.774]
 [ 1.774]
 [ 1.774]] [[0.616]
 [0.558]
 [0.558]
 [0.558]
 [0.558]
 [0.558]
 [0.558]]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.019323413566285804, 0.03828007700863451, 0.019323413566285804, 0.9230730958587939]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.01955243378262925, 0.03874598078315398, 0.01955243378262925, 0.9221491516515876]
Printing some Q and Qe and total Qs values:  [[0.895]
 [0.938]
 [0.936]
 [0.936]
 [0.936]
 [0.936]
 [0.936]] [[4.537]
 [4.049]
 [4.431]
 [4.431]
 [4.431]
 [4.431]
 [4.431]] [[2.104]
 [1.765]
 [2.068]
 [2.068]
 [2.068]
 [2.068]
 [2.068]]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.01955243378262925, 0.03874598078315398, 0.01955243378262925, 0.9221491516515876]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
probs:  [0.019552484261573397, 0.03874608832391214, 0.019552484261573397, 0.922148943152941]
from probs:  [0.019552484261573397, 0.03874608832391214, 0.019552484261573397, 0.922148943152941]
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
probs:  [0.020024820311172226, 0.03970697806602601, 0.020024820311172226, 0.9202433813116296]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9975851851851852 -1.0 -0.9975851851851852
probs:  [0.020024873008199346, 0.03970709021947915, 0.020024873008199346, 0.9202431637641222]
Printing some Q and Qe and total Qs values:  [[0.493]
 [0.39 ]
 [0.412]
 [0.579]
 [0.383]
 [0.34 ]
 [0.481]] [[0.104]
 [0.965]
 [0.944]
 [0.674]
 [0.851]
 [0.583]
 [0.77 ]] [[0.493]
 [0.39 ]
 [0.412]
 [0.579]
 [0.383]
 [0.34 ]
 [0.481]]
maxi score, test score, baseline:  -0.9975851851851852 -1.0 -0.9975851851851852
probs:  [0.020024873008199346, 0.03970709021947915, 0.020024873008199346, 0.9202431637641222]
maxi score, test score, baseline:  -0.9975905311778291 -1.0 -0.9975905311778291
probs:  [0.02002492546157074, 0.03970720185433901, 0.02002492546157074, 0.9202429472225194]
maxi score, test score, baseline:  -0.9975905311778291 -1.0 -0.9975905311778291
probs:  [0.02002492546157074, 0.03970720185433901, 0.02002492546157074, 0.9202429472225194]
Printing some Q and Qe and total Qs values:  [[0.605]
 [0.64 ]
 [0.636]
 [0.648]
 [0.597]
 [0.6  ]
 [0.648]] [[3.473]
 [3.947]
 [3.58 ]
 [3.555]
 [3.705]
 [3.669]
 [3.555]] [[1.082]
 [1.459]
 [1.192]
 [1.187]
 [1.24 ]
 [1.218]
 [1.187]]
maxi score, test score, baseline:  -0.9975905311778291 -1.0 -0.9975905311778291
909 538
Printing some Q and Qe and total Qs values:  [[0.765]
 [0.833]
 [0.833]
 [0.833]
 [0.906]
 [0.856]
 [0.833]] [[3.055]
 [3.06 ]
 [3.06 ]
 [3.06 ]
 [2.022]
 [2.187]
 [3.06 ]] [[2.084]
 [2.134]
 [2.134]
 [2.134]
 [1.7  ]
 [1.742]
 [2.134]]
maxi score, test score, baseline:  -0.9975958525345622 -1.0 -0.9975958525345622
probs:  [0.021567774203426027, 0.04284587910228341, 0.021567774203426027, 0.9140185724908646]
912 539
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.021845161565957696, 0.04341018347757982, 0.021845161565957696, 0.9128994933905048]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.02212878175120681, 0.043987162230997495, 0.02212878175120681, 0.9117552742665889]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.02212878175120681, 0.043987162230997495, 0.02212878175120681, 0.9117552742665889]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.022715778109326578, 0.04518131005468471, 0.022715778109326578, 0.9093871337266621]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.023019618381055644, 0.045799423257968624, 0.023019618381055644, 0.90816133997992]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.023330681167107674, 0.046432229482157056, 0.023330681167107674, 0.9069064081836276]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.023330681167107674, 0.046432229482157056, 0.023330681167107674, 0.9069064081836276]
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.255]
 [0.514]
 [0.457]
 [0.457]
 [0.493]
 [0.495]] [[0.198]
 [3.13 ]
 [0.6  ]
 [0.769]
 [0.769]
 [0.177]
 [0.342]] [[0.485]
 [0.255]
 [0.514]
 [0.457]
 [0.457]
 [0.493]
 [0.495]]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.023649227092092384, 0.04708025892527497, 0.023649227092092384, 0.9056212868905402]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.59 ]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]] [[1.537]
 [1.704]
 [1.704]
 [1.704]
 [1.704]
 [1.704]
 [1.704]] [[0.59 ]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.023649227092092384, 0.04708025892527497, 0.023649227092092384, 0.9056212868905402]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.617]
 [0.593]
 [0.617]
 [0.617]
 [0.617]
 [0.617]] [[1.91 ]
 [1.91 ]
 [2.189]
 [1.91 ]
 [1.91 ]
 [1.91 ]
 [1.91 ]] [[0.812]
 [0.812]
 [1.137]
 [0.812]
 [0.812]
 [0.812]
 [0.812]]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.023649227092092384, 0.04708025892527497, 0.023649227092092384, 0.9056212868905402]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.023649227092092384, 0.04708025892527497, 0.023649227092092384, 0.9056212868905402]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.023649227092092384, 0.04708025892527497, 0.023649227092092384, 0.9056212868905402]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.02397552947281273, 0.047744067605535116, 0.02397552947281273, 0.9043048734488394]
Printing some Q and Qe and total Qs values:  [[ 0.185]
 [-0.002]
 [ 0.134]
 [ 0.099]
 [ 0.1  ]
 [ 0.089]
 [ 0.089]] [[3.64 ]
 [4.41 ]
 [3.538]
 [3.781]
 [3.955]
 [3.746]
 [3.693]] [[0.636]
 [0.982]
 [0.509]
 [0.644]
 [0.768]
 [0.608]
 [0.571]]
in main func line 156:  919
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.045579133450751694, 0.06838981006701189, 0.022959341157640617, 0.8630717153245957]
Printing some Q and Qe and total Qs values:  [[0.797]
 [0.695]
 [0.796]
 [0.794]
 [0.804]
 [0.807]
 [0.798]] [[4.686]
 [4.978]
 [4.755]
 [4.615]
 [4.595]
 [4.554]
 [4.632]] [[1.722]
 [1.81 ]
 [1.765]
 [1.675]
 [1.671]
 [1.647]
 [1.689]]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.06619631900463394, 0.08841913640436774, 0.022306254640158885, 0.8230782899508395]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.06706304163128189, 0.08958127205460314, 0.022589536545222742, 0.8207661497688922]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.377]
 [0.328]
 [0.392]
 [0.394]
 [0.41 ]
 [0.382]
 [0.381]] [[4.676]
 [4.479]
 [4.582]
 [4.317]
 [4.525]
 [4.489]
 [4.508]] [[1.294]
 [1.078]
 [1.238]
 [1.029]
 [1.214]
 [1.152]
 [1.166]]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.06794921296168971, 0.09076948528870996, 0.022879175115824893, 0.8184021266337754]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.06794921296168971, 0.09076948528870996, 0.022879175115824893, 0.8184021266337754]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.06794921296168971, 0.09076948528870996, 0.022879175115824893, 0.8184021266337754]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.2097603780268709
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.06885571383218579, 0.09198495903956695, 0.023175454547605875, 0.8159838725806413]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.06885571383218579, 0.09198495903956695, 0.023175454547605875, 0.8159838725806413]
922 549
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.04697888648620494, 0.09412958654558147, 0.02369822833188726, 0.8351932986363264]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.0496464076881111, 0.09953238220740776, 0.025015207769209465, 0.8258060023352718]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.05108046716552367, 0.10243692222923544, 0.025723217477815932, 0.8207593931274251]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.05108046716552367, 0.10243692222923544, 0.025723217477815932, 0.8207593931274251]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.05108046716552367, 0.10243692222923544, 0.025723217477815932, 0.8207593931274251]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.05258832988001944, 0.10549094311934434, 0.02646766459310241, 0.8154530624075339]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.0533717410871485, 0.10707766196922287, 0.02685444265162457, 0.812696154292004]
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.595]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]] [[5.147]
 [5.308]
 [4.854]
 [4.854]
 [4.854]
 [4.854]
 [4.854]] [[1.398]
 [1.512]
 [1.23 ]
 [1.23 ]
 [1.23 ]
 [1.23 ]
 [1.23 ]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[1.032]
 [1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]] [[2.997]
 [2.839]
 [2.839]
 [2.839]
 [2.839]
 [2.839]
 [2.839]] [[1.969]
 [1.79 ]
 [1.79 ]
 [1.79 ]
 [1.79 ]
 [1.79 ]
 [1.79 ]]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.05417584368669511, 0.10870628910695757, 0.0272514362604407, 0.8098664309459066]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.05417584368669511, 0.10870628910695757, 0.0272514362604407, 0.8098664309459066]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.02841166396072036, 0.11346600885222594, 0.02841166396072036, 0.8297106632263335]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.02841166396072036, 0.11346600885222594, 0.02841166396072036, 0.8297106632263335]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.02841166396072036, 0.11346600885222594, 0.02841166396072036, 0.8297106632263335]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.02841166396072036, 0.11346600885222594, 0.02841166396072036, 0.8297106632263335]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.028854506909338613, 0.11528272838588546, 0.028854506909338613, 0.8270082577954373]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9976220956719818 -1.0 -0.9976220956719818
from probs:  [0.0306729346937558, 0.09179486093044809, 0.0306729346937558, 0.8468592696820403]
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
probs:  [0.031186036164017307, 0.0933647500487095, 0.031186036164017307, 0.8442631776232558]
from probs:  [0.031186036164017307, 0.0933647500487095, 0.031186036164017307, 0.8442631776232558]
Printing some Q and Qe and total Qs values:  [[1.204]
 [0.777]
 [0.777]
 [0.777]
 [0.777]
 [0.777]
 [0.777]] [[2.866]
 [2.569]
 [2.569]
 [2.569]
 [2.569]
 [2.569]
 [2.569]] [[1.929]
 [1.41 ]
 [1.41 ]
 [1.41 ]
 [1.41 ]
 [1.41 ]
 [1.41 ]]
Printing some Q and Qe and total Qs values:  [[1.099]
 [0.799]
 [1.099]
 [1.085]
 [1.076]
 [1.084]
 [1.076]] [[3.521]
 [3.321]
 [3.423]
 [3.533]
 [3.493]
 [3.564]
 [3.592]] [[2.173]
 [1.492]
 [2.07 ]
 [2.163]
 [2.107]
 [2.194]
 [2.211]]
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
probs:  [0.03379859148894098, 0.03379859148894098, 0.03379859148894098, 0.8986042255331771]
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
probs:  [0.035065178562782115, 0.035065178562782115, 0.035065178562782115, 0.8948044643116537]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
probs:  [0.035731537577505586, 0.035731537577505586, 0.035731537577505586, 0.8928053872674832]
using another actor
Printing some Q and Qe and total Qs values:  [[0.723]
 [0.321]
 [0.723]
 [0.723]
 [0.723]
 [0.723]
 [0.723]] [[4.332]
 [3.478]
 [4.332]
 [4.332]
 [4.332]
 [4.332]
 [4.332]] [[1.027]
 [0.279]
 [1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]]
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
Printing some Q and Qe and total Qs values:  [[0.558]
 [0.553]
 [0.553]
 [0.553]
 [0.556]
 [0.553]
 [0.568]] [[3.786]
 [3.703]
 [3.703]
 [3.703]
 [3.761]
 [3.703]
 [3.814]] [[1.493]
 [1.404]
 [1.404]
 [1.404]
 [1.465]
 [1.404]
 [1.535]]
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
probs:  [0.037877982122994744, 0.037877982122994744, 0.037877982122994744, 0.8863660536310157]
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
probs:  [0.037877982122994744, 0.037877982122994744, 0.037877982122994744, 0.8863660536310157]
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
probs:  [0.037877982122994744, 0.037877982122994744, 0.037877982122994744, 0.8863660536310157]
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
probs:  [0.037877982122994744, 0.037877982122994744, 0.037877982122994744, 0.8863660536310157]
Printing some Q and Qe and total Qs values:  [[0.983]
 [1.038]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[4.282]
 [4.094]
 [3.99 ]
 [3.99 ]
 [3.99 ]
 [3.99 ]
 [3.99 ]] [[1.48 ]
 [1.528]
 [1.236]
 [1.236]
 [1.236]
 [1.236]
 [1.236]]
maxi score, test score, baseline:  -0.9976477477477478 -1.0 -0.9976477477477478
probs:  [0.0411379435300697, 0.0411379435300697, 0.0411379435300697, 0.8765861694097908]
in main func line 156:  945
from probs:  [0.03661845402562754, 0.07299282615483595, 0.07299282615483595, 0.8173958936647006]
maxi score, test score, baseline:  -0.9976477477477478 -1.0 -0.9976477477477478
probs:  [0.03806005165678488, 0.07590645129193598, 0.07590645129193598, 0.8101270457593431]
maxi score, test score, baseline:  -0.9976477477477478 -1.0 -0.9976477477477478
probs:  [0.03806005165678488, 0.07590645129193598, 0.07590645129193598, 0.8101270457593431]
maxi score, test score, baseline:  -0.9976477477477478 -1.0 -0.9976477477477478
probs:  [0.03806005165678488, 0.07590645129193598, 0.07590645129193598, 0.8101270457593431]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
probs:  [0.04034687226165695, 0.04034687226165695, 0.08052837335192715, 0.8387778821247589]
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
probs:  [0.04398110909592652, 0.04398110909592652, 0.087873560974941, 0.8241642208332061]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
probs:  [0.04713193210285728, 0.04713193210285728, 0.09424171671387935, 0.8114944190804061]
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
probs:  [0.04713193210285728, 0.04713193210285728, 0.09424171671387935, 0.8114944190804061]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3312702221382691, 0.3312702221382691, 0.3345549475597774, 0.0029046081636844552]
line 256 mcts: sample exp_bonus 4.83537091114836
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3312702221382691, 0.3312702221382691, 0.3345549475597774, 0.0029046081636844552]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.33236302557724773, 0.33236302557724773, 0.33236302557724773, 0.0029109232682568878]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
line 256 mcts: sample exp_bonus 4.565041353837837
siam score:  -0.7112102
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.845]
 [0.758]
 [0.63 ]
 [0.835]
 [0.835]
 [0.623]] [[3.247]
 [3.863]
 [3.444]
 [2.786]
 [3.507]
 [3.507]
 [2.802]] [[1.054]
 [1.563]
 [1.249]
 [0.775]
 [1.424]
 [1.424]
 [0.766]]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3345430403168715, 0.32799039820476594, 0.3345430403168715, 0.0029235211614910416]
Printing some Q and Qe and total Qs values:  [[1.299]
 [0.811]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]] [[1.379]
 [1.775]
 [1.319]
 [1.319]
 [1.319]
 [1.319]
 [1.319]] [[1.817]
 [1.281]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3345430403168715, 0.32799039820476594, 0.3345430403168715, 0.0029235211614910416]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3345430403168715, 0.32799039820476594, 0.3345430403168715, 0.0029235211614910416]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3345430403168715, 0.32799039820476594, 0.3345430403168715, 0.0029235211614910416]
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.838]
 [0.619]
 [0.619]
 [0.619]
 [0.596]
 [0.606]
 [0.623]] [[2.229]
 [1.929]
 [1.929]
 [1.929]
 [1.822]
 [2.062]
 [2.259]] [[1.06 ]
 [0.586]
 [0.586]
 [0.586]
 [0.489]
 [0.655]
 [0.804]]
Printing some Q and Qe and total Qs values:  [[0.143]
 [0.059]
 [0.138]
 [0.127]
 [0.134]
 [0.193]
 [0.145]] [[6.941]
 [6.825]
 [7.096]
 [7.059]
 [7.082]
 [6.343]
 [7.02 ]] [[0.371]
 [0.166]
 [0.413]
 [0.379]
 [0.4  ]
 [0.271]
 [0.402]]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3345430403168715, 0.32799039820476594, 0.3345430403168715, 0.0029235211614910416]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3345430403168715, 0.32799039820476594, 0.3345430403168715, 0.0029235211614910416]
Printing some Q and Qe and total Qs values:  [[0.879]
 [0.714]
 [0.879]
 [0.879]
 [0.879]
 [0.879]
 [1.129]] [[2.632]
 [2.998]
 [2.632]
 [2.632]
 [2.632]
 [2.632]
 [6.07 ]] [[0.56 ]
 [0.573]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [1.943]]
start point for exploration sampling:  10624
line 256 mcts: sample exp_bonus 3.7238105855688794
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.33234764146253176, 0.3290740461757728, 0.3356484035151562, 0.0029299088465391497]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3345493116142782, 0.33125396488139214, 0.33125396488139214, 0.0029427586229375116]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]] [[2.359]
 [2.228]
 [2.228]
 [2.228]
 [2.228]
 [2.228]
 [2.228]] [[0.485]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3367437693593768, 0.3334267424354853, 0.3268739219001241, 0.0029555663050136864]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3367437693593768, 0.3334267424354853, 0.3268739219001241, 0.0029555663050136864]
first move QE:  2.1788766457460667
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.3367437693593768, 0.3334267424354853, 0.3268739219001241, 0.0029555663050136864]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.848]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]] [[3.819]
 [4.017]
 [3.819]
 [3.819]
 [3.819]
 [3.819]
 [3.819]] [[1.62 ]
 [1.788]
 [1.62 ]
 [1.62 ]
 [1.62 ]
 [1.62 ]
 [1.62 ]]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.3367437653567141, 0.3334267427216696, 0.3268739306589694, 0.002955561262646799]
Printing some Q and Qe and total Qs values:  [[-0.019]
 [-0.077]
 [-0.075]
 [-0.083]
 [-0.086]
 [-0.109]
 [-0.084]] [[5.45 ]
 [4.067]
 [3.912]
 [3.749]
 [3.583]
 [3.59 ]
 [3.693]] [[ 0.218]
 [-0.765]
 [-0.86 ]
 [-0.978]
 [-1.088]
 [-1.126]
 [-1.015]]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.3356278006610273, 0.3356278006610273, 0.32575614730682606, 0.002988251371119376]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.33674607748548346, 0.3334175785527865, 0.32684143491247813, 0.002994909049252078]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.33674607748548346, 0.3334175785527865, 0.32684143491247813, 0.002994909049252078]
Printing some Q and Qe and total Qs values:  [[1.141]
 [0.737]
 [0.781]
 [0.765]
 [0.744]
 [0.758]
 [0.739]] [[2.347]
 [2.669]
 [2.453]
 [2.337]
 [2.314]
 [2.367]
 [2.386]] [[1.156]
 [0.821]
 [0.732]
 [0.629]
 [0.585]
 [0.641]
 [0.627]]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.33784463851122193, 0.33450524886063543, 0.32464866327906616, 0.003001449349076367]
Printing some Q and Qe and total Qs values:  [[0.311]
 [0.318]
 [0.33 ]
 [0.323]
 [0.323]
 [0.305]
 [0.33 ]] [[8.156]
 [8.789]
 [8.184]
 [8.08 ]
 [8.08 ]
 [8.386]
 [8.201]] [[0.927]
 [1.152]
 [0.975]
 [0.925]
 [0.925]
 [0.992]
 [0.979]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.33784463851122193, 0.33450524886063543, 0.32464866327906616, 0.003001449349076367]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.33784463851122193, 0.33450524886063543, 0.32464866327906616, 0.003001449349076367]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.3378446329829469, 0.3345052477314553, 0.32464867513431034, 0.0030014441512873904]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.33896855549938654, 0.33229474080118265, 0.32572856827553043, 0.0030081354239004103]
siam score:  -0.6995356
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
Printing some Q and Qe and total Qs values:  [[0.937]
 [0.938]
 [0.955]
 [0.955]
 [0.955]
 [0.931]
 [0.955]] [[2.311]
 [2.709]
 [2.359]
 [2.359]
 [2.359]
 [2.154]
 [2.359]] [[1.503]
 [1.878]
 [1.582]
 [1.582]
 [1.582]
 [1.344]
 [1.582]]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.3378481355545903, 0.3345026999981099, 0.32462761913861976, 0.0030215453086799987]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.33894714676114607, 0.3355907964116355, 0.32243390304155456, 0.003028153785663979]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.33894714676114607, 0.3355907964116355, 0.32243390304155456, 0.003028153785663979]
siam score:  -0.6929239
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34008053340972966, 0.3333725883967024, 0.32351190922755224, 0.003034968966015588]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34118528115462776, 0.3344554814512676, 0.32131762545666004, 0.0030416119374445543]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
line 256 mcts: sample exp_bonus 3.6704761574742246
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34232446218149404, 0.33223679956484775, 0.32239027629361894, 0.0030484619600391616]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34232446218149404, 0.33223679956484775, 0.32239027629361894, 0.0030484619600391616]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34232446218149404, 0.33223679956484775, 0.32239027629361894, 0.0030484619600391616]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34232446218149404, 0.33223679956484775, 0.32239027629361894, 0.0030484619600391616]
Printing some Q and Qe and total Qs values:  [[0.374]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]] [[ 0.054]
 [-0.034]
 [-0.034]
 [-0.034]
 [-0.034]
 [-0.034]
 [-0.034]] [[0.374]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34232446218149404, 0.33223679956484775, 0.32239027629361894, 0.0030484619600391616]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34232446218149404, 0.33223679956484775, 0.32239027629361894, 0.0030484619600391616]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.34232446218149404, 0.33223679956484775, 0.32239027629361894, 0.0030484619600391616]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.3400886468539231, 0.3333680119466222, 0.3234878753697532, 0.0030554658297015087]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.3412065034184199, 0.33445076315655436, 0.3212597130009752, 0.0030830204240505543]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34346559108354907, 0.3333054944371242, 0.3201320357932033, 0.003096878686123369]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34461536151405703, 0.33107723792898136, 0.3212034686607324, 0.0031039318962291593]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34461536151405703, 0.33107723792898136, 0.3212034686607324, 0.0031039318962291593]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.244]
 [1.022]
 [1.022]
 [1.022]
 [1.022]
 [1.022]
 [1.022]] [[5.536]
 [6.347]
 [6.347]
 [6.347]
 [6.347]
 [6.347]
 [6.347]] [[2.457]
 [2.284]
 [2.284]
 [2.284]
 [2.284]
 [2.284]
 [2.284]]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34236391254296156, 0.33221636256306647, 0.3223085184882082, 0.0031112064057637863]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34350863809688525, 0.3299870712115723, 0.3233859913148054, 0.0031182993767371286]
siam score:  -0.7058197
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34350863809688525, 0.3299870712115723, 0.3233859913148054, 0.0031182993767371286]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.3423959434378079, 0.32889059194911274, 0.32558071742087946, 0.0031327471921998957]
using explorer policy with actor:  1
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.3435252796793648, 0.32997525307019526, 0.3233596518433652, 0.0031398154070746485]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34467112919231235, 0.3277438417494414, 0.3244380420841276, 0.003146986974118736]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.3424105396009252, 0.3288761374881106, 0.3255588820683028, 0.0031544408426612803]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.342425638771413, 0.32553656412696796, 0.32886139372363893, 0.0031764033779800144]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.342425638771413, 0.32553656412696796, 0.32886139372363893, 0.0031764033779800144]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.342425638771413, 0.32553656412696796, 0.32886139372363893, 0.0031764033779800144]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.342425638771413, 0.32553656412696796, 0.32886139372363893, 0.0031764033779800144]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.555]
 [0.513]
 [0.492]
 [0.516]
 [0.489]
 [0.496]
 [0.509]] [[3.11 ]
 [3.193]
 [3.492]
 [3.295]
 [3.353]
 [3.583]
 [3.541]] [[0.384]
 [0.329]
 [0.387]
 [0.37 ]
 [0.334]
 [0.425]
 [0.438]]
from probs:  [0.342425638771413, 0.32553656412696796, 0.32886139372363893, 0.0031764033779800144]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34356026337455664, 0.3233051452788413, 0.3299509421965205, 0.0031836491500815203]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.34356026337455664, 0.3233051452788413, 0.3299509421965205, 0.0031836491500815203]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
Printing some Q and Qe and total Qs values:  [[0.463]
 [0.317]
 [0.32 ]
 [0.316]
 [0.32 ]
 [0.293]
 [0.302]] [[-0.79 ]
 [ 2.537]
 [ 1.699]
 [ 1.522]
 [ 1.232]
 [ 1.522]
 [ 1.391]] [[0.463]
 [0.317]
 [0.32 ]
 [0.316]
 [0.32 ]
 [0.293]
 [0.302]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976777777777778 -1.0 -0.9976777777777778
probs:  [0.34129369310295055, 0.32442311833890347, 0.3310919573044561, 0.00319123125368988]
maxi score, test score, baseline:  -0.9976777777777778 -1.0 -0.9976777777777778
probs:  [0.34129369310295055, 0.32442311833890347, 0.3310919573044561, 0.00319123125368988]
maxi score, test score, baseline:  -0.9976777777777778 -1.0 -0.9976777777777778
probs:  [0.34129369310295055, 0.32442311833890347, 0.3310919573044561, 0.00319123125368988]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.69875944
maxi score, test score, baseline:  -0.9976777777777778 -1.0 -0.9976777777777778
probs:  [0.34129369310295055, 0.32442311833890347, 0.3310919573044561, 0.00319123125368988]
maxi score, test score, baseline:  -0.9976827050997783 -1.0 -0.9976827050997783
probs:  [0.34242340572265284, 0.32219026456409544, 0.33218781666597086, 0.003198513047280939]
maxi score, test score, baseline:  -0.9976827050997783 -1.0 -0.9976827050997783
probs:  [0.34242340572265284, 0.32219026456409544, 0.33218781666597086, 0.003198513047280939]
Printing some Q and Qe and total Qs values:  [[1.138]
 [1.078]
 [1.078]
 [1.078]
 [1.078]
 [1.078]
 [1.078]] [[2.751]
 [2.684]
 [2.684]
 [2.684]
 [2.684]
 [2.684]
 [2.684]] [[1.525]
 [1.336]
 [1.336]
 [1.336]
 [1.336]
 [1.336]
 [1.336]]
maxi score, test score, baseline:  -0.9976827050997783 -1.0 -0.9976827050997783
probs:  [0.34242340572265284, 0.32219026456409544, 0.33218781666597086, 0.003198513047280939]
Printing some Q and Qe and total Qs values:  [[0.802]
 [0.71 ]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]] [[3.116]
 [2.701]
 [3.14 ]
 [3.14 ]
 [3.14 ]
 [3.14 ]
 [3.14 ]] [[0.802]
 [0.71 ]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]]
Printing some Q and Qe and total Qs values:  [[0.393]
 [0.398]
 [0.398]
 [0.398]
 [0.398]
 [0.398]
 [0.398]] [[1.57 ]
 [1.376]
 [1.376]
 [1.376]
 [1.376]
 [1.376]
 [1.376]] [[0.393]
 [0.398]
 [0.398]
 [0.398]
 [0.398]
 [0.398]
 [0.398]]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
Printing some Q and Qe and total Qs values:  [[0.95 ]
 [0.933]
 [0.946]
 [0.946]
 [0.946]
 [0.946]
 [0.946]] [[5.014]
 [4.485]
 [3.721]
 [3.721]
 [3.721]
 [3.721]
 [3.721]] [[1.677]
 [1.466]
 [1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.237]]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.701]
 [0.816]
 [0.818]
 [0.821]
 [0.824]
 [0.797]] [[6.927]
 [7.236]
 [4.755]
 [5.14 ]
 [4.411]
 [6.143]
 [5.853]] [[1.674]
 [1.561]
 [0.962]
 [1.095]
 [0.857]
 [1.442]
 [1.291]]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.3424233932510717, 0.3221902808480413, 0.3321878187413033, 0.0031985071595835865]
UNIT TEST: sample policy line 217 mcts : [0.082 0.    0.388 0.531 0.    0.    0.   ]
Printing some Q and Qe and total Qs values:  [[0.997]
 [1.009]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]] [[4.068]
 [4.976]
 [4.068]
 [4.068]
 [4.068]
 [4.068]
 [4.068]] [[2.885]
 [3.151]
 [2.885]
 [2.885]
 [2.885]
 [2.885]
 [2.885]]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.34015554085633287, 0.3233030732623114, 0.33333524808886994, 0.003206137792485732]
using another actor
line 256 mcts: sample exp_bonus 0.8706497487472944
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.337889962959239, 0.3244147496234681, 0.334481526644897, 0.0032137607723957307]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.337889962959239, 0.3244147496234681, 0.334481526644897, 0.0032137607723957307]
Printing some Q and Qe and total Qs values:  [[0.654]
 [0.76 ]
 [0.646]
 [0.654]
 [0.63 ]
 [0.611]
 [0.641]] [[3.376]
 [2.259]
 [3.415]
 [3.239]
 [3.562]
 [3.396]
 [3.329]] [[0.654]
 [0.76 ]
 [0.646]
 [0.654]
 [0.63 ]
 [0.611]
 [0.641]]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]] [[3.734]
 [3.734]
 [3.734]
 [3.734]
 [3.734]
 [3.734]
 [3.734]] [[0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]]
Printing some Q and Qe and total Qs values:  [[0.443]
 [0.44 ]
 [0.441]
 [0.44 ]
 [0.44 ]
 [0.418]
 [0.409]] [[4.057]
 [3.796]
 [3.742]
 [3.796]
 [3.796]
 [4.021]
 [4.03 ]] [[1.157]
 [0.936]
 [0.892]
 [0.936]
 [0.936]
 [1.085]
 [1.079]]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.33903772786159836, 0.32551660578494535, 0.3322243499401598, 0.0032213164132963885]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.3390377201567049, 0.32551661740945737, 0.3322243519754749, 0.003221310458362834]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.3390377201567049, 0.32551661740945737, 0.3322243519754749, 0.003221310458362834]
Printing some Q and Qe and total Qs values:  [[1.115]
 [1.115]
 [1.115]
 [1.115]
 [1.115]
 [1.115]
 [1.115]] [[6.115]
 [6.115]
 [6.115]
 [6.115]
 [6.115]
 [6.115]
 [6.115]] [[2.372]
 [2.372]
 [2.372]
 [2.372]
 [2.372]
 [2.372]
 [2.372]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.33677062936154833, 0.32663478097235094, 0.33336561779330226, 0.0032289718727984834]
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.3356271803853181, 0.32550147351938075, 0.3356271803853181, 0.003244165709983023]
siam score:  -0.6917316
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.33336073978395553, 0.32661349238613196, 0.3367738981355889, 0.0032518696943236508]
siam score:  -0.69809514
siam score:  -0.70244807
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.3322354305686783, 0.32885178257102704, 0.3356454104573621, 0.0032673764029324585]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.248]
 [0.279]
 [0.279]
 [0.279]
 [0.279]
 [0.279]] [[4.49 ]
 [3.752]
 [4.744]
 [4.744]
 [4.744]
 [4.744]
 [4.744]] [[ 0.491]
 [-0.118]
 [ 0.274]
 [ 0.274]
 [ 0.274]
 [ 0.274]
 [ 0.274]]
first move QE:  2.1830481129865653
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.3322354305686783, 0.32885178257102704, 0.3356454104573621, 0.0032673764029324585]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.945]
 [0.955]
 [0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]] [[2.836]
 [3.609]
 [2.442]
 [2.442]
 [2.442]
 [2.442]
 [2.442]] [[2.218]
 [2.68 ]
 [1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.332235432611812, 0.328851789508003, 0.33564540756856925, 0.003267370311615639]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.3299693704440094, 0.3299693704440094, 0.33678614630334885, 0.0032751128086324324]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.3310859116033819, 0.32770541657853797, 0.33792582371590685, 0.0032828481021731954]
line 256 mcts: sample exp_bonus 4.847386033148876
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
siam score:  -0.69390595
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.3310859116033819, 0.32770541657853797, 0.33792582371590685, 0.0032828481021731954]
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.744]
 [0.742]
 [0.733]
 [0.727]
 [0.728]
 [0.722]] [[3.354]
 [3.207]
 [3.323]
 [3.38 ]
 [3.3  ]
 [3.538]
 [3.587]] [[0.861]
 [0.773]
 [0.847]
 [0.865]
 [0.801]
 [0.96 ]
 [0.981]]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.3310859116033819, 0.32770541657853797, 0.33792582371590685, 0.0032828481021731954]
line 256 mcts: sample exp_bonus 5.702675082585918
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.576]] [[3.789]
 [3.789]
 [3.789]
 [3.789]
 [3.789]
 [3.789]
 [3.789]] [[0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.3310859116033819, 0.32770541657853797, 0.33792582371590685, 0.0032828481021731954]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.3310859116033819, 0.32770541657853797, 0.33792582371590685, 0.0032828481021731954]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33220141443652945, 0.32544356807447766, 0.3390644412867066, 0.0032905762022862237]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33220141443652945, 0.32544356807447766, 0.3390644412867066, 0.0032905762022862237]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33220141443652945, 0.32544356807447766, 0.3390644412867066, 0.0032905762022862237]
using explorer policy with actor:  1
siam score:  -0.6911052
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.3333158803911643, 0.3231838219963757, 0.34020200049345894, 0.0032982971190011335]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33442931091230854, 0.32092617541423357, 0.34133850281112904, 0.003306010862328909]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33442931091230854, 0.32092617541423357, 0.34133850281112904, 0.003306010862328909]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33442931091230854, 0.32092617541423357, 0.34133850281112904, 0.003306010862328909]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33442931091230854, 0.32092617541423357, 0.34133850281112904, 0.003306010862328909]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33442931091230854, 0.32092617541423357, 0.34133850281112904, 0.003306010862328909]
siam score:  -0.7021772
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.33442931091230854, 0.32092617541423357, 0.34133850281112904, 0.003306010862328909]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.3344711194429094, 0.32427705542663626, 0.33792161987570196, 0.003330205254752439]
Starting evaluation
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.33447111822496584, 0.32427706929383104, 0.3379216135517205, 0.0033301989294826223]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.489]] [[-0.57 ]
 [-0.57 ]
 [-0.57 ]
 [-0.57 ]
 [-0.57 ]
 [-0.57 ]
 [ 0.535]] [[0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.489]]
Printing some Q and Qe and total Qs values:  [[0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]] [[2.49]
 [2.49]
 [2.49]
 [2.49]
 [2.49]
 [2.49]
 [2.49]] [[0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]]
Printing some Q and Qe and total Qs values:  [[0.25 ]
 [0.234]
 [0.25 ]
 [0.25 ]
 [0.25 ]
 [0.25 ]
 [0.25 ]] [[0.442]
 [2.7  ]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]] [[0.25 ]
 [0.234]
 [0.25 ]
 [0.25 ]
 [0.25 ]
 [0.25 ]
 [0.25 ]]
Printing some Q and Qe and total Qs values:  [[0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]] [[-2.25]
 [-2.25]
 [-2.25]
 [-2.25]
 [-2.25]
 [-2.25]
 [-2.25]] [[0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]] [[-1.482]
 [ 0.206]
 [ 0.206]
 [ 0.206]
 [ 0.206]
 [ 0.206]
 [ 0.206]] [[0.693]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]]
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]] [[-1.273]
 [-1.273]
 [-1.273]
 [-1.273]
 [-1.273]
 [-1.273]
 [-1.273]] [[0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]] [[-0.747]
 [-0.051]
 [-0.051]
 [-0.051]
 [-0.051]
 [-0.051]
 [-0.051]] [[0.581]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]]
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.33447111822496584, 0.32427706929383104, 0.3379216135517205, 0.0033301989294826223]
line 256 mcts: sample exp_bonus 2.2589799210234047
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 0.3768398660884382
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
line 256 mcts: sample exp_bonus 0.36728948770833936
Printing some Q and Qe and total Qs values:  [[0.257]
 [0.248]
 [0.257]
 [0.257]
 [0.319]
 [0.257]
 [0.257]] [[2.841]
 [3.153]
 [2.841]
 [2.841]
 [0.379]
 [2.841]
 [2.841]] [[0.257]
 [0.248]
 [0.257]
 [0.257]
 [0.319]
 [0.257]
 [0.257]]
using explorer policy with actor:  0
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.714]] [[2.497]
 [2.497]
 [2.497]
 [2.497]
 [2.497]
 [2.497]
 [3.921]] [[0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.714]]
Printing some Q and Qe and total Qs values:  [[0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]] [[0.222]
 [0.222]
 [0.222]
 [0.222]
 [0.222]
 [0.222]
 [0.222]] [[0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]] [[-0.133]
 [ 0.133]
 [ 0.133]
 [ 0.133]
 [ 0.133]
 [ 0.133]
 [ 0.133]] [[0.559]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]]
Printing some Q and Qe and total Qs values:  [[0.394]
 [0.312]
 [0.391]
 [0.438]
 [0.357]
 [0.528]
 [0.354]] [[-2.123]
 [ 1.714]
 [-1.783]
 [-0.537]
 [-2.012]
 [-0.458]
 [-2.372]] [[0.394]
 [0.312]
 [0.391]
 [0.438]
 [0.357]
 [0.528]
 [0.354]]
Printing some Q and Qe and total Qs values:  [[0.804]
 [0.533]
 [0.533]
 [0.533]
 [0.533]
 [0.533]
 [0.533]] [[0.607]
 [0.847]
 [0.847]
 [0.847]
 [0.847]
 [0.847]
 [0.847]] [[0.804]
 [0.533]
 [0.533]
 [0.533]
 [0.533]
 [0.533]
 [0.533]]
siam score:  -0.6997477
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus -0.2900928656044746
line 256 mcts: sample exp_bonus 3.575416664894117
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.33218561082602904, 0.325392262805696, 0.33908387541810464, 0.0033382509501702494]
Printing some Q and Qe and total Qs values:  [[0.494]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]] [[0.608]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]] [[0.494]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]]
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.73 ]
 [0.796]
 [0.822]
 [0.748]
 [0.758]
 [0.727]] [[5.012]
 [5.679]
 [4.816]
 [4.637]
 [4.743]
 [4.652]
 [4.65 ]] [[0.739]
 [0.73 ]
 [0.796]
 [0.822]
 [0.748]
 [0.758]
 [0.727]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.732]
 [0.528]
 [0.528]
 [0.53 ]
 [0.529]
 [0.582]] [[ 0.169]
 [ 2.438]
 [-0.458]
 [-0.458]
 [-0.334]
 [-0.362]
 [ 0.265]] [[0.599]
 [0.732]
 [0.528]
 [0.528]
 [0.53 ]
 [0.529]
 [0.582]]
Printing some Q and Qe and total Qs values:  [[0.372]
 [0.378]
 [0.454]
 [0.368]
 [0.338]
 [0.454]
 [0.454]] [[1.78 ]
 [3.772]
 [2.114]
 [2.059]
 [2.104]
 [2.114]
 [2.114]] [[0.372]
 [0.378]
 [0.454]
 [0.368]
 [0.338]
 [0.454]
 [0.454]]
Printing some Q and Qe and total Qs values:  [[0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]] [[0.369]
 [0.354]
 [0.354]
 [0.354]
 [0.354]
 [0.354]
 [0.354]] [[0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]]
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.644]
 [0.564]
 [0.644]
 [0.644]
 [0.644]
 [0.644]] [[-0.736]
 [ 0.   ]
 [ 0.948]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.616]
 [0.644]
 [0.564]
 [0.644]
 [0.644]
 [0.644]
 [0.644]]
Printing some Q and Qe and total Qs values:  [[0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]] [[4.649]
 [4.649]
 [4.649]
 [4.649]
 [4.649]
 [4.649]
 [4.649]] [[0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]]
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.33218561082602904, 0.325392262805696, 0.33908387541810464, 0.0033382509501702494]
Printing some Q and Qe and total Qs values:  [[0.545]
 [0.485]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]] [[0.657]
 [2.528]
 [1.357]
 [1.357]
 [1.357]
 [1.357]
 [1.357]] [[0.545]
 [0.485]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]]
line 256 mcts: sample exp_bonus -0.8638096662852
Printing some Q and Qe and total Qs values:  [[0.637]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]] [[0.818]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[0.637]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.735]] [[2.56 ]
 [2.56 ]
 [2.56 ]
 [2.56 ]
 [2.56 ]
 [2.56 ]
 [6.149]] [[0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.735]]
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]] [[0.071]
 [0.182]
 [0.182]
 [0.182]
 [0.182]
 [0.182]
 [0.182]] [[0.427]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]]
Printing some Q and Qe and total Qs values:  [[0.415]
 [0.362]
 [0.653]
 [0.653]
 [0.367]
 [0.405]
 [0.473]] [[-0.413]
 [ 0.64 ]
 [ 3.567]
 [ 3.567]
 [-0.339]
 [-0.121]
 [ 0.537]] [[0.415]
 [0.362]
 [0.653]
 [0.653]
 [0.367]
 [0.405]
 [0.473]]
Printing some Q and Qe and total Qs values:  [[0.365]
 [0.291]
 [0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.354]] [[-1.891]
 [ 0.015]
 [ 0.894]
 [ 0.894]
 [ 0.894]
 [ 0.894]
 [-2.355]] [[0.365]
 [0.291]
 [0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.354]]
Printing some Q and Qe and total Qs values:  [[0.41 ]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]] [[-0.13 ]
 [ 0.177]
 [ 0.177]
 [ 0.177]
 [ 0.177]
 [ 0.177]
 [ 0.177]] [[0.41 ]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.3333059964987834, 0.32312023165152376, 0.3402275973216316, 0.0033461745280612986]
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.3333059964987834, 0.32312023165152376, 0.3402275973216316, 0.0033461745280612986]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.499]
 [0.485]
 [0.47 ]
 [0.539]
 [0.445]
 [0.465]] [[2.155]
 [3.544]
 [2.371]
 [1.607]
 [2.124]
 [1.55 ]
 [1.569]] [[0.563]
 [0.499]
 [0.485]
 [0.47 ]
 [0.539]
 [0.445]
 [0.465]]
line 256 mcts: sample exp_bonus -0.9171318726340358
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.408]
 [0.221]
 [0.361]
 [0.347]
 [0.324]
 [0.364]
 [0.328]] [[-2.001]
 [ 2.347]
 [-2.27 ]
 [-2.748]
 [-2.446]
 [-2.407]
 [-2.754]] [[0.408]
 [0.221]
 [0.361]
 [0.347]
 [0.324]
 [0.364]
 [0.328]]
Printing some Q and Qe and total Qs values:  [[0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]] [[0.766]
 [0.766]
 [0.766]
 [0.766]
 [0.766]
 [0.766]
 [0.766]] [[0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.483]
 [0.404]
 [0.407]
 [0.379]
 [0.385]
 [0.412]] [[-0.322]
 [ 0.307]
 [ 0.914]
 [ 0.848]
 [ 0.714]
 [ 0.778]
 [ 0.569]] [[0.552]
 [0.483]
 [0.404]
 [0.407]
 [0.379]
 [0.385]
 [0.412]]
line 256 mcts: sample exp_bonus 1.9693182211992766
Printing some Q and Qe and total Qs values:  [[0.676]
 [0.441]
 [0.559]
 [0.665]
 [0.532]
 [0.534]
 [0.533]] [[-0.935]
 [ 2.867]
 [ 0.848]
 [ 0.   ]
 [ 0.776]
 [ 0.751]
 [ 0.84 ]] [[0.676]
 [0.441]
 [0.559]
 [0.665]
 [0.532]
 [0.534]
 [0.533]]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]] [[-0.155]
 [ 0.533]
 [ 0.533]
 [ 0.533]
 [ 0.533]
 [ 0.533]
 [ 0.533]] [[0.617]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.3333059995102852, 0.3231203243355841, 0.3402275393973405, 0.0033461367567902273]
Printing some Q and Qe and total Qs values:  [[0.728]
 [0.581]
 [0.581]
 [0.581]
 [0.581]
 [0.581]
 [0.581]] [[-0.888]
 [ 0.479]
 [ 0.479]
 [ 0.479]
 [ 0.479]
 [ 0.479]
 [ 0.479]] [[0.728]
 [0.581]
 [0.581]
 [0.581]
 [0.581]
 [0.581]
 [0.581]]
Printing some Q and Qe and total Qs values:  [[0.343]
 [0.199]
 [0.384]
 [0.353]
 [0.33 ]
 [0.653]
 [0.356]] [[-2.092]
 [ 1.594]
 [-0.704]
 [-2.271]
 [-1.995]
 [ 1.654]
 [-2.545]] [[0.343]
 [0.199]
 [0.384]
 [0.353]
 [0.33 ]
 [0.653]
 [0.356]]
Printing some Q and Qe and total Qs values:  [[0.662]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]] [[2.409]
 [2.81 ]
 [2.81 ]
 [2.81 ]
 [2.81 ]
 [2.81 ]
 [2.81 ]] [[0.662]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.3333059995102852, 0.3231203243355841, 0.3402275393973405, 0.0033461367567902273]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.3333059995102852, 0.3231203243355841, 0.3402275393973405, 0.0033461367567902273]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.3333059995102852, 0.3231203243355841, 0.3402275393973405, 0.0033461367567902273]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.3333059995102852, 0.3231203243355841, 0.3402275393973405, 0.0033461367567902273]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.569]
 [0.569]
 [0.569]
 [0.569]
 [0.569]
 [0.569]] [[-0.533]
 [-0.675]
 [-0.675]
 [-0.675]
 [-0.675]
 [-0.675]
 [-0.675]] [[0.566]
 [0.569]
 [0.569]
 [0.569]
 [0.569]
 [0.569]
 [0.569]]
maxi score, test score, baseline:  -0.9977401727861771 -1.0 -0.9977401727861771
probs:  [0.333306000004587, 0.3231203395486939, 0.34022752988967264, 0.0033461305570464516]
maxi score, test score, baseline:  -0.9977401727861771 -1.0 -0.9977401727861771
probs:  [0.333306000004587, 0.3231203395486939, 0.34022752988967264, 0.0033461305570464516]
Printing some Q and Qe and total Qs values:  [[0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]] [[2.94]
 [2.94]
 [2.94]
 [2.94]
 [2.94]
 [2.94]
 [2.94]] [[0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]]
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.437]
 [0.426]
 [0.437]
 [0.419]
 [0.423]
 [0.423]] [[0.525]
 [0.814]
 [0.853]
 [0.814]
 [0.788]
 [0.759]
 [0.789]] [[0.566]
 [0.437]
 [0.426]
 [0.437]
 [0.419]
 [0.423]
 [0.423]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.33101843432503847, 0.3242306065154623, 0.3413967347597575, 0.00335422439974163]
Printing some Q and Qe and total Qs values:  [[1.002]
 [1.107]
 [1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]] [[4.676]
 [5.949]
 [4.676]
 [4.676]
 [4.676]
 [4.676]
 [4.676]] [[1.695]
 [2.345]
 [1.695]
 [1.695]
 [1.695]
 [1.695]
 [1.695]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.33101843432503847, 0.3242306065154623, 0.3413967347597575, 0.00335422439974163]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.145661519769112
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.71 ]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]] [[0.266]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]] [[0.71 ]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]]
Printing some Q and Qe and total Qs values:  [[0.4  ]
 [0.399]
 [0.399]
 [0.399]
 [0.399]
 [0.399]
 [0.399]] [[-1.463]
 [-1.329]
 [-1.329]
 [-1.329]
 [-1.329]
 [-1.329]
 [-1.329]] [[0.4  ]
 [0.399]
 [0.399]
 [0.399]
 [0.399]
 [0.399]
 [0.399]]
Printing some Q and Qe and total Qs values:  [[0.553]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]] [[0.622]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]] [[0.553]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]]
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[1.723]
 [1.12 ]
 [1.12 ]
 [1.12 ]
 [1.12 ]
 [1.12 ]
 [1.12 ]] [[0.52 ]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.301]
 [0.362]
 [0.366]
 [0.354]
 [0.578]
 [0.366]] [[-1.397]
 [ 2.449]
 [-1.915]
 [-1.229]
 [-1.849]
 [ 0.026]
 [-2.248]] [[0.397]
 [0.301]
 [0.362]
 [0.366]
 [0.354]
 [0.578]
 [0.366]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.33213400981706576, 0.32195640228293404, 0.3425473920431078, 0.003362195856892329]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.894745545457088
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.33213400981706576, 0.32195640228293404, 0.3425473920431078, 0.003362195856892329]
Printing some Q and Qe and total Qs values:  [[0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]] [[2.967]
 [2.967]
 [2.967]
 [2.967]
 [2.967]
 [2.967]
 [2.967]] [[0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]]
Printing some Q and Qe and total Qs values:  [[0.602]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]] [[0.539]
 [0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]] [[0.602]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]]
Printing some Q and Qe and total Qs values:  [[0.593]
 [0.328]
 [0.552]
 [0.524]
 [0.512]
 [0.523]
 [0.498]] [[-0.212]
 [ 2.802]
 [ 0.72 ]
 [ 0.929]
 [ 0.772]
 [ 0.833]
 [ 0.88 ]] [[0.593]
 [0.328]
 [0.552]
 [0.524]
 [0.512]
 [0.523]
 [0.498]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.33213400981706576, 0.32195640228293404, 0.3425473920431078, 0.003362195856892329]
start point for exploration sampling:  10624
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.523]
 [0.504]] [[3.717]
 [3.401]
 [3.401]
 [3.401]
 [3.401]
 [3.5  ]
 [3.401]] [[0.542]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.523]
 [0.504]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.604]] [[1.174]
 [1.147]
 [1.147]
 [1.147]
 [1.147]
 [1.147]
 [1.147]] [[0.625]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.604]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.3309958118424612, 0.3241701257327715, 0.34143048141244675, 0.0034035810123206425]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]] [[0.614]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.873]] [[0.576]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.3309958118424612, 0.3241701257327715, 0.34143048141244675, 0.0034035810123206425]
Printing some Q and Qe and total Qs values:  [[0.603]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]] [[1.263]
 [1.223]
 [1.223]
 [1.223]
 [1.223]
 [1.223]
 [1.223]] [[0.603]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.32869719362483785, 0.32528549494267295, 0.3426054212027057, 0.0034118902297835406]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.32869719362483785, 0.32528549494267295, 0.3426054212027057, 0.0034118902297835406]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.32869719362483785, 0.32528549494267295, 0.3426054212027057, 0.0034118902297835406]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.32869719362483785, 0.32528549494267295, 0.3426054212027057, 0.0034118902297835406]
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.208]
 [0.436]
 [0.431]
 [0.419]
 [0.52 ]
 [0.421]] [[-0.515]
 [ 2.76 ]
 [ 1.011]
 [ 0.959]
 [ 0.871]
 [ 0.177]
 [ 0.805]] [[0.584]
 [0.208]
 [0.436]
 [0.431]
 [0.419]
 [0.52 ]
 [0.421]]
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]] [[-0.371]
 [ 0.839]
 [ 0.839]
 [ 0.839]
 [ 0.839]
 [ 0.839]
 [ 0.839]] [[0.683]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.3286972154041847, 0.325285531730409, 0.342605381798427, 0.003411871066979355]
Printing some Q and Qe and total Qs values:  [[0.848]
 [0.848]
 [0.848]
 [0.848]
 [0.848]
 [0.848]
 [0.848]] [[4.817]
 [5.001]
 [5.001]
 [5.001]
 [5.001]
 [5.001]
 [5.001]] [[1.701]
 [1.855]
 [1.855]
 [1.855]
 [1.855]
 [1.855]
 [1.855]]
Printing some Q and Qe and total Qs values:  [[0.692]
 [0.46 ]
 [0.607]
 [0.577]
 [0.565]
 [0.59 ]
 [0.581]] [[-0.098]
 [ 2.893]
 [ 0.888]
 [ 0.962]
 [ 0.874]
 [ 0.737]
 [ 0.801]] [[0.692]
 [0.46 ]
 [0.607]
 [0.577]
 [0.565]
 [0.59 ]
 [0.581]]
rdn probs:  [0.3286972721335558, 0.32528562755265533, 0.34260527916067474, 0.003411821153114107]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.32869728601771264, 0.32528565100455575, 0.3426052540406973, 0.0034118089370342567]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.32869728601771264, 0.32528565100455575, 0.3426052540406973, 0.0034118089370342567]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.32985845724002594, 0.3264347334961865, 0.34028644024607113, 0.0034203690177164988]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.32985845724002594, 0.3264347334961865, 0.34028644024607113, 0.0034203690177164988]
Printing some Q and Qe and total Qs values:  [[ 0.057]
 [ 0.067]
 [ 0.067]
 [ 0.067]
 [ 0.067]
 [-0.   ]
 [-0.005]] [[9.063]
 [8.573]
 [8.573]
 [8.573]
 [8.573]
 [8.939]
 [8.379]] [[0.428]
 [0.285]
 [0.285]
 [0.285]
 [0.285]
 [0.273]
 [0.078]]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3298584625391468, 0.3264347435828176, 0.3402864309633861, 0.0034203629146494015]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3298584625391468, 0.3264347435828176, 0.3402864309633861, 0.0034203629146494015]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3298584625391468, 0.3264347435828176, 0.3402864309633861, 0.0034203629146494015]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3298584625391468, 0.3264347435828176, 0.3402864309633861, 0.0034203629146494015]
Printing some Q and Qe and total Qs values:  [[-0.05]
 [-0.05]
 [-0.05]
 [-0.05]
 [-0.05]
 [-0.05]
 [-0.05]] [[6.345]
 [6.499]
 [6.499]
 [6.499]
 [6.499]
 [6.499]
 [6.499]] [[-0.763]
 [-0.712]
 [-0.712]
 [-0.712]
 [-0.712]
 [-0.712]
 [-0.712]]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3298584625391468, 0.3264347435828176, 0.3402864309633861, 0.0034203629146494015]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3298584625391468, 0.3264347435828176, 0.3402864309633861, 0.0034203629146494015]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3275572697537356, 0.3275572697537356, 0.3414567353496028, 0.003428725142926021]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3275572697537356, 0.3275572697537356, 0.3414567353496028, 0.003428725142926021]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3275572697537356, 0.3275572697537356, 0.3414567353496028, 0.003428725142926021]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3275572697537356, 0.3275572697537356, 0.3414567353496028, 0.003428725142926021]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3252575634970713, 0.3286790707931334, 0.3426262837404402, 0.0034370819693550444]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3252575634970713, 0.3286790707931334, 0.3426262837404402, 0.0034370819693550444]
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
probs:  [0.32525757526124033, 0.32867907776006206, 0.342626271152205, 0.003437075826492661]
siam score:  -0.6981262
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
probs:  [0.3263753144886344, 0.3263753144886344, 0.34380388079028373, 0.003445490232447584]
Printing some Q and Qe and total Qs values:  [[0.539]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]] [[4.603]
 [4.449]
 [4.449]
 [4.449]
 [4.449]
 [4.449]
 [4.449]] [[1.67 ]
 [1.549]
 [1.549]
 [1.549]
 [1.549]
 [1.549]
 [1.549]]
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
probs:  [0.3263753144886344, 0.3263753144886344, 0.34380388079028373, 0.003445490232447584]
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
Printing some Q and Qe and total Qs values:  [[1.343]
 [1.127]
 [1.127]
 [1.127]
 [1.127]
 [1.127]
 [1.127]] [[8.853]
 [6.385]
 [6.385]
 [6.385]
 [6.385]
 [6.385]
 [6.385]] [[2.358]
 [1.747]
 [1.747]
 [1.747]
 [1.747]
 [1.747]
 [1.747]]
UNIT TEST: sample policy line 217 mcts : [0.041 0.857 0.02  0.02  0.02  0.02  0.02 ]
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
probs:  [0.3275354709090168, 0.3275354709090168, 0.3414748342244664, 0.003454223957499954]
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
probs:  [0.3275354709090168, 0.3275354709090168, 0.3414748342244664, 0.003454223957499954]
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
probs:  [0.3275354709090168, 0.3275354709090168, 0.3414748342244664, 0.003454223957499954]
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
probs:  [0.3275354709090168, 0.3275354709090168, 0.3414748342244664, 0.003454223957499954]
siam score:  -0.6965785
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
probs:  [0.32866051543630415, 0.3252289126962574, 0.34264788477976466, 0.0034626870876738342]
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
probs:  [0.32866051543630415, 0.3252289126962574, 0.34264788477976466, 0.0034626870876738342]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
probs:  [0.32866051543630415, 0.3252289126962574, 0.34264788477976466, 0.0034626870876738342]
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
probs:  [0.32866052244378346, 0.3252289245251339, 0.34264787213500925, 0.003462680896073257]
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
probs:  [0.32866052244378346, 0.3252289245251339, 0.34264787213500925, 0.003462680896073257]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.32404056522331043, 0.32747018908459913, 0.34500952023833753, 0.003479725453752958]
Printing some Q and Qe and total Qs values:  [[0.691]
 [0.651]
 [0.702]
 [0.709]
 [0.717]
 [0.705]
 [0.708]] [[3.03 ]
 [4.945]
 [2.846]
 [2.896]
 [2.824]
 [3.079]
 [2.78 ]] [[0.72 ]
 [1.619]
 [0.641]
 [0.672]
 [0.645]
 [0.758]
 [0.615]]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.32519967753579426, 0.32864160718974705, 0.3426700780520697, 0.0034886372223889516]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.32519967753579426, 0.32864160718974705, 0.3426700780520697, 0.0034886372223889516]
Printing some Q and Qe and total Qs values:  [[0.275]
 [0.196]
 [0.326]
 [0.329]
 [0.271]
 [0.196]
 [0.351]] [[ 0.298]
 [-0.13 ]
 [ 0.532]
 [ 0.399]
 [ 0.108]
 [-0.13 ]
 [ 0.452]] [[0.275]
 [0.196]
 [0.326]
 [0.329]
 [0.271]
 [0.196]
 [0.351]]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.32519967753579426, 0.32864160718974705, 0.3426700780520697, 0.0034886372223889516]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.32519967753579426, 0.32864160718974705, 0.3426700780520697, 0.0034886372223889516]
Printing some Q and Qe and total Qs values:  [[0.27 ]
 [0.242]
 [0.292]
 [0.242]
 [0.242]
 [0.242]
 [0.266]] [[0.087]
 [0.214]
 [0.258]
 [0.214]
 [0.214]
 [0.214]
 [0.218]] [[0.27 ]
 [0.242]
 [0.292]
 [0.242]
 [0.242]
 [0.242]
 [0.266]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.32635829528662974, 0.32981252548270007, 0.34033163404205413, 0.0034975451886160346]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.32975349143774146, 0.3228502158686057, 0.3438726437338606, 0.0035236489597921753]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.33211800264977176, 0.32516507688649804, 0.33917509209489216, 0.0035418283688381136]
line 256 mcts: sample exp_bonus 2.8693035560796485
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.7065651
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3332996342025373, 0.32632190652687015, 0.33682755248631663, 0.0035509067842760082]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.3344547960328503, 0.3239904492388161, 0.3379949730576976, 0.0035597816706360013]
Printing some Q and Qe and total Qs values:  [[0.922]
 [0.83 ]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]] [[5.068]
 [4.677]
 [4.908]
 [4.908]
 [4.908]
 [4.908]
 [4.908]] [[1.04 ]
 [0.725]
 [0.755]
 [0.755]
 [0.755]
 [0.755]
 [0.755]]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.3344547960328503, 0.3239904492388161, 0.3379949730576976, 0.0035597816706360013]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.3344547960328503, 0.3239904492388161, 0.3379949730576976, 0.0035597816706360013]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.33210901227370293, 0.32513401110196055, 0.33918811794054604, 0.0035688586837903666]
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.567]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.559]] [[2.909]
 [3.849]
 [3.863]
 [3.863]
 [3.863]
 [3.863]
 [3.353]] [[0.607]
 [0.567]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.559]]
first move QE:  2.210912540189019
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.3297640555692362, 0.3262771697786698, 0.34038084215543835, 0.0035779324966556266]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.3309105700759775, 0.32393811285856783, 0.3415643806376536, 0.003586936427801122]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
line 256 mcts: sample exp_bonus 3.3159566533421265
1020 616
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.3344776302159866, 0.32742979659885635, 0.3344776302159866, 0.003614942969170379]
Printing some Q and Qe and total Qs values:  [[0.846]
 [1.027]
 [0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]] [[4.018]
 [4.426]
 [3.3  ]
 [3.3  ]
 [3.3  ]
 [3.3  ]
 [3.3  ]] [[2.02 ]
 [2.52 ]
 [1.886]
 [1.886]
 [1.886]
 [1.886]
 [1.886]]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.3344776302159866, 0.32742979659885635, 0.3344776302159866, 0.003614942969170379]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.3321165735117611, 0.3285931003564961, 0.33566605015894707, 0.0036242759727957716]
Printing some Q and Qe and total Qs values:  [[0.978]
 [1.069]
 [1.   ]
 [1.   ]
 [1.   ]
 [1.   ]
 [1.   ]] [[4.44 ]
 [4.383]
 [4.712]
 [4.712]
 [4.712]
 [4.712]
 [4.712]] [[1.435]
 [1.597]
 [1.57 ]
 [1.57 ]
 [1.57 ]
 [1.57 ]
 [1.57 ]]
Printing some Q and Qe and total Qs values:  [[0.896]
 [1.138]
 [0.957]
 [0.944]
 [0.838]
 [0.817]
 [0.84 ]] [[3.03 ]
 [3.601]
 [2.71 ]
 [2.681]
 [2.883]
 [2.881]
 [2.672]] [[0.8  ]
 [1.474]
 [0.814]
 [0.78 ]
 [0.634]
 [0.591]
 [0.568]]
first move QE:  2.21144773434957
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.32975611123628934, 0.32975611123628934, 0.3368541709007131, 0.0036336066267081313]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.3273962431651162, 0.3309188293488264, 0.33804199255426276, 0.003642934931794702]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
from probs:  [0.3273962431651162, 0.3309188293488264, 0.33804199255426276, 0.003642934931794702]
Printing some Q and Qe and total Qs values:  [[1.107]
 [1.17 ]
 [1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]] [[5.21 ]
 [6.27 ]
 [5.209]
 [5.209]
 [5.209]
 [5.209]
 [5.209]] [[1.868]
 [2.349]
 [1.658]
 [1.658]
 [1.658]
 [1.658]
 [1.658]]
maxi score, test score, baseline:  -0.997846611909651 -1.0 -0.997846611909651
probs:  [0.32267832129788543, 0.3332433889152846, 0.34041671895809456, 0.00366157082873541]
maxi score, test score, baseline:  -0.997846611909651 -1.0 -0.997846611909651
probs:  [0.32267832129788543, 0.3332433889152846, 0.34041671895809456, 0.00366157082873541]
siam score:  -0.7084506
maxi score, test score, baseline:  -0.9978508196721312 -1.0 -0.9978508196721312
probs:  [0.32267833747725516, 0.333243389512116, 0.3404167089748995, 0.00366156403572938]
Printing some Q and Qe and total Qs values:  [[0.506]
 [0.485]
 [0.487]
 [0.485]
 [0.487]
 [0.487]
 [0.486]] [[3.705]
 [3.616]
 [3.631]
 [3.616]
 [3.596]
 [3.514]
 [3.63 ]] [[ 0.077]
 [ 0.004]
 [ 0.015]
 [ 0.004]
 [ 0.002]
 [-0.025]
 [ 0.012]]
Printing some Q and Qe and total Qs values:  [[0.415]
 [0.442]
 [0.446]
 [0.449]
 [0.468]
 [0.502]
 [0.432]] [[3.745]
 [3.579]
 [3.709]
 [3.64 ]
 [3.574]
 [3.523]
 [3.783]] [[-0.098]
 [-0.099]
 [-0.047]
 [-0.065]
 [-0.049]
 [ 0.001]
 [-0.051]]
maxi score, test score, baseline:  -0.9978508196721312 -1.0 -0.9978508196721312
probs:  [0.32267833747725516, 0.333243389512116, 0.3404167089748995, 0.00366156403572938]
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.345]
 [0.491]
 [0.494]
 [0.474]
 [0.483]
 [0.492]] [[-0.175]
 [ 2.737]
 [ 0.759]
 [ 0.713]
 [ 0.729]
 [ 0.757]
 [ 0.767]] [[0.636]
 [0.345]
 [0.491]
 [0.494]
 [0.474]
 [0.483]
 [0.492]]
maxi score, test score, baseline:  -0.9978508196721312 -1.0 -0.9978508196721312
probs:  [0.32267833747725516, 0.333243389512116, 0.3404167089748995, 0.00366156403572938]
maxi score, test score, baseline:  -0.9978508196721312 -1.0 -0.9978508196721312
probs:  [0.32267833747725516, 0.333243389512116, 0.3404167089748995, 0.00366156403572938]
maxi score, test score, baseline:  -0.9978508196721312 -1.0 -0.9978508196721312
probs:  [0.32267833747725516, 0.333243389512116, 0.3404167089748995, 0.00366156403572938]
line 256 mcts: sample exp_bonus 3.5018581777870668
UNIT TEST: sample policy line 217 mcts : [0.694 0.02  0.122 0.02  0.061 0.02  0.061]
Printing some Q and Qe and total Qs values:  [[0.035]
 [0.075]
 [0.08 ]
 [0.067]
 [0.017]
 [0.014]
 [0.02 ]] [[3.389]
 [3.066]
 [3.079]
 [2.895]
 [3.245]
 [3.182]
 [3.049]] [[0.333]
 [0.198]
 [0.216]
 [0.068]
 [0.2  ]
 [0.153]
 [0.076]]
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.3226448975522709, 0.3368323758010241, 0.3368323758010241, 0.003690350845680842]
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.802]
 [0.914]
 [0.849]
 [0.921]
 [0.952]
 [1.067]] [[1.268]
 [2.893]
 [1.621]
 [1.54 ]
 [2.793]
 [1.507]
 [1.652]] [[2.641]
 [2.968]
 [2.768]
 [2.61 ]
 [3.173]
 [2.805]
 [3.084]]
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.3238070322916097, 0.33444711142183386, 0.33804577066368036, 0.003700085622876166]
Printing some Q and Qe and total Qs values:  [[1.009]
 [1.24 ]
 [0.946]
 [0.946]
 [0.946]
 [0.946]
 [0.946]] [[3.313]
 [3.805]
 [3.309]
 [3.309]
 [3.309]
 [3.309]
 [3.309]] [[1.895]
 [2.52 ]
 [1.767]
 [1.767]
 [1.767]
 [1.767]
 [1.767]]
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.32143600111732346, 0.33562152788720095, 0.33923286162531996, 0.0037096093701556375]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.32143600111732346, 0.33562152788720095, 0.33923286162531996, 0.0037096093701556375]
siam score:  -0.7149365
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.597]
 [0.568]
 [0.582]
 [0.594]
 [0.583]
 [0.597]
 [0.583]] [[2.373]
 [2.945]
 [2.574]
 [2.459]
 [2.625]
 [2.63 ]
 [2.451]] [[0.597]
 [0.568]
 [0.582]
 [0.594]
 [0.583]
 [0.597]
 [0.583]]
in main func line 156:  1028
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.31906538619444236, 0.33679573817539515, 0.34041974418468895, 0.0037191314454734625]
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.3166951874133623, 0.3379697423407058, 0.34160641839666206, 0.0037286518492698883]
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.898]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]] [[4.797]
 [4.348]
 [4.866]
 [4.866]
 [4.866]
 [4.866]
 [4.866]] [[1.829]
 [1.67 ]
 [1.835]
 [1.835]
 [1.835]
 [1.835]
 [1.835]]
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.315477646885844, 0.34038704924565294, 0.34038704924565294, 0.0037482546228502518]
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.315477646885844, 0.34038704924565294, 0.34038704924565294, 0.0037482546228502518]
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.31310355035058524, 0.3415693038585248, 0.3415693038585248, 0.003757841932365247]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.31539878998724813, 0.3440738343984425, 0.3367492306629744, 0.0037781449513349472]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.3130155610545003, 0.3452733901413205, 0.3379231762672706, 0.003787872536908464]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
line 256 mcts: sample exp_bonus 3.198852157956303
Printing some Q and Qe and total Qs values:  [[0.849]
 [0.8  ]
 [0.802]
 [0.802]
 [0.802]
 [0.802]
 [0.802]] [[6.005]
 [7.939]
 [6.474]
 [6.474]
 [6.474]
 [6.474]
 [6.474]] [[0.983]
 [1.531]
 [1.045]
 [1.045]
 [1.045]
 [1.045]
 [1.045]]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.3117707996170062, 0.3477428086054738, 0.33667849392743243, 0.003807897850087528]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.3129091511796421, 0.34901292373064247, 0.33425972746519766, 0.0038181976245178963]
Printing some Q and Qe and total Qs values:  [[1.307]
 [1.356]
 [1.277]
 [1.277]
 [1.277]
 [1.277]
 [1.277]] [[2.516]
 [2.637]
 [2.79 ]
 [2.79 ]
 [2.79 ]
 [2.79 ]
 [2.79 ]] [[1.611]
 [1.79 ]
 [1.734]
 [1.734]
 [1.734]
 [1.734]
 [1.734]]
Printing some Q and Qe and total Qs values:  [[0.994]
 [0.929]
 [0.981]
 [0.981]
 [0.981]
 [0.981]
 [0.981]] [[3.28 ]
 [3.123]
 [3.198]
 [3.198]
 [3.198]
 [3.198]
 [3.198]] [[1.904]
 [1.67 ]
 [1.824]
 [1.824]
 [1.824]
 [1.824]
 [1.824]]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.31408116954632864, 0.3465780574902122, 0.3355119709481702, 0.0038288020152890305]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
siam score:  -0.7096722
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.3128512795781745, 0.3453517370309197, 0.3379475560764574, 0.003849427314448435]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.3128512795781745, 0.3453517370309197, 0.3379475560764574, 0.003849427314448435]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.628]
 [0.805]
 [0.809]
 [0.706]
 [0.848]
 [0.779]] [[4.175]
 [4.348]
 [3.822]
 [3.754]
 [4.389]
 [3.844]
 [4.134]] [[0.472]
 [0.323]
 [0.502]
 [0.486]
 [0.493]
 [0.594]
 [0.553]]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.30804692519029836, 0.34776989256931484, 0.3403137175282568, 0.0038694647121300055]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.30804692519029836, 0.34776989256931484, 0.3403137175282568, 0.0038694647121300055]
actor:  1 policy actor:  1  step number:  95 total reward:  0.11999999999999933  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.1346474847255027, 0.7144133594072819, 0.1486924005981268, 0.0022467552690886156]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13204040024147787, 0.716569914076518, 0.1491391504567734, 0.0022505352252307734]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13204040024147787, 0.716569914076518, 0.1491391504567734, 0.0022505352252307734]
siam score:  -0.6954424
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13204040024147787, 0.716569914076518, 0.1491391504567734, 0.0022505352252307734]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13204040024147787, 0.716569914076518, 0.1491391504567734, 0.0022505352252307734]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13204040024147787, 0.716569914076518, 0.1491391504567734, 0.0022505352252307734]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13204040024147787, 0.716569914076518, 0.1491391504567734, 0.0022505352252307734]
Printing some Q and Qe and total Qs values:  [[-0.054]
 [-0.054]
 [-0.054]
 [-0.054]
 [-0.054]
 [-0.054]
 [-0.054]] [[8.387]
 [8.387]
 [8.387]
 [8.387]
 [8.387]
 [8.387]
 [8.387]] [[0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13204040024147787, 0.716569914076518, 0.1491391504567734, 0.0022505352252307734]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13252332699295688, 0.7155364248265745, 0.14968508978173733, 0.002255158398731149]
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]] [[0.415]
 [2.209]
 [2.209]
 [2.209]
 [2.209]
 [2.209]
 [2.209]] [[0.81 ]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.198]
 [1.346]
 [1.198]
 [1.198]
 [1.198]
 [1.198]
 [1.198]] [[3.593]
 [3.564]
 [3.589]
 [3.589]
 [3.589]
 [3.589]
 [3.589]] [[2.249]
 [2.536]
 [2.247]
 [2.247]
 [2.247]
 [2.247]
 [2.247]]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13191574398055148, 0.7167470907598539, 0.1490734078637895, 0.002263757395805246]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13239633696741435, 0.7157182669998285, 0.1496169848871793, 0.0022684111455778476]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.13239633696741435, 0.7157182669998285, 0.1496169848871793, 0.0022684111455778476]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
probs:  [0.13357538540978667, 0.7148302377806176, 0.14931455213295006, 0.002279824676645702]
Printing some Q and Qe and total Qs values:  [[1.467]
 [1.467]
 [1.467]
 [1.467]
 [1.467]
 [1.467]
 [1.467]] [[2.124]
 [2.205]
 [2.205]
 [2.205]
 [2.205]
 [2.205]
 [2.205]] [[2.301]
 [2.382]
 [2.382]
 [2.382]
 [2.382]
 [2.382]
 [2.382]]
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
probs:  [0.1337919522260056, 0.7159962774544131, 0.1479298485566948, 0.0022819217628865284]
first move QE:  2.2050954607978293
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
probs:  [0.13391541778960728, 0.714020773204277, 0.1497658195631543, 0.002297989442961488]
Printing some Q and Qe and total Qs values:  [[-0.073]
 [-0.073]
 [-0.061]
 [-0.061]
 [-0.061]
 [-0.061]
 [-0.061]] [[6.23 ]
 [5.567]
 [5.155]
 [5.155]
 [5.155]
 [5.155]
 [5.155]] [[ 0.534]
 [ 0.098]
 [-0.147]
 [-0.147]
 [-0.147]
 [-0.147]
 [-0.147]]
maxi score, test score, baseline:  -0.9978716024340771 -1.0 -0.9978716024340771
probs:  [0.1343958671624145, 0.712997907407305, 0.1503035335671758, 0.00230269186310464]
maxi score, test score, baseline:  -0.9978716024340771 -1.0 -0.9978716024340771
probs:  [0.1343958671624145, 0.712997907407305, 0.1503035335671758, 0.00230269186310464]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9978716024340771 -1.0 -0.9978716024340771
probs:  [0.1330680165546248, 0.7140939131052577, 0.15053336707187695, 0.002304703268240441]
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]] [[1.325]
 [1.515]
 [1.515]
 [1.515]
 [1.515]
 [1.515]
 [1.515]] [[0.418]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]]
maxi score, test score, baseline:  -0.9978716024340771 -1.0 -0.9978716024340771
probs:  [0.1330680165546248, 0.7140939131052577, 0.15053336707187695, 0.002304703268240441]
Printing some Q and Qe and total Qs values:  [[1.083]
 [0.845]
 [0.968]
 [0.894]
 [0.894]
 [0.699]
 [0.894]] [[3.081]
 [2.771]
 [2.434]
 [3.217]
 [3.217]
 [2.905]
 [3.217]] [[1.549]
 [1.131]
 [1.084]
 [1.421]
 [1.421]
 [1.048]
 [1.421]]
maxi score, test score, baseline:  -0.9978716024340771 -1.0 -0.9978716024340771
probs:  [0.13328638017647404, 0.7152729263618891, 0.14913382645161669, 0.0023068670100202474]
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.723]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]] [[5.97 ]
 [5.17 ]
 [4.392]
 [4.392]
 [4.392]
 [4.392]
 [4.392]] [[2.121]
 [1.559]
 [1.206]
 [1.206]
 [1.206]
 [1.206]
 [1.206]]
Printing some Q and Qe and total Qs values:  [[0.68 ]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]] [[5.604]
 [5.431]
 [5.431]
 [5.431]
 [5.431]
 [5.431]
 [5.431]] [[0.68 ]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]]
maxi score, test score, baseline:  -0.9978716024340771 -1.0 -0.9978716024340771
probs:  [0.13328638017647404, 0.7152729263618891, 0.14913382645161669, 0.0023068670100202474]
maxi score, test score, baseline:  -0.9978716024340771 -1.0 -0.9978716024340771
probs:  [0.13328638017647404, 0.7152729263618891, 0.14913382645161669, 0.0023068670100202474]
using another actor
from probs:  [0.1332865891726436, 0.7152725131723151, 0.14913403228018898, 0.002306865374852276]
maxi score, test score, baseline:  -0.9978757085020243 -1.0 -0.9978757085020243
probs:  [0.13350412549803287, 0.7164470570624764, 0.14773979652654512, 0.002309020912945694]
maxi score, test score, baseline:  -0.9978757085020243 -1.0 -0.9978757085020243
probs:  [0.13350412549803287, 0.7164470570624764, 0.14773979652654512, 0.002309020912945694]
Printing some Q and Qe and total Qs values:  [[0.948]
 [0.848]
 [0.917]
 [0.917]
 [0.917]
 [0.917]
 [0.917]] [[2.763]
 [4.096]
 [3.16 ]
 [3.16 ]
 [3.16 ]
 [3.16 ]
 [3.16 ]] [[1.634]
 [1.988]
 [1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]]
Printing some Q and Qe and total Qs values:  [[1.029]
 [1.   ]
 [1.04 ]
 [0.905]
 [1.04 ]
 [0.903]
 [0.921]] [[3.785]
 [3.866]
 [3.249]
 [2.688]
 [3.249]
 [2.675]
 [2.673]] [[1.595]
 [1.592]
 [1.286]
 [0.695]
 [1.286]
 [0.684]
 [0.716]]
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
Printing some Q and Qe and total Qs values:  [[0.875]
 [0.858]
 [0.871]
 [0.871]
 [0.896]
 [0.929]
 [0.871]] [[6.621]
 [6.391]
 [5.291]
 [5.291]
 [5.995]
 [6.018]
 [5.291]] [[1.825]
 [1.713]
 [1.372]
 [1.372]
 [1.657]
 [1.732]
 [1.372]]
Printing some Q and Qe and total Qs values:  [[0.863]
 [1.226]
 [0.863]
 [0.863]
 [0.863]
 [0.863]
 [0.863]] [[2.882]
 [4.419]
 [2.882]
 [2.882]
 [2.882]
 [2.882]
 [2.882]] [[1.078]
 [2.176]
 [1.078]
 [1.078]
 [1.078]
 [1.078]
 [1.078]]
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
probs:  [0.1349432412312735, 0.7134000162312375, 0.14933346908040562, 0.0023232734570834265]
using explorer policy with actor:  1
from probs:  [0.13408025409171218, 0.7134928158983871, 0.15009682637146946, 0.002330103638431215]
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
probs:  [0.13503210521364511, 0.7114650174775511, 0.151163231947824, 0.0023396453609798324]
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
probs:  [0.13503210521364511, 0.7114650174775511, 0.151163231947824, 0.0023396453609798324]
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
probs:  [0.13503210521364511, 0.7114650174775511, 0.151163231947824, 0.0023396453609798324]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
probs:  [0.13503231508029007, 0.71146460285642, 0.15116343837896448, 0.002339643684325459]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
probs:  [0.13503231508029007, 0.71146460285642, 0.15116343837896448, 0.002339643684325459]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
probs:  [0.13503231508029007, 0.71146460285642, 0.15116343837896448, 0.002339643684325459]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
probs:  [0.13503231508029007, 0.71146460285642, 0.15116343837896448, 0.002339643684325459]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
Printing some Q and Qe and total Qs values:  [[0.971]
 [1.054]
 [0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.979]] [[3.552]
 [4.185]
 [4.319]
 [4.319]
 [4.319]
 [4.319]
 [3.204]] [[1.982]
 [2.474]
 [2.385]
 [2.385]
 [2.385]
 [2.385]
 [1.802]]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
probs:  [0.13415848259064167, 0.7115620016567514, 0.1519329865120914, 0.0023465292405155146]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
probs:  [0.13415848259064167, 0.7115620016567514, 0.1519329865120914, 0.0023465292405155146]
Printing some Q and Qe and total Qs values:  [[0.324]
 [0.247]
 [0.247]
 [0.247]
 [0.247]
 [0.247]
 [0.247]] [[5.228]
 [5.338]
 [5.338]
 [5.338]
 [5.338]
 [5.338]
 [5.338]] [[1.297]
 [1.216]
 [1.216]
 [1.216]
 [1.216]
 [1.216]
 [1.216]]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.706]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.687]] [[4.663]
 [4.984]
 [4.663]
 [4.663]
 [4.663]
 [4.663]
 [4.835]] [[1.362]
 [1.545]
 [1.362]
 [1.362]
 [1.362]
 [1.362]
 [1.435]]
Printing some Q and Qe and total Qs values:  [[0.66 ]
 [0.666]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]] [[5.003]
 [5.547]
 [5.033]
 [5.033]
 [5.033]
 [5.033]
 [5.033]] [[1.502]
 [1.797]
 [1.563]
 [1.563]
 [1.563]
 [1.563]
 [1.563]]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.13557564023370589, 0.7085241878583033, 0.15353927392522868, 0.0023608979827620183]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.1360482066134927, 0.7075111844477552, 0.15407491827380712, 0.0023656906649449343]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.13652089833408834, 0.7064979123539653, 0.1546107046936347, 0.002370484618311511]
Printing some Q and Qe and total Qs values:  [[0.936]
 [0.79 ]
 [0.936]
 [0.805]
 [0.818]
 [0.867]
 [0.805]] [[3.804]
 [3.742]
 [3.804]
 [3.166]
 [2.718]
 [2.904]
 [3.462]] [[1.965]
 [1.651]
 [1.965]
 [1.49 ]
 [1.366]
 [1.526]
 [1.589]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.13722738039148732, 0.7066947907214727, 0.1537001792563325, 0.0023776496307073847]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.13722738039148732, 0.7066947907214727, 0.1537001792563325, 0.0023776496307073847]
Printing some Q and Qe and total Qs values:  [[0.547]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.533]
 [0.498]] [[4.845]
 [4.53 ]
 [4.53 ]
 [4.53 ]
 [4.53 ]
 [4.893]
 [4.53 ]] [[1.626]
 [1.318]
 [1.318]
 [1.318]
 [1.318]
 [1.63 ]
 [1.318]]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.13770195235103208, 0.7056834495757747, 0.1542321354200782, 0.0023824626531150457]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.1381766559069048, 0.704671827990454, 0.15476423909249232, 0.002387277010148706]
line 256 mcts: sample exp_bonus 5.098291463849969
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.13679747925645458, 0.705801838894373, 0.15501117065652537, 0.0023895111926469054]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.1358900310834016, 0.70592048931845, 0.15579289553071876, 0.0023965840674297187]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
from probs:  [0.13659229488203742, 0.7061366101315112, 0.1548672195036465, 0.0024038754828047747]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.1370610043582052, 0.705131154596397, 0.1553990990786769, 0.0024087419667209375]
Printing some Q and Qe and total Qs values:  [[0.89 ]
 [0.875]
 [0.89 ]
 [0.89 ]
 [0.89 ]
 [0.89 ]
 [0.89 ]] [[4.907]
 [5.166]
 [5.027]
 [5.027]
 [5.027]
 [5.027]
 [5.027]] [[1.865]
 [1.972]
 [1.924]
 [1.924]
 [1.924]
 [1.924]
 [1.924]]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
siam score:  -0.69498616
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.1370610043582052, 0.705131154596397, 0.1553990990786769, 0.0024087419667209375]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]] [[1.768]
 [1.768]
 [1.768]
 [1.768]
 [1.768]
 [1.768]
 [1.768]] [[0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]]
line 256 mcts: sample exp_bonus 2.3568695732040084
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.1370610043582052, 0.705131154596397, 0.1553990990786769, 0.0024087419667209375]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.1375302910871753, 0.7041245359617373, 0.1559315665826826, 0.002413606368404871]
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.1375302910871753, 0.7041245359617373, 0.1559315665826826, 0.002413606368404871]
Printing some Q and Qe and total Qs values:  [[0.527]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.542]
 [0.513]] [[0.543]
 [0.557]
 [0.557]
 [0.557]
 [0.557]
 [0.589]
 [0.47 ]] [[0.527]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.542]
 [0.513]]
Printing some Q and Qe and total Qs values:  [[0.759]
 [0.576]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.556]] [[-0.262]
 [ 1.329]
 [ 0.927]
 [ 0.927]
 [ 0.927]
 [ 0.927]
 [ 0.913]] [[0.759]
 [0.576]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.556]]
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.13799929359397353, 0.7031184520881498, 0.15646377845083823, 0.002418475867038504]
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.13893773731908368, 0.7011053432360282, 0.157528700025585, 0.0024282194193029944]
line 256 mcts: sample exp_bonus 1.4646562612132312
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.13893773731908368, 0.7011053432360282, 0.157528700025585, 0.0024282194193029944]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
line 256 mcts: sample exp_bonus 3.814738597139968
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.1391804137480233, 0.7023370230332155, 0.15605182416998492, 0.002430739048776201]
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.1391804137480233, 0.7023370230332155, 0.15605182416998492, 0.002430739048776201]
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.039]
 [0.042]
 [0.045]
 [0.054]
 [0.066]
 [0.049]] [[3.644]
 [3.48 ]
 [3.642]
 [3.553]
 [3.662]
 [3.63 ]
 [3.254]] [[0.355]
 [0.26 ]
 [0.374]
 [0.321]
 [0.413]
 [0.415]
 [0.132]]
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
line 256 mcts: sample exp_bonus 1.857009828503182
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
from probs:  [0.1382459569066279, 0.7024805485938277, 0.15683550410220934, 0.002437990397335079]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.9702305662921415
siam score:  -0.7049634
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.13835438055632407, 0.7022669805484537, 0.15694156559241268, 0.0024370733028094157]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.13835438055632407, 0.7022669805484537, 0.15694156559241268, 0.0024370733028094157]
Printing some Q and Qe and total Qs values:  [[0.858]
 [0.847]
 [0.858]
 [0.858]
 [0.858]
 [0.858]
 [0.858]] [[2.774]
 [3.083]
 [2.774]
 [2.774]
 [2.774]
 [2.774]
 [2.774]] [[2.024]
 [2.199]
 [2.024]
 [2.024]
 [2.024]
 [2.024]
 [2.024]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
first move QE:  2.195367955466097
first move QE:  2.1944848718768952
using another actor
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14213533900321856, 0.6977347903675863, 0.1576531304445208, 0.002476740184674267]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.9  ]
 [0.847]
 [0.873]
 [0.843]
 [0.837]
 [0.855]
 [0.842]] [[4.539]
 [4.402]
 [4.488]
 [4.44 ]
 [4.522]
 [4.438]
 [4.274]] [[1.991]
 [1.793]
 [1.902]
 [1.811]
 [1.852]
 [1.833]
 [1.698]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14286047014392678, 0.6979782262264804, 0.1566769559317182, 0.0024843476978746895]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14286047014392678, 0.6979782262264804, 0.1566769559317182, 0.0024843476978746895]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14333423945573087, 0.6969795757657445, 0.15719686666069255, 0.002489318117832084]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14358830382281043, 0.6982218606436482, 0.15569785196953304, 0.0024919835640083814]
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]] [[5.149]
 [5.149]
 [5.149]
 [5.149]
 [5.149]
 [5.149]
 [5.149]] [[1.512]
 [1.512]
 [1.512]
 [1.512]
 [1.512]
 [1.512]
 [1.512]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14358830382281043, 0.6982218606436482, 0.15569785196953304, 0.0024919835640083814]
line 256 mcts: sample exp_bonus 4.880625527816649
Printing some Q and Qe and total Qs values:  [[0.593]
 [0.498]
 [0.598]
 [0.609]
 [0.601]
 [0.51 ]
 [0.526]] [[4.387]
 [4.292]
 [4.562]
 [4.464]
 [4.511]
 [4.674]
 [4.703]] [[0.676]
 [0.421]
 [0.801]
 [0.759]
 [0.774]
 [0.701]
 [0.752]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1445397657118343, 0.696228152644856, 0.15673011607953027, 0.002501965563779317]
Printing some Q and Qe and total Qs values:  [[0.889]
 [1.03 ]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]] [[3.575]
 [3.982]
 [3.535]
 [3.535]
 [3.535]
 [3.535]
 [3.535]] [[1.121]
 [1.54 ]
 [1.103]
 [1.103]
 [1.103]
 [1.103]
 [1.103]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14308680658581582, 0.6974131108097716, 0.1569955502903166, 0.002504532314096031]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14355879701790902, 0.6964179176241203, 0.15751374212589936, 0.002509543232071375]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14257479343239562, 0.696607834218263, 0.15830022383470604, 0.002517148514635325]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14304314626950773, 0.6956140756661622, 0.15882059753309388, 0.002522180531236312]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14251699430293926, 0.6948136003354595, 0.1601345192004247, 0.0025348861611766563]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.807]
 [0.863]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]] [[2.19 ]
 [2.699]
 [1.671]
 [1.671]
 [1.671]
 [1.671]
 [1.671]] [[2.261]
 [2.597]
 [1.989]
 [1.989]
 [1.989]
 [1.989]
 [1.989]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14251699430293926, 0.6948136003354595, 0.1601345192004247, 0.0025348861611766563]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
siam score:  -0.695748
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14490776097914523, 0.6933896448924852, 0.1591417112584702, 0.0025608828698993427]
Printing some Q and Qe and total Qs values:  [[0.255]
 [0.253]
 [0.69 ]
 [0.72 ]
 [0.361]
 [0.706]
 [0.332]] [[3.596]
 [3.194]
 [1.925]
 [1.542]
 [2.99 ]
 [2.434]
 [3.83 ]] [[0.629]
 [0.357]
 [0.387]
 [0.191]
 [0.438]
 [0.758]
 [0.939]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1458462620496805, 0.6914096128919466, 0.1601730371194429, 0.0025710879389298992]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1458462620496805, 0.6914096128919466, 0.1601730371194429, 0.0025710879389298992]
line 256 mcts: sample exp_bonus 4.3706046220715935
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.69894
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14678558873587777, 0.6894278390229305, 0.16120527025565498, 0.0025813019855366005]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14678558873587777, 0.6894278390229305, 0.16120527025565498, 0.0025813019855366005]
from probs:  [0.14678558873587777, 0.6894278390229305, 0.16120527025565498, 0.0025813019855366005]
siam score:  -0.69528943
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1472555620253816, 0.6884362981692956, 0.1617217274261889, 0.0025864123791338816]
siam score:  -0.69578826
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[ 0.014]
 [ 0.002]
 [ 0.006]
 [ 0.005]
 [ 0.002]
 [ 0.001]
 [-0.001]] [[ 0.394]
 [ 0.898]
 [ 0.077]
 [-0.151]
 [ 0.898]
 [-0.06 ]
 [ 0.226]] [[ 0.014]
 [ 0.002]
 [ 0.006]
 [ 0.005]
 [ 0.002]
 [ 0.001]
 [-0.001]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14622249808345716, 0.6886593405093572, 0.16252381232053306, 0.0025943490866527134]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14668889273196992, 0.6876690665192622, 0.16304255861739173, 0.0025994821313761293]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1471554980053294, 0.6866783453192603, 0.1635615391812165, 0.0026046174941938066]
siam score:  -0.69595397
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1471554980053294, 0.6866783453192603, 0.1635615391812165, 0.0026046174941938066]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1471554980053294, 0.6866783453192603, 0.1635615391812165, 0.0026046174941938066]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1476223140462457, 0.6856871766063416, 0.16408075417073634, 0.002609755176676384]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14836819401479145, 0.6859916874214463, 0.16302215438372553, 0.002617964180036638]
Printing some Q and Qe and total Qs values:  [[0.841]
 [0.816]
 [0.831]
 [0.824]
 [0.765]
 [0.783]
 [0.821]] [[4.938]
 [5.246]
 [5.029]
 [4.894]
 [5.305]
 [4.717]
 [5.294]] [[1.086]
 [1.138]
 [1.095]
 [1.037]
 [1.057]
 [0.896]
 [1.164]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14836819401479145, 0.6859916874214463, 0.16302215438372553, 0.002617964180036638]
line 256 mcts: sample exp_bonus 3.2196547363575343
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  0
1090 697
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14977588926108285, 0.6830208298693282, 0.16456982388173555, 0.002633456987853357]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14977588926108285, 0.6830208298693282, 0.16456982388173555, 0.002633456987853357]
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.632]
 [0.663]
 [0.654]
 [0.663]
 [0.684]
 [0.655]] [[2.736]
 [3.581]
 [3.271]
 [2.65 ]
 [2.781]
 [2.942]
 [3.048]] [[0.661]
 [0.632]
 [0.663]
 [0.654]
 [0.663]
 [0.684]
 [0.655]]
Printing some Q and Qe and total Qs values:  [[0.034]
 [0.071]
 [0.071]
 [0.045]
 [0.043]
 [0.071]
 [0.031]] [[6.674]
 [6.176]
 [6.176]
 [6.027]
 [6.587]
 [6.176]
 [5.877]] [[-0.26 ]
 [-0.353]
 [-0.353]
 [-0.455]
 [-0.272]
 [-0.353]
 [-0.532]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14977588926108285, 0.6830208298693282, 0.16456982388173555, 0.002633456987853357]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14977588926108285, 0.6830208298693282, 0.16456982388173555, 0.002633456987853357]
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14824700174160751, 0.6842515839314116, 0.16486500248003075, 0.0026364118469501333]
Printing some Q and Qe and total Qs values:  [[0.606]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]] [[1.709]
 [1.594]
 [1.594]
 [1.594]
 [1.594]
 [1.594]
 [1.594]] [[0.606]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]]
line 256 mcts: sample exp_bonus 2.9615049702599823
siam score:  -0.70327866
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14746472777534853, 0.6858021581188402, 0.16408538894014968, 0.0026477251656617067]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14746472777534853, 0.6858021581188402, 0.16408538894014968, 0.0026477251656617067]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1483923455510877, 0.6838311997254679, 0.16511826892887224, 0.0026581857945722244]
Printing some Q and Qe and total Qs values:  [[0.842]
 [0.855]
 [0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.842]] [[1.808]
 [2.635]
 [1.808]
 [1.808]
 [1.808]
 [1.808]
 [1.808]] [[1.659]
 [2.234]
 [1.659]
 [1.659]
 [1.659]
 [1.659]
 [1.659]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14885650196414096, 0.6828449821237021, 0.16563509588413172, 0.00266342002802524]
siam score:  -0.70376176
Printing some Q and Qe and total Qs values:  [[0.633]
 [0.62 ]
 [0.606]
 [0.586]
 [0.587]
 [0.593]
 [0.593]] [[1.383]
 [2.092]
 [0.966]
 [0.352]
 [0.518]
 [1.133]
 [0.448]] [[0.633]
 [0.62 ]
 [0.606]
 [0.586]
 [0.587]
 [0.593]
 [0.593]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14932089029217036, 0.6818582717599595, 0.1661521810711159, 0.0026686568767542536]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15025036338876102, 0.679883371268559, 0.16718712691479545, 0.0026791384278845097]
in main func line 156:  1096
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.1680565610209914
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15054611192588602, 0.6771785998067978, 0.16957199675421142, 0.0027032915131048637]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
Printing some Q and Qe and total Qs values:  [[0.828]
 [0.873]
 [0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.829]] [[2.001]
 [3.531]
 [2.637]
 [2.637]
 [2.637]
 [2.637]
 [2.637]] [[1.086]
 [1.688]
 [1.301]
 [1.301]
 [1.301]
 [1.301]
 [1.301]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.674]
 [0.67 ]
 [0.7  ]
 [0.663]
 [0.667]
 [0.66 ]] [[4.338]
 [4.6  ]
 [3.825]
 [4.255]
 [3.856]
 [3.844]
 [3.77 ]] [[0.898]
 [0.946]
 [0.68 ]
 [0.882]
 [0.676]
 [0.679]
 [0.642]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
line 256 mcts: sample exp_bonus 6.2639713264966295
line 256 mcts: sample exp_bonus 6.476275742801092
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15100815672513254, 0.6761904537536849, 0.17009282326856026, 0.002708566252622374]
Printing some Q and Qe and total Qs values:  [[0.455]
 [0.338]
 [0.463]
 [0.443]
 [0.415]
 [0.429]
 [0.441]] [[-1.275]
 [ 0.689]
 [-0.831]
 [-1.27 ]
 [-0.88 ]
 [-1.486]
 [-1.384]] [[0.455]
 [0.338]
 [0.463]
 [0.443]
 [0.415]
 [0.429]
 [0.441]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]] [[4.052]
 [3.543]
 [3.543]
 [3.543]
 [3.543]
 [3.543]
 [3.543]] [[1.941]
 [1.458]
 [1.458]
 [1.458]
 [1.458]
 [1.458]
 [1.458]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.603]] [[4.731]
 [3.417]
 [3.417]
 [3.417]
 [3.417]
 [3.417]
 [3.417]] [[0.805]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.555]
 [0.572]] [[3.037]
 [3.119]
 [3.119]
 [3.119]
 [3.119]
 [2.796]
 [3.119]] [[0.942]
 [1.025]
 [1.025]
 [1.025]
 [1.025]
 [0.669]
 [1.025]]
Printing some Q and Qe and total Qs values:  [[0.569]
 [0.559]
 [0.554]
 [0.559]
 [0.559]
 [0.559]
 [0.559]] [[3.09 ]
 [3.052]
 [2.888]
 [3.052]
 [3.052]
 [3.052]
 [3.052]] [[0.772]
 [0.714]
 [0.539]
 [0.714]
 [0.714]
 [0.714]
 [0.714]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.7102474
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14788172831917612, 0.6786856518618365, 0.17071772479339214, 0.0027148950255952782]
line 256 mcts: sample exp_bonus 5.9782160643575235
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1501557852989304, 0.6737573839359794, 0.17334532437663977, 0.0027415063884504895]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1521349925734209, 0.6735166167270815, 0.17158372332457397, 0.002764667374923585]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15243967053077653, 0.6748723371870686, 0.16991975951913874, 0.0027682327630160378]
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.507]] [[0.305]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [1.124]] [[0.599]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.507]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15243967053077653, 0.6748723371870686, 0.16991975951913874, 0.0027682327630160378]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15243967053077653, 0.6748723371870686, 0.16991975951913874, 0.0027682327630160378]
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.53 ]
 [0.515]
 [0.518]
 [0.505]
 [0.504]
 [0.504]] [[-0.242]
 [ 1.001]
 [ 0.431]
 [ 0.316]
 [ 0.533]
 [ 0.603]
 [ 0.646]] [[0.583]
 [0.53 ]
 [0.515]
 [0.518]
 [0.505]
 [0.504]
 [0.504]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1529015271881094, 0.6738899102496135, 0.17043492508196303, 0.002773637480314155]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15367122292068305, 0.6742632620284489, 0.169282870473278, 0.0027826445775900707]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15506481222776486, 0.6713172753658508, 0.17081895983341328, 0.002798952572971041]
Printing some Q and Qe and total Qs values:  [[0.275]
 [0.253]
 [0.268]
 [0.237]
 [0.231]
 [0.25 ]
 [0.243]] [[0.277]
 [1.898]
 [1.209]
 [0.27 ]
 [0.211]
 [1.207]
 [0.742]] [[0.275]
 [0.253]
 [0.268]
 [0.237]
 [0.231]
 [0.25 ]
 [0.243]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15506481222776486, 0.6713172753658508, 0.17081895983341328, 0.002798952572971041]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15506481222776486, 0.6713172753658508, 0.17081895983341328, 0.002798952572971041]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.406]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]] [[6.415]
 [6.375]
 [6.375]
 [6.375]
 [6.375]
 [6.375]
 [6.375]] [[1.248]
 [1.197]
 [1.197]
 [1.197]
 [1.197]
 [1.197]
 [1.197]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15631140151717104, 0.6707137186343457, 0.1701613394968385, 0.00281354035164464]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15677892560519172, 0.6697315088970692, 0.1706705541076549, 0.002819011390084147]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15677892560519172, 0.6697315088970692, 0.1706705541076549, 0.002819011390084147]
line 256 mcts: sample exp_bonus 2.922791826831063
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1572467296568102, 0.6687487109912279, 0.17118007364726132, 0.002824485704700531]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1572467296568102, 0.6687487109912279, 0.17118007364726132, 0.002824485704700531]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15756588299154659, 0.6701126439572379, 0.16949325256534073, 0.002828220485874766]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15756588299154659, 0.6701126439572379, 0.16949325256534073, 0.002828220485874766]
Printing some Q and Qe and total Qs values:  [[-0.014]
 [-0.019]
 [-0.009]
 [-0.014]
 [-0.021]
 [-0.021]
 [-0.023]] [[5.95 ]
 [6.333]
 [5.247]
 [5.391]
 [5.639]
 [5.595]
 [5.554]] [[ 0.111]
 [ 0.357]
 [-0.347]
 [-0.26 ]
 [-0.111]
 [-0.14 ]
 [-0.17 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1580358842787817, 0.6691313370266265, 0.16999905818171304, 0.0028337205128786537]
Printing some Q and Qe and total Qs values:  [[-0.04 ]
 [-0.067]
 [-0.038]
 [-0.033]
 [-0.033]
 [-0.042]
 [-0.033]] [[5.391]
 [4.87 ]
 [5.312]
 [5.085]
 [5.085]
 [5.373]
 [5.085]] [[-0.13 ]
 [-0.498]
 [-0.175]
 [-0.304]
 [-0.304]
 [-0.144]
 [-0.304]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.70923096
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1563914681561392, 0.6704409005959924, 0.17033030878357544, 0.002837322464293041]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15685774713220266, 0.6694609927970542, 0.17083841258940335, 0.002842847481339857]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15685774713220266, 0.6694609927970542, 0.17083841258940335, 0.002842847481339857]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15732431677119213, 0.6684804741559321, 0.1713468331303759, 0.0028483759424999685]
Printing some Q and Qe and total Qs values:  [[0.254]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]] [[3.195]
 [2.974]
 [2.974]
 [2.974]
 [2.974]
 [2.974]
 [2.974]] [[-0.104]
 [-0.239]
 [-0.239]
 [-0.239]
 [-0.239]
 [-0.239]
 [-0.239]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15732431677119213, 0.6684804741559321, 0.1713468331303759, 0.0028483759424999685]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15732431677119213, 0.6684804741559321, 0.1713468331303759, 0.0028483759424999685]
Printing some Q and Qe and total Qs values:  [[0.469]
 [0.511]
 [0.729]
 [0.595]
 [0.425]
 [0.544]
 [0.494]] [[4.392]
 [3.861]
 [4.071]
 [4.459]
 [4.486]
 [5.036]
 [4.3  ]] [[1.463]
 [1.192]
 [1.584]
 [1.657]
 [1.467]
 [1.946]
 [1.437]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15890789756686832, 0.6692665239766077, 0.16895843840210753, 0.0028671400544163735]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15890789756686832, 0.6692665239766077, 0.16895843840210753, 0.0028671400544163735]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15890789756686832, 0.6692665239766077, 0.16895843840210753, 0.0028671400544163735]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15923145594285565, 0.6706357972578136, 0.16726177284796692, 0.0028709739513637813]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1605049016566232, 0.6700528971310484, 0.16655613799115424, 0.0028860632211742286]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1605049016566232, 0.6700528971310484, 0.16655613799115424, 0.0028860632211742286]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1605049016566232, 0.6700528971310484, 0.16655613799115424, 0.0028860632211742286]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1588295036182799, 0.6713929176193124, 0.16688773006027233, 0.002889848702135215]
line 256 mcts: sample exp_bonus -0.4014699070712579
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1588295036182799, 0.6713929176193124, 0.16688773006027233, 0.002889848702135215]
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.466]
 [0.483]
 [0.461]
 [0.492]
 [0.492]
 [0.46 ]
 [0.457]] [[1.28 ]
 [2.225]
 [1.367]
 [2.291]
 [2.291]
 [1.43 ]
 [1.271]] [[0.466]
 [0.483]
 [0.461]
 [0.492]
 [0.492]
 [0.46 ]
 [0.457]]
siam score:  -0.70523965
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]] [[2.615]
 [1.893]
 [1.893]
 [1.893]
 [1.893]
 [1.893]
 [1.893]] [[0.516]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1588295036182799, 0.6713929176193124, 0.16688773006027233, 0.002889848702135215]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1588295036182799, 0.6713929176193124, 0.16688773006027233, 0.002889848702135215]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1588295036182799, 0.6713929176193124, 0.16688773006027233, 0.002889848702135215]
line 256 mcts: sample exp_bonus 4.916808983244996
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15930128195553533, 0.6704196133543867, 0.16738359515330978, 0.002895509536768273]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.869]
 [0.869]
 [0.869]
 [0.869]
 [0.869]
 [0.869]
 [0.869]] [[4.35]
 [4.35]
 [4.35]
 [4.35]
 [4.35]
 [4.35]
 [4.35]] [[1.785]
 [1.785]
 [1.785]
 [1.785]
 [1.785]
 [1.785]
 [1.785]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16071855899045487, 0.6674956940606485, 0.16887323160603177, 0.0029125153428648065]
using explorer policy with actor:  1
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.0000],
        [-0.2634],
        [-0.0000],
        [-0.2775],
        [-0.4329],
        [-0.2187],
        [-0.0000],
        [-0.3926],
        [-0.4266],
        [-0.5678]], dtype=torch.float64)
-0.9560860847999999 -0.9560860847999999
-0.0727797758985 -0.3361809015430421
-0.9553499999999999 -0.9553499999999999
-0.0628797758985 -0.3403541449720394
-0.024259925299500003 -0.45716321334257365
-0.0727797758985 -0.29145055895725236
-0.7850519652194999 -0.7850519652194999
-0.024259925299500003 -0.4168995145273397
-0.024259925299500003 -0.45082551198301296
-0.024259925299500003 -0.5920481604868327
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16104938217770953, 0.6688761726305803, 0.16715796032500763, 0.0029164848667024732]
Printing some Q and Qe and total Qs values:  [[0.715]
 [0.69 ]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]] [[4.543]
 [4.72 ]
 [4.925]
 [4.925]
 [4.925]
 [4.925]
 [4.925]] [[1.289]
 [1.357]
 [1.527]
 [1.527]
 [1.527]
 [1.527]
 [1.527]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16104938217770953, 0.6688761726305803, 0.16715796032500763, 0.0029164848667024732]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16104938217770953, 0.6688761726305803, 0.16715796032500763, 0.0029164848667024732]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16104938217770953, 0.6688761726305803, 0.16715796032500763, 0.0029164848667024732]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15935910463499944, 0.6702265953296062, 0.1674939320695904, 0.002920367965804094]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15935910463499944, 0.6702265953296062, 0.1674939320695904, 0.002920367965804094]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15935910463499944, 0.6702265953296062, 0.1674939320695904, 0.002920367965804094]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.15767294916284733, 0.671573724760214, 0.1678290844817253, 0.0029242415952132664]
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.647]
 [0.723]
 [0.728]
 [0.742]
 [0.736]
 [0.725]] [[3.664]
 [4.103]
 [3.941]
 [3.737]
 [3.863]
 [3.92 ]
 [3.708]] [[0.764]
 [0.942]
 [0.985]
 [0.863]
 [0.971]
 [0.996]
 [0.838]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15813985046413515, 0.6706039104503015, 0.1683262513281626, 0.002929987757400665]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15860708925060457, 0.6696333951400759, 0.16882377753629563, 0.0029357380730238836]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.501]
 [0.681]
 [0.681]
 [0.655]
 [0.747]
 [0.681]] [[2.125]
 [2.738]
 [1.633]
 [1.633]
 [0.557]
 [0.536]
 [1.633]] [[1.505]
 [1.597]
 [1.249]
 [1.249]
 [0.533]
 [0.691]
 [1.249]]
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.504]
 [0.685]
 [0.57 ]
 [0.568]
 [0.558]
 [0.685]] [[-0.449]
 [ 2.256]
 [ 0.   ]
 [-0.497]
 [-0.359]
 [-0.349]
 [ 0.   ]] [[0.587]
 [0.504]
 [0.685]
 [0.57 ]
 [0.568]
 [0.558]
 [0.685]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15860708925060457, 0.6696333951400759, 0.16882377753629563, 0.0029357380730238836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15907466588829877, 0.6686621780692177, 0.16932166349589567, 0.0029414925465878227]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1595425807437909, 0.6676902584763076, 0.16981990959729754, 0.002947251182603903]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16034496319750358, 0.6681164794950977, 0.16858143119040803, 0.0029571261169907604]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16034496319750358, 0.6681164794950977, 0.16858143119040803, 0.0029571261169907604]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16034496319750358, 0.6681164794950977, 0.16858143119040803, 0.0029571261169907604]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16067830886509918, 0.6695120438845327, 0.16684841864262562, 0.002961228607742421]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16067830886509918, 0.6695120438845327, 0.16684841864262562, 0.002961228607742421]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16067830886509918, 0.6695120438845327, 0.16684841864262562, 0.002961228607742421]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16115084925149817, 0.668542888630194, 0.1673392179480626, 0.0029670441702453615]
Starting evaluation
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16115084925149817, 0.668542888630194, 0.1673392179480626, 0.0029670441702453615]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.235]
 [0.529]
 [0.55 ]
 [0.512]
 [0.495]
 [0.523]
 [0.34 ]] [[3.716]
 [3.792]
 [4.135]
 [2.242]
 [1.813]
 [3.544]
 [4.266]] [[0.235]
 [0.529]
 [0.55 ]
 [0.512]
 [0.495]
 [0.523]
 [0.34 ]]
siam score:  -0.71336776
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.602]
 [0.635]
 [0.594]
 [0.594]
 [0.568]
 [0.594]
 [0.594]] [[3.137]
 [3.514]
 [3.244]
 [3.244]
 [2.608]
 [3.244]
 [3.244]] [[0.602]
 [0.635]
 [0.594]
 [0.594]
 [0.568]
 [0.594]
 [0.594]]
Printing some Q and Qe and total Qs values:  [[0.588]
 [0.594]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.629]] [[4.245]
 [4.063]
 [4.196]
 [4.196]
 [4.196]
 [4.196]
 [4.196]] [[0.588]
 [0.594]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.629]]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus -0.1542873221742094
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.686]
 [0.379]
 [0.483]
 [0.405]
 [0.638]
 [0.423]
 [0.409]] [[-1.428]
 [-0.145]
 [-1.801]
 [-2.236]
 [ 0.   ]
 [-2.119]
 [-2.368]] [[0.686]
 [0.379]
 [0.483]
 [0.405]
 [0.638]
 [0.423]
 [0.409]]
Printing some Q and Qe and total Qs values:  [[0.579]
 [0.566]
 [0.579]
 [0.579]
 [0.579]
 [0.579]
 [0.579]] [[4.591]
 [4.514]
 [4.591]
 [4.591]
 [4.591]
 [4.591]
 [4.591]] [[0.579]
 [0.566]
 [0.579]
 [0.579]
 [0.579]
 [0.579]
 [0.579]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.9799943126694686
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.366]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]] [[-1.78 ]
 [ 0.948]
 [-2.182]
 [-2.182]
 [-2.182]
 [-2.182]
 [-2.182]] [[0.722]
 [0.366]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]]
line 256 mcts: sample exp_bonus 3.186731374302133
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.0510829975242173
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]] [[-1.538]
 [-1.706]
 [-1.706]
 [-1.706]
 [-1.706]
 [-1.706]
 [-1.706]] [[0.644]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]]
Printing some Q and Qe and total Qs values:  [[0.568]
 [0.443]
 [0.561]
 [0.561]
 [0.561]
 [0.536]
 [0.561]] [[3.245]
 [4.067]
 [3.581]
 [4.193]
 [4.193]
 [3.479]
 [4.193]] [[0.568]
 [0.443]
 [0.561]
 [0.561]
 [0.561]
 [0.536]
 [0.561]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16209699207035913, 0.6666023999214046, 0.16832191964236629, 0.0029786883658700523]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.63 ]
 [0.627]
 [0.63 ]
 [0.61 ]
 [0.63 ]
 [0.63 ]] [[2.832]
 [3.908]
 [3.925]
 [4.837]
 [3.822]
 [4.837]
 [4.837]] [[0.734]
 [0.63 ]
 [0.627]
 [0.63 ]
 [0.61 ]
 [0.63 ]
 [0.63 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16243549894748313, 0.6680009782779321, 0.1665806683988703, 0.002982854375714401]
Printing some Q and Qe and total Qs values:  [[0.716]
 [0.631]
 [0.62 ]
 [0.619]
 [0.631]
 [0.597]
 [0.612]] [[3.332]
 [3.902]
 [3.593]
 [3.547]
 [3.682]
 [3.867]
 [3.765]] [[0.716]
 [0.631]
 [0.62 ]
 [0.619]
 [0.631]
 [0.597]
 [0.612]]
siam score:  -0.7199852
line 256 mcts: sample exp_bonus 4.435460245682407
line 256 mcts: sample exp_bonus 4.009181044243376
line 256 mcts: sample exp_bonus 2.101609316743597
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16243549894748313, 0.6680009782779321, 0.1665806683988703, 0.002982854375714401]
Printing some Q and Qe and total Qs values:  [[0.694]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]] [[5.421]
 [5.44 ]
 [5.44 ]
 [5.44 ]
 [5.44 ]
 [5.44 ]
 [5.44 ]] [[0.694]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]]
Printing some Q and Qe and total Qs values:  [[0.484]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.422]] [[1.866]
 [1.444]
 [1.444]
 [1.444]
 [1.444]
 [1.444]
 [2.059]] [[0.484]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.422]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16243549894748313, 0.6680009782779321, 0.1665806683988703, 0.002982854375714401]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16243549894748313, 0.6680009782779321, 0.1665806683988703, 0.002982854375714401]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16243549894748313, 0.6680009782779321, 0.1665806683988703, 0.002982854375714401]
Printing some Q and Qe and total Qs values:  [[0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]] [[3.13]
 [3.13]
 [3.13]
 [3.13]
 [3.13]
 [3.13]
 [3.13]] [[1.425]
 [1.425]
 [1.425]
 [1.425]
 [1.425]
 [1.425]
 [1.425]]
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.324]
 [0.433]
 [0.433]
 [0.433]
 [0.433]
 [0.417]] [[-0.755]
 [ 1.467]
 [-1.97 ]
 [-1.97 ]
 [-1.97 ]
 [-1.97 ]
 [-2.041]] [[0.581]
 [0.324]
 [0.433]
 [0.433]
 [0.433]
 [0.433]
 [0.417]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16291109748378793, 0.6670317163929044, 0.1670684785483879, 0.0029887075749197964]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16291109748378793, 0.6670317163929044, 0.1670684785483879, 0.0029887075749197964]
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.558]
 [0.539]
 [0.538]
 [0.531]
 [0.533]
 [0.529]] [[3.136]
 [4.449]
 [3.668]
 [3.635]
 [3.344]
 [3.509]
 [3.738]] [[0.616]
 [0.558]
 [0.539]
 [0.538]
 [0.531]
 [0.533]
 [0.529]]
Printing some Q and Qe and total Qs values:  [[0.961]
 [0.961]
 [0.961]
 [0.961]
 [0.961]
 [0.961]
 [0.961]] [[2.33]
 [2.33]
 [2.33]
 [2.33]
 [2.33]
 [2.33]
 [2.33]] [[2.257]
 [2.257]
 [2.257]
 [2.257]
 [2.257]
 [2.257]
 [2.257]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16165540684946844, 0.6674432269972251, 0.16790264942155195, 0.002998716731754269]
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.591]
 [0.592]
 [0.581]
 [0.568]
 [0.594]
 [0.572]] [[4.294]
 [4.907]
 [4.294]
 [4.46 ]
 [4.53 ]
 [4.172]
 [4.405]] [[0.591]
 [0.591]
 [0.592]
 [0.581]
 [0.568]
 [0.594]
 [0.572]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.7261938
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16120412861896424, 0.6683029092937107, 0.16747398598921034, 0.003018976098114725]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16120412861896424, 0.6683029092937107, 0.16747398598921034, 0.003018976098114725]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16167498130973393, 0.667336831267218, 0.1679632658317896, 0.003024921591258496]
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.339]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]] [[-1.81 ]
 [ 1.183]
 [-1.815]
 [-1.815]
 [-1.815]
 [-1.815]
 [-1.815]] [[0.582]
 [0.339]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]]
first move QE:  2.133836055803861
Printing some Q and Qe and total Qs values:  [[0.788]
 [0.825]
 [0.787]
 [0.787]
 [0.787]
 [0.787]
 [0.787]] [[3.645]
 [4.444]
 [4.305]
 [4.305]
 [4.305]
 [4.305]
 [4.305]] [[0.966]
 [1.307]
 [1.184]
 [1.184]
 [1.184]
 [1.184]
 [1.184]]
Printing some Q and Qe and total Qs values:  [[0.639]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]] [[3.078]
 [2.985]
 [2.985]
 [2.985]
 [2.985]
 [2.985]
 [2.985]] [[0.639]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.97 ]
 [0.929]
 [0.92 ]
 [0.92 ]
 [0.92 ]
 [0.92 ]
 [0.92 ]] [[3.413]
 [3.396]
 [2.778]
 [2.778]
 [2.778]
 [2.778]
 [2.778]] [[1.883]
 [1.788]
 [1.359]
 [1.359]
 [1.359]
 [1.359]
 [1.359]]
Printing some Q and Qe and total Qs values:  [[0.969]
 [0.894]
 [0.969]
 [0.969]
 [0.969]
 [0.969]
 [0.969]] [[3.179]
 [3.878]
 [3.179]
 [3.179]
 [3.179]
 [3.179]
 [3.179]] [[1.934]
 [2.248]
 [1.934]
 [1.934]
 [1.934]
 [1.934]
 [1.934]]
using another actor
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.584]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]] [[1.582]
 [2.054]
 [1.582]
 [1.582]
 [1.582]
 [1.582]
 [1.582]] [[0.577]
 [0.584]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]]
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.358]
 [0.634]
 [0.473]
 [0.476]
 [0.527]
 [0.496]] [[-1.876]
 [ 1.219]
 [ 0.   ]
 [-2.726]
 [-2.608]
 [-2.378]
 [-2.759]] [[0.65 ]
 [0.358]
 [0.634]
 [0.473]
 [0.476]
 [0.527]
 [0.496]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1614494584161531, 0.6633524831774926, 0.1721225946532517, 0.003075463753102592]
siam score:  -0.7257938
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16191510509522372, 0.6623841809629346, 0.17261921549135106, 0.0030814984504905093]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.63 ]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]] [[-2.019]
 [-2.157]
 [-2.157]
 [-2.157]
 [-2.157]
 [-2.157]
 [-2.157]] [[0.63 ]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16273428028209794, 0.6628602081354349, 0.17131339676857785, 0.0030921148138893487]
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
siam score:  -0.7265358
line 256 mcts: sample exp_bonus 2.3475170160517327
Printing some Q and Qe and total Qs values:  [[0.741]
 [0.329]
 [0.521]
 [0.517]
 [0.487]
 [0.485]
 [0.746]] [[-2.44 ]
 [ 2.405]
 [-1.1  ]
 [-1.133]
 [-1.277]
 [-1.228]
 [-0.767]] [[0.741]
 [0.329]
 [0.521]
 [0.517]
 [0.487]
 [0.485]
 [0.746]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16273428028209794, 0.6628602081354349, 0.17131339676857785, 0.0030921148138893487]
Printing some Q and Qe and total Qs values:  [[0.54 ]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]] [[-1.297]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.54 ]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]]
rdn probs:  [0.16273428028209794, 0.6628602081354349, 0.17131339676857785, 0.0030921148138893487]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16449942347572455, 0.661402518267643, 0.1709830675037562, 0.003114990752876261]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16449942347572455, 0.661402518267643, 0.1709830675037562, 0.003114990752876261]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16497114012897499, 0.6604342659152784, 0.17147348983970642, 0.0031211041160401284]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1636476327137766, 0.660887035272794, 0.1723335073430027, 0.003131824670426676]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16411600846590055, 0.6599191213725919, 0.17282689516167066, 0.003137974999836737]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1623198871058879, 0.6613400742217398, 0.17319744458601546, 0.0031425940863569137]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1623198871058879, 0.6613400742217398, 0.17319744458601546, 0.0031425940863569137]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16314425013716288, 0.6618394570136319, 0.17186272977445327, 0.0031535630747518565]
siam score:  -0.7363179
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16350327952743404, 0.6633026996994613, 0.1700356804472317, 0.0031583403258729245]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16350327952743404, 0.6633026996994613, 0.1700356804472317, 0.0031583403258729245]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.466]
 [0.3  ]
 [0.372]
 [0.426]
 [0.391]
 [0.333]
 [0.363]] [[6.721]
 [6.214]
 [6.17 ]
 [5.178]
 [5.892]
 [6.094]
 [5.566]] [[1.142]
 [0.642]
 [0.771]
 [0.546]
 [0.715]
 [0.668]
 [0.552]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
1153 767
from probs:  [0.16350327952743404, 0.6633026996994613, 0.1700356804472317, 0.0031583403258729245]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1617001830490844, 0.6647354416591392, 0.1704013572947287, 0.003163017997047609]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1617001830490844, 0.6647354416591392, 0.1704013572947287, 0.003163017997047609]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1617001830490844, 0.6647354416591392, 0.1704013572947287, 0.003163017997047609]
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]] [[-0.648]
 [-0.156]
 [-0.156]
 [-0.156]
 [-0.156]
 [-0.156]
 [-0.156]] [[0.368]
 [0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]]
Printing some Q and Qe and total Qs values:  [[-0.065]
 [-0.07 ]
 [-0.064]
 [-0.061]
 [-0.061]
 [-0.061]
 [-0.055]] [[4.284]
 [3.913]
 [3.927]
 [3.849]
 [3.865]
 [4.162]
 [4.066]] [[-0.57 ]
 [-0.827]
 [-0.806]
 [-0.852]
 [-0.842]
 [-0.644]
 [-0.696]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.144]
 [0.341]
 [0.338]
 [0.395]
 [0.314]
 [0.316]] [[-0.858]
 [ 2.685]
 [-0.174]
 [-0.313]
 [-0.036]
 [-0.304]
 [-0.304]] [[0.571]
 [0.144]
 [0.341]
 [0.338]
 [0.395]
 [0.314]
 [0.316]]
1157 768
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16220881260671136, 0.6613596960780513, 0.17323226091817487, 0.003199230397062388]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16220881260671136, 0.6613596960780513, 0.17323226091817487, 0.003199230397062388]
Printing some Q and Qe and total Qs values:  [[0.978]
 [0.93 ]
 [0.847]
 [0.847]
 [0.847]
 [0.847]
 [0.847]] [[3.815]
 [3.832]
 [3.989]
 [3.989]
 [3.989]
 [3.989]
 [3.989]] [[0.931]
 [0.84 ]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16157175119856168, 0.6648170096380153, 0.17039086781445775, 0.0032203713489654313]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16157175119856168, 0.6648170096380153, 0.17039086781445775, 0.0032203713489654313]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16369410084518957, 0.6649223756473907, 0.16813375257378851, 0.0032497709336313783]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16369410084518957, 0.6649223756473907, 0.16813375257378851, 0.0032497709336313783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16369410084518957, 0.6649223756473907, 0.16813375257378851, 0.0032497709336313783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16369410084518957, 0.6649223756473907, 0.16813375257378851, 0.0032497709336313783]
Printing some Q and Qe and total Qs values:  [[0.273]
 [0.673]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]] [[3.087]
 [2.363]
 [1.435]
 [1.435]
 [1.435]
 [1.435]
 [1.435]] [[1.986]
 [2.193]
 [1.869]
 [1.869]
 [1.869]
 [1.869]
 [1.869]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16463228163089746, 0.6630074172751288, 0.1690975341276268, 0.0032627669663469147]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.979]
 [0.818]
 [0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.934]] [[3.17 ]
 [3.233]
 [3.203]
 [3.203]
 [3.203]
 [3.203]
 [3.203]] [[1.866]
 [1.586]
 [1.797]
 [1.797]
 [1.797]
 [1.797]
 [1.797]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1669859609882998, 0.6582032280828762, 0.17151543991174772, 0.0032953710170764393]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1669859609882998, 0.6582032280828762, 0.17151543991174772, 0.0032953710170764393]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1669859609882998, 0.6582032280828762, 0.17151543991174772, 0.0032953710170764393]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1669859609882998, 0.6582032280828762, 0.17151543991174772, 0.0032953710170764393]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16736544111722185, 0.6597057111249405, 0.1696282200394459, 0.003300627718391895]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16783975744108554, 0.6587440569261306, 0.17010898750647452, 0.003307198126309379]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.385]
 [0.424]
 [0.388]
 [0.39 ]
 [0.379]
 [0.389]
 [0.384]] [[4.308]
 [5.583]
 [4.34 ]
 [4.356]
 [4.228]
 [4.266]
 [4.061]] [[0.633]
 [1.497]
 [0.659]
 [0.672]
 [0.573]
 [0.616]
 [0.479]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16822074671338866, 0.6602460308403767, 0.16822074671338866, 0.0033124757328459303]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16822074671338866, 0.6602460308403767, 0.16822074671338866, 0.0033124757328459303]
Printing some Q and Qe and total Qs values:  [[0.353]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]] [[-2.258]
 [-1.078]
 [-1.078]
 [-1.078]
 [-1.078]
 [-1.078]
 [-1.078]] [[0.353]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]
 [0.26 ]]
siam score:  -0.722369
Printing some Q and Qe and total Qs values:  [[0.213]
 [0.206]
 [0.132]
 [0.206]
 [0.206]
 [0.144]
 [0.151]] [[3.551]
 [3.432]
 [3.494]
 [3.432]
 [3.432]
 [3.161]
 [3.263]] [[0.672]
 [0.586]
 [0.486]
 [0.586]
 [0.586]
 [0.299]
 [0.377]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.72321326
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.358]] [[1.057]
 [1.057]
 [1.057]
 [1.057]
 [1.057]
 [1.057]
 [1.057]] [[0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.358]]
Printing some Q and Qe and total Qs values:  [[0.473]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]] [[-0.162]
 [-1.52 ]
 [-1.52 ]
 [-1.52 ]
 [-1.52 ]
 [-1.52 ]
 [-1.52 ]] [[0.473]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16917518258068465, 0.6583239379015721, 0.16917518258068465, 0.003325696937058613]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16965313804902296, 0.6573614061461815, 0.16965313804902296, 0.0033323177557725756]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16965313804902296, 0.6573614061461815, 0.16965313804902296, 0.0033323177557725756]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16965313804902296, 0.6573614061461815, 0.16965313804902296, 0.0033323177557725756]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.173]
 [0.141]
 [0.22 ]
 [0.211]
 [0.172]
 [0.169]
 [0.159]] [[5.148]
 [5.119]
 [4.798]
 [5.043]
 [5.062]
 [5.152]
 [5.284]] [[-0.552]
 [-0.625]
 [-0.574]
 [-0.51 ]
 [-0.583]
 [-0.559]
 [-0.535]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16822939129325862, 0.6579055997884088, 0.17052067373234403, 0.003344335185988682]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16870403896134303, 0.6569431361709818, 0.17100182459911295, 0.0033510002685622074]
siam score:  -0.7275424
Printing some Q and Qe and total Qs values:  [[0.245]
 [0.157]
 [0.2  ]
 [0.193]
 [0.187]
 [0.188]
 [0.185]] [[-2.015]
 [ 0.479]
 [-1.848]
 [-1.915]
 [-1.87 ]
 [-2.063]
 [-1.853]] [[0.245]
 [0.157]
 [0.2  ]
 [0.193]
 [0.187]
 [0.188]
 [0.185]]
line 256 mcts: sample exp_bonus 2.9297233228008857
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16680069406293516, 0.6584504181671851, 0.17139247605064428, 0.0033564117192354825]
siam score:  -0.726535
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16765799086694183, 0.65901485187399, 0.16995854106053923, 0.0033686161985288475]
line 256 mcts: sample exp_bonus 2.691131400680837
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.288]
 [0.285]
 [0.269]
 [0.269]
 [0.269]
 [0.269]
 [0.269]] [[0.135]
 [0.422]
 [0.492]
 [0.492]
 [0.492]
 [0.492]
 [0.492]] [[0.288]
 [0.285]
 [0.269]
 [0.269]
 [0.269]
 [0.269]
 [0.269]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1690801011420615, 0.6561307557895549, 0.17140028170467453, 0.0033888613637090555]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1695551556249982, 0.655167326442266, 0.17188189369230383, 0.003395624240431707]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16857268682994045, 0.6547636753548293, 0.1732488189794736, 0.0034148188357566917]
Printing some Q and Qe and total Qs values:  [[0.554]
 [0.578]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]] [[4.965]
 [4.55 ]
 [5.856]
 [5.856]
 [5.856]
 [5.856]
 [5.856]] [[1.137]
 [0.962]
 [1.686]
 [1.686]
 [1.686]
 [1.686]
 [1.686]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17039325778797249, 0.6534162832036703, 0.17274936203800978, 0.0034410969703475747]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16931732757809273, 0.6555464700815126, 0.1716765818609443, 0.003459620479450306]
Printing some Q and Qe and total Qs values:  [[0.575]
 [0.5  ]
 [0.583]
 [0.576]
 [0.573]
 [0.579]
 [0.575]] [[2.696]
 [3.194]
 [2.595]
 [2.584]
 [2.515]
 [2.979]
 [2.808]] [[0.575]
 [0.5  ]
 [0.583]
 [0.576]
 [0.573]
 [0.579]
 [0.575]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16979181167141932, 0.6545839066479178, 0.17215771650029157, 0.003466565180371368]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17019371855572746, 0.6561401152704928, 0.17019371855572746, 0.003472447618052402]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17019371855572746, 0.6561401152704928, 0.17019371855572746, 0.003472447618052402]
Printing some Q and Qe and total Qs values:  [[0.918]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]] [[3.608]
 [3.599]
 [3.599]
 [3.599]
 [3.599]
 [3.599]
 [3.599]] [[1.326]
 [1.28 ]
 [1.28 ]
 [1.28 ]
 [1.28 ]
 [1.28 ]
 [1.28 ]]
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[4.281]
 [4.281]
 [4.281]
 [4.281]
 [4.281]
 [4.281]
 [4.281]] [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
Printing some Q and Qe and total Qs values:  [[1.028]
 [1.158]
 [1.055]
 [1.059]
 [0.943]
 [1.067]
 [1.101]] [[2.862]
 [2.835]
 [2.846]
 [2.606]
 [3.135]
 [3.012]
 [3.111]] [[2.036]
 [2.232]
 [2.067]
 [1.872]
 [2.122]
 [2.227]
 [2.367]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17059504524629845, 0.6576940773465869, 0.1682325558432821, 0.003478321563832364]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17059504524629845, 0.6576940773465869, 0.1682325558432821, 0.003478321563832364]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17059504524629845, 0.6576940773465869, 0.1682325558432821, 0.003478321563832364]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17059504524629845, 0.6576940773465869, 0.1682325558432821, 0.003478321563832364]
first move QE:  2.113939537481309
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1710746042417249, 0.6567346205628265, 0.16870543465280516, 0.0034853405426434167]
Printing some Q and Qe and total Qs values:  [[0.345]
 [0.354]
 [0.35 ]
 [0.35 ]
 [0.347]
 [0.347]
 [0.354]] [[2.535]
 [3.344]
 [2.807]
 [2.869]
 [2.623]
 [2.758]
 [2.966]] [[0.345]
 [0.354]
 [0.35 ]
 [0.35 ]
 [0.347]
 [0.347]
 [0.354]]
Printing some Q and Qe and total Qs values:  [[0.34 ]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]] [[6.228]
 [6.167]
 [6.167]
 [6.167]
 [6.167]
 [6.167]
 [6.167]] [[0.696]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17203539047560396, 0.6548123693306932, 0.16965283727649888, 0.0034994029172039274]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17203539047560396, 0.6548123693306932, 0.16965283727649888, 0.0034994029172039274]
from probs:  [0.17244298213211506, 0.6563704321524957, 0.16768121715636042, 0.003505368559028809]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17292651084630864, 0.6554097271610927, 0.1681513163526855, 0.0035124456399131783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17292651084630864, 0.6554097271610927, 0.1681513163526855, 0.0035124456399131783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17292651084630864, 0.6554097271610927, 0.1681513163526855, 0.0035124456399131783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17292651084630864, 0.6554097271610927, 0.1681513163526855, 0.0035124456399131783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17292651084630864, 0.6554097271610927, 0.1681513163526855, 0.0035124456399131783]
Printing some Q and Qe and total Qs values:  [[0.907]
 [0.885]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]] [[3.672]
 [3.667]
 [3.843]
 [3.843]
 [3.843]
 [3.843]
 [3.843]] [[2.121]
 [2.075]
 [2.126]
 [2.126]
 [2.126]
 [2.126]
 [2.126]]
Printing some Q and Qe and total Qs values:  [[0.893]
 [0.914]
 [0.893]
 [0.893]
 [0.893]
 [0.893]
 [0.893]] [[4.302]
 [4.314]
 [4.302]
 [4.302]
 [4.302]
 [4.302]
 [4.302]] [[1.609]
 [1.654]
 [1.609]
 [1.609]
 [1.609]
 [1.609]
 [1.609]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17292651084630864, 0.6554097271610927, 0.1681513163526855, 0.0035124456399131783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17292651084630864, 0.6554097271610927, 0.1681513163526855, 0.0035124456399131783]
siam score:  -0.73423827
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1709401830802423, 0.6569870880267074, 0.16855421779688584, 0.0035185110961643805]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1709401830802423, 0.6569870880267074, 0.16855421779688584, 0.0035185110961643805]
Printing some Q and Qe and total Qs values:  [[0.446]
 [0.44 ]
 [0.455]
 [0.442]
 [0.455]
 [0.455]
 [0.435]] [[7.01 ]
 [7.791]
 [7.205]
 [6.965]
 [7.205]
 [7.205]
 [6.875]] [[1.12 ]
 [1.369]
 [1.202]
 [1.096]
 [1.202]
 [1.202]
 [1.053]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1709401830802423, 0.6569870880267074, 0.16855421779688584, 0.0035185110961643805]
Printing some Q and Qe and total Qs values:  [[0.47 ]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.446]
 [0.445]] [[6.621]
 [6.543]
 [6.543]
 [6.543]
 [6.543]
 [6.347]
 [6.543]] [[1.091]
 [1.014]
 [1.014]
 [1.014]
 [1.014]
 [0.95 ]
 [1.014]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1709401830802423, 0.6569870880267074, 0.16855421779688584, 0.0035185110961643805]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1709401830802423, 0.6569870880267074, 0.16855421779688584, 0.0035185110961643805]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1709401830802423, 0.6569870880267074, 0.16855421779688584, 0.0035185110961643805]
Printing some Q and Qe and total Qs values:  [[1.099]
 [1.206]
 [1.099]
 [1.099]
 [1.099]
 [1.099]
 [1.099]] [[3.474]
 [4.008]
 [3.474]
 [3.474]
 [3.474]
 [3.474]
 [3.474]] [[3.322]
 [3.7  ]
 [3.322]
 [3.322]
 [3.322]
 [3.322]
 [3.322]]
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]] [[2.814]
 [2.814]
 [2.814]
 [2.814]
 [2.814]
 [2.814]
 [2.814]] [[0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16895656883727384, 0.6585622940590589, 0.16895656883727384, 0.0035245682663935488]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16895656883727384, 0.6585622940590589, 0.16895656883727384, 0.0035245682663935488]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16895656883727384, 0.6585622940590589, 0.16895656883727384, 0.0035245682663935488]
in main func line 156:  1184
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.166975662560781, 0.6601353496707107, 0.1693583706009399, 0.003530617167568401]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1683895565000803, 0.6572656738021206, 0.17079256158584455, 0.0035522081119544993]
siam score:  -0.7212922
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1683895565000803, 0.6572656738021206, 0.17079256158584455, 0.0035522081119544993]
Printing some Q and Qe and total Qs values:  [[-0.039]
 [-0.039]
 [-0.039]
 [-0.039]
 [-0.039]
 [-0.039]
 [-0.039]] [[7.322]
 [7.322]
 [7.322]
 [7.322]
 [7.322]
 [7.322]
 [7.322]] [[0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1683895565000803, 0.6572656738021206, 0.17079256158584455, 0.0035522081119544993]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1683895565000803, 0.6572656738021206, 0.17079256158584455, 0.0035522081119544993]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1683895565000803, 0.6572656738021206, 0.17079256158584455, 0.0035522081119544993]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16639785932904286, 0.6588430996933422, 0.17120068873927508, 0.003558352238339983]
siam score:  -0.7220448
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16733433427119979, 0.6569284495897747, 0.17216435642186267, 0.0035728597171628368]
using explorer policy with actor:  1
siam score:  -0.7283157
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16733433427119979, 0.6569284495897747, 0.17216435642186267, 0.0035728597171628368]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16733433427119979, 0.6569284495897747, 0.17216435642186267, 0.0035728597171628368]
using explorer policy with actor:  1
first move QE:  2.108068908797141
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16780343728915406, 0.6559693549023705, 0.1726470809432104, 0.0035801268652650947]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16780343728915406, 0.6559693549023705, 0.1726470809432104, 0.0035801268652650947]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16780343728915406, 0.6559693549023705, 0.1726470809432104, 0.0035801268652650947]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16827311876144177, 0.6550090775483518, 0.1731304007156661, 0.003587402974540379]
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.604]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]] [[2.553]
 [3.182]
 [2.553]
 [2.553]
 [2.553]
 [2.553]
 [2.553]] [[0.573]
 [0.604]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16626599206970724, 0.6565930350265744, 0.1735472938360551, 0.0035936790676632654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16626599206970724, 0.6565930350265744, 0.1735472938360551, 0.0035936790676632654]
from probs:  [0.16626599206970724, 0.6565930350265744, 0.1735472938360551, 0.0035936790676632654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16626599206970724, 0.6565930350265744, 0.1735472938360551, 0.0035936790676632654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1666721900775934, 0.6582043513065234, 0.1715233950516899, 0.0036000635641932665]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1666721900775934, 0.6582043513065234, 0.1715233950516899, 0.0036000635641932665]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1666721900775934, 0.6582043513065234, 0.1715233950516899, 0.0036000635641932665]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16714023239993211, 0.6572472052523853, 0.17200514223686705, 0.003607420110815479]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.594]
 [0.594]
 [0.641]
 [0.636]
 [0.626]
 [0.638]] [[3.031]
 [2.664]
 [2.664]
 [2.952]
 [3.009]
 [3.228]
 [2.896]] [[0.652]
 [0.594]
 [0.594]
 [0.641]
 [0.636]
 [0.626]
 [0.638]]
line 256 mcts: sample exp_bonus 3.11366796237381
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16714023239993211, 0.6572472052523853, 0.17200514223686705, 0.003607420110815479]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1680191683224893, 0.6579025833610396, 0.1704570133586138, 0.0036212349578573495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1680191683224893, 0.6579025833610396, 0.1704570133586138, 0.0036212349578573495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1680191683224893, 0.6579025833610396, 0.1704570133586138, 0.0036212349578573495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1680191683224893, 0.6579025833610396, 0.1704570133586138, 0.0036212349578573495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1680191683224893, 0.6579025833610396, 0.1704570133586138, 0.0036212349578573495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1684907103982276, 0.6569452050970328, 0.17093543799220245, 0.003628646512537215]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16896285493653423, 0.6559866036451123, 0.17141447388181336, 0.0036360675365401766]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.863]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]] [[4.242]
 [4.78 ]
 [4.78 ]
 [4.78 ]
 [4.78 ]
 [4.78 ]
 [4.78 ]] [[0.863]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16896285493653423, 0.6559866036451123, 0.17141447388181336, 0.0036360675365401766]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16943560309274563, 0.6550267766595825, 0.17189412219964614, 0.0036434980480254562]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16943560309274563, 0.6550267766595825, 0.17189412219964614, 0.0036434980480254562]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16943560309274563, 0.6550267766595825, 0.17189412219964614, 0.0036434980480254562]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.654]
 [0.684]
 [0.7  ]
 [0.664]
 [0.665]
 [0.658]] [[5.048]
 [4.785]
 [5.33 ]
 [5.787]
 [5.563]
 [5.256]
 [4.966]] [[1.761]
 [1.526]
 [1.93 ]
 [2.258]
 [2.06 ]
 [1.855]
 [1.651]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16943560309274563, 0.6550267766595825, 0.17189412219964614, 0.0036434980480254562]
using explorer policy with actor:  1
1200 821
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17032810201200677, 0.6556862699018693, 0.17032810201200677, 0.003657526074117228]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17080441931022858, 0.6547261486952536, 0.17080441931022858, 0.0036650126842892004]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17080441931022858, 0.6547261486952536, 0.17080441931022858, 0.0036650126842892004]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1671774637167734, 0.6570090518221119, 0.17212767327418096, 0.0036858111869335864]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1671774637167734, 0.6570090518221119, 0.17212767327418096, 0.0036858111869335864]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using another actor
from probs:  [0.16759271572108517, 0.6586482885217826, 0.17006646334539322, 0.0036925324117390635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16554011465041726, 0.6602758101652173, 0.17048486958208384, 0.003699205602281651]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16554011465041726, 0.6602758101652173, 0.17048486958208384, 0.003699205602281651]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16554011465041726, 0.6602758101652173, 0.17048486958208384, 0.003699205602281651]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.254]
 [0.693]
 [0.69 ]
 [0.649]
 [0.442]
 [0.138]] [[2.643]
 [2.858]
 [0.594]
 [0.414]
 [1.845]
 [2.42 ]
 [4.169]] [[1.212]
 [1.173]
 [0.603]
 [0.489]
 [1.277]
 [1.249]
 [1.753]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1664728789450907, 0.6583669270605512, 0.17144566460458172, 0.0037145293897763326]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1664728789450907, 0.6583669270605512, 0.17144566460458172, 0.0037145293897763326]
1205 828
from probs:  [0.1664728789450907, 0.6583669270605512, 0.17144566460458172, 0.0037145293897763326]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16777523429965546, 0.6607136064484862, 0.16777523429965546, 0.003735924952202851]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16777523429965546, 0.6607136064484862, 0.16777523429965546, 0.003735924952202851]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16777523429965546, 0.6607136064484862, 0.16777523429965546, 0.003735924952202851]
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.564]
 [0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.603]] [[4.181]
 [4.662]
 [4.523]
 [4.523]
 [4.523]
 [4.523]
 [4.523]] [[0.591]
 [0.564]
 [0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.603]]
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.402]
 [0.621]
 [0.562]
 [0.513]
 [0.519]
 [0.551]] [[2.63 ]
 [4.218]
 [2.501]
 [2.571]
 [2.755]
 [2.669]
 [2.536]] [[0.308]
 [1.202]
 [0.494]
 [0.423]
 [0.448]
 [0.402]
 [0.378]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16777523429965546, 0.6607136064484862, 0.16777523429965546, 0.003735924952202851]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16777523429965546, 0.6607136064484862, 0.16777523429965546, 0.003735924952202851]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.4418257435389554
siam score:  -0.72376204
Printing some Q and Qe and total Qs values:  [[0.436]
 [0.25 ]
 [0.417]
 [0.394]
 [0.349]
 [0.369]
 [0.609]] [[3.39 ]
 [3.503]
 [2.807]
 [2.918]
 [3.11 ]
 [3.047]
 [5.136]] [[ 0.19 ]
 [ 0.021]
 [-0.053]
 [-0.037]
 [-0.015]
 [-0.016]
 [ 1.049]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1682479244002072, 0.65976046072431, 0.1682479244002072, 0.0037436904752755707]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1682479244002072, 0.65976046072431, 0.1682479244002072, 0.0037436904752755707]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1682479244002072, 0.65976046072431, 0.1682479244002072, 0.0037436904752755707]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1687212686063278, 0.6588059960431143, 0.1687212686063278, 0.0037514667442299595]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1687212686063278, 0.6588059960431143, 0.1687212686063278, 0.0037514667442299595]
first move QE:  2.098337823154372
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16710849326215507, 0.6595060193949868, 0.1696192679423841, 0.0037662194004740644]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16842239476423826, 0.6618825147407831, 0.16590695958881094, 0.0037881309061677196]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16842239476423826, 0.6618825147407831, 0.16590695958881094, 0.0037881309061677196]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16842239476423826, 0.6618825147407831, 0.16590695958881094, 0.0037881309061677196]
Printing some Q and Qe and total Qs values:  [[0.555]
 [0.507]
 [0.527]
 [0.561]
 [0.521]
 [0.523]
 [0.561]] [[2.875]
 [2.766]
 [2.964]
 [2.858]
 [2.956]
 [2.875]
 [2.71 ]] [[0.555]
 [0.507]
 [0.527]
 [0.561]
 [0.521]
 [0.523]
 [0.561]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16842239476423826, 0.6618825147407831, 0.16590695958881094, 0.0037881309061677196]
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.449]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]] [[5.791]
 [5.604]
 [5.165]
 [5.165]
 [5.165]
 [5.165]
 [5.165]] [[1.439]
 [1.361]
 [1.264]
 [1.264]
 [1.264]
 [1.264]
 [1.264]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16889779314877104, 0.6609309323540135, 0.16637521552764808, 0.0037960589695673944]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16889779314877104, 0.6609309323540135, 0.16637521552764808, 0.0037960589695673944]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 4.621843329695333
siam score:  -0.72353506
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
first move QE:  2.093259576728577
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1691136252657773, 0.6604793183718456, 0.16656463324829496, 0.003842423114082232]
siam score:  -0.7226494
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.302]
 [0.249]
 [0.249]
 [0.249]
 [0.249]
 [0.249]
 [0.249]] [[-0.136]
 [ 0.674]
 [ 0.674]
 [ 0.674]
 [ 0.674]
 [ 0.674]
 [ 0.674]] [[0.302]
 [0.249]
 [0.249]
 [0.249]
 [0.249]
 [0.249]
 [0.249]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17006728622749903, 0.6585703093364511, 0.16750383484321688, 0.003858569592832938]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17006728622749903, 0.6585703093364511, 0.16750383484321688, 0.003858569592832938]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17006728622749903, 0.6585703093364511, 0.16750383484321688, 0.003858569592832938]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17006728622749903, 0.6585703093364511, 0.16750383484321688, 0.003858569592832938]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17006728622749903, 0.6585703093364511, 0.16750383484321688, 0.003858569592832938]
from probs:  [0.17054516513032758, 0.657613706120066, 0.16797446816651637, 0.003866660583090104]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16888032092791516, 0.6583571244057077, 0.16888032092791516, 0.003882233738461939]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.1693547929040677, 0.6574000234701499, 0.1693547929040677, 0.0038903907217147085]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16979142936330766, 0.6591023993536198, 0.1672082740352309, 0.003897897247841814]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16979142936330766, 0.6591023993536198, 0.1672082740352309, 0.003897897247841814]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16979142936330766, 0.6591023993536198, 0.1672082740352309, 0.003897897247841814]
Printing some Q and Qe and total Qs values:  [[-0.069]
 [-0.071]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.074]
 [-0.045]] [[4.927]
 [5.212]
 [5.062]
 [5.062]
 [5.062]
 [5.674]
 [5.395]] [[0.492]
 [0.677]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.979]
 [0.851]]
Printing some Q and Qe and total Qs values:  [[-0.074]
 [-0.079]
 [-0.076]
 [-0.071]
 [-0.073]
 [-0.072]
 [-0.075]] [[5.44 ]
 [5.207]
 [5.888]
 [6.415]
 [5.891]
 [5.661]
 [5.857]] [[0.602]
 [0.487]
 [0.808]
 [1.06 ]
 [0.813]
 [0.708]
 [0.795]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17122652177860168, 0.6562295047264073, 0.16862140455864896, 0.003922568936342057]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17122652177860168, 0.6562295047264073, 0.16862140455864896, 0.003922568936342057]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.17170632267303854, 0.6552689969590543, 0.16909386283510996, 0.003930817532797258]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17218684464454517, 0.6543070456759964, 0.16956703115366023, 0.003939078525798259]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17218684464454517, 0.6543070456759964, 0.16956703115366023, 0.003939078525798259]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.3046],
        [-0.3975],
        [-0.4464],
        [-0.3355],
        [-0.0000],
        [-0.4410],
        [-0.4092],
        [-0.3019],
        [-0.2799],
        [-0.3177]], dtype=torch.float64)
-0.0727797758985 -0.37739657858262154
-0.024259925299500003 -0.4217615155128905
-0.024259925299500003 -0.4706340589922887
-0.024259925299500003 -0.35979251546071767
-0.6939112949999998 -0.6939112949999998
-0.024259925299500003 -0.46525353402472663
-0.0727797758985 -0.4820075965579405
-0.0632698753995 -0.3651964787012768
-0.0727797758985 -0.35267280409674584
-0.024259925299500003 -0.3419469990143827
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[0.605]
 [1.258]
 [1.258]
 [1.258]
 [1.258]
 [1.258]
 [1.258]] [[0.581]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17218684464454517, 0.6543070456759964, 0.16956703115366023, 0.003939078525798259]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17218684464454517, 0.6543070456759964, 0.16956703115366023, 0.003939078525798259]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17218684464454517, 0.6543070456759964, 0.16956703115366023, 0.003939078525798259]
Printing some Q and Qe and total Qs values:  [[0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]] [[2.635]
 [2.635]
 [2.635]
 [2.635]
 [2.635]
 [2.635]
 [2.635]] [[0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17266808931986857, 0.6533436476206678, 0.1700409111161521, 0.003947351943311617]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17266808931986857, 0.6533436476206678, 0.1700409111161521, 0.003947351943311617]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17315005833065297, 0.6523787995266992, 0.17051550432925988, 0.003955637813388077]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17144292430716876, 0.6531423218501194, 0.17144292430716876, 0.00397182953554303]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1697282302380698, 0.6539078101594822, 0.17237584235456688, 0.0039881172478811585]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16800588703688887, 0.6546753023858872, 0.17331430874903087, 0.004004501828193074]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1658105383245721, 0.6564063560416987, 0.17377063682446509, 0.004012468809264147]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1658105383245721, 0.6564063560416987, 0.17377063682446509, 0.004012468809264147]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
from probs:  [0.16672117483438034, 0.657208342869326, 0.17204134692102255, 0.004029135375271031]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1671896903711858, 0.6562476965106897, 0.17252490292179645, 0.004037710196327858]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16765894949902482, 0.6552855254896625, 0.17300922638464605, 0.004046298626666665]
Printing some Q and Qe and total Qs values:  [[0.453]
 [0.408]
 [0.424]
 [0.419]
 [0.426]
 [0.419]
 [0.426]] [[-0.34 ]
 [ 2.002]
 [ 0.34 ]
 [ 0.279]
 [ 0.182]
 [ 0.322]
 [ 0.159]] [[0.453]
 [0.408]
 [0.424]
 [0.419]
 [0.426]
 [0.419]
 [0.426]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16765894949902482, 0.6552855254896625, 0.17300922638464605, 0.004046298626666665]
line 256 mcts: sample exp_bonus 1.966826434394964
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16765894949902482, 0.6552855254896625, 0.17300922638464605, 0.004046298626666665]
line 256 mcts: sample exp_bonus 2.0799905520606226
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.702]
 [0.739]
 [0.739]
 [0.739]
 [0.739]
 [0.739]] [[1.448]
 [2.686]
 [1.448]
 [1.448]
 [1.448]
 [1.448]
 [1.448]] [[1.718]
 [2.103]
 [1.718]
 [1.718]
 [1.718]
 [1.718]
 [1.718]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16858167082098852, 0.6560915048147595, 0.17126363799406444, 0.0040631863701876296]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16903414626134278, 0.6578602398536169, 0.16903414626134278, 0.0040714676236976045]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.4088],
        [-0.3102],
        [-0.3335],
        [-0.2474],
        [-0.4314],
        [-0.0000],
        [-0.2966],
        [-0.0000],
        [-0.0000],
        [-0.2960]], dtype=torch.float64)
-0.0727797758985 -0.48154374658433025
-0.024259925299500003 -0.33444798265761916
-0.0439609252995 -0.3774887229257486
-0.0727797758985 -0.32016484764920444
-0.024259925299500003 -0.45566751410668227
-0.799316815968 -0.799316815968
-0.0530787758985 -0.349693429814206
-0.6618133582334997 -0.6618133582334997
-0.7645274999999999 -0.7645274999999999
-0.0727797758985 -0.36881144408878375
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1677482712038195, 0.6577104127379255, 0.1704440443305268, 0.004097271727728072]
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.492]
 [0.473]
 [0.485]
 [0.471]
 [0.463]
 [0.463]] [[0.836]
 [1.84 ]
 [0.455]
 [0.823]
 [0.424]
 [0.375]
 [0.376]] [[0.462]
 [0.492]
 [0.473]
 [0.485]
 [0.471]
 [0.463]
 [0.463]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[-0.006]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.017]
 [-0.018]] [[4.139]
 [3.861]
 [3.861]
 [3.861]
 [3.861]
 [4.173]
 [3.969]] [[-0.278]
 [-0.507]
 [-0.507]
 [-0.507]
 [-0.507]
 [-0.277]
 [-0.415]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1677482712038195, 0.6577104127379255, 0.1704440443305268, 0.004097271727728072]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1677482712038195, 0.6577104127379255, 0.1704440443305268, 0.004097271727728072]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1677482712038195, 0.6577104127379255, 0.1704440443305268, 0.004097271727728072]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16691521263955814, 0.6566011947018849, 0.17235141208386504, 0.004132180574691729]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.44609041781740644, 0.08382694702531052, 0.46067355218791106, 0.009409082969372028]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4527040865858937, 0.08505773388691344, 0.4527040865858937, 0.009534092941299224]
siam score:  -0.73173445
Printing some Q and Qe and total Qs values:  [[0.175]
 [0.019]
 [0.127]
 [0.134]
 [0.086]
 [0.085]
 [0.075]] [[-1.529]
 [ 1.509]
 [-0.853]
 [-0.779]
 [-0.779]
 [-0.881]
 [-0.96 ]] [[0.175]
 [0.019]
 [0.127]
 [0.134]
 [0.086]
 [0.085]
 [0.075]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45605521081723843, 0.08568136954511152, 0.4486659845543795, 0.009597435083270578]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45605521081723843, 0.08568136954511152, 0.4486659845543795, 0.009597435083270578]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45605521081723843, 0.08568136954511152, 0.4486659845543795, 0.009597435083270578]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45605521081723843, 0.08568136954511152, 0.4486659845543795, 0.009597435083270578]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
line 256 mcts: sample exp_bonus 4.599916092932498
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4520119741536617, 0.08631432759959418, 0.4520119741536617, 0.009661724093082467]
line 256 mcts: sample exp_bonus 3.136164967669703
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45130308886846054, 0.08760137396794646, 0.45130308886846054, 0.009792448295132506]
siam score:  -0.71902573
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45130308886846054, 0.08760137396794646, 0.45130308886846054, 0.009792448295132506]
using explorer policy with actor:  1
using explorer policy with actor:  0
UNIT TEST: sample policy line 217 mcts : [0.163 0.082 0.347 0.02  0.02  0.347 0.02 ]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45130308886846054, 0.08760137396794646, 0.45130308886846054, 0.009792448295132506]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45130308886846054, 0.08760137396794646, 0.45130308886846054, 0.009792448295132506]
from probs:  [0.45130308886846054, 0.08760137396794646, 0.45130308886846054, 0.009792448295132506]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45057681353437884, 0.08891999356785586, 0.45057681353437884, 0.009926379363386393]
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.438]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]] [[1.569]
 [1.805]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.45 ]] [[0.426]
 [0.438]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]]
siam score:  -0.71661085
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
1245 870
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4532881580150459, 0.09095870658397168, 0.4456196856951484, 0.010133449705834047]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47418532230301474, 0.096738519275235, 0.4183556580698457, 0.010720500351904649]
using explorer policy with actor:  1
using explorer policy with actor:  1
first move QE:  2.0628984878007097
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4779177568368079, 0.09749371940551262, 0.41379131837257155, 0.010797205385107943]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4779177568368079, 0.09749371940551262, 0.41379131837257155, 0.010797205385107943]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 7.402485456862473
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4779177568368079, 0.09749371940551262, 0.41379131837257155, 0.010797205385107943]
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.445]
 [0.473]
 [0.478]
 [0.488]
 [0.494]
 [0.487]] [[5.626]
 [5.698]
 [5.958]
 [5.97 ]
 [5.943]
 [5.827]
 [5.871]] [[0.765]
 [0.454]
 [0.596]
 [0.609]
 [0.622]
 [0.594]
 [0.594]]
siam score:  -0.71756315
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4779177568368079, 0.09749371940551262, 0.41379131837257155, 0.010797205385107943]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 4.886574516470866
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48168794923263747, 0.09825655925246099, 0.4091808051370831, 0.010874686377818344]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48168794923263747, 0.09825655925246099, 0.4091808051370831, 0.010874686377818344]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48168794923263747, 0.09825655925246099, 0.4091808051370831, 0.010874686377818344]
using explorer policy with actor:  1
first move QE:  2.060967509390049
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4773877504045513, 0.09906816451824743, 0.41258696464466793, 0.010957120432533395]
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.385]
 [0.402]
 [0.395]
 [0.389]
 [0.39 ]
 [0.395]] [[6.693]
 [7.087]
 [7.229]
 [7.072]
 [7.145]
 [7.209]
 [7.123]] [[0.418]
 [0.385]
 [0.402]
 [0.395]
 [0.389]
 [0.39 ]
 [0.395]]
first move QE:  2.0598810658266404
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47244543288105667, 0.10152836716527178, 0.4148191988363223, 0.011207001117349237]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47244543288105667, 0.10152836716527178, 0.4148191988363223, 0.011207001117349237]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47244543288105667, 0.10152836716527178, 0.4148191988363223, 0.011207001117349237]
line 256 mcts: sample exp_bonus 5.046969919811213
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46799782896130626, 0.10238074348539195, 0.418327851300018, 0.011293576253283704]
Printing some Q and Qe and total Qs values:  [[0.371]
 [0.354]
 [0.367]
 [0.373]
 [0.363]
 [0.36 ]
 [0.364]] [[4.018]
 [4.625]
 [5.011]
 [4.979]
 [5.016]
 [5.126]
 [5.416]] [[0.371]
 [0.354]
 [0.367]
 [0.373]
 [0.363]
 [0.36 ]
 [0.364]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46799782896130626, 0.10238074348539195, 0.418327851300018, 0.011293576253283704]
Printing some Q and Qe and total Qs values:  [[0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]] [[2.056]
 [2.056]
 [2.056]
 [2.056]
 [2.056]
 [2.056]
 [2.056]] [[0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46733224982456717, 0.10408985306679268, 0.41711072805268934, 0.011467169055950723]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.499]
 [0.499]
 [0.499]
 [0.499]
 [0.499]
 [0.499]
 [0.499]] [[7.463]
 [7.463]
 [7.463]
 [7.463]
 [7.463]
 [7.463]
 [7.463]] [[1.3]
 [1.3]
 [1.3]
 [1.3]
 [1.3]
 [1.3]
 [1.3]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47120629137483483, 0.1049462947918764, 0.4122932567216886, 0.011554157111600351]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]] [[5.029]
 [5.029]
 [5.029]
 [5.029]
 [5.029]
 [5.029]
 [5.029]] [[1.242]
 [1.242]
 [1.242]
 [1.242]
 [1.242]
 [1.242]
 [1.242]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47120629137483483, 0.1049462947918764, 0.4122932567216886, 0.011554157111600351]
first move QE:  2.057647919482722
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47120629137483483, 0.1049462947918764, 0.4122932567216886, 0.011554157111600351]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47120629137483483, 0.1049462947918764, 0.4122932567216886, 0.011554157111600351]
Printing some Q and Qe and total Qs values:  [[0.521]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]] [[3.979]
 [4.068]
 [4.068]
 [4.068]
 [4.068]
 [4.068]
 [4.068]] [[1.388]
 [1.459]
 [1.459]
 [1.459]
 [1.459]
 [1.459]
 [1.459]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4666482108622987, 0.1058474143035774, 0.4158586917821881, 0.01164568305193584]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]] [[7.764]
 [7.764]
 [7.764]
 [7.764]
 [7.764]
 [7.764]
 [7.764]] [[0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.829]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4705609083520554, 0.10672844054517878, 0.41097548296680303, 0.011735168135962749]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4705609083520554, 0.10672844054517878, 0.41097548296680303, 0.011735168135962749]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4705609083520554, 0.10672844054517878, 0.41097548296680303, 0.011735168135962749]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4745175628684588, 0.10761936463706952, 0.4060374139582691, 0.011825658536202646]
UNIT TEST: sample policy line 217 mcts : [0.551 0.163 0.204 0.02  0.02  0.02  0.02 ]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.393]
 [0.179]
 [0.221]
 [0.418]
 [0.418]
 [0.215]
 [0.22 ]] [[-4.441]
 [-0.117]
 [-3.657]
 [ 0.   ]
 [ 0.   ]
 [-3.771]
 [-3.636]] [[0.393]
 [0.179]
 [0.221]
 [0.418]
 [0.418]
 [0.215]
 [0.22 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46522150774983395, 0.10951637357479192, 0.4132437825591221, 0.01201833611625209]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46048913314168927, 0.11048209040991626, 0.4169123532967548, 0.012116423151639598]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46048913314168927, 0.11048209040991626, 0.4169123532967548, 0.012116423151639598]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46048913314168927, 0.11048209040991626, 0.4169123532967548, 0.012116423151639598]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46048913314168927, 0.11048209040991626, 0.4169123532967548, 0.012116423151639598]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46447710072020654, 0.11143232643946903, 0.41187763502551733, 0.01221293781480709]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46447710072020654, 0.11143232643946903, 0.41187763502551733, 0.01221293781480709]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46447710072020654, 0.11143232643946903, 0.41187763502551733, 0.01221293781480709]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4685122213688721, 0.11239379790293044, 0.4067833870767821, 0.012310593651415217]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4685122213688721, 0.11239379790293044, 0.4067833870767821, 0.012310593651415217]
Printing some Q and Qe and total Qs values:  [[0.285]
 [0.177]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]] [[3.161]
 [2.913]
 [3.206]
 [3.206]
 [3.206]
 [3.206]
 [3.206]] [[0.65 ]
 [0.188]
 [0.745]
 [0.745]
 [0.745]
 [0.745]
 [0.745]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4685122213688721, 0.11239379790293044, 0.4067833870767821, 0.012310593651415217]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4685122213688721, 0.11239379790293044, 0.4067833870767821, 0.012310593651415217]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4685122213688721, 0.11239379790293044, 0.4067833870767821, 0.012310593651415217]
Printing some Q and Qe and total Qs values:  [[1.016]
 [1.016]
 [1.016]
 [1.016]
 [1.016]
 [1.016]
 [1.016]] [[5.119]
 [5.119]
 [5.119]
 [5.119]
 [5.119]
 [5.119]
 [5.119]] [[2.717]
 [2.717]
 [2.717]
 [2.717]
 [2.717]
 [2.717]
 [2.717]]
line 256 mcts: sample exp_bonus 1.9731089222354803
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48514136567699645, 0.11635612000086637, 0.3857894709942732, 0.012713043327863932]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48032399536694653, 0.11744180914755002, 0.3894108796368783, 0.012823315848624992]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48032399536694653, 0.11744180914755002, 0.3894108796368783, 0.012823315848624992]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48032399536694653, 0.11744180914755002, 0.3894108796368783, 0.012823315848624992]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48032399536694653, 0.11744180914755002, 0.3894108796368783, 0.012823315848624992]
siam score:  -0.7549586
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48032399536694653, 0.11744180914755002, 0.3894108796368783, 0.012823315848624992]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48032399536694653, 0.11744180914755002, 0.3894108796368783, 0.012823315848624992]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4797212867836609, 0.11960183223146277, 0.38763417343366996, 0.01304270755120647]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.042]
 [-0.053]
 [-0.019]
 [-0.053]
 [-0.019]
 [-0.019]
 [-0.019]] [[5.935]
 [4.99 ]
 [6.267]
 [5.3  ]
 [6.267]
 [6.267]
 [6.267]] [[-0.35 ]
 [-0.687]
 [-0.192]
 [-0.585]
 [-0.192]
 [-0.192]
 [-0.192]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.48405355534127786, 0.1206751665214547, 0.38211955293755795, 0.013151725199709502]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47910003607892826, 0.12183088008685501, 0.38579997379325365, 0.013269110040963318]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47910003607892826, 0.12183088008685501, 0.38579997379325365, 0.013269110040963318]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47910003607892826, 0.12183088008685501, 0.38579997379325365, 0.013269110040963318]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47910003607892826, 0.12183088008685501, 0.38579997379325365, 0.013269110040963318]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47910003607892826, 0.12183088008685501, 0.38579997379325365, 0.013269110040963318]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4740784005152666, 0.12300248597633438, 0.38953100445637795, 0.013388109052021042]
line 256 mcts: sample exp_bonus 5.9949808837657805
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4740784005152666, 0.12300248597633438, 0.38953100445637795, 0.013388109052021042]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4740784005152666, 0.12300248597633438, 0.38953100445637795, 0.013388109052021042]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4689872339128668, 0.12419031426456367, 0.3933136960642841, 0.01350875575828536]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4689872339128668, 0.12419031426456367, 0.3933136960642841, 0.01350875575828536]
Printing some Q and Qe and total Qs values:  [[0.445]
 [0.506]
 [0.493]
 [0.419]
 [0.431]
 [0.508]
 [0.432]] [[2.049]
 [2.515]
 [2.157]
 [1.751]
 [1.665]
 [2.176]
 [1.557]] [[0.445]
 [0.506]
 [0.493]
 [0.419]
 [0.431]
 [0.508]
 [0.432]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4689872339128668, 0.12419031426456367, 0.3933136960642841, 0.01350875575828536]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4689872339128668, 0.12419031426456367, 0.3933136960642841, 0.01350875575828536]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.496]
 [0.568]
 [0.568]
 [0.568]
 [0.568]
 [0.568]] [[-0.227]
 [ 1.359]
 [ 0.41 ]
 [ 0.41 ]
 [ 0.41 ]
 [ 0.41 ]
 [ 0.41 ]] [[0.642]
 [0.496]
 [0.568]
 [0.568]
 [0.568]
 [0.568]
 [0.568]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4689872339128668, 0.12419031426456367, 0.3933136960642841, 0.01350875575828536]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4689872339128668, 0.12419031426456367, 0.3933136960642841, 0.01350875575828536]
Printing some Q and Qe and total Qs values:  [[0.479]
 [0.482]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]] [[4.702]
 [4.607]
 [4.975]
 [4.975]
 [4.975]
 [4.975]
 [4.975]] [[0.479]
 [0.482]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.47336360851178083, 0.12534235382689973, 0.38766827022713823, 0.01362576743418114]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46819589592085326, 0.12656948677539345, 0.3914842110224835, 0.01375040628126984]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46819589592085326, 0.12656948677539345, 0.3914842110224835, 0.01375040628126984]
siam score:  -0.752193
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46819589592085326, 0.12656948677539345, 0.3914842110224835, 0.01375040628126984]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46819589592085326, 0.12656948677539345, 0.3914842110224835, 0.01375040628126984]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.069]
 [0.147]
 [0.147]
 [0.147]
 [0.09 ]
 [0.147]
 [0.147]] [[7.036]
 [5.533]
 [5.533]
 [5.533]
 [4.925]
 [5.533]
 [5.533]] [[0.692]
 [0.345]
 [0.345]
 [0.345]
 [0.027]
 [0.345]
 [0.345]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46819589592085326, 0.12656948677539345, 0.3914842110224835, 0.01375040628126984]
Printing some Q and Qe and total Qs values:  [[ 0.041]
 [-0.01 ]
 [ 0.025]
 [-0.008]
 [-0.014]
 [ 0.04 ]
 [ 0.096]] [[5.242]
 [5.447]
 [4.028]
 [4.979]
 [4.797]
 [4.324]
 [3.562]] [[ 0.113]
 [ 0.081]
 [-0.324]
 [-0.072]
 [-0.145]
 [-0.195]
 [-0.338]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46819589592085326, 0.12656948677539345, 0.3914842110224835, 0.01375040628126984]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46737857623241924, 0.1290285434614647, 0.3895927097343071, 0.014000170571808962]
Starting evaluation
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46737857623241924, 0.1290285434614647, 0.3895927097343071, 0.014000170571808962]
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.674]
 [0.607]
 [0.603]
 [0.559]
 [0.416]
 [0.551]] [[2.143]
 [2.221]
 [1.841]
 [1.973]
 [2.054]
 [2.419]
 [1.796]] [[0.583]
 [0.674]
 [0.607]
 [0.603]
 [0.559]
 [0.416]
 [0.551]]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 1.7131392414141748
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.593]] [[0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.057]] [[0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.593]]
first move QE:  2.037922137959607
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]] [[-4.194]
 [-4.008]
 [-4.008]
 [-4.008]
 [-4.008]
 [-4.008]
 [-4.008]] [[0.667]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]]
line 256 mcts: sample exp_bonus 0.22902416610908746
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46737857623241924, 0.1290285434614647, 0.3895927097343071, 0.014000170571808962]
Printing some Q and Qe and total Qs values:  [[0.702]
 [0.649]
 [0.555]
 [0.56 ]
 [0.576]
 [0.551]
 [0.554]] [[-5.347]
 [ 0.   ]
 [-3.946]
 [-4.085]
 [-4.034]
 [-3.923]
 [-3.948]] [[0.702]
 [0.649]
 [0.555]
 [0.56 ]
 [0.576]
 [0.551]
 [0.554]]
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]] [[5.602]
 [5.602]
 [5.602]
 [5.602]
 [5.602]
 [5.602]
 [5.602]] [[0.903]
 [0.903]
 [0.903]
 [0.903]
 [0.903]
 [0.903]
 [0.903]]
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]] [[0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]] [[0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]]
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.644]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]] [[2.642]
 [3.966]
 [2.642]
 [2.642]
 [2.642]
 [2.642]
 [2.642]] [[0.626]
 [0.644]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.3497626331732
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.46737857623241924, 0.1290285434614647, 0.3895927097343071, 0.014000170571808962]
Printing some Q and Qe and total Qs values:  [[0.149]
 [0.079]
 [0.097]
 [0.116]
 [0.105]
 [0.105]
 [0.104]] [[6.123]
 [6.961]
 [6.149]
 [6.322]
 [6.351]
 [6.045]
 [5.9  ]] [[0.347]
 [0.486]
 [0.251]
 [0.346]
 [0.334]
 [0.231]
 [0.181]]
using explorer policy with actor:  0
siam score:  -0.76645505
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.7643288
Printing some Q and Qe and total Qs values:  [[0.918]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]] [[2.709]
 [2.824]
 [2.824]
 [2.824]
 [2.824]
 [2.824]
 [2.824]] [[0.918]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]]
Printing some Q and Qe and total Qs values:  [[0.975]
 [0.975]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.975]] [[1.986]
 [1.976]
 [3.346]
 [3.346]
 [3.346]
 [3.346]
 [2.037]] [[0.975]
 [0.975]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.975]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.561]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]] [[0.554]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]] [[0.561]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.086]
 [0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.084]] [[-3.033]
 [-3.062]
 [-3.062]
 [-3.062]
 [-3.062]
 [-3.062]
 [-3.062]] [[0.086]
 [0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.084]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45916782687459273, 0.13835476540185815, 0.38752998074258654, 0.014947426980962407]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.45916782687459273, 0.13835476540185815, 0.38752998074258654, 0.014947426980962407]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.531]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.528]] [[0.301]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]] [[0.531]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.528]]
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]] [[-3.239]
 [-3.239]
 [-3.239]
 [-3.239]
 [-3.239]
 [-3.239]
 [-3.239]] [[0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.645]
 [0.569]
 [0.569]
 [0.569]
 [0.569]
 [0.569]
 [0.569]] [[0.656]
 [0.357]
 [0.357]
 [0.357]
 [0.357]
 [0.357]
 [0.357]] [[0.645]
 [0.569]
 [0.569]
 [0.569]
 [0.569]
 [0.569]
 [0.569]]
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]] [[0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]] [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]]
Printing some Q and Qe and total Qs values:  [[0.698]
 [0.423]
 [0.604]
 [0.575]
 [0.578]
 [0.566]
 [0.608]] [[-3.908]
 [ 2.221]
 [-3.806]
 [-3.848]
 [-3.58 ]
 [-3.478]
 [-3.794]] [[0.698]
 [0.423]
 [0.604]
 [0.575]
 [0.578]
 [0.566]
 [0.608]]
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.719]
 [0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]] [[3.949]
 [4.185]
 [3.949]
 [3.949]
 [3.949]
 [3.949]
 [3.949]] [[1.767]
 [1.717]
 [1.767]
 [1.767]
 [1.767]
 [1.767]
 [1.767]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
line 256 mcts: sample exp_bonus 4.8700670220492315
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4581364965637255, 0.14122925162450242, 0.385394865716516, 0.015239386095256078]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4581364965637255, 0.14122925162450242, 0.385394865716516, 0.015239386095256078]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4523611288802532, 0.14273219351781902, 0.38951463898026517, 0.015392038621662647]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4523611288802532, 0.14273219351781902, 0.38951463898026517, 0.015392038621662647]
from probs:  [0.4523611288802532, 0.14273219351781902, 0.38951463898026517, 0.015392038621662647]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.898]
 [1.219]
 [0.893]
 [0.89 ]
 [0.893]
 [0.891]
 [0.893]] [[4.814]
 [3.816]
 [5.163]
 [4.451]
 [5.163]
 [4.42 ]
 [5.163]] [[2.905]
 [3.197]
 [3.005]
 [2.775]
 [3.005]
 [2.767]
 [3.005]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4511888501479581, 0.14576934698762975, 0.38734128315488264, 0.015700519709529567]
siam score:  -0.75856316
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.244]
 [0.23 ]
 [0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.224]] [[-0.476]
 [ 0.581]
 [ 0.095]
 [ 0.095]
 [ 0.095]
 [ 0.095]
 [ 0.095]] [[0.244]
 [0.23 ]
 [0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.224]]
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.322]
 [0.501]
 [0.513]
 [0.505]
 [0.493]
 [0.545]] [[0.353]
 [2.361]
 [0.81 ]
 [0.444]
 [0.666]
 [0.723]
 [0.684]] [[0.586]
 [0.322]
 [0.501]
 [0.513]
 [0.505]
 [0.493]
 [0.545]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4511888501479581, 0.14576934698762975, 0.38734128315488264, 0.015700519709529567]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn probs:  [0.4511888501479581, 0.14576934698762975, 0.38734128315488264, 0.015700519709529567]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4511888501479581, 0.14576934698762975, 0.38734128315488264, 0.015700519709529567]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4391395572760213, 0.1489652840217232, 0.39587003039364427, 0.016025128308611244]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4329640944073322, 0.1506032548715048, 0.4002411551101889, 0.01619149561097424]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.114]
 [0.149]
 [0.187]
 [0.462]
 [0.462]
 [0.462]] [[4.06 ]
 [3.446]
 [3.512]
 [3.538]
 [4.06 ]
 [4.06 ]
 [4.06 ]] [[ 0.626]
 [-0.275]
 [-0.183]
 [-0.1  ]
 [ 0.626]
 [ 0.626]
 [ 0.626]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.715]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]] [[3.689]
 [4.163]
 [3.689]
 [3.689]
 [3.689]
 [3.689]
 [3.689]] [[0.944]
 [1.053]
 [0.944]
 [0.944]
 [0.944]
 [0.944]
 [0.944]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4202987374676995, 0.15396259584890426, 0.40920596567416834, 0.01653270100922786]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4202987374676995, 0.15396259584890426, 0.40920596567416834, 0.01653270100922786]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4202987374676995, 0.15396259584890426, 0.40920596567416834, 0.01653270100922786]
Printing some Q and Qe and total Qs values:  [[0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]] [[4.421]
 [4.421]
 [4.421]
 [4.421]
 [4.421]
 [4.421]
 [4.421]] [[1.191]
 [1.191]
 [1.191]
 [1.191]
 [1.191]
 [1.191]
 [1.191]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4202987374676995, 0.15396259584890426, 0.40920596567416834, 0.01653270100922786]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
first move QE:  2.032354645406158
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4071960433082165, 0.15743793551868845, 0.4184803328773507, 0.016885688295744213]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.4071960433082165, 0.15743793551868845, 0.4184803328773507, 0.016885688295744213]
using explorer policy with actor:  1
start point for exploration sampling:  10624
line 256 mcts: sample exp_bonus 7.883160937177784
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.40510404852095183, 0.16105504395621387, 0.4165878326077337, 0.01725307491510066]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.40510404852095183, 0.16105504395621387, 0.4165878326077337, 0.01725307491510066]
Printing some Q and Qe and total Qs values:  [[0.276]
 [0.078]
 [0.078]
 [0.078]
 [0.078]
 [0.078]
 [0.078]] [[5.452]
 [3.881]
 [3.881]
 [3.881]
 [3.881]
 [3.881]
 [3.881]] [[1.066]
 [0.13 ]
 [0.13 ]
 [0.13 ]
 [0.13 ]
 [0.13 ]
 [0.13 ]]
line 256 mcts: sample exp_bonus 5.503158517048178
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.39823696548928167, 0.16291198593750195, 0.42140936564466247, 0.017441682928553855]
Printing some Q and Qe and total Qs values:  [[-0.065]
 [-0.079]
 [-0.062]
 [-0.062]
 [-0.062]
 [-0.062]
 [-0.044]] [[3.629]
 [3.315]
 [3.886]
 [3.886]
 [3.886]
 [3.886]
 [2.406]] [[ 0.328]
 [-0.015]
 [ 0.59 ]
 [ 0.59 ]
 [ 0.59 ]
 [ 0.59 ]
 [-0.854]]
line 256 mcts: sample exp_bonus 4.705101891803398
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3959060966275883, 0.16675828482277694, 0.41950327032339846, 0.017832348226236312]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38875788564238745, 0.16872949115926364, 0.4244800612255457, 0.01803256197280327]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38147660781278847, 0.17073739230056253, 0.42954949710724716, 0.018236502779401902]
siam score:  -0.75534284
Printing some Q and Qe and total Qs values:  [[0.692]
 [0.728]
 [0.798]
 [0.728]
 [0.789]
 [0.746]
 [0.792]] [[5.116]
 [5.231]
 [3.568]
 [5.231]
 [3.488]
 [3.88 ]
 [3.162]] [[1.85 ]
 [1.992]
 [0.835]
 [1.992]
 [0.761]
 [0.993]
 [0.518]]
Printing some Q and Qe and total Qs values:  [[ 0.261]
 [-0.009]
 [ 0.114]
 [ 0.103]
 [ 0.146]
 [ 0.24 ]
 [ 0.189]] [[4.27 ]
 [4.577]
 [3.727]
 [3.639]
 [3.483]
 [3.031]
 [3.01 ]] [[ 0.061]
 [-0.375]
 [-0.413]
 [-0.466]
 [-0.43 ]
 [-0.393]
 [-0.502]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.36649970714034913, 0.17486745527262215, 0.4399768478336415, 0.018655989753387184]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.36649970714034913, 0.17486745527262215, 0.4399768478336415, 0.018655989753387184]
siam score:  -0.7597438
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3711106848296875, 0.1770609141812094, 0.4329496234849362, 0.018878777504167076]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3711106848296875, 0.1770609141812094, 0.4329496234849362, 0.018878777504167076]
first move QE:  2.031984235544011
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3711106848296875, 0.1770609141812094, 0.4329496234849362, 0.018878777504167076]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3711106848296875, 0.1770609141812094, 0.4329496234849362, 0.018878777504167076]
Printing some Q and Qe and total Qs values:  [[0.166]
 [0.195]
 [0.195]
 [0.195]
 [0.195]
 [0.195]
 [0.195]] [[4.512]
 [4.071]
 [4.071]
 [4.071]
 [4.071]
 [4.071]
 [4.071]] [[0.949]
 [0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3711106848296875, 0.1770609141812094, 0.4329496234849362, 0.018878777504167076]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3711106848296875, 0.1770609141812094, 0.4329496234849362, 0.018878777504167076]
siam score:  -0.75225294
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3633657972943464, 0.17923953708379067, 0.43829460724739394, 0.019100058374468883]
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Printing some Q and Qe and total Qs values:  [[0.727]
 [0.707]
 [0.69 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]] [[2.659]
 [2.357]
 [1.342]
 [2.407]
 [2.407]
 [2.407]
 [2.407]] [[1.981]
 [1.638]
 [0.59 ]
 [1.897]
 [1.897]
 [1.897]
 [1.897]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38260484172122006, 0.1887028952294609, 0.4086310194582755, 0.020061243591043627]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38260484172122006, 0.1887028952294609, 0.4086310194582755, 0.020061243591043627]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.36629526570316423, 0.19368561688872432, 0.4194517830273641, 0.02056733438074727]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.36629526570316423, 0.19368561688872432, 0.4194517830273641, 0.02056733438074727]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.37127442471829114, 0.19631204484967998, 0.4115794320030854, 0.02083409842894337]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38689010254615036, 0.20454906896394282, 0.38689010254615036, 0.02167072594375659]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3782823826356119, 0.20742083575678372, 0.3923343727597201, 0.021962408847884193]
first move QE:  2.0267702318320993
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3782823826356119, 0.20742083575678372, 0.3923343727597201, 0.021962408847884193]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.488]
 [0.434]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.485]] [[3.575]
 [3.668]
 [4.871]
 [4.871]
 [4.871]
 [4.871]
 [3.885]] [[0.768]
 [0.759]
 [1.51 ]
 [1.51 ]
 [1.51 ]
 [1.51 ]
 [0.96 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3782823826356119, 0.20742083575678372, 0.3923343727597201, 0.021962408847884193]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.508286933428655
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38368138360678744, 0.21037479301857362, 0.38368138360678744, 0.022262439767851527]
from probs:  [0.38368138360678744, 0.21037479301857362, 0.38368138360678744, 0.022262439767851527]
Printing some Q and Qe and total Qs values:  [[0.35 ]
 [0.388]
 [0.35 ]
 [0.35 ]
 [0.35 ]
 [0.35 ]
 [0.35 ]] [[2.858]
 [3.362]
 [2.858]
 [2.858]
 [2.858]
 [2.858]
 [2.858]] [[0.35 ]
 [0.388]
 [0.35 ]
 [0.35 ]
 [0.35 ]
 [0.35 ]
 [0.35 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38368138360678744, 0.21037479301857362, 0.38368138360678744, 0.022262439767851527]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38920802162145623, 0.21339858437995238, 0.3748238303208313, 0.02256956367776006]
Printing some Q and Qe and total Qs values:  [[0.441]
 [0.438]
 [0.438]
 [0.438]
 [0.438]
 [0.438]
 [0.438]] [[-2.185]
 [-1.62 ]
 [-1.62 ]
 [-1.62 ]
 [-1.62 ]
 [-1.62 ]
 [-1.62 ]] [[0.441]
 [0.438]
 [0.438]
 [0.438]
 [0.438]
 [0.438]
 [0.438]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38920802162145623, 0.21339858437995238, 0.3748238303208313, 0.02256956367776006]
Printing some Q and Qe and total Qs values:  [[0.45 ]
 [0.474]
 [0.474]
 [0.474]
 [0.396]
 [0.474]
 [0.474]] [[-3.332]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-2.974]
 [ 0.   ]
 [ 0.   ]] [[0.45 ]
 [0.474]
 [0.474]
 [0.474]
 [0.396]
 [0.474]
 [0.474]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.03922362055351
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38920802162145623, 0.21339858437995238, 0.3748238303208313, 0.02256956367776006]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.83711284940344
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38920802162145623, 0.21339858437995238, 0.3748238303208313, 0.02256956367776006]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38920802162145623, 0.21339858437995238, 0.3748238303208313, 0.02256956367776006]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38920802162145623, 0.21339858437995238, 0.3748238303208313, 0.02256956367776006]
line 256 mcts: sample exp_bonus 3.7234520375227813
line 256 mcts: sample exp_bonus 4.394239501488416
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.815]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]] [[2.331]
 [2.944]
 [2.331]
 [2.331]
 [2.331]
 [2.331]
 [2.331]] [[1.084]
 [1.426]
 [1.084]
 [1.084]
 [1.084]
 [1.084]
 [1.084]]
Printing some Q and Qe and total Qs values:  [[0.267]
 [0.22 ]
 [0.22 ]
 [0.22 ]
 [0.22 ]
 [0.22 ]
 [0.22 ]] [[0.557]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]] [[0.267]
 [0.22 ]
 [0.22 ]
 [0.22 ]
 [0.22 ]
 [0.22 ]
 [0.22 ]]
Printing some Q and Qe and total Qs values:  [[0.753]
 [0.819]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]] [[2.648]
 [2.737]
 [2.862]
 [2.862]
 [2.862]
 [2.862]
 [2.862]] [[1.038]
 [1.199]
 [1.064]
 [1.064]
 [1.064]
 [1.064]
 [1.064]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.36733044868067144, 0.22634959096192525, 0.3824349739856338, 0.023884986371769543]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.37486618333774835, 0.24082297899801652, 0.3589558016124369, 0.025355036051798285]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38090387782138563, 0.2446959864165262, 0.3486517216496637, 0.025748414112424595]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.38090387782138563, 0.2446959864165262, 0.3486517216496637, 0.025748414112424595]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.37073820833737076, 0.24871699093866395, 0.35438797661130983, 0.026156824112655495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.37073820833737076, 0.24871699093866395, 0.35438797661130983, 0.026156824112655495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.360285948154514, 0.2528513556775437, 0.360285948154514, 0.02657674801342834]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3663525727297865, 0.25710394295171307, 0.3495348046422095, 0.02700867967629098]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3616843634798313, 0.26603149543334, 0.34436869751832866, 0.027915443568499943]
Printing some Q and Qe and total Qs values:  [[0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]] [[5.568]
 [5.568]
 [5.568]
 [5.568]
 [5.568]
 [5.568]
 [5.568]] [[0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3616843634798313, 0.26603149543334, 0.34436869751832866, 0.027915443568499943]
Printing some Q and Qe and total Qs values:  [[0.666]
 [0.652]
 [0.633]
 [0.636]
 [0.636]
 [0.635]
 [0.638]] [[2.581]
 [2.281]
 [2.37 ]
 [2.246]
 [2.149]
 [2.21 ]
 [2.226]] [[0.43 ]
 [0.302]
 [0.293]
 [0.257]
 [0.226]
 [0.243]
 [0.256]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3616843634798313, 0.26603149543334, 0.34436869751832866, 0.027915443568499943]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3616843634798313, 0.26603149543334, 0.34436869751832866, 0.027915443568499943]
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.537]
 [0.531]
 [0.538]
 [0.539]
 [0.541]
 [0.536]] [[1.469]
 [1.409]
 [1.499]
 [1.518]
 [1.508]
 [1.448]
 [1.323]] [[-0.068]
 [-0.083]
 [-0.064]
 [-0.045]
 [-0.046]
 [-0.062]
 [-0.114]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3616843634798313, 0.26603149543334, 0.34436869751832866, 0.027915443568499943]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.35044382269715085, 0.2707206387494478, 0.35044382269715085, 0.028391715856250548]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.35044382269715085, 0.2707206387494478, 0.35044382269715085, 0.028391715856250548]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.674]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.66 ]] [[5.299]
 [4.693]
 [5.299]
 [5.299]
 [5.299]
 [5.299]
 [5.058]] [[1.662]
 [1.464]
 [1.662]
 [1.662]
 [1.662]
 [1.662]
 [1.601]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3388583920833978, 0.275553657514025, 0.3567053489519706, 0.028882601450606525]
siam score:  -0.7547183
Printing some Q and Qe and total Qs values:  [[1.049]
 [1.092]
 [1.049]
 [1.049]
 [1.049]
 [1.049]
 [1.049]] [[5.744]
 [5.491]
 [5.744]
 [5.744]
 [5.744]
 [5.744]
 [5.744]] [[2.367]
 [2.37 ]
 [2.367]
 [2.367]
 [2.367]
 [2.367]
 [2.367]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3269119511156271, 0.28053727662082045, 0.3631619888702618, 0.02938878339329068]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31458735871609567, 0.2856786467017916, 0.3698230066142198, 0.02991098796789299]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31458735871609567, 0.2856786467017916, 0.3698230066142198, 0.02991098796789299]
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.53 ]
 [0.53 ]
 [0.53 ]
 [0.53 ]
 [0.53 ]
 [0.53 ]] [[0.565]
 [1.154]
 [1.154]
 [1.154]
 [1.154]
 [1.154]
 [1.154]] [[0.616]
 [0.53 ]
 [0.53 ]
 [0.53 ]
 [0.53 ]
 [0.53 ]
 [0.53 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.320523908258199, 0.2910679298571698, 0.3579497890225868, 0.030458372862044423]
Printing some Q and Qe and total Qs values:  [[0.263]
 [0.279]
 [0.279]
 [0.279]
 [0.279]
 [0.274]
 [0.293]] [[6.368]
 [5.663]
 [5.663]
 [5.663]
 [5.663]
 [5.839]
 [5.639]] [[0.567]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.412]
 [0.384]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.307670323181488, 0.2965794301081872, 0.3647320754679507, 0.03101817124237395]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.559]
 [0.504]
 [0.504]
 [0.504]
 [0.503]
 [0.556]] [[0.377]
 [0.906]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.508]
 [0.27 ]] [[0.544]
 [0.559]
 [0.504]
 [0.504]
 [0.504]
 [0.503]
 [0.556]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2943870439017162, 0.30227517932117853, 0.3717410931444601, 0.03159668363264515]
1327 934
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.28634351935222707, 0.3144158489258833, 0.3664108306309668, 0.03282980109092284]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.28634351935222707, 0.3144158489258833, 0.3664108306309668, 0.03282980109092284]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.738]
 [0.771]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]] [[1.346]
 [2.385]
 [1.187]
 [1.187]
 [1.187]
 [1.187]
 [1.187]] [[0.946]
 [1.704]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]]
line 256 mcts: sample exp_bonus 1.3730810318266258
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.27766952184417754, 0.3275073438807756, 0.3606636412058845, 0.03415949306916234]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.27766952184417754, 0.3275073438807756, 0.3606636412058845, 0.03415949306916234]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2682879714815886, 0.3416659156702096, 0.35444854571671075, 0.035597567131490995]
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]] [[2.644]
 [2.9  ]
 [2.9  ]
 [2.9  ]
 [2.9  ]
 [2.9  ]
 [2.9  ]] [[0.613]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.27424169645490176, 0.34925407852966883, 0.3401359346534316, 0.03636829036199787]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.726]
 [0.763]
 [0.753]
 [0.753]
 [0.753]
 [0.517]] [[2.317]
 [2.585]
 [2.336]
 [2.67 ]
 [2.67 ]
 [2.67 ]
 [2.959]] [[1.783]
 [2.061]
 [2.005]
 [2.105]
 [2.105]
 [2.105]
 [2.047]]
Printing some Q and Qe and total Qs values:  [[0.621]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]] [[1.821]
 [1.928]
 [1.928]
 [1.928]
 [1.928]
 [1.928]
 [1.928]] [[0.621]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]]
Printing some Q and Qe and total Qs values:  [[0.442]
 [0.326]
 [0.388]
 [0.411]
 [0.389]
 [0.42 ]
 [0.461]] [[3.749]
 [4.187]
 [3.71 ]
 [3.884]
 [3.687]
 [3.65 ]
 [3.96 ]] [[0.624]
 [0.685]
 [0.49 ]
 [0.652]
 [0.477]
 [0.514]
 [0.804]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.280434862752104, 0.357147415002141, 0.32524771242962675, 0.03717000981612844]
from probs:  [0.280434862752104, 0.357147415002141, 0.32524771242962675, 0.03717000981612844]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.280434862752104, 0.357147415002141, 0.32524771242962675, 0.03717000981612844]
1332 944
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.280434862752104, 0.357147415002141, 0.32524771242962675, 0.03717000981612844]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.28688221122987145, 0.3653647126570213, 0.30974844238182253, 0.038004633731284695]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.877]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]] [[3.701]
 [3.874]
 [3.547]
 [3.547]
 [3.547]
 [3.547]
 [3.547]] [[1.501]
 [1.847]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.45 ]]
Printing some Q and Qe and total Qs values:  [[0.252]
 [0.244]
 [0.244]
 [0.244]
 [0.244]
 [0.244]
 [0.244]] [[4.825]
 [4.669]
 [4.669]
 [4.669]
 [4.669]
 [4.669]
 [4.669]] [[0.685]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.491]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.486]] [[5.46 ]
 [5.723]
 [5.46 ]
 [5.46 ]
 [5.46 ]
 [5.46 ]
 [5.787]] [[1.443]
 [1.473]
 [1.443]
 [1.443]
 [1.443]
 [1.443]
 [1.484]]
line 256 mcts: sample exp_bonus 9.34020378306484
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.451]
 [0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]] [[2.682]
 [3.515]
 [2.317]
 [2.317]
 [2.317]
 [2.317]
 [2.317]] [[1.039]
 [1.193]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.873]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2935997180949064, 0.3739263335464493, 0.2935997180949064, 0.038874230263737736]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2935997180949064, 0.3739263335464493, 0.2935997180949064, 0.038874230263737736]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.30791609898116507, 0.3921728985473464, 0.2591834841611438, 0.040727518310344706]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.30791609898116507, 0.3921728985473464, 0.2591834841611438, 0.040727518310344706]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3057254275116352, 0.4229638843196984, 0.22745575569174625, 0.043854932476920246]
line 256 mcts: sample exp_bonus 4.531997575352592
Printing some Q and Qe and total Qs values:  [[0.281]
 [0.978]
 [0.281]
 [0.281]
 [0.281]
 [0.281]
 [0.281]] [[3.881]
 [3.413]
 [3.881]
 [3.881]
 [3.881]
 [3.881]
 [3.881]] [[1.624]
 [2.38 ]
 [1.624]
 [1.624]
 [1.624]
 [1.624]
 [1.624]]
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.706]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]] [[4.249]
 [2.802]
 [2.369]
 [2.369]
 [2.369]
 [2.369]
 [2.369]] [[2.159]
 [1.697]
 [1.496]
 [1.496]
 [1.496]
 [1.496]
 [1.496]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3057254275116352, 0.4229638843196984, 0.22745575569174625, 0.043854932476920246]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2674082038995057, 0.4463530819862894, 0.24000816077642192, 0.046230553337783004]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2674082038995057, 0.4463530819862894, 0.24000816077642192, 0.046230553337783004]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
line 256 mcts: sample exp_bonus 6.8678872315516415
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.24676929604376363, 0.45895126760503235, 0.24676929604376363, 0.047510140307440454]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.24676929604376363, 0.45895126760503235, 0.24676929604376363, 0.047510140307440454]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.24676929604376363, 0.45895126760503235, 0.24676929604376363, 0.047510140307440454]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
from probs:  [0.23172194543206234, 0.48627111520578786, 0.23172194543206234, 0.05028499393008762]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.20831186019602219, 0.501115594209161, 0.2387798105916175, 0.0517927350031994]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.1708582694949414
Printing some Q and Qe and total Qs values:  [[0.172]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]] [[-1.186]
 [-2.618]
 [-2.618]
 [-2.618]
 [-2.618]
 [-2.618]
 [-2.618]] [[0.172]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.20831186019602219, 0.501115594209161, 0.2387798105916175, 0.0517927350031994]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.20831186019602219, 0.501115594209161, 0.2387798105916175, 0.0517927350031994]
siam score:  -0.7386098
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.20831186019602219, 0.501115594209161, 0.2387798105916175, 0.0517927350031994]
Printing some Q and Qe and total Qs values:  [[0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]] [[5.535]
 [5.535]
 [5.535]
 [5.535]
 [5.535]
 [5.535]
 [5.535]] [[0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.20831186019602219, 0.501115594209161, 0.2387798105916175, 0.0517927350031994]
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.686]
 [0.585]
 [0.629]
 [0.635]
 [0.639]
 [0.64 ]] [[5.37 ]
 [5.26 ]
 [5.702]
 [5.551]
 [5.426]
 [4.885]
 [5.375]] [[1.317]
 [1.138]
 [1.231]
 [1.217]
 [1.147]
 [0.794]
 [1.123]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.20831186019602219, 0.501115594209161, 0.2387798105916175, 0.0517927350031994]
siam score:  -0.73907477
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21485372963351743, 0.5168969108561224, 0.21485372963351743, 0.05339562987684266]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21485372963351743, 0.5168969108561224, 0.21485372963351743, 0.05339562987684266]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21485372963351743, 0.5168969108561224, 0.21485372963351743, 0.05339562987684266]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21485372963351743, 0.5168969108561224, 0.21485372963351743, 0.05339562987684266]
Printing some Q and Qe and total Qs values:  [[0.59 ]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]] [[4.758]
 [4.507]
 [4.507]
 [4.507]
 [4.507]
 [4.507]
 [4.507]] [[0.955]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21485372963351743, 0.5168969108561224, 0.21485372963351743, 0.05339562987684266]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21485372963351743, 0.5168969108561224, 0.21485372963351743, 0.05339562987684266]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21485372963351743, 0.5168969108561224, 0.21485372963351743, 0.05339562987684266]
line 256 mcts: sample exp_bonus 5.195456119322828
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21485372963351743, 0.5168969108561224, 0.21485372963351743, 0.05339562987684266]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.22178673098413854, 0.5336217768402891, 0.18949713192355847, 0.05509436025201391]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2291470232908494, 0.5513774206384767, 0.16257777021995828, 0.05689778585071556]
Printing some Q and Qe and total Qs values:  [[0.406]
 [0.419]
 [0.419]
 [0.419]
 [0.419]
 [0.419]
 [0.419]] [[3.619]
 [3.674]
 [3.674]
 [3.674]
 [3.674]
 [3.674]
 [3.674]] [[0.503]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]]
siam score:  -0.72874963
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.818]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]] [[3.617]
 [3.526]
 [3.617]
 [3.617]
 [3.617]
 [3.617]
 [3.617]] [[2.757]
 [2.761]
 [2.757]
 [2.757]
 [2.757]
 [2.757]
 [2.757]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.23697536438027889, 0.5702621646299504, 0.1339465777966099, 0.05881589319316106]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.23697536438027889, 0.5702621646299504, 0.1339465777966099, 0.05881589319316106]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.23697536438027889, 0.5702621646299504, 0.1339465777966099, 0.05881589319316106]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.20969571623612182, 0.5906945760240802, 0.1387185119459431, 0.06089119579385515]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18053316762152236, 0.6125372767600266, 0.14381981533813762, 0.06310974028031352]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18053316762152236, 0.6125372767600266, 0.14381981533813762, 0.06310974028031352]
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.794]
 [0.853]
 [0.72 ]
 [0.708]
 [0.676]
 [0.701]] [[4.313]
 [4.721]
 [4.221]
 [4.256]
 [4.296]
 [4.227]
 [4.154]] [[1.357]
 [1.704]
 [1.653]
 [1.399]
 [1.39 ]
 [1.301]
 [1.328]]
Printing some Q and Qe and total Qs values:  [[0.714]
 [0.838]
 [0.808]
 [0.741]
 [0.73 ]
 [0.808]
 [0.733]] [[4.12 ]
 [4.857]
 [4.523]
 [3.951]
 [4.096]
 [4.523]
 [3.977]] [[1.229]
 [1.724]
 [1.553]
 [1.228]
 [1.255]
 [1.553]
 [1.221]]
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.998]
 [1.303]
 [0.811]
 [0.939]
 [0.818]
 [0.519]] [[2.821]
 [2.928]
 [2.718]
 [2.609]
 [3.347]
 [2.89 ]
 [3.193]] [[2.389]
 [2.878]
 [3.249]
 [2.418]
 [3.006]
 [2.576]
 [2.264]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.15515704534441477, 0.6610808945696861, 0.11572178594229243, 0.06804027414360678]
Printing some Q and Qe and total Qs values:  [[0.648]
 [0.648]
 [0.648]
 [0.648]
 [0.648]
 [0.648]
 [0.648]] [[6.746]
 [6.746]
 [6.746]
 [6.746]
 [6.746]
 [6.746]
 [6.746]] [[2.533]
 [2.533]
 [2.533]
 [2.533]
 [2.533]
 [2.533]
 [2.533]]
siam score:  -0.7400993
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
siam score:  -0.74103004
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.422]
 [0.419]
 [0.418]
 [0.426]
 [0.429]
 [0.428]] [[5.873]
 [5.141]
 [6.008]
 [6.05 ]
 [6.052]
 [5.778]
 [5.78 ]] [[1.035]
 [0.566]
 [1.137]
 [1.163]
 [1.18 ]
 [1.004]
 [1.004]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.805]
 [0.81 ]
 [0.874]
 [0.81 ]
 [0.81 ]
 [0.81 ]] [[3.528]
 [3.368]
 [3.528]
 [3.901]
 [3.528]
 [3.528]
 [3.528]] [[1.616]
 [1.525]
 [1.616]
 [1.884]
 [1.616]
 [1.616]
 [1.616]]
Printing some Q and Qe and total Qs values:  [[-0.01 ]
 [-0.024]
 [-0.024]
 [-0.024]
 [-0.024]
 [-0.024]
 [-0.024]] [[5.314]
 [5.57 ]
 [5.57 ]
 [5.57 ]
 [5.57 ]
 [5.57 ]
 [5.57 ]] [[-0.071]
 [ 0.071]
 [ 0.071]
 [ 0.071]
 [ 0.071]
 [ 0.071]
 [ 0.071]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12045138231588759, 0.6882930461907829, 0.12045138231588759, 0.07080418917744206]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08295151056206598, 0.7176960918867481, 0.12556176609710193, 0.07379063145408384]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08295151056206598, 0.7176960918867481, 0.12556176609710193, 0.07379063145408384]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08295151056206598, 0.7176960918867481, 0.12556176609710193, 0.07379063145408384]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 3.750647332634616
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.989476323848202
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08661432130373228, 0.7497273394404322, 0.08661432130373228, 0.07704401795210318]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08661432130373228, 0.7497273394404322, 0.08661432130373228, 0.07704401795210318]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08661432130373228, 0.7497273394404322, 0.08661432130373228, 0.07704401795210318]
using another actor
siam score:  -0.7345314
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08661432130373228, 0.7497273394404322, 0.08661432130373228, 0.07704401795210318]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08661432130373228, 0.7497273394404322, 0.08661432130373228, 0.07704401795210318]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0703553380816588, 0.71672461376605, 0.1108322603780723, 0.10208778777421891]
Printing some Q and Qe and total Qs values:  [[0.861]
 [0.905]
 [0.772]
 [0.903]
 [0.772]
 [0.772]
 [0.912]] [[2.919]
 [2.682]
 [3.481]
 [2.39 ]
 [3.481]
 [3.481]
 [2.936]] [[1.215]
 [1.145]
 [1.411]
 [0.946]
 [1.411]
 [1.411]
 [1.327]]
Printing some Q and Qe and total Qs values:  [[0.885]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]] [[4.183]
 [4.046]
 [4.046]
 [4.046]
 [4.046]
 [4.046]
 [4.046]] [[1.722]
 [1.621]
 [1.621]
 [1.621]
 [1.621]
 [1.621]
 [1.621]]
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.543]
 [0.643]
 [0.643]
 [0.54 ]
 [0.529]
 [0.643]] [[1.555]
 [1.719]
 [1.839]
 [1.839]
 [1.179]
 [1.335]
 [1.839]] [[0.535]
 [0.543]
 [0.643]
 [0.643]
 [0.54 ]
 [0.529]
 [0.643]]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0703553380816588, 0.71672461376605, 0.1108322603780723, 0.10208778777421891]
siam score:  -0.73393965
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0703553380816588, 0.71672461376605, 0.1108322603780723, 0.10208778777421891]
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.473]
 [0.581]
 [0.571]
 [0.513]
 [0.598]
 [0.522]] [[4.501]
 [6.499]
 [4.032]
 [5.474]
 [4.285]
 [5.206]
 [5.931]] [[0.591]
 [1.289]
 [0.681]
 [1.144]
 [0.63 ]
 [1.108]
 [1.199]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0703553380816588, 0.71672461376605, 0.1108322603780723, 0.10208778777421891]
using explorer policy with actor:  0
siam score:  -0.7301396
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.0703553380816588, 0.71672461376605, 0.1108322603780723, 0.10208778777421891]
Printing some Q and Qe and total Qs values:  [[-0.013]
 [ 0.121]
 [ 0.143]
 [ 0.143]
 [ 0.143]
 [ 0.102]
 [ 0.1  ]] [[2.867]
 [2.862]
 [1.811]
 [0.664]
 [1.845]
 [1.313]
 [2.215]] [[-0.013]
 [ 0.121]
 [ 0.143]
 [ 0.143]
 [ 0.143]
 [ 0.102]
 [ 0.1  ]]
Printing some Q and Qe and total Qs values:  [[0.239]
 [0.197]
 [0.195]
 [0.183]
 [0.203]
 [0.182]
 [0.199]] [[5.27 ]
 [5.445]
 [5.38 ]
 [5.387]
 [5.081]
 [5.281]
 [5.438]] [[0.152]
 [0.127]
 [0.101]
 [0.08 ]
 [0.018]
 [0.041]
 [0.129]]
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.539]
 [0.573]
 [0.577]
 [0.586]
 [0.617]
 [0.585]] [[3.591]
 [3.918]
 [3.106]
 [3.085]
 [3.225]
 [3.433]
 [3.886]] [[0.573]
 [0.539]
 [0.573]
 [0.577]
 [0.586]
 [0.617]
 [0.585]]
Printing some Q and Qe and total Qs values:  [[0.224]
 [0.149]
 [0.149]
 [0.224]
 [0.224]
 [0.138]
 [0.115]] [[0.   ]
 [1.964]
 [0.982]
 [0.   ]
 [0.   ]
 [0.538]
 [1.554]] [[0.224]
 [0.149]
 [0.149]
 [0.224]
 [0.224]
 [0.138]
 [0.115]]
1375 971
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0703553380816588, 0.71672461376605, 0.1108322603780723, 0.10208778777421891]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0703553380816588, 0.71672461376605, 0.1108322603780723, 0.10208778777421891]
Printing some Q and Qe and total Qs values:  [[0.838]
 [0.843]
 [0.829]
 [0.836]
 [0.822]
 [0.821]
 [0.83 ]] [[2.808]
 [2.748]
 [1.657]
 [2.701]
 [1.882]
 [2.215]
 [2.193]] [[1.661]
 [1.636]
 [1.012]
 [1.598]
 [1.125]
 [1.305]
 [1.308]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.503]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]] [[0.746]
 [1.696]
 [1.108]
 [1.108]
 [1.108]
 [1.108]
 [1.108]] [[0.574]
 [0.503]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]]
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.499]
 [0.505]
 [0.505]
 [0.486]
 [0.497]
 [0.498]] [[1.494]
 [1.787]
 [1.357]
 [1.417]
 [1.309]
 [1.44 ]
 [1.411]] [[0.513]
 [0.499]
 [0.505]
 [0.505]
 [0.486]
 [0.497]
 [0.498]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.64 ]] [[1.028]
 [1.028]
 [1.028]
 [1.028]
 [1.028]
 [1.028]
 [5.18 ]] [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.64 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.301]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.263]] [[5.   ]
 [4.901]
 [4.901]
 [4.901]
 [4.901]
 [4.901]
 [4.901]] [[0.775]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
Printing some Q and Qe and total Qs values:  [[-0.037]
 [-0.03 ]
 [-0.009]
 [-0.012]
 [-0.014]
 [-0.01 ]
 [-0.013]] [[3.405]
 [2.651]
 [2.952]
 [3.318]
 [3.344]
 [3.083]
 [2.26 ]] [[ 0.151]
 [-0.336]
 [-0.095]
 [ 0.144]
 [ 0.157]
 [-0.01 ]
 [-0.563]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
Printing some Q and Qe and total Qs values:  [[0.504]
 [0.715]
 [0.814]
 [0.824]
 [0.752]
 [0.651]
 [0.824]] [[4.357]
 [4.055]
 [3.179]
 [3.817]
 [3.077]
 [2.77 ]
 [3.959]] [[1.81 ]
 [2.019]
 [1.653]
 [2.075]
 [1.471]
 [1.086]
 [2.166]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.825]
 [0.824]
 [0.867]
 [0.867]
 [0.821]
 [0.822]] [[4.014]
 [4.199]
 [3.588]
 [3.219]
 [3.219]
 [3.802]
 [3.574]] [[0.817]
 [0.825]
 [0.824]
 [0.867]
 [0.867]
 [0.821]
 [0.822]]
Printing some Q and Qe and total Qs values:  [[0.847]
 [0.784]
 [0.817]
 [0.816]
 [0.801]
 [0.784]
 [0.782]] [[6.124]
 [6.382]
 [6.143]
 [6.264]
 [6.142]
 [6.382]
 [6.228]] [[2.043]
 [2.085]
 [1.999]
 [2.071]
 [1.97 ]
 [2.085]
 [1.988]]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.419]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]] [[3.562]
 [3.224]
 [3.224]
 [3.224]
 [3.224]
 [3.224]
 [3.224]] [[2.048]
 [1.913]
 [1.913]
 [1.913]
 [1.913]
 [1.913]
 [1.913]]
Printing some Q and Qe and total Qs values:  [[0.633]
 [0.613]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]] [[4.279]
 [3.578]
 [3.531]
 [3.531]
 [3.531]
 [3.531]
 [3.531]] [[1.597]
 [1.289]
 [1.206]
 [1.206]
 [1.206]
 [1.206]
 [1.206]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
1385 980
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
Printing some Q and Qe and total Qs values:  [[1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]] [[1.984]
 [1.959]
 [1.984]
 [1.984]
 [1.984]
 [1.984]
 [1.984]] [[2.43 ]
 [2.414]
 [2.43 ]
 [2.43 ]
 [2.43 ]
 [2.43 ]
 [2.43 ]]
Printing some Q and Qe and total Qs values:  [[0.249]
 [0.389]
 [0.687]
 [0.703]
 [0.69 ]
 [0.695]
 [0.397]] [[3.064]
 [2.449]
 [0.9  ]
 [0.537]
 [0.5  ]
 [0.656]
 [2.684]] [[1.363]
 [1.233]
 [0.8  ]
 [0.591]
 [0.54 ]
 [0.654]
 [1.405]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06274295804078299, 0.6754498981075377, 0.1348049701974029, 0.12700217365427635]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
first move QE:  1.9826368622327277
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05663733959384154, 0.6423449212194047, 0.15403262547868615, 0.14698511370806772]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05663733959384154, 0.6423449212194047, 0.15403262547868615, 0.14698511370806772]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05663733959384154, 0.6423449212194047, 0.15403262547868615, 0.14698511370806772]
line 256 mcts: sample exp_bonus 3.9384603547486816
Printing some Q and Qe and total Qs values:  [[0.14 ]
 [0.126]
 [0.126]
 [0.126]
 [0.126]
 [0.126]
 [0.126]] [[-3.266]
 [-3.377]
 [-3.377]
 [-3.377]
 [-3.377]
 [-3.377]
 [-3.377]] [[0.14 ]
 [0.126]
 [0.126]
 [0.126]
 [0.126]
 [0.126]
 [0.126]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05852143627723831, 0.6640619341499439, 0.1254881112718512, 0.15192851830096651]
line 256 mcts: sample exp_bonus 4.073175790918792
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.443]
 [0.4  ]
 [0.448]
 [0.432]
 [0.448]
 [0.448]
 [0.448]] [[5.153]
 [5.253]
 [5.664]
 [5.471]
 [5.664]
 [5.664]
 [5.664]] [[1.194]
 [1.176]
 [1.538]
 [1.38 ]
 [1.538]
 [1.538]
 [1.538]]
using explorer policy with actor:  1
using another actor
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]] [[2.929]
 [2.914]
 [2.914]
 [2.914]
 [2.914]
 [2.914]
 [2.914]] [[0.853]
 [0.857]
 [0.857]
 [0.857]
 [0.857]
 [0.857]
 [0.857]]
Printing some Q and Qe and total Qs values:  [[0.508]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]] [[-0.05]
 [ 0.32]
 [ 0.32]
 [ 0.32]
 [ 0.32]
 [ 0.32]
 [ 0.32]] [[0.508]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.666]
 [0.678]
 [0.649]
 [0.678]
 [0.678]
 [0.678]
 [0.678]] [[2.767]
 [2.871]
 [2.861]
 [2.871]
 [2.871]
 [2.871]
 [2.871]] [[0.647]
 [0.741]
 [0.678]
 [0.741]
 [0.741]
 [0.741]
 [0.741]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06052754623494947, 0.6871853313065872, 0.09509506685274882, 0.1571920556057145]
from probs:  [0.06052754623494947, 0.6871853313065872, 0.09509506685274882, 0.1571920556057145]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 6.222885465510685
Printing some Q and Qe and total Qs values:  [[0.704]
 [0.792]
 [0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]] [[3.683]
 [4.084]
 [3.683]
 [3.683]
 [3.683]
 [3.683]
 [3.683]] [[1.237]
 [1.618]
 [1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.237]]
using explorer policy with actor:  1
first move QE:  1.9766270249295887
Printing some Q and Qe and total Qs values:  [[0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]] [[5.776]
 [5.776]
 [5.776]
 [5.776]
 [5.776]
 [5.776]
 [5.776]] [[1.466]
 [1.466]
 [1.466]
 [1.466]
 [1.466]
 [1.466]
 [1.466]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
line 256 mcts: sample exp_bonus 2.918668810439832
Printing some Q and Qe and total Qs values:  [[0.398]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]] [[5.416]
 [5.087]
 [5.087]
 [5.087]
 [5.087]
 [5.087]
 [5.087]] [[1.2  ]
 [0.969]
 [0.969]
 [0.969]
 [0.969]
 [0.969]
 [0.969]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.287]
 [0.311]
 [0.295]
 [0.3  ]
 [0.303]
 [0.318]
 [0.3  ]] [[3.771]
 [3.625]
 [3.73 ]
 [3.818]
 [3.816]
 [3.691]
 [3.765]] [[0.295]
 [0.245]
 [0.283]
 [0.352]
 [0.357]
 [0.303]
 [0.318]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
Printing some Q and Qe and total Qs values:  [[0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]] [[2.465]
 [2.465]
 [2.465]
 [2.465]
 [2.465]
 [2.465]
 [2.465]] [[-0.091]
 [-0.091]
 [-0.091]
 [-0.091]
 [-0.091]
 [-0.091]
 [-0.091]]
Printing some Q and Qe and total Qs values:  [[0.966]
 [0.849]
 [0.849]
 [0.849]
 [0.849]
 [0.849]
 [0.849]] [[3.8 ]
 [4.09]
 [4.09]
 [4.09]
 [4.09]
 [4.09]
 [4.09]] [[1.651]
 [1.609]
 [1.609]
 [1.609]
 [1.609]
 [1.609]
 [1.609]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
Printing some Q and Qe and total Qs values:  [[-0.011]
 [-0.015]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.013]
 [-0.01 ]] [[4.522]
 [4.001]
 [4.287]
 [4.345]
 [4.544]
 [3.99 ]
 [4.297]] [[-0.092]
 [-0.448]
 [-0.251]
 [-0.212]
 [-0.079]
 [-0.45 ]
 [-0.24 ]]
Printing some Q and Qe and total Qs values:  [[-0.013]
 [-0.015]
 [-0.016]
 [-0.015]
 [-0.013]
 [-0.015]
 [-0.013]] [[4.683]
 [4.168]
 [4.457]
 [4.587]
 [4.231]
 [4.272]
 [4.231]] [[-0.141]
 [-0.486]
 [-0.296]
 [-0.209]
 [-0.44 ]
 [-0.418]
 [-0.44 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06266791837300681, 0.7118562995259877, 0.06266791837300681, 0.16280786372799874]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.056589984366890174, 0.6753499592281943, 0.08879043320284578, 0.17926962320206957]
Printing some Q and Qe and total Qs values:  [[0.802]
 [0.802]
 [0.802]
 [0.802]
 [0.802]
 [0.802]
 [0.802]] [[2.771]
 [2.771]
 [2.771]
 [2.771]
 [2.771]
 [2.771]
 [2.771]] [[0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.056589984366890174, 0.6753499592281943, 0.08879043320284578, 0.17926962320206957]
first move QE:  1.9683863199502984
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05844734270923461, 0.6978796860605013, 0.05844734270923461, 0.18522562852102956]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05844734270923461, 0.6978796860605013, 0.05844734270923461, 0.18522562852102956]
siam score:  -0.7258737
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05844734270923461, 0.6978796860605013, 0.05844734270923461, 0.18522562852102956]
from probs:  [0.05844734270923461, 0.6978796860605013, 0.05844734270923461, 0.18522562852102956]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08326938123951222, 0.6649847319318087, 0.053141590553967805, 0.1986042962747111]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08326938123951222, 0.6649847319318087, 0.053141590553967805, 0.1986042962747111]
from probs:  [0.08326938123951222, 0.6649847319318087, 0.053141590553967805, 0.1986042962747111]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08326938123951222, 0.6649847319318087, 0.053141590553967805, 0.1986042962747111]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08326938123951222, 0.6649847319318087, 0.053141590553967805, 0.1986042962747111]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08326938123951222, 0.6649847319318087, 0.053141590553967805, 0.1986042962747111]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10389067180482381, 0.6376567424762718, 0.0487337552858118, 0.20971883043309253]
Printing some Q and Qe and total Qs values:  [[0.789]
 [0.75 ]
 [0.789]
 [0.801]
 [0.789]
 [0.842]
 [0.797]] [[4.701]
 [3.446]
 [4.701]
 [4.028]
 [4.701]
 [4.029]
 [4.045]] [[1.942]
 [1.229]
 [1.942]
 [1.594]
 [1.942]
 [1.639]
 [1.599]]
from probs:  [0.1151456435961872, 0.6093776467330829, 0.04282983157810435, 0.2326468780926256]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12971911450427862, 0.5909565670666049, 0.03994826198646949, 0.239376056442647]
Printing some Q and Qe and total Qs values:  [[-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]] [[3.228]
 [3.228]
 [3.228]
 [3.228]
 [3.228]
 [3.228]
 [3.228]] [[0.126]
 [0.126]
 [0.126]
 [0.126]
 [0.126]
 [0.126]
 [0.126]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12971911450427862, 0.5909565670666049, 0.03994826198646949, 0.239376056442647]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12971911450427862, 0.5909565670666049, 0.03994826198646949, 0.239376056442647]
Printing some Q and Qe and total Qs values:  [[0.839]
 [0.777]
 [0.834]
 [0.834]
 [0.837]
 [0.843]
 [0.834]] [[2.556]
 [2.703]
 [2.483]
 [2.757]
 [2.838]
 [2.606]
 [2.71 ]] [[0.957]
 [0.931]
 [0.898]
 [1.081]
 [1.14 ]
 [0.997]
 [1.049]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12971911450427862, 0.5909565670666049, 0.03994826198646949, 0.239376056442647]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12971911450427862, 0.5909565670666049, 0.03994826198646949, 0.239376056442647]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12971911450427862, 0.5909565670666049, 0.03994826198646949, 0.239376056442647]
Printing some Q and Qe and total Qs values:  [[0.793]
 [0.812]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]] [[1.835]
 [2.295]
 [1.515]
 [1.515]
 [1.515]
 [1.515]
 [1.515]] [[1.348]
 [1.694]
 [1.149]
 [1.149]
 [1.149]
 [1.149]
 [1.149]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1424120051953318, 0.5749125682078318, 0.03743853399675802, 0.2452368926000784]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]] [[2.412]
 [2.42 ]
 [2.42 ]
 [2.42 ]
 [2.42 ]
 [2.42 ]
 [2.42 ]] [[1.023]
 [1.031]
 [1.031]
 [1.031]
 [1.031]
 [1.031]
 [1.031]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1424120051953318, 0.5749125682078318, 0.03743853399675802, 0.2452368926000784]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
UNIT TEST: sample policy line 217 mcts : [0.122 0.    0.122 0.286 0.041 0.224 0.204]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12383079629465532, 0.5873909955548038, 0.038230888411626925, 0.2505473197389138]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12383079629465532, 0.5873909955548038, 0.038230888411626925, 0.2505473197389138]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12383079629465532, 0.5873909955548038, 0.038230888411626925, 0.2505473197389138]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12383079629465532, 0.5873909955548038, 0.038230888411626925, 0.2505473197389138]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12383079629465532, 0.5873909955548038, 0.038230888411626925, 0.2505473197389138]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12383079629465532, 0.5873909955548038, 0.038230888411626925, 0.2505473197389138]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10451808099942513, 0.6003606745446077, 0.039054436293203154, 0.25606680816276395]
Printing some Q and Qe and total Qs values:  [[0.36 ]
 [0.192]
 [0.192]
 [0.192]
 [0.192]
 [0.192]
 [0.192]] [[ 4.032]
 [-0.196]
 [-0.196]
 [-0.196]
 [-0.196]
 [-0.196]
 [-0.196]] [[0.36 ]
 [0.192]
 [0.192]
 [0.192]
 [0.192]
 [0.192]
 [0.192]]
Printing some Q and Qe and total Qs values:  [[0.364]
 [0.112]
 [0.182]
 [0.172]
 [0.176]
 [0.184]
 [0.173]] [[-1.641]
 [ 1.478]
 [-1.817]
 [-2.068]
 [-1.9  ]
 [-2.066]
 [-2.276]] [[0.364]
 [0.112]
 [0.182]
 [0.172]
 [0.176]
 [0.184]
 [0.173]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
Printing some Q and Qe and total Qs values:  [[0.382]
 [0.906]
 [0.641]
 [0.99 ]
 [0.641]
 [0.641]
 [0.641]] [[2.118]
 [2.486]
 [2.443]
 [1.968]
 [2.443]
 [2.443]
 [2.443]] [[0.76 ]
 [1.823]
 [1.364]
 [1.676]
 [1.364]
 [1.364]
 [1.364]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.304]
 [0.282]
 [0.275]
 [0.284]
 [0.278]
 [0.275]
 [0.281]] [[1.108]
 [1.574]
 [1.409]
 [1.128]
 [1.33 ]
 [1.186]
 [1.226]] [[0.304]
 [0.282]
 [0.275]
 [0.284]
 [0.278]
 [0.275]
 [0.281]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
line 256 mcts: sample exp_bonus -0.8849449752170105
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
Printing some Q and Qe and total Qs values:  [[0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]] [[1.824]
 [1.824]
 [1.824]
 [1.824]
 [1.824]
 [1.824]
 [1.824]] [[2.468]
 [2.468]
 [2.468]
 [2.468]
 [2.468]
 [2.468]
 [2.468]]
using explorer policy with actor:  1
siam score:  -0.73592454
line 256 mcts: sample exp_bonus 2.5172848697387784
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
1424 1052
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11844158984215067, 0.5841266071336478, 0.036658810942133316, 0.2607729920820683]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.09989481069065236, 0.5964365993151535, 0.037411658990786585, 0.2662569310034075]
Printing some Q and Qe and total Qs values:  [[1.047]
 [1.047]
 [1.047]
 [1.047]
 [1.047]
 [1.047]
 [1.047]] [[1.951]
 [1.951]
 [1.951]
 [1.951]
 [1.951]
 [1.951]
 [1.951]] [[1.338]
 [1.338]
 [1.338]
 [1.338]
 [1.338]
 [1.338]
 [1.338]]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.813]
 [0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.296]] [[3.812]
 [2.804]
 [2.804]
 [2.804]
 [2.804]
 [2.804]
 [2.804]] [[1.656]
 [0.114]
 [0.114]
 [0.114]
 [0.114]
 [0.114]
 [0.114]]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.571]
 [0.787]
 [0.693]
 [0.68 ]
 [0.684]
 [0.676]] [[-3.023]
 [ 1.698]
 [-2.239]
 [-3.377]
 [-3.265]
 [-3.324]
 [-3.308]] [[0.693]
 [0.571]
 [0.787]
 [0.693]
 [0.68 ]
 [0.684]
 [0.676]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.09989481069065236, 0.5964365993151535, 0.037411658990786585, 0.2662569310034075]
Printing some Q and Qe and total Qs values:  [[0.715]
 [0.716]
 [0.747]
 [0.716]
 [0.68 ]
 [0.716]
 [0.676]] [[-3.848]
 [ 0.   ]
 [-3.084]
 [ 0.   ]
 [-3.269]
 [ 0.   ]
 [-3.311]] [[0.715]
 [0.716]
 [0.747]
 [0.716]
 [0.68 ]
 [0.716]
 [0.676]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.09989481069065236, 0.5964365993151535, 0.037411658990786585, 0.2662569310034075]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
UNIT TEST: sample policy line 217 mcts : [0.082 0.102 0.633 0.061 0.02  0.082 0.02 ]
Printing some Q and Qe and total Qs values:  [[0.753]
 [0.639]
 [0.766]
 [0.759]
 [0.77 ]
 [0.786]
 [0.734]] [[2.017]
 [2.508]
 [2.246]
 [2.172]
 [2.098]
 [2.084]
 [2.062]] [[0.753]
 [0.639]
 [0.766]
 [0.759]
 [0.77 ]
 [0.786]
 [0.734]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.09989481069065236, 0.5964365993151535, 0.037411658990786585, 0.2662569310034075]
Printing some Q and Qe and total Qs values:  [[0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]] [[3.749]
 [3.749]
 [3.749]
 [3.749]
 [3.749]
 [3.749]
 [3.749]] [[2.223]
 [2.223]
 [2.223]
 [2.223]
 [2.223]
 [2.223]
 [2.223]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.824]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]] [[2.974]
 [3.539]
 [3.539]
 [3.539]
 [3.539]
 [3.539]
 [3.539]] [[1.013]
 [1.401]
 [1.401]
 [1.401]
 [1.401]
 [1.401]
 [1.401]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.09989481069065236, 0.5964365993151535, 0.037411658990786585, 0.2662569310034075]
Printing some Q and Qe and total Qs values:  [[0.748]
 [0.751]
 [0.756]
 [0.751]
 [0.751]
 [0.749]
 [0.75 ]] [[2.31 ]
 [2.15 ]
 [2.401]
 [2.15 ]
 [2.15 ]
 [2.338]
 [2.23 ]] [[0.748]
 [0.751]
 [0.756]
 [0.751]
 [0.751]
 [0.749]
 [0.75 ]]
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.801]
 [0.79 ]
 [0.782]
 [0.782]
 [0.782]
 [0.784]
 [0.785]] [[2.182]
 [2.157]
 [2.106]
 [2.106]
 [2.106]
 [2.361]
 [2.21 ]] [[0.801]
 [0.79 ]
 [0.782]
 [0.782]
 [0.782]
 [0.784]
 [0.785]]
Printing some Q and Qe and total Qs values:  [[0.748]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]] [[-2.276]
 [-2.062]
 [-2.062]
 [-2.062]
 [-2.062]
 [-2.062]
 [-2.062]] [[0.748]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]]
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]] [[2.228]
 [2.228]
 [2.228]
 [2.228]
 [2.228]
 [2.228]
 [2.228]] [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.09989481069065236, 0.5964365993151535, 0.037411658990786585, 0.2662569310034075]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.293]
 [1.203]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]] [[2.308]
 [2.999]
 [2.927]
 [2.927]
 [2.927]
 [2.927]
 [2.927]] [[1.533]
 [1.815]
 [1.359]
 [1.359]
 [1.359]
 [1.359]
 [1.359]]
Printing some Q and Qe and total Qs values:  [[0.7  ]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]] [[-4.378]
 [-4.536]
 [-4.536]
 [-4.536]
 [-4.536]
 [-4.536]
 [-4.536]] [[0.7  ]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]]
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.531]
 [0.728]
 [0.683]
 [0.655]
 [0.661]
 [0.691]] [[-3.981]
 [ 2.125]
 [-2.846]
 [-4.89 ]
 [-2.91 ]
 [-2.654]
 [-4.31 ]] [[0.703]
 [0.531]
 [0.728]
 [0.683]
 [0.655]
 [0.661]
 [0.691]]
Printing some Q and Qe and total Qs values:  [[0.641]
 [0.981]
 [0.641]
 [0.599]
 [0.641]
 [0.641]
 [0.641]] [[4.296]
 [3.835]
 [4.296]
 [4.03 ]
 [4.296]
 [4.296]
 [4.296]] [[1.97 ]
 [2.342]
 [1.97 ]
 [1.709]
 [1.97 ]
 [1.97 ]
 [1.97 ]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08064175135120856, 0.6092153685021212, 0.03819317625779615, 0.27194970388887396]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08064175135120856, 0.6092153685021212, 0.03819317625779615, 0.27194970388887396]
siam score:  -0.73196566
line 256 mcts: sample exp_bonus 2.39838646342703
Printing some Q and Qe and total Qs values:  [[0.944]
 [0.808]
 [1.226]
 [0.871]
 [1.226]
 [0.9  ]
 [0.914]] [[4.387]
 [3.946]
 [3.901]
 [4.596]
 [3.901]
 [4.082]
 [3.758]] [[1.881]
 [1.315]
 [2.121]
 [1.874]
 [2.121]
 [1.589]
 [1.4  ]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08064175135120856, 0.6092153685021212, 0.03819317625779615, 0.27194970388887396]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08064175135120856, 0.6092153685021212, 0.03819317625779615, 0.27194970388887396]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08064175135120856, 0.6092153685021212, 0.03819317625779615, 0.27194970388887396]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.08064175135120856, 0.6092153685021212, 0.03819317625779615, 0.27194970388887396]
line 256 mcts: sample exp_bonus 2.3977674536106757
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]] [[2.272]
 [2.272]
 [2.272]
 [2.272]
 [2.272]
 [2.272]
 [2.272]] [[0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
from probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 3.1188286053536607
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
using explorer policy with actor:  0
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.741]
 [0.707]
 [0.741]
 [0.741]
 [0.741]
 [0.741]
 [0.741]] [[4.44 ]
 [4.177]
 [4.44 ]
 [4.44 ]
 [4.44 ]
 [4.44 ]
 [4.44 ]] [[1.956]
 [1.8  ]
 [1.956]
 [1.956]
 [1.956]
 [1.956]
 [1.956]]
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [0.786]
 [0.72 ]
 [0.842]
 [0.72 ]
 [0.884]
 [0.788]] [[4.795]
 [4.471]
 [4.795]
 [4.483]
 [4.795]
 [4.538]
 [4.06 ]] [[2.162]
 [2.089]
 [2.162]
 [2.193]
 [2.162]
 [2.296]
 [1.856]]
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.67 ]
 [0.646]
 [0.646]
 [0.646]
 [0.646]
 [0.646]] [[4.274]
 [5.275]
 [4.453]
 [4.453]
 [4.453]
 [4.453]
 [4.453]] [[0.973]
 [1.359]
 [1.036]
 [1.036]
 [1.036]
 [1.036]
 [1.036]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.752]
 [0.579]
 [0.753]
 [0.753]
 [0.748]
 [0.747]
 [0.748]] [[1.628]
 [2.451]
 [2.03 ]
 [1.671]
 [1.756]
 [1.884]
 [1.795]] [[0.752]
 [0.579]
 [0.753]
 [0.753]
 [0.748]
 [0.747]
 [0.748]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
Printing some Q and Qe and total Qs values:  [[0.758]
 [0.601]
 [0.76 ]
 [0.764]
 [0.752]
 [0.752]
 [0.746]] [[1.574]
 [2.654]
 [2.056]
 [1.773]
 [1.85 ]
 [2.006]
 [1.774]] [[0.758]
 [0.601]
 [0.76 ]
 [0.764]
 [0.752]
 [0.752]
 [0.746]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.76 ]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[0.514]
 [1.104]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]] [[0.784]
 [1.64 ]
 [1.308]
 [1.308]
 [1.308]
 [1.308]
 [1.308]]
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]] [[2.035]
 [2.035]
 [2.035]
 [2.035]
 [2.035]
 [2.035]
 [2.035]] [[1.137]
 [1.137]
 [1.137]
 [1.137]
 [1.137]
 [1.137]
 [1.137]]
siam score:  -0.7273303
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]] [[4.762]
 [4.762]
 [4.762]
 [4.762]
 [4.762]
 [4.762]
 [4.762]] [[0.772]
 [0.772]
 [0.772]
 [0.772]
 [0.772]
 [0.772]
 [0.772]]
Printing some Q and Qe and total Qs values:  [[0.618]
 [0.648]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]] [[1.81 ]
 [2.49 ]
 [1.824]
 [1.824]
 [1.824]
 [1.824]
 [1.824]] [[0.697]
 [1.206]
 [0.7  ]
 [0.7  ]
 [0.7  ]
 [0.7  ]
 [0.7  ]]
Printing some Q and Qe and total Qs values:  [[0.76 ]
 [0.601]
 [0.762]
 [0.765]
 [0.751]
 [0.751]
 [0.748]] [[1.614]
 [2.798]
 [2.048]
 [1.841]
 [1.864]
 [2.073]
 [1.819]] [[0.76 ]
 [0.601]
 [0.762]
 [0.765]
 [0.751]
 [0.751]
 [0.748]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.754]
 [0.757]
 [0.752]
 [0.754]
 [0.754]
 [0.754]] [[1.806]
 [1.795]
 [2.041]
 [1.869]
 [1.795]
 [1.795]
 [1.795]] [[0.751]
 [0.754]
 [0.757]
 [0.752]
 [0.754]
 [0.754]
 [0.754]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
using explorer policy with actor:  0
first move QE:  1.9420227787700233
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06064128494681403, 0.6224902117001472, 0.03900503215912049, 0.27786347119391824]
line 256 mcts: sample exp_bonus 2.2069688214151566
Printing some Q and Qe and total Qs values:  [[-0.033]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]] [[6.124]
 [6.124]
 [6.124]
 [6.124]
 [6.124]
 [6.124]
 [6.124]] [[-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]]
in main func line 156:  1439
Printing some Q and Qe and total Qs values:  [[0.738]
 [0.676]
 [0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]] [[2.849]
 [2.605]
 [2.849]
 [2.849]
 [2.849]
 [2.849]
 [2.849]] [[1.959]
 [1.83 ]
 [1.959]
 [1.959]
 [1.959]
 [1.959]
 [1.959]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03984902829036494, 0.6362905872147331, 0.03984902829036494, 0.2840113562045369]
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.758]
 [0.745]
 [0.744]
 [0.742]
 [0.742]
 [0.743]] [[2.157]
 [2.589]
 [2.095]
 [3.108]
 [2.089]
 [2.192]
 [2.431]] [[0.743]
 [0.758]
 [0.745]
 [0.744]
 [0.742]
 [0.742]
 [0.743]]
rdn probs:  [0.03984902829036494, 0.6362905872147331, 0.03984902829036494, 0.2840113562045369]
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.643]
 [0.682]
 [0.738]
 [0.7  ]
 [0.671]
 [1.086]] [[3.68 ]
 [3.694]
 [4.216]
 [4.357]
 [4.299]
 [4.429]
 [5.688]] [[0.815]
 [0.741]
 [1.013]
 [1.146]
 [1.073]
 [1.091]
 [2.162]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03984902829036494, 0.6362905872147331, 0.03984902829036494, 0.2840113562045369]
Printing some Q and Qe and total Qs values:  [[1.288]
 [1.288]
 [0.055]
 [0.055]
 [0.055]
 [0.055]
 [0.055]] [[1.893]
 [1.869]
 [3.363]
 [3.363]
 [3.363]
 [3.363]
 [3.363]] [[1.181]
 [1.162]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]]
1440 1090
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0373629380805575, 0.6175536565627833, 0.058013639455897506, 0.2870697659007617]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0373629380805575, 0.6175536565627833, 0.058013639455897506, 0.2870697659007617]
siam score:  -0.7331113
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 2.2735108987010393
first move QE:  1.9409347497500324
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0373629380805575, 0.6175536565627833, 0.058013639455897506, 0.2870697659007617]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0373629380805575, 0.6175536565627833, 0.058013639455897506, 0.2870697659007617]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0373629380805575, 0.6175536565627833, 0.058013639455897506, 0.2870697659007617]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0373629380805575, 0.6175536565627833, 0.058013639455897506, 0.2870697659007617]
from probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
Printing some Q and Qe and total Qs values:  [[0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]
 [0.329]] [[4.248]
 [4.248]
 [4.248]
 [4.248]
 [4.248]
 [4.248]
 [4.248]] [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.1312288633208356
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
using explorer policy with actor:  1
UNIT TEST: sample policy line 217 mcts : [0.939 0.02  0.    0.    0.02  0.02  0.   ]
Printing some Q and Qe and total Qs values:  [[0.123]
 [0.054]
 [0.123]
 [0.123]
 [0.123]
 [0.123]
 [0.123]] [[3.331]
 [3.204]
 [3.331]
 [3.331]
 [3.331]
 [3.331]
 [3.331]] [[-0.232]
 [-0.456]
 [-0.232]
 [-0.232]
 [-0.232]
 [-0.232]
 [-0.232]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.574974136145554
Printing some Q and Qe and total Qs values:  [[ 0.021]
 [-0.008]
 [ 0.059]
 [ 0.088]
 [ 0.009]
 [ 0.006]
 [ 0.04 ]] [[3.699]
 [3.527]
 [2.8  ]
 [2.644]
 [2.892]
 [3.055]
 [2.933]] [[-0.091]
 [-0.264]
 [-0.613]
 [-0.66 ]
 [-0.653]
 [-0.55 ]
 [-0.562]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
siam score:  -0.72753423
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03813290857190368, 0.6306075847344533, 0.03813290857190368, 0.2931265981217394]
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.626]
 [0.762]
 [0.706]
 [0.706]
 [0.706]
 [0.683]] [[2.354]
 [2.485]
 [2.79 ]
 [2.354]
 [2.354]
 [2.354]
 [2.718]] [[2.841]
 [2.75 ]
 [3.039]
 [2.841]
 [2.841]
 [2.841]
 [2.899]]
Printing some Q and Qe and total Qs values:  [[0.888]
 [0.711]
 [0.725]
 [0.715]
 [0.728]
 [0.727]
 [0.712]] [[ 1.411]
 [ 1.827]
 [ 0.491]
 [-0.225]
 [ 1.659]
 [-0.801]
 [-0.923]] [[2.555]
 [2.407]
 [2.121]
 [1.944]
 [2.393]
 [1.828]
 [1.781]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
from probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.229]
 [0.072]
 [0.13 ]
 [0.138]
 [0.138]
 [0.123]
 [0.123]] [[-4.583]
 [ 0.019]
 [-2.347]
 [-3.024]
 [-3.024]
 [-2.496]
 [-2.567]] [[0.229]
 [0.072]
 [0.13 ]
 [0.138]
 [0.138]
 [0.123]
 [0.123]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.787]
 [0.8  ]
 [0.79 ]
 [0.791]
 [0.789]
 [0.792]
 [0.793]] [[3.299]
 [4.103]
 [3.277]
 [3.332]
 [3.355]
 [3.453]
 [3.274]] [[1.106]
 [1.667]
 [1.096]
 [1.135]
 [1.147]
 [1.216]
 [1.1  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
from probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.797]
 [0.904]
 [0.797]
 [0.797]
 [0.797]
 [0.797]
 [0.797]] [[3.253]
 [3.68 ]
 [3.253]
 [3.253]
 [3.253]
 [3.253]
 [3.253]] [[1.768]
 [2.098]
 [1.768]
 [1.768]
 [1.768]
 [1.768]
 [1.768]]
first move QE:  1.93377478635609
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.978]
 [0.883]
 [1.024]
 [0.883]
 [0.883]
 [0.883]
 [0.883]] [[2.721]
 [4.144]
 [2.529]
 [4.144]
 [4.144]
 [4.144]
 [4.144]] [[1.232]
 [1.99 ]
 [1.197]
 [1.99 ]
 [1.99 ]
 [1.99 ]
 [1.99 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.431]
 [0.373]
 [0.331]
 [0.331]
 [0.316]
 [0.324]
 [0.355]] [[3.715]
 [4.326]
 [3.51 ]
 [3.432]
 [3.585]
 [3.624]
 [3.409]] [[0.664]
 [0.957]
 [0.33 ]
 [0.277]
 [0.348]
 [0.39 ]
 [0.31 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.445]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]] [[0.035]
 [0.253]
 [0.253]
 [0.253]
 [0.253]
 [0.253]
 [0.253]] [[0.445]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]]
from probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
first move QE:  1.9322958653812337
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.558]
 [0.558]
 [0.558]
 [0.558]
 [0.558]
 [0.558]] [[1.195]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]] [[0.591]
 [0.558]
 [0.558]
 [0.558]
 [0.558]
 [0.558]
 [0.558]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
in main func line 156:  1462
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.545]
 [0.54 ]
 [0.543]
 [0.544]
 [0.545]
 [0.544]] [[2.815]
 [2.925]
 [2.869]
 [2.813]
 [2.877]
 [2.964]
 [2.924]] [[1.391]
 [1.53 ]
 [1.453]
 [1.391]
 [1.47 ]
 [1.578]
 [1.529]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]] [[2.727]
 [2.727]
 [2.727]
 [2.727]
 [2.727]
 [2.727]
 [2.727]] [[0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]]
using explorer policy with actor:  1
from probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.287]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]] [[-1.221]
 [-1.594]
 [-1.594]
 [-1.594]
 [-1.594]
 [-1.594]
 [-1.594]] [[0.287]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.309]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.236]] [[ 0.062]
 [-1.788]
 [-1.788]
 [-1.788]
 [-1.788]
 [-1.788]
 [-1.788]] [[0.309]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.236]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.143]
 [0.068]
 [0.109]
 [0.112]
 [0.098]
 [0.116]
 [0.12 ]] [[-3.227]
 [ 1.473]
 [-2.839]
 [-2.799]
 [-2.801]
 [-3.003]
 [-3.046]] [[0.143]
 [0.068]
 [0.109]
 [0.112]
 [0.098]
 [0.116]
 [0.12 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
first move QE:  1.9260072933396033
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
from probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.914]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]] [[2.371]
 [2.7  ]
 [2.7  ]
 [2.7  ]
 [2.7  ]
 [2.7  ]
 [2.7  ]] [[1.464]
 [1.252]
 [1.252]
 [1.252]
 [1.252]
 [1.252]
 [1.252]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
Printing some Q and Qe and total Qs values:  [[0.597]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.59 ]] [[1.66 ]
 [1.834]
 [1.834]
 [1.834]
 [1.834]
 [1.834]
 [1.663]] [[0.597]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.59 ]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03585712325452165, 0.6130266796012246, 0.05560428571416955, 0.29551191143008426]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Printing some Q and Qe and total Qs values:  [[0.882]
 [0.81 ]
 [0.777]
 [0.863]
 [0.882]
 [0.882]
 [0.866]] [[3.683]
 [3.164]
 [2.923]
 [3.023]
 [3.683]
 [3.683]
 [3.311]] [[2.229]
 [1.826]
 [1.638]
 [1.836]
 [2.229]
 [2.229]
 [1.998]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Printing some Q and Qe and total Qs values:  [[0.173]
 [0.163]
 [0.163]
 [0.163]
 [0.163]
 [0.163]
 [0.163]] [[-3.37 ]
 [-2.676]
 [-2.676]
 [-2.676]
 [-2.676]
 [-2.676]
 [-2.676]] [[0.173]
 [0.163]
 [0.163]
 [0.163]
 [0.163]
 [0.163]
 [0.163]]
Printing some Q and Qe and total Qs values:  [[0.058]
 [0.058]
 [0.058]
 [0.058]
 [0.058]
 [0.058]
 [0.058]] [[4.679]
 [4.679]
 [4.679]
 [4.679]
 [4.679]
 [4.679]
 [4.679]] [[0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]
 [0.32]]
Printing some Q and Qe and total Qs values:  [[0.501]
 [0.447]
 [0.496]
 [0.498]
 [0.505]
 [0.52 ]
 [0.52 ]] [[4.013]
 [3.765]
 [4.027]
 [3.966]
 [4.014]
 [4.   ]
 [3.977]] [[0.976]
 [0.702]
 [0.975]
 [0.939]
 [0.983]
 [1.004]
 [0.99 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.215]
 [0.485]
 [0.492]
 [0.486]
 [0.493]
 [0.47 ]] [[-0.573]
 [ 2.288]
 [-0.02 ]
 [-0.056]
 [ 0.016]
 [ 0.166]
 [ 0.068]] [[0.544]
 [0.215]
 [0.485]
 [0.492]
 [0.486]
 [0.493]
 [0.47 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.87 ]
 [0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]] [[3.829]
 [3.687]
 [3.772]
 [3.772]
 [3.772]
 [3.772]
 [3.772]] [[1.837]
 [1.887]
 [1.874]
 [1.874]
 [1.874]
 [1.874]
 [1.874]]
siam score:  -0.71880853
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Printing some Q and Qe and total Qs values:  [[0.619]
 [0.616]
 [0.635]
 [0.643]
 [0.591]
 [0.609]
 [0.621]] [[5.971]
 [5.124]
 [5.369]
 [5.463]
 [5.799]
 [4.989]
 [4.829]] [[2.131]
 [1.621]
 [1.801]
 [1.87 ]
 [1.978]
 [1.527]
 [1.454]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Printing some Q and Qe and total Qs values:  [[0.262]
 [0.264]
 [0.264]
 [0.264]
 [0.264]
 [0.264]
 [0.264]] [[4.909]
 [4.937]
 [4.937]
 [4.937]
 [4.937]
 [4.937]
 [4.937]] [[0.888]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]]
first move QE:  1.9210227342071737
Printing some Q and Qe and total Qs values:  [[0.986]
 [0.949]
 [0.986]
 [0.885]
 [0.986]
 [0.986]
 [0.82 ]] [[4.18 ]
 [4.235]
 [4.18 ]
 [5.156]
 [4.18 ]
 [4.18 ]
 [5.463]] [[1.804]
 [1.766]
 [1.804]
 [2.252]
 [1.804]
 [1.804]
 [2.326]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
siam score:  -0.72403216
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.587]
 [0.61 ]
 [0.595]
 [0.588]
 [0.593]
 [0.61 ]] [[3.915]
 [4.861]
 [4.576]
 [3.713]
 [3.779]
 [3.421]
 [4.576]] [[0.691]
 [1.469]
 [1.326]
 [0.724]
 [0.754]
 [0.528]
 [1.326]]
Printing some Q and Qe and total Qs values:  [[0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]] [[3.436]
 [3.436]
 [3.436]
 [3.436]
 [3.436]
 [3.436]
 [3.436]] [[1.521]
 [1.521]
 [1.521]
 [1.521]
 [1.521]
 [1.521]
 [1.521]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.55 ]
 [0.594]
 [0.603]
 [0.611]
 [0.595]
 [0.582]] [[5.637]
 [5.049]
 [5.432]
 [5.595]
 [5.215]
 [5.579]
 [5.536]] [[1.619]
 [1.144]
 [1.488]
 [1.615]
 [1.377]
 [1.587]
 [1.532]]
Printing some Q and Qe and total Qs values:  [[0.361]
 [0.359]
 [0.38 ]
 [0.38 ]
 [0.38 ]
 [0.38 ]
 [0.38 ]] [[5.667]
 [5.94 ]
 [5.334]
 [5.334]
 [5.334]
 [5.334]
 [5.334]] [[1.181]
 [1.347]
 [1.009]
 [1.009]
 [1.009]
 [1.009]
 [1.009]]
first move QE:  1.9199593882433168
line 256 mcts: sample exp_bonus 4.976539146007796
using explorer policy with actor:  1
first move QE:  1.9199223038381268
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]] [[1.065]
 [1.065]
 [1.065]
 [1.065]
 [1.065]
 [1.065]
 [1.065]] [[0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03656226508453313, 0.6254063328996646, 0.03656226508453313, 0.30146913693126914]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.663]
 [0.615]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]] [[2.783]
 [3.005]
 [2.783]
 [2.783]
 [2.783]
 [2.783]
 [2.783]] [[0.663]
 [0.615]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.053387130576970386, 0.6088603261223806, 0.03447129869679909, 0.3032812446038499]
Printing some Q and Qe and total Qs values:  [[0.852]
 [0.945]
 [0.852]
 [0.852]
 [0.852]
 [0.852]
 [0.852]] [[2.717]
 [3.375]
 [2.717]
 [2.717]
 [2.717]
 [2.717]
 [2.717]] [[1.118]
 [1.612]
 [1.118]
 [1.118]
 [1.118]
 [1.118]
 [1.118]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]] [[3.089]
 [3.089]
 [3.089]
 [3.089]
 [3.089]
 [3.089]
 [3.089]] [[1.786]
 [1.786]
 [1.786]
 [1.786]
 [1.786]
 [1.786]
 [1.786]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.053387130576970386, 0.6088603261223806, 0.03447129869679909, 0.3032812446038499]
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.932]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]] [[2.971]
 [4.227]
 [2.971]
 [2.971]
 [2.971]
 [2.971]
 [2.971]] [[1.401]
 [2.53 ]
 [1.401]
 [1.401]
 [1.401]
 [1.401]
 [1.401]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
using explorer policy with actor:  1
1499 1134
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.697582930919084
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
siam score:  -0.70855
first move QE:  1.9112213816562562
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
in main func line 156:  1503
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.602]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]] [[0.413]
 [1.239]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]] [[0.52 ]
 [0.602]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.393]
 [0.337]
 [0.384]
 [0.382]
 [0.378]
 [0.444]
 [0.376]] [[3.196]
 [3.5  ]
 [2.38 ]
 [2.331]
 [2.476]
 [3.175]
 [2.555]] [[0.765]
 [0.822]
 [0.412]
 [0.39 ]
 [0.445]
 [0.82 ]
 [0.476]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
line 256 mcts: sample exp_bonus 4.074809817195206
Printing some Q and Qe and total Qs values:  [[1.012]
 [0.92 ]
 [0.92 ]
 [0.753]
 [0.92 ]
 [0.92 ]
 [0.92 ]] [[3.873]
 [2.71 ]
 [2.71 ]
 [2.533]
 [2.71 ]
 [2.71 ]
 [2.71 ]] [[2.006]
 [1.014]
 [1.014]
 [0.688]
 [1.014]
 [1.014]
 [1.014]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.917]
 [0.919]
 [0.901]
 [0.915]
 [0.917]
 [0.914]
 [0.894]] [[2.642]
 [2.871]
 [2.783]
 [2.59 ]
 [2.841]
 [2.924]
 [2.846]] [[1.166]
 [1.357]
 [1.263]
 [1.122]
 [1.33 ]
 [1.395]
 [1.306]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
from probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
Printing some Q and Qe and total Qs values:  [[0.339]
 [0.231]
 [0.231]
 [0.231]
 [0.231]
 [0.231]
 [0.231]] [[ 1.588]
 [-0.99 ]
 [-0.99 ]
 [-0.99 ]
 [-0.99 ]
 [-0.99 ]
 [-0.99 ]] [[0.339]
 [0.231]
 [0.231]
 [0.231]
 [0.231]
 [0.231]
 [0.231]]
Printing some Q and Qe and total Qs values:  [[0.14 ]
 [0.116]
 [0.116]
 [0.116]
 [0.116]
 [0.116]
 [0.116]] [[-2.765]
 [-2.784]
 [-2.784]
 [-2.784]
 [-2.784]
 [-2.784]
 [-2.784]] [[0.14 ]
 [0.116]
 [0.116]
 [0.116]
 [0.116]
 [0.116]
 [0.116]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
Printing some Q and Qe and total Qs values:  [[0.56 ]
 [0.424]
 [0.499]
 [0.494]
 [0.494]
 [0.494]
 [0.513]] [[-0.157]
 [ 1.928]
 [ 0.668]
 [ 0.844]
 [ 0.844]
 [ 0.844]
 [ 0.606]] [[0.56 ]
 [0.424]
 [0.499]
 [0.494]
 [0.494]
 [0.494]
 [0.513]]
UNIT TEST: sample policy line 217 mcts : [0.653 0.082 0.082 0.061 0.041 0.02  0.061]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
1512 1143
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.369]
 [0.128]
 [0.128]
 [0.128]
 [0.128]
 [0.128]
 [0.128]] [[4.526]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]] [[0.369]
 [0.128]
 [0.128]
 [0.128]
 [0.128]
 [0.128]
 [0.128]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
1517 1152
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0683408407462961, 0.5941544617623717, 0.032612876390241456, 0.30489182110109075]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05134008000991422, 0.6050131443379116, 0.03319167191127091, 0.3104551037409033]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05134008000991422, 0.6050131443379116, 0.03319167191127091, 0.3104551037409033]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
Printing some Q and Qe and total Qs values:  [[0.845]
 [0.866]
 [0.893]
 [0.893]
 [0.893]
 [0.893]
 [0.864]] [[3.703]
 [4.392]
 [4.34 ]
 [4.34 ]
 [4.34 ]
 [4.34 ]
 [4.769]] [[1.522]
 [1.947]
 [1.963]
 [1.963]
 [1.963]
 [1.963]
 [2.155]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
Printing some Q and Qe and total Qs values:  [[0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]] [[5.158]
 [5.158]
 [5.158]
 [5.158]
 [5.158]
 [5.158]
 [5.158]] [[0.984]
 [0.984]
 [0.984]
 [0.984]
 [0.984]
 [0.984]
 [0.984]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]] [[1.723]
 [1.723]
 [1.723]
 [1.723]
 [1.723]
 [1.723]
 [1.723]] [[0.58]
 [0.58]
 [0.58]
 [0.58]
 [0.58]
 [0.58]
 [0.58]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
Printing some Q and Qe and total Qs values:  [[0.773]
 [0.933]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]] [[2.811]
 [3.433]
 [2.811]
 [2.811]
 [2.811]
 [2.811]
 [2.811]] [[2.021]
 [2.475]
 [2.021]
 [2.021]
 [2.021]
 [2.021]
 [2.021]]
siam score:  -0.7138731
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
using explorer policy with actor:  1
using explorer policy with actor:  1
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]] [[-0.405]
 [ 0.106]
 [ 0.106]
 [ 0.106]
 [ 0.106]
 [ 0.106]
 [ 0.106]] [[0.518]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.386]
 [0.441]
 [0.444]
 [0.431]
 [0.427]
 [0.429]] [[-0.917]
 [ 2.049]
 [ 0.293]
 [ 0.142]
 [ 0.382]
 [ 0.267]
 [ 0.268]] [[0.622]
 [0.386]
 [0.441]
 [0.444]
 [0.431]
 [0.427]
 [0.429]]
Printing some Q and Qe and total Qs values:  [[0.932]
 [0.932]
 [0.932]
 [0.932]
 [0.932]
 [0.932]
 [0.932]] [[2.75]
 [2.75]
 [2.75]
 [2.75]
 [2.75]
 [2.75]
 [2.75]] [[1.954]
 [1.954]
 [1.954]
 [1.954]
 [1.954]
 [1.954]
 [1.954]]
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.1  ]
 [0.1  ]
 [0.1  ]
 [0.1  ]
 [0.1  ]
 [0.1  ]] [[-2.433]
 [-1.437]
 [-1.437]
 [-1.437]
 [-1.437]
 [-1.437]
 [-1.437]] [[0.193]
 [0.1  ]
 [0.1  ]
 [0.1  ]
 [0.1  ]
 [0.1  ]
 [0.1  ]]
Printing some Q and Qe and total Qs values:  [[0.792]
 [0.846]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]] [[2.481]
 [3.434]
 [2.632]
 [2.632]
 [2.632]
 [2.632]
 [2.632]] [[0.681]
 [1.209]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
line 256 mcts: sample exp_bonus 0.10573245499830666
Printing some Q and Qe and total Qs values:  [[0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]] [[0.165]
 [0.165]
 [0.165]
 [0.165]
 [0.165]
 [0.165]
 [0.165]] [[0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
line 256 mcts: sample exp_bonus 5.178885350376002
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03378919651129499, 0.6162231999223027, 0.03378919651129499, 0.3161984070551073]
Printing some Q and Qe and total Qs values:  [[0.885]
 [0.817]
 [0.885]
 [0.885]
 [0.885]
 [0.885]
 [0.885]] [[2.203]
 [2.754]
 [2.203]
 [2.203]
 [2.203]
 [2.203]
 [2.203]] [[1.124]
 [1.355]
 [1.124]
 [1.124]
 [1.124]
 [1.124]
 [1.124]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.864]
 [0.864]
 [0.864]
 [0.864]
 [0.864]
 [0.864]
 [0.864]] [[2.705]
 [2.705]
 [2.705]
 [2.705]
 [2.705]
 [2.705]
 [2.705]] [[2.03]
 [2.03]
 [2.03]
 [2.03]
 [2.03]
 [2.03]
 [2.03]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
Printing some Q and Qe and total Qs values:  [[0.448]
 [0.452]
 [0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]] [[2.469]
 [2.774]
 [2.469]
 [2.469]
 [2.469]
 [2.469]
 [2.469]] [[0.448]
 [0.452]
 [0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
Printing some Q and Qe and total Qs values:  [[0.486]
 [0.442]
 [0.539]
 [0.492]
 [0.539]
 [0.484]
 [0.539]] [[5.028]
 [5.267]
 [3.627]
 [5.068]
 [3.627]
 [5.101]
 [3.627]] [[0.486]
 [0.442]
 [0.539]
 [0.492]
 [0.539]
 [0.484]
 [0.539]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
Printing some Q and Qe and total Qs values:  [[0.749]
 [0.732]
 [0.749]
 [0.749]
 [0.749]
 [0.749]
 [0.749]] [[0.831]
 [2.294]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]] [[0.219]
 [1.16 ]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
line 256 mcts: sample exp_bonus 3.0751882170273297
siam score:  -0.7326524
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.553]
 [0.555]
 [0.549]
 [0.543]
 [0.551]
 [0.546]
 [0.559]] [[2.176]
 [2.422]
 [2.017]
 [2.036]
 [2.228]
 [2.186]
 [2.16 ]] [[0.553]
 [0.555]
 [0.549]
 [0.543]
 [0.551]
 [0.546]
 [0.559]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
line 256 mcts: sample exp_bonus 4.308843647186646
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
Printing some Q and Qe and total Qs values:  [[0.21 ]
 [0.286]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]] [[2.049]
 [2.126]
 [2.049]
 [2.049]
 [2.049]
 [2.049]
 [2.049]] [[0.21 ]
 [0.286]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
siam score:  -0.73028183
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.032006486266901474, 0.6014498010153815, 0.04944430121933037, 0.31709941149838666]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.030407897606898226, 0.588202225849096, 0.06348251799411816, 0.3179073585498877]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.73305565
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.697]
 [0.697]
 [0.701]
 [0.697]
 [0.697]
 [0.697]
 [0.697]] [[2.059]
 [2.059]
 [2.107]
 [2.059]
 [2.059]
 [2.059]
 [2.059]] [[0.596]
 [0.596]
 [0.634]
 [0.596]
 [0.596]
 [0.596]
 [0.596]]
using another actor
Printing some Q and Qe and total Qs values:  [[0.901]
 [0.936]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]] [[2.934]
 [2.802]
 [2.934]
 [2.934]
 [2.934]
 [2.934]
 [2.934]] [[1.971]
 [1.957]
 [1.971]
 [1.971]
 [1.971]
 [1.971]
 [1.971]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.030407897606898226, 0.588202225849096, 0.06348251799411816, 0.3179073585498877]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.030407897606898226, 0.588202225849096, 0.06348251799411816, 0.3179073585498877]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.030407897606898226, 0.588202225849096, 0.06348251799411816, 0.3179073585498877]
Printing some Q and Qe and total Qs values:  [[0.928]
 [0.896]
 [0.888]
 [0.819]
 [0.928]
 [0.925]
 [0.888]] [[3.967]
 [3.094]
 [3.312]
 [3.946]
 [3.967]
 [3.238]
 [3.163]] [[2.277]
 [1.849]
 [1.936]
 [2.123]
 [2.277]
 [1.951]
 [1.87 ]]
Printing some Q and Qe and total Qs values:  [[1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]] [[1.878]
 [1.878]
 [1.878]
 [1.878]
 [1.878]
 [1.878]
 [1.878]] [[1.825]
 [1.825]
 [1.825]
 [1.825]
 [1.825]
 [1.825]
 [1.825]]
1545 1192
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
Printing some Q and Qe and total Qs values:  [[1.47]
 [1.47]
 [1.47]
 [1.47]
 [1.47]
 [1.47]
 [1.47]] [[1.877]
 [1.877]
 [1.877]
 [1.877]
 [1.877]
 [1.877]
 [1.877]] [[2.691]
 [2.691]
 [2.691]
 [2.691]
 [2.691]
 [2.691]
 [2.691]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
using explorer policy with actor:  1
siam score:  -0.7222287
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.896]
 [0.788]
 [0.788]
 [0.788]
 [0.912]
 [0.788]] [[2.249]
 [1.659]
 [0.476]
 [0.476]
 [0.476]
 [0.502]
 [0.476]] [[1.071]
 [1.411]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.873]
 [0.68 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
Printing some Q and Qe and total Qs values:  [[0.753]
 [0.804]
 [0.786]
 [0.749]
 [0.786]
 [0.786]
 [0.786]] [[1.259]
 [2.19 ]
 [2.144]
 [1.164]
 [2.144]
 [2.144]
 [2.144]] [[0.567]
 [1.29 ]
 [1.223]
 [0.496]
 [1.223]
 [1.223]
 [1.223]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]] [[3.42]
 [3.42]
 [3.42]
 [3.42]
 [3.42]
 [3.42]
 [3.42]] [[0.395]
 [0.395]
 [0.395]
 [0.395]
 [0.395]
 [0.395]
 [0.395]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
from probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03090565873176155, 0.5981399927300476, 0.0476836423403078, 0.323270706197883]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3282975805946582, 0.0010520891269583286, 0.32906039059807934, 0.34158993968030404]
Printing some Q and Qe and total Qs values:  [[0.796]
 [0.741]
 [0.791]
 [0.789]
 [0.771]
 [0.781]
 [0.771]] [[2.382]
 [2.586]
 [2.295]
 [2.267]
 [2.269]
 [2.335]
 [2.263]] [[1.564]
 [1.704]
 [1.455]
 [1.417]
 [1.39 ]
 [1.483]
 [1.383]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3277874258107283, 0.0010521319045741575, 0.3293106672741603, 0.3418497750105373]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3277874258107283, 0.0010521319045741575, 0.3293106672741603, 0.3418497750105373]
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [0.84 ]
 [0.86 ]
 [0.879]
 [0.816]
 [0.834]
 [0.793]] [[3.275]
 [2.935]
 [2.487]
 [2.81 ]
 [1.908]
 [1.915]
 [2.935]] [[1.706]
 [1.648]
 [1.414]
 [1.622]
 [1.032]
 [1.057]
 [1.595]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3277874258107283, 0.0010521319045741575, 0.3293106672741603, 0.3418497750105373]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3277874258107283, 0.0010521319045741575, 0.3293106672741603, 0.3418497750105373]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3280380857368687, 0.0010521749473961222, 0.32879851808754185, 0.34211122122819343]
Printing some Q and Qe and total Qs values:  [[0.458]
 [0.418]
 [0.469]
 [0.467]
 [0.418]
 [0.418]
 [0.434]] [[3.709]
 [3.103]
 [3.695]
 [3.799]
 [3.103]
 [3.103]
 [3.187]] [[1.179]
 [0.781]
 [1.181]
 [1.241]
 [0.781]
 [0.781]
 [0.846]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3280380857368687, 0.0010521749473961222, 0.32879851808754185, 0.34211122122819343]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3280380857368687, 0.0010521749473961222, 0.32879851808754185, 0.34211122122819343]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3280380857368687, 0.0010521749473961222, 0.32879851808754185, 0.34211122122819343]
line 256 mcts: sample exp_bonus 2.921217380030718
siam score:  -0.71221274
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3280380857368687, 0.0010521749473961222, 0.32879851808754185, 0.34211122122819343]
Printing some Q and Qe and total Qs values:  [[0.121]
 [0.197]
 [0.055]
 [0.052]
 [0.102]
 [0.129]
 [0.088]] [[2.945]
 [1.945]
 [2.352]
 [2.308]
 [3.074]
 [3.015]
 [2.778]] [[1.305]
 [0.124]
 [0.383]
 [0.319]
 [1.44 ]
 [1.416]
 [1.018]]
Printing some Q and Qe and total Qs values:  [[0.091]
 [0.035]
 [0.12 ]
 [0.093]
 [0.066]
 [0.045]
 [0.072]] [[-3.409]
 [ 0.744]
 [-1.391]
 [-1.759]
 [-1.923]
 [-1.986]
 [-1.982]] [[0.091]
 [0.035]
 [0.12 ]
 [0.093]
 [0.066]
 [0.045]
 [0.072]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32827603394514043, 0.0010523461790768703, 0.32752032104036893, 0.34315129883541373]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32827603394514043, 0.0010523461790768703, 0.32752032104036893, 0.34315129883541373]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32827603394514043, 0.0010523461790768703, 0.32752032104036893, 0.34315129883541373]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32776825482220745, 0.00105238895129908, 0.32776825482220745, 0.3434111014042859]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32776825482220745, 0.00105238895129908, 0.32776825482220745, 0.3434111014042859]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.47 ]
 [0.452]
 [0.443]
 [0.448]
 [0.456]
 [0.459]
 [0.448]] [[3.763]
 [4.822]
 [3.496]
 [4.092]
 [4.033]
 [4.393]
 [4.942]] [[0.47 ]
 [0.452]
 [0.443]
 [0.448]
 [0.456]
 [0.459]
 [0.448]]
Printing some Q and Qe and total Qs values:  [[0.153]
 [0.125]
 [0.125]
 [0.125]
 [0.125]
 [0.159]
 [0.125]] [[5.129]
 [4.877]
 [4.877]
 [4.877]
 [4.877]
 [4.615]
 [4.877]] [[-0.187]
 [-0.327]
 [-0.327]
 [-0.327]
 [-0.327]
 [-0.347]
 [-0.327]]
Printing some Q and Qe and total Qs values:  [[0.379]
 [0.18 ]
 [0.18 ]
 [0.18 ]
 [0.18 ]
 [0.195]
 [0.18 ]] [[4.168]
 [3.932]
 [3.932]
 [3.932]
 [3.932]
 [4.088]
 [3.932]] [[ 0.031]
 [-0.446]
 [-0.446]
 [-0.446]
 [-0.446]
 [-0.363]
 [-0.446]]
Printing some Q and Qe and total Qs values:  [[0.14 ]
 [0.095]
 [0.099]
 [0.14 ]
 [0.14 ]
 [0.09 ]
 [0.14 ]] [[1.597]
 [1.851]
 [1.794]
 [1.597]
 [1.597]
 [1.793]
 [1.597]] [[0.14 ]
 [0.095]
 [0.099]
 [0.14 ]
 [0.14 ]
 [0.09 ]
 [0.14 ]]
siam score:  -0.70438623
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.327262049312729, 0.001052431590969673, 0.32801542025434977, 0.34367009884195154]
Printing some Q and Qe and total Qs values:  [[-0.007]
 [-0.013]
 [ 0.185]
 [ 0.026]
 [-0.006]
 [-0.002]
 [-0.009]] [[5.312]
 [4.4  ]
 [4.799]
 [4.219]
 [4.779]
 [4.519]
 [4.631]] [[-0.566]
 [-0.882]
 [-0.354]
 [-0.866]
 [-0.742]
 [-0.821]
 [-0.798]]
in main func line 156:  1559
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32750901866267773, 0.001052474295193057, 0.32750901866267773, 0.34392948837945153]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3270041834107719, 0.0010525168673289325, 0.3277552241170932, 0.3441880756048059]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32725019369955194, 0.0010525595037158598, 0.32725019369955194, 0.3444470530971802]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32725019369955194, 0.0010525595037158598, 0.32725019369955194, 0.3444470530971802]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32749544451270013, 0.0010526020084770037, 0.3267467223968647, 0.3447052310819581]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32749544451270013, 0.0010526020084770037, 0.3267467223968647, 0.3447052310819581]
Printing some Q and Qe and total Qs values:  [[0.122]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]] [[-1.972]
 [-2.159]
 [-2.159]
 [-2.159]
 [-2.159]
 [-2.159]
 [-2.159]] [[0.122]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3277399393617419, 0.0010526443822209543, 0.3262448030002796, 0.34496261325575767]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32822667510570086, 0.001052728739072912, 0.3252455913119276, 0.3454750048432986]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32822667510570086, 0.001052728739072912, 0.3252455913119276, 0.3454750048432986]
line 256 mcts: sample exp_bonus 1.4252850076700088
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32822667510570086, 0.001052728739072912, 0.3252455913119276, 0.3454750048432986]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32822667510570086, 0.001052728739072912, 0.3252455913119276, 0.3454750048432986]
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]] [[1.832]
 [1.749]
 [1.749]
 [1.749]
 [1.749]
 [1.749]
 [1.749]] [[0.462]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3284689229162587, 0.0010527707233794806, 0.3247482848231578, 0.34573002153720406]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3284689229162587, 0.0010527707233794806, 0.3247482848231578, 0.34573002153720406]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32871042859431854, 0.001052812579066027, 0.32425250184581167, 0.3459842569808037]
Printing some Q and Qe and total Qs values:  [[0.453]
 [0.371]
 [0.371]
 [0.371]
 [0.371]
 [0.371]
 [0.371]] [[5.179]
 [4.034]
 [4.034]
 [4.034]
 [4.034]
 [4.034]
 [4.034]] [[ 0.207]
 [-0.339]
 [-0.339]
 [-0.339]
 [-0.339]
 [-0.339]
 [-0.339]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3291912271525355, 0.001052895906936029, 0.3232654785070168, 0.3464903984335116]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3291912271525355, 0.001052895906936029, 0.3232654785070168, 0.3464903984335116]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3286862260019063, 0.001052938919154074, 0.32350917631888315, 0.3467516587600564]
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.776]
 [1.097]
 [0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.748]] [[3.024]
 [6.575]
 [3.763]
 [3.763]
 [3.763]
 [3.763]
 [3.763]] [[0.473]
 [1.734]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.604]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.522]
 [0.55 ]
 [0.492]
 [0.502]
 [0.724]
 [0.52 ]
 [0.51 ]] [[3.39 ]
 [3.606]
 [3.228]
 [3.457]
 [4.006]
 [3.199]
 [3.372]] [[ 0.   ]
 [ 0.128]
 [-0.113]
 [-0.017]
 [ 0.611]
 [-0.068]
 [-0.03 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3281827769767872, 0.0010529817991736898, 0.3237521251233659, 0.34701211610067334]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3281827769767872, 0.0010529817991736898, 0.3237521251233659, 0.34701211610067334]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3281827769767872, 0.0010529817991736898, 0.3237521251233659, 0.34701211610067334]
Printing some Q and Qe and total Qs values:  [[0.987]
 [1.198]
 [0.987]
 [0.987]
 [0.987]
 [0.987]
 [0.987]] [[2.981]
 [3.802]
 [2.981]
 [2.981]
 [2.981]
 [2.981]
 [2.981]] [[1.663]
 [2.36 ]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]]
Printing some Q and Qe and total Qs values:  [[0.98 ]
 [0.91 ]
 [0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.916]] [[5.533]
 [4.724]
 [4.463]
 [4.463]
 [4.463]
 [4.463]
 [4.664]] [[2.337]
 [1.926]
 [1.875]
 [1.875]
 [1.875]
 [1.875]
 [1.918]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3269200342651941, 0.0010531514378612468, 0.3239842965820649, 0.34804251771487976]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.1056476402649706
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3269200342651941, 0.0010531514378612468, 0.3239842965820649, 0.34804251771487976]
1569 1235
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.326422535456986, 0.0010531938571819327, 0.3242240939596901, 0.348300176726142]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32689671890998223, 0.0010532771719161476, 0.3232437655272685, 0.34880623839083313]
Printing some Q and Qe and total Qs values:  [[0.384]
 [0.364]
 [0.384]
 [0.384]
 [0.384]
 [0.384]
 [0.384]] [[3.684]
 [2.762]
 [3.684]
 [3.684]
 [3.684]
 [3.684]
 [3.684]] [[0.384]
 [0.364]
 [0.384]
 [0.384]
 [0.384]
 [0.384]
 [0.384]]
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32689671890998223, 0.0010532771719161476, 0.3232437655272685, 0.34880623839083313]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32689671890998223, 0.0010532771719161476, 0.3232437655272685, 0.34880623839083313]
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.368]
 [0.353]
 [0.355]
 [0.342]
 [0.335]
 [0.361]] [[0.979]
 [1.628]
 [1.061]
 [1.048]
 [1.377]
 [1.302]
 [1.116]] [[0.367]
 [0.368]
 [0.353]
 [0.355]
 [0.342]
 [0.335]
 [0.361]]
Printing some Q and Qe and total Qs values:  [[0.345]
 [0.373]
 [0.381]
 [0.334]
 [0.308]
 [0.334]
 [0.301]] [[0.01 ]
 [0.88 ]
 [0.485]
 [0.421]
 [0.521]
 [0.68 ]
 [0.558]] [[0.345]
 [0.373]
 [0.381]
 [0.334]
 [0.308]
 [0.334]
 [0.301]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32689671890998223, 0.0010532771719161476, 0.3232437655272685, 0.34880623839083313]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32640036496155933, 0.0010533195852788075, 0.3234824542406957, 0.34906386121246613]
Printing some Q and Qe and total Qs values:  [[0.255]
 [0.269]
 [0.269]
 [0.269]
 [0.269]
 [0.269]
 [0.269]] [[-4.945]
 [-4.293]
 [-4.293]
 [-4.293]
 [-4.293]
 [-4.293]
 [-4.293]] [[0.255]
 [0.269]
 [0.269]
 [0.269]
 [0.269]
 [0.269]
 [0.269]]
Printing some Q and Qe and total Qs values:  [[0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]] [[1.805]
 [1.851]
 [1.852]
 [1.852]
 [1.852]
 [1.852]
 [1.852]] [[0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32663619463617083, 0.0010533611148433116, 0.3229943284893998, 0.34931611575958604]
Starting evaluation
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.49 ]
 [0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.351]] [[2.579]
 [2.801]
 [2.801]
 [2.801]
 [2.801]
 [2.801]
 [2.801]] [[0.49 ]
 [0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.351]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3268713112840705, 0.0010534025188439398, 0.3225076785773934, 0.3495676076196922]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]] [[3.202]
 [3.202]
 [3.202]
 [3.202]
 [3.202]
 [3.202]
 [3.202]] [[0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]]
Printing some Q and Qe and total Qs values:  [[0.242]
 [0.168]
 [0.254]
 [0.259]
 [0.233]
 [0.271]
 [0.27 ]] [[3.252]
 [2.549]
 [3.246]
 [3.136]
 [3.202]
 [3.124]
 [3.104]] [[0.242]
 [0.168]
 [0.254]
 [0.259]
 [0.233]
 [0.271]
 [0.27 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32710571813411204, 0.0010534437978492873, 0.32202249782152, 0.3498183402465188]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32710571813411204, 0.0010534437978492873, 0.32202249782152, 0.3498183402465188]
rdn probs:  [0.32733941839568304, 0.001053484952424529, 0.32153877957891397, 0.35006831707297853]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32733941839568304, 0.001053484952424529, 0.32153877957891397, 0.35006831707297853]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32684384030615227, 0.0010535274812483973, 0.3217759909955426, 0.3503266412170567]
UNIT TEST: sample policy line 217 mcts : [0.02  0.857 0.041 0.02  0.02  0.02  0.02 ]
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.58 ]
 [0.588]
 [0.592]
 [0.569]
 [0.643]
 [0.61 ]] [[5.24 ]
 [4.898]
 [3.742]
 [4.857]
 [4.947]
 [5.918]
 [5.084]] [[0.676]
 [0.558]
 [0.189]
 [0.568]
 [0.552]
 [1.025]
 [0.681]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32559836921195984, 0.0010536955689930843, 0.3220003129631465, 0.35134762225590055]
siam score:  -0.7201416
line 256 mcts: sample exp_bonus 5.583156997324477
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32559836921195984, 0.0010536955689930843, 0.3220003129631465, 0.35134762225590055]
Printing some Q and Qe and total Qs values:  [[0.863]
 [0.855]
 [0.855]
 [0.857]
 [0.851]
 [0.855]
 [0.855]] [[3.777]
 [3.719]
 [3.719]
 [3.758]
 [3.767]
 [3.719]
 [3.719]] [[2.224]
 [2.151]
 [2.151]
 [2.192]
 [2.191]
 [2.151]
 [2.151]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.58 ]
 [0.294]
 [0.269]
 [0.238]
 [0.172]
 [0.546]
 [0.216]] [[ 1.416]
 [ 2.068]
 [ 1.707]
 [-0.332]
 [ 0.305]
 [ 2.36 ]
 [ 2.529]] [[0.58 ]
 [0.294]
 [0.269]
 [0.238]
 [0.172]
 [0.546]
 [0.216]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3253399751392656, 0.0010537788546909994, 0.32175273845470176, 0.3518535075513417]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3253399751392656, 0.0010537788546909994, 0.32175273845470176, 0.3518535075513417]
Printing some Q and Qe and total Qs values:  [[0.897]
 [0.924]
 [1.16 ]
 [1.004]
 [0.898]
 [0.827]
 [0.886]] [[1.594]
 [1.868]
 [1.672]
 [1.537]
 [1.355]
 [1.135]
 [1.087]] [[0.534]
 [0.795]
 [0.926]
 [0.62 ]
 [0.338]
 [0.067]
 [0.101]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3253399751392656, 0.0010537788546909994, 0.32175273845470176, 0.3518535075513417]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3253399751392656, 0.0010537788546909994, 0.32175273845470176, 0.3518535075513417]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32485148350728105, 0.001053820864337462, 0.321986017466193, 0.35210867816218855]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.716]
 [0.724]
 [0.724]
 [0.724]
 [0.724]
 [0.724]
 [0.724]] [[3.361]
 [3.215]
 [3.215]
 [3.215]
 [3.215]
 [3.215]
 [3.215]] [[1.718]
 [1.589]
 [1.589]
 [1.589]
 [1.589]
 [1.589]
 [1.589]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32459480194278995, 0.0010539039528003286, 0.32173792867135514, 0.35261336543305455]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32505342046082814, 0.0010539859942587876, 0.3207809004458843, 0.35311169309902884]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3245673245368584, 0.0010540279298955528, 0.32101223336535323, 0.35336641416789283]
Printing some Q and Qe and total Qs values:  [[1.018]
 [0.997]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]] [[4.167]
 [3.648]
 [4.02 ]
 [4.02 ]
 [4.02 ]
 [4.02 ]
 [4.02 ]] [[1.886]
 [1.671]
 [1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]]
from probs:  [0.32453786611950763, 0.0010541515290393138, 0.3202908151620836, 0.3541171671893695]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32453786611950763, 0.0010541515290393138, 0.3202908151620836, 0.3541171671893695]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32453786611950763, 0.0010541515290393138, 0.3202908151620836, 0.3541171671893695]
siam score:  -0.7123961
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32453786611950763, 0.0010541515290393138, 0.3202908151620836, 0.3541171671893695]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32453786611950763, 0.0010541515290393138, 0.3202908151620836, 0.3541171671893695]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.46293464994881
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3240543227631707, 0.0010541933315120632, 0.3205204044980541, 0.3543710794072632]
Printing some Q and Qe and total Qs values:  [[0.512]
 [0.46 ]
 [0.499]
 [0.499]
 [0.499]
 [0.499]
 [0.499]] [[2.868]
 [2.918]
 [3.041]
 [3.041]
 [3.041]
 [3.041]
 [3.041]] [[0.718]
 [0.629]
 [0.749]
 [0.749]
 [0.749]
 [0.749]
 [0.749]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3240543227631707, 0.0010541933315120632, 0.3205204044980541, 0.3543710794072632]
Printing some Q and Qe and total Qs values:  [[0.374]
 [0.354]
 [0.471]
 [0.474]
 [0.456]
 [0.474]
 [0.482]] [[3.301]
 [4.036]
 [2.552]
 [2.536]
 [2.694]
 [2.527]
 [2.578]] [[0.12 ]
 [0.326]
 [0.064]
 [0.065]
 [0.081]
 [0.061]
 [0.094]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32354298966017797, 0.001054358217145719, 0.320030041605243, 0.35537261051743324]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32354298966017797, 0.001054358217145719, 0.320030041605243, 0.35537261051743324]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32354298966017797, 0.001054358217145719, 0.320030041605243, 0.35537261051743324]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.667641084160128
1588 1269
Printing some Q and Qe and total Qs values:  [[0.827]
 [0.867]
 [0.834]
 [0.834]
 [0.834]
 [0.834]
 [0.834]] [[3.12 ]
 [3.341]
 [2.821]
 [2.821]
 [2.821]
 [2.821]
 [2.821]] [[1.409]
 [1.562]
 [1.323]
 [1.323]
 [1.323]
 [1.323]
 [1.323]]
Printing some Q and Qe and total Qs values:  [[0.762]
 [1.065]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]] [[1.502]
 [2.671]
 [1.502]
 [1.502]
 [1.502]
 [1.502]
 [1.502]] [[0.598]
 [1.594]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]]
Printing some Q and Qe and total Qs values:  [[0.803]
 [0.885]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]] [[2.472]
 [3.041]
 [2.472]
 [2.472]
 [2.472]
 [2.472]
 [2.472]] [[1.012]
 [1.366]
 [1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.012]]
Printing some Q and Qe and total Qs values:  [[0.702]
 [0.979]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]] [[1.497]
 [2.656]
 [1.497]
 [1.497]
 [1.497]
 [1.497]
 [1.497]] [[0.485]
 [1.425]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3237677030183153, 0.0010543988632869894, 0.31955839905107586, 0.35561949906732176]
line 256 mcts: sample exp_bonus 2.555012369524553
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]] [[3.62]
 [3.62]
 [3.62]
 [3.62]
 [3.62]
 [3.62]
 [3.62]] [[0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]]
first move QE:  1.8309494246095372
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3237677030183153, 0.0010543988632869894, 0.31955839905107586, 0.35561949906732176]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3232879461416535, 0.001054440467223089, 0.31978540803649663, 0.3558722053546267]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32280961371754713, 0.0010544819476323898, 0.32001174300650437, 0.35612416132831615]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32280961371754713, 0.0010544819476323898, 0.32001174300650437, 0.35612416132831615]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32280961371754713, 0.0010544819476323898, 0.32001174300650437, 0.35612416132831615]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.178]
 [0.191]
 [0.18 ]
 [0.176]
 [0.17 ]
 [0.167]] [[-2.645]
 [ 0.587]
 [-3.041]
 [-3.215]
 [-3.286]
 [-3.345]
 [-3.29 ]] [[0.193]
 [0.178]
 [0.191]
 [0.18 ]
 [0.176]
 [0.17 ]
 [0.167]]
Printing some Q and Qe and total Qs values:  [[0.015]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.032]] [[4.723]
 [4.687]
 [4.687]
 [4.687]
 [4.687]
 [4.687]
 [4.627]] [[-0.816]
 [-0.851]
 [-0.851]
 [-0.851]
 [-0.851]
 [-0.851]
 [-0.813]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3223326994113586, 0.0010545233050642156, 0.32023740695849146, 0.3563753703250856]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3213831000014337, 0.0010546056531765518, 0.3206867337093724, 0.3568755606360173]
siam score:  -0.712577
siam score:  -0.70970964
Printing some Q and Qe and total Qs values:  [[0.312]
 [0.308]
 [0.308]
 [0.308]
 [0.308]
 [0.308]
 [0.308]] [[1.787]
 [1.846]
 [1.846]
 [1.846]
 [1.846]
 [1.846]
 [1.846]] [[0.312]
 [0.308]
 [0.308]
 [0.308]
 [0.308]
 [0.308]
 [0.308]]
siam score:  -0.71064657
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.399]
 [0.197]
 [0.262]
 [0.27 ]
 [0.27 ]
 [0.271]
 [0.27 ]] [[-6.249]
 [ 0.485]
 [-3.476]
 [-4.621]
 [-4.621]
 [-4.135]
 [-4.621]] [[0.399]
 [0.197]
 [0.262]
 [0.27 ]
 [0.27 ]
 [0.271]
 [0.27 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3201918436912653, 0.0010547692514265782, 0.3208841150024146, 0.35786927205489355]
Printing some Q and Qe and total Qs values:  [[0.262]
 [0.519]
 [0.566]
 [0.681]
 [0.441]
 [0.501]
 [0.699]] [[3.468]
 [3.587]
 [3.171]
 [3.197]
 [3.452]
 [3.41 ]
 [3.103]] [[1.444]
 [1.843]
 [1.64 ]
 [1.801]
 [1.66 ]
 [1.708]
 [1.765]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3204138519906518, 0.0010548101157564045, 0.3204138519906518, 0.35811748590293996]
Printing some Q and Qe and total Qs values:  [[0.294]
 [0.813]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.89 ]] [[2.017]
 [2.205]
 [1.924]
 [1.924]
 [1.924]
 [1.924]
 [2.273]] [[1.626]
 [1.882]
 [1.768]
 [1.768]
 [1.768]
 [1.768]
 [1.931]]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32085591557551096, 0.0010548914849312768, 0.3194774628854654, 0.35861173005409236]
Printing some Q and Qe and total Qs values:  [[0.593]
 [0.622]
 [0.593]
 [0.796]
 [0.593]
 [0.593]
 [0.593]] [[2.562]
 [3.07 ]
 [2.562]
 [2.292]
 [2.562]
 [2.562]
 [2.562]] [[1.161]
 [1.633]
 [1.161]
 [1.19 ]
 [1.161]
 [1.161]
 [1.161]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32085591557551096, 0.0010548914849312768, 0.3194774628854654, 0.35861173005409236]
siam score:  -0.706028
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3206065817435917, 0.0010549729043070632, 0.31923216622170236, 0.35910627913039883]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3196719112911182, 0.0010550543722232192, 0.3196719112911182, 0.35960112304554037]
Printing some Q and Qe and total Qs values:  [[0.814]
 [0.842]
 [0.856]
 [0.842]
 [0.856]
 [0.842]
 [0.867]] [[2.038]
 [1.792]
 [1.976]
 [1.792]
 [2.026]
 [1.792]
 [1.912]] [[1.224]
 [1.033]
 [1.246]
 [1.033]
 [1.295]
 [1.033]
 [1.203]]
1603 1289
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3198908204785694, 0.0010550949277099522, 0.3192066236426233, 0.3598474609510972]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3194253634680852, 0.001055135538952839, 0.3194253634680852, 0.36009413752487673]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.137]
 [0.128]
 [0.132]
 [0.132]
 [0.132]
 [0.132]
 [0.132]] [[5.953]
 [5.73 ]
 [6.204]
 [6.204]
 [6.204]
 [6.204]
 [6.204]] [[0.183]
 [0.091]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]]
from probs:  [0.3194253634680852, 0.001055135538952839, 0.3194253634680852, 0.36009413752487673]
using another actor
first move QE:  1.8161879726770125
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.318716279840185, 0.0010552570104448659, 0.31939649616316096, 0.3608319669862091]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.45 ]
 [0.499]
 [0.503]
 [0.497]
 [0.502]
 [0.502]] [[1.446]
 [2.225]
 [1.719]
 [1.802]
 [1.714]
 [1.598]
 [1.851]] [[0.516]
 [0.45 ]
 [0.499]
 [0.503]
 [0.497]
 [0.502]
 [0.502]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3182547080292782, 0.0010552973232627245, 0.3196131637496466, 0.3610768308978125]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31847167150139155, 0.001055337863981945, 0.31914991153053135, 0.3613230791040951]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3180112714796145, 0.0010553781148227492, 0.3193657838444213, 0.3615675665611414]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.0605103354635315
first move QE:  1.8131172558530757
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3180112714796145, 0.0010553781148227492, 0.3193657838444213, 0.3615675665611414]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3177682044901364, 0.0010554587816912625, 0.31911879189187814, 0.3620575448362943]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.729]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]] [[4.033]
 [4.719]
 [4.033]
 [4.033]
 [4.033]
 [4.033]
 [4.033]] [[0.869]
 [1.287]
 [0.869]
 [0.869]
 [0.869]
 [0.869]
 [0.869]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3177682044901364, 0.0010554587816912625, 0.31911879189187814, 0.3620575448362943]
Printing some Q and Qe and total Qs values:  [[1.035]
 [0.899]
 [0.816]
 [0.889]
 [0.889]
 [0.832]
 [0.832]] [[1.987]
 [2.09 ]
 [1.871]
 [2.328]
 [2.328]
 [2.106]
 [2.07 ]] [[3.155]
 [2.932]
 [2.709]
 [2.988]
 [2.988]
 [2.813]
 [2.801]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31798357770062796, 0.0010554991968442496, 0.31865789276127426, 0.36230303034125355]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31798357770062796, 0.0010554991968442496, 0.31865789276127426, 0.36230303034125355]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31752550624508175, 0.0010555393241567206, 0.31887218695538355, 0.362546767475378]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31752550624508175, 0.0010555393241567206, 0.31887218695538355, 0.362546767475378]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31752550624508175, 0.0010555393241567206, 0.31887218695538355, 0.362546767475378]
Printing some Q and Qe and total Qs values:  [[-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]] [[5.152]
 [5.152]
 [5.152]
 [5.152]
 [5.152]
 [5.152]
 [5.152]] [[-0.294]
 [-0.294]
 [-0.294]
 [-0.294]
 [-0.294]
 [-0.294]
 [-0.294]]
first move QE:  1.810073741206419
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31752550624508175, 0.0010555393241567206, 0.31887218695538355, 0.362546767475378]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3170687571396952, 0.001055579335630584, 0.3190858625299339, 0.36278980099474034]
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.878]
 [0.716]
 [0.716]
 [0.716]
 [0.716]
 [0.716]] [[2.615]
 [2.563]
 [1.337]
 [1.337]
 [1.337]
 [1.337]
 [1.337]] [[0.991]
 [1.36 ]
 [0.414]
 [0.414]
 [0.414]
 [0.414]
 [0.414]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3167996158515528, 0.0010557802080059832, 0.31813468492404134, 0.36400991901639984]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3167996158515528, 0.0010557802080059832, 0.31813468492404134, 0.36400991901639984]
line 256 mcts: sample exp_bonus 1.8024617654193098
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3167996158515528, 0.0010557802080059832, 0.31813468492404134, 0.36400991901639984]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31701185797158177, 0.0010558203737790833, 0.3176784318905645, 0.36425388976407463]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31701185797158177, 0.0010558203737790833, 0.3176784318905645, 0.36425388976407463]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31701185797158177, 0.0010558203737790833, 0.3176784318905645, 0.36425388976407463]
rdn beta is 0 so we're just using the maxi policy
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3165583844701563, 0.0010558602557260352, 0.317889618749542, 0.3644961365245756]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -1.259360749358001
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.386]
 [0.406]
 [0.386]
 [0.386]
 [0.386]
 [0.386]
 [0.386]] [[0.834]
 [1.221]
 [0.834]
 [0.834]
 [0.834]
 [0.834]
 [0.834]] [[0.386]
 [0.406]
 [0.386]
 [0.386]
 [0.386]
 [0.386]
 [0.386]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31719097542853664, 0.0010559802224241676, 0.3165282186251695, 0.36522482572386983]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31719097542853664, 0.0010559802224241676, 0.3165282186251695, 0.36522482572386983]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.916609270091542
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.028417758146869
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31760969090264757, 0.0010560596290489725, 0.31562710031011976, 0.36570714915818375]
using another actor
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.436]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]] [[-5.604]
 [-5.124]
 [-5.124]
 [-5.124]
 [-5.124]
 [-5.124]
 [-5.124]] [[0.436]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31757272277904597, 0.0010561787218022179, 0.31494056856651165, 0.3664305299326402]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.619]
 [0.556]
 [0.561]
 [0.554]
 [0.57 ]
 [0.571]] [[4.142]
 [4.44 ]
 [3.987]
 [4.007]
 [4.   ]
 [3.931]
 [4.01 ]] [[0.411]
 [0.674]
 [0.397]
 [0.414]
 [0.398]
 [0.407]
 [0.435]]
first move QE:  1.7984025845534675
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31687680800255064, 0.0010562981212657075, 0.3149111201817128, 0.3671557736944709]
Printing some Q and Qe and total Qs values:  [[1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]] [[1.738]
 [1.731]
 [1.797]
 [1.798]
 [1.796]
 [1.798]
 [1.797]] [[2.623]
 [2.62 ]
 [2.66 ]
 [2.661]
 [2.66 ]
 [2.661]
 [2.66 ]]
Printing some Q and Qe and total Qs values:  [[0.149]
 [0.149]
 [0.149]
 [0.149]
 [0.149]
 [0.149]
 [0.149]] [[-4.43]
 [-4.43]
 [-4.43]
 [-4.43]
 [-4.43]
 [-4.43]
 [-4.43]] [[0.149]
 [0.149]
 [0.149]
 [0.149]
 [0.149]
 [0.149]
 [0.149]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3161848110263885, 0.001056417162290051, 0.3148799315486904, 0.36787884026263107]
line 256 mcts: sample exp_bonus 4.5285222977696
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3161848110263885, 0.001056417162290051, 0.3148799315486904, 0.36787884026263107]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3163901292111011, 0.0010564565084542456, 0.3144355816530268, 0.3681178326274179]
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.067]
 [0.112]
 [0.381]
 [0.157]
 [0.122]
 [0.152]
 [0.19 ]] [[4.312]
 [4.372]
 [3.184]
 [3.539]
 [3.782]
 [3.779]
 [3.75 ]] [[-0.586]
 [-0.474]
 [-0.334]
 [-0.663]
 [-0.652]
 [-0.593]
 [-0.527]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3163901292111011, 0.0010564565084542456, 0.3144355816530268, 0.3681178326274179]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3163901292111011, 0.0010564565084542456, 0.3144355816530268, 0.3681178326274179]
Printing some Q and Qe and total Qs values:  [[0.764]
 [0.84 ]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]] [[2.023]
 [2.465]
 [2.023]
 [2.023]
 [2.023]
 [2.023]
 [2.023]] [[1.144]
 [1.663]
 [1.144]
 [1.144]
 [1.144]
 [1.144]
 [1.144]]
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.423]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]] [[1.699]
 [1.972]
 [1.329]
 [1.329]
 [1.329]
 [1.329]
 [1.329]] [[0.426]
 [0.423]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3159427783809809, 0.0010564962340981103, 0.3146415953969029, 0.3683591299880181]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31549669514135176, 0.0010565358471774189, 0.31484702539074394, 0.36859974362072695]
Printing some Q and Qe and total Qs values:  [[0.769]
 [0.843]
 [0.769]
 [0.717]
 [0.769]
 [0.769]
 [0.733]] [[2.818]
 [2.636]
 [2.818]
 [2.6  ]
 [2.818]
 [2.818]
 [2.75 ]] [[1.495]
 [1.441]
 [1.495]
 [1.271]
 [1.495]
 [1.495]
 [1.402]]
using explorer policy with actor:  1
siam score:  -0.70691055
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31505187411216623, 0.001056575348169925, 0.31505187411216623, 0.3688396764274976]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31505187411216623, 0.001056575348169925, 0.31505187411216623, 0.3688396764274976]
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.791]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[1.808]
 [3.054]
 [1.808]
 [1.808]
 [1.808]
 [1.808]
 [1.808]] [[1.574]
 [2.137]
 [1.574]
 [1.574]
 [1.574]
 [1.574]
 [1.574]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.836]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]] [[6.116]
 [5.663]
 [5.663]
 [5.663]
 [5.663]
 [5.663]
 [5.663]] [[2.558]
 [2.486]
 [2.486]
 [2.486]
 [2.486]
 [2.486]
 [2.486]]
siam score:  -0.70164907
Printing some Q and Qe and total Qs values:  [[0.154]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]] [[-1.064]
 [-3.149]
 [-3.149]
 [-3.149]
 [-3.149]
 [-3.149]
 [-3.149]] [[0.154]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3150159625326074, 0.0010566935076075454, 0.3143699558062185, 0.3695573881535666]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3150159625326074, 0.0010566935076075454, 0.3143699558062185, 0.3695573881535666]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3150159625326074, 0.0010566935076075454, 0.3143699558062185, 0.3695573881535666]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3152189276381032, 0.0010567327262298136, 0.3139287338191633, 0.36979560581650367]
Printing some Q and Qe and total Qs values:  [[0.763]
 [0.885]
 [0.763]
 [0.763]
 [0.763]
 [0.763]
 [0.763]] [[4.195]
 [5.382]
 [4.195]
 [4.195]
 [4.195]
 [4.195]
 [4.195]] [[2.3  ]
 [2.931]
 [2.3  ]
 [2.3  ]
 [2.3  ]
 [2.3  ]
 [2.3  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3152189276381032, 0.0010567327262298136, 0.3139287338191633, 0.36979560581650367]
from probs:  [0.3152189276381032, 0.0010567327262298136, 0.3139287338191633, 0.36979560581650367]
siam score:  -0.7056514
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31409626105721344, 0.0010568899483375525, 0.31409626105721344, 0.3707505879372357]
Printing some Q and Qe and total Qs values:  [[0.14 ]
 [0.238]
 [0.14 ]
 [0.14 ]
 [0.14 ]
 [0.14 ]
 [0.14 ]] [[0.711]
 [1.75 ]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]] [[0.14 ]
 [0.238]
 [0.14 ]
 [0.14 ]
 [0.14 ]
 [0.14 ]
 [0.14 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31409626105721344, 0.0010568899483375525, 0.31409626105721344, 0.3707505879372357]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31409626105721344, 0.0010568899483375525, 0.31409626105721344, 0.3707505879372357]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31409626105721344, 0.0010568899483375525, 0.31409626105721344, 0.3707505879372357]
siam score:  -0.7087258
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31409626105721344, 0.0010568899483375525, 0.31409626105721344, 0.3707505879372357]
UNIT TEST: sample policy line 217 mcts : [0.163 0.184 0.082 0.061 0.184 0.204 0.122]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31409626105721344, 0.0010568899483375525, 0.31409626105721344, 0.3707505879372357]
using explorer policy with actor:  1
from probs:  [0.3136570531721736, 0.0010569290986257199, 0.31429762719691456, 0.3709883905322861]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3134201362060407, 0.0010570073901588662, 0.31405891561057214, 0.37146394079322825]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3134201362060407, 0.0010570073901588662, 0.31405891561057214, 0.37146394079322825]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3134201362060407, 0.0010570073901588662, 0.31405891561057214, 0.37146394079322825]
from probs:  [0.312983231903242, 0.0010570463716504854, 0.31425900362320763, 0.3717007181018999]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.312983231903242, 0.0010570463716504854, 0.31425900362320763, 0.3717007181018999]
Printing some Q and Qe and total Qs values:  [[0.389]
 [0.125]
 [0.357]
 [0.279]
 [0.31 ]
 [0.304]
 [0.285]] [[-5.799]
 [-3.393]
 [-4.127]
 [-5.3  ]
 [-5.339]
 [-5.151]
 [-4.884]] [[0.389]
 [0.125]
 [0.357]
 [0.279]
 [0.31 ]
 [0.304]
 [0.285]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.312983231903242, 0.0010570463716504854, 0.31425900362320763, 0.3717007181018999]
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]] [[4.234]
 [4.234]
 [4.234]
 [4.234]
 [4.234]
 [4.234]
 [4.234]] [[2.136]
 [2.136]
 [2.136]
 [2.136]
 [2.136]
 [2.136]
 [2.136]]
Printing some Q and Qe and total Qs values:  [[0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]] [[3.89]
 [3.89]
 [3.89]
 [3.89]
 [3.89]
 [3.89]
 [3.89]] [[0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.312983231903242, 0.0010570463716504854, 0.31425900362320763, 0.3717007181018999]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3127477405618966, 0.0010571244852858482, 0.3140199471581277, 0.37217518779468983]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31314644888106463, 0.0010572026387809116, 0.31314644888106463, 0.3726498995990899]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3127115258476409, 0.0010572415521434625, 0.31334496951490814, 0.3728862630853074]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3127115258476409, 0.0010572415521434625, 0.31334496951490814, 0.3728862630853074]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3127115258476409, 0.0010572415521434625, 0.31334496951490814, 0.3728862630853074]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3129098960392132, 0.0010572805150335558, 0.3129098960392132, 0.37312292740654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3129098960392132, 0.0010572805150335558, 0.3129098960392132, 0.37312292740654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3129098960392132, 0.0010572805150335558, 0.3129098960392132, 0.37312292740654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3129098960392132, 0.0010572805150335558, 0.3129098960392132, 0.37312292740654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3129098960392132, 0.0010572805150335558, 0.3129098960392132, 0.37312292740654]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3129098960392132, 0.0010572805150335558, 0.3129098960392132, 0.37312292740654]
first move QE:  1.7689249025302776
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3120433761241976, 0.0010573581159954595, 0.3133049826881254, 0.37359428307168163]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31180928861764406, 0.0010574357570626509, 0.3130673932850958, 0.3740658823401975]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31200610962594183, 0.0010574746508684306, 0.3126342886864975, 0.37430212703669224]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31239811677749907, 0.0010575521154142517, 0.31177167700956726, 0.37477265409751936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 3.799020092231035
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3111091173381597, 0.0010576679764972938, 0.31235680928730125, 0.3754764053980417]
Printing some Q and Qe and total Qs values:  [[0.228]
 [0.213]
 [0.213]
 [0.213]
 [0.213]
 [0.213]
 [0.213]] [[6.366]
 [6.042]
 [6.042]
 [6.042]
 [6.042]
 [6.042]
 [6.042]] [[0.274]
 [0.135]
 [0.135]
 [0.135]
 [0.135]
 [0.135]
 [0.135]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3111091173381597, 0.0010576679764972938, 0.31235680928730125, 0.3754764053980417]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3111091173381597, 0.0010576679764972938, 0.31235680928730125, 0.3754764053980417]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3111091173381597, 0.0010576679764972938, 0.31235680928730125, 0.3754764053980417]
siam score:  -0.705264
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3111091173381597, 0.0010576679764972938, 0.31235680928730125, 0.3754764053980417]
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.29 ]
 [0.29 ]
 [0.29 ]
 [0.29 ]
 [0.29 ]
 [0.29 ]] [[ 0.035]
 [-2.63 ]
 [-2.63 ]
 [-2.63 ]
 [-2.63 ]
 [-2.63 ]
 [-2.63 ]] [[0.424]
 [0.29 ]
 [0.29 ]
 [0.29 ]
 [0.29 ]
 [0.29 ]
 [0.29 ]]
Printing some Q and Qe and total Qs values:  [[0.201]
 [0.202]
 [0.199]
 [0.199]
 [0.199]
 [0.199]
 [0.199]] [[-2.021]
 [ 0.975]
 [-0.118]
 [-0.118]
 [-0.118]
 [-0.118]
 [-0.118]] [[0.201]
 [0.202]
 [0.199]
 [0.199]
 [0.199]
 [0.199]
 [0.199]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.9967236546032463
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3106818196522725, 0.001057706383940427, 0.3125507780824636, 0.37570969588132347]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.10851025041761
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.537]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]] [[3.221]
 [3.044]
 [2.941]
 [2.941]
 [2.941]
 [2.941]
 [2.941]] [[1.035]
 [0.962]
 [0.944]
 [0.944]
 [0.944]
 [0.944]
 [0.944]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]] [[1.573]
 [1.573]
 [1.573]
 [1.573]
 [1.573]
 [1.573]
 [1.573]] [[0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]]
from probs:  [0.3106818196522725, 0.001057706383940427, 0.3125507780824636, 0.37570969588132347]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3106818196522725, 0.001057706383940427, 0.3125507780824636, 0.37570969588132347]
Printing some Q and Qe and total Qs values:  [[0.46 ]
 [0.092]
 [0.092]
 [0.092]
 [0.092]
 [0.092]
 [0.092]] [[-2.101]
 [-3.592]
 [-3.592]
 [-3.592]
 [-3.592]
 [-3.592]
 [-3.592]] [[0.46 ]
 [0.092]
 [0.092]
 [0.092]
 [0.092]
 [0.092]
 [0.092]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.227]
 [0.227]
 [0.227]
 [0.227]
 [0.227]
 [0.227]] [[2.227]
 [0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]] [[0.457]
 [0.227]
 [0.227]
 [0.227]
 [0.227]
 [0.227]
 [0.227]]
siam score:  -0.70705503
siam score:  -0.7076907
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001085534294358448, 0.001085534294358448, 0.4530898459057154, 0.5447390855055677]
Printing some Q and Qe and total Qs values:  [[0.161]
 [0.156]
 [0.156]
 [0.156]
 [0.156]
 [0.156]
 [0.156]] [[-0.113]
 [-0.28 ]
 [-0.28 ]
 [-0.28 ]
 [-0.28 ]
 [-0.28 ]
 [-0.28 ]] [[0.161]
 [0.156]
 [0.156]
 [0.156]
 [0.156]
 [0.156]
 [0.156]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.0010856159441340327, 0.0010856159441340327, 0.4525937340594443, 0.5452350340522876]
Printing some Q and Qe and total Qs values:  [[0.219]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.203]
 [0.236]] [[-5.654]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-5.593]
 [ 0.   ]] [[0.219]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.203]
 [0.236]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010856159441340327, 0.0010856159441340327, 0.4525937340594443, 0.5452350340522876]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010856159441340327, 0.0010856159441340327, 0.4525937340594443, 0.5452350340522876]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010856159441340327, 0.0010856159441340327, 0.4525937340594443, 0.5452350340522876]
Printing some Q and Qe and total Qs values:  [[0.288]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.501]] [[3.998]
 [1.781]
 [1.781]
 [1.781]
 [1.781]
 [1.781]
 [1.781]] [[1.917]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]]
Printing some Q and Qe and total Qs values:  [[0.238]
 [0.241]
 [0.238]
 [0.204]
 [0.23 ]
 [0.233]
 [0.227]] [[-4.709]
 [ 0.   ]
 [-5.752]
 [-3.992]
 [-5.636]
 [-5.564]
 [-5.792]] [[0.238]
 [0.241]
 [0.238]
 [0.204]
 [0.23 ]
 [0.233]
 [0.227]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.00108577870707086, 0.00108577870707086, 0.4516047708869747, 0.5462236716988835]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.00108577870707086, 0.00108577870707086, 0.4516047708869747, 0.5462236716988835]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.00108577870707086, 0.00108577870707086, 0.4516047708869747, 0.5462236716988835]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.00108577870707086, 0.00108577870707086, 0.4516047708869747, 0.5462236716988835]
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.704]
 [0.682]
 [0.672]
 [0.682]
 [0.682]
 [0.694]] [[3.075]
 [3.219]
 [3.454]
 [2.575]
 [3.454]
 [3.454]
 [2.948]] [[1.702]
 [1.896]
 [2.044]
 [1.387]
 [2.044]
 [2.044]
 [1.686]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Printing some Q and Qe and total Qs values:  [[0.326]
 [0.342]
 [0.318]
 [0.318]
 [0.318]
 [0.318]
 [0.318]] [[0.995]
 [1.361]
 [1.138]
 [1.138]
 [1.138]
 [1.138]
 [1.138]] [[0.326]
 [0.342]
 [0.318]
 [0.318]
 [0.318]
 [0.318]
 [0.318]]
Printing some Q and Qe and total Qs values:  [[0.04 ]
 [0.035]
 [0.035]
 [0.035]
 [0.035]
 [0.035]
 [0.035]] [[-5.971]
 [-5.248]
 [-5.248]
 [-5.248]
 [-5.248]
 [-5.248]
 [-5.248]] [[0.04 ]
 [0.035]
 [0.035]
 [0.035]
 [0.035]
 [0.035]
 [0.035]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Printing some Q and Qe and total Qs values:  [[0.515]
 [0.595]
 [0.484]
 [0.474]
 [0.482]
 [0.495]
 [0.5  ]] [[1.929]
 [2.334]
 [1.613]
 [1.229]
 [1.267]
 [1.912]
 [1.765]] [[0.515]
 [0.595]
 [0.484]
 [0.474]
 [0.482]
 [0.495]
 [0.5  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Printing some Q and Qe and total Qs values:  [[0.495]
 [0.502]
 [0.5  ]
 [0.498]
 [0.537]
 [0.482]
 [0.474]] [[1.619]
 [2.037]
 [1.569]
 [1.646]
 [1.438]
 [1.543]
 [1.615]] [[0.495]
 [0.502]
 [0.5  ]
 [0.498]
 [0.537]
 [0.482]
 [0.474]]
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.889]
 [0.824]
 [0.74 ]
 [0.541]
 [0.68 ]
 [0.536]] [[1.992]
 [1.829]
 [1.922]
 [1.808]
 [1.805]
 [1.787]
 [1.678]] [[1.251]
 [1.591]
 [1.588]
 [1.409]
 [1.185]
 [1.326]
 [1.084]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
siam score:  -0.71106964
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
siam score:  -0.71104294
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.65 ]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]] [[0.117]
 [0.875]
 [0.117]
 [0.117]
 [0.117]
 [0.117]
 [0.117]] [[1.025]
 [1.913]
 [1.025]
 [1.025]
 [1.025]
 [1.025]
 [1.025]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Printing some Q and Qe and total Qs values:  [[0.26 ]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]] [[-3.957]
 [-4.055]
 [-4.055]
 [-4.055]
 [-4.055]
 [-4.055]
 [-4.055]] [[0.26 ]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Printing some Q and Qe and total Qs values:  [[0.551]
 [0.579]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]] [[2.237]
 [2.625]
 [2.237]
 [2.237]
 [2.237]
 [2.237]
 [2.237]] [[1.877]
 [2.337]
 [1.877]
 [1.877]
 [1.877]
 [1.877]
 [1.877]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
from probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Printing some Q and Qe and total Qs values:  [[0.448]
 [0.492]
 [0.428]
 [0.421]
 [0.455]
 [0.431]
 [0.432]] [[0.927]
 [1.887]
 [1.19 ]
 [1.145]
 [1.352]
 [1.331]
 [1.554]] [[0.448]
 [0.492]
 [0.428]
 [0.421]
 [0.455]
 [0.431]
 [0.432]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
from probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Printing some Q and Qe and total Qs values:  [[0.329]
 [0.108]
 [0.108]
 [0.108]
 [0.108]
 [0.108]
 [0.108]] [[-0.559]
 [-3.811]
 [-3.811]
 [-3.811]
 [-3.811]
 [-3.811]
 [-3.811]] [[0.329]
 [0.108]
 [0.108]
 [0.108]
 [0.108]
 [0.108]
 [0.108]]
siam score:  -0.70992965
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.7115912
Printing some Q and Qe and total Qs values:  [[0.914]
 [0.914]
 [0.914]
 [0.914]
 [0.914]
 [0.914]
 [0.914]] [[1.773]
 [1.736]
 [1.773]
 [1.773]
 [1.773]
 [1.773]
 [1.773]] [[0.914]
 [0.914]
 [0.914]
 [0.914]
 [0.914]
 [0.914]
 [0.914]]
1681 1413
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Printing some Q and Qe and total Qs values:  [[ 0.026]
 [ 0.121]
 [ 0.113]
 [ 0.098]
 [-0.007]
 [ 0.087]
 [ 0.081]] [[-0.043]
 [ 1.496]
 [-0.416]
 [-2.608]
 [-1.716]
 [-2.447]
 [-2.589]] [[ 0.026]
 [ 0.121]
 [ 0.113]
 [ 0.098]
 [-0.007]
 [ 0.087]
 [ 0.081]]
Printing some Q and Qe and total Qs values:  [[0.692]
 [0.66 ]
 [0.759]
 [0.689]
 [0.672]
 [0.623]
 [0.655]] [[-3.739]
 [ 0.659]
 [-3.599]
 [-4.093]
 [-4.132]
 [-4.681]
 [-4.241]] [[0.544]
 [1.752]
 [0.611]
 [0.444]
 [0.427]
 [0.253]
 [0.389]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.324]
 [0.274]
 [0.274]
 [0.274]
 [0.274]
 [0.274]
 [0.274]] [[-1.122]
 [-1.386]
 [-1.386]
 [-1.386]
 [-1.386]
 [-1.386]
 [-1.386]] [[0.324]
 [0.274]
 [0.274]
 [0.274]
 [0.274]
 [0.274]
 [0.274]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.365766775564479
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
1683 1423
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
from probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001159912638493361, 0.001159912638493361, 0.001159912638493361, 0.99652026208452]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7147648
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.7252634093257329
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.302]
 [0.317]
 [0.309]
 [0.31 ]
 [0.304]
 [0.314]
 [0.291]] [[2.778]
 [2.97 ]
 [2.619]
 [2.561]
 [2.503]
 [2.535]
 [2.559]] [[0.302]
 [0.317]
 [0.309]
 [0.31 ]
 [0.304]
 [0.314]
 [0.291]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.618]
 [0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]] [[4.864]
 [5.222]
 [5.222]
 [5.222]
 [5.222]
 [5.222]
 [5.222]] [[1.197]
 [1.353]
 [1.353]
 [1.353]
 [1.353]
 [1.353]
 [1.353]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1693 1442
Printing some Q and Qe and total Qs values:  [[0.6]
 [0.6]
 [0.6]
 [0.6]
 [0.6]
 [0.6]
 [0.6]] [[1.733]
 [1.733]
 [1.733]
 [1.733]
 [1.733]
 [1.733]
 [1.733]] [[2.601]
 [2.601]
 [2.601]
 [2.601]
 [2.601]
 [2.601]
 [2.601]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]] [[2.812]
 [2.812]
 [2.812]
 [2.812]
 [2.812]
 [2.812]
 [2.812]] [[2.071]
 [2.071]
 [2.071]
 [2.071]
 [2.071]
 [2.071]
 [2.071]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 4.8782687486846905
siam score:  -0.7234017
Printing some Q and Qe and total Qs values:  [[0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]] [[-3.303]
 [-3.227]
 [-3.227]
 [-3.227]
 [-3.227]
 [-3.227]
 [-3.227]] [[0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.606]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]] [[5.234]
 [5.107]
 [5.107]
 [5.107]
 [5.107]
 [5.107]
 [5.107]] [[1.928]
 [1.86 ]
 [1.86 ]
 [1.86 ]
 [1.86 ]
 [1.86 ]
 [1.86 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.4139159071279346
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.315]
 [0.617]
 [0.63 ]
 [0.63 ]
 [0.63 ]
 [0.63 ]
 [0.584]] [[2.578]
 [2.854]
 [1.69 ]
 [1.69 ]
 [1.69 ]
 [1.69 ]
 [2.206]] [[1.416]
 [1.654]
 [1.346]
 [1.346]
 [1.346]
 [1.346]
 [1.461]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7207897
first move QE:  1.698637297766257
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.283]
 [0.305]
 [0.277]
 [0.283]
 [0.305]
 [0.305]
 [0.287]] [[2.04 ]
 [1.714]
 [1.877]
 [1.879]
 [1.714]
 [1.714]
 [1.871]] [[-0.143]
 [-0.208]
 [-0.209]
 [-0.197]
 [-0.208]
 [-0.208]
 [-0.191]]
Printing some Q and Qe and total Qs values:  [[0.565]
 [0.586]
 [0.586]
 [0.586]
 [0.586]
 [0.586]
 [0.586]] [[2.606]
 [2.386]
 [2.386]
 [2.386]
 [2.386]
 [2.386]
 [2.386]] [[0.987]
 [0.882]
 [0.882]
 [0.882]
 [0.882]
 [0.882]
 [0.882]]
from probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.416]
 [0.414]
 [0.404]
 [0.404]
 [0.404]
 [0.41 ]] [[1.603]
 [2.293]
 [1.822]
 [1.687]
 [1.687]
 [1.687]
 [1.793]] [[0.418]
 [0.416]
 [0.414]
 [0.404]
 [0.404]
 [0.404]
 [0.41 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]] [[2.635]
 [2.689]
 [2.689]
 [2.689]
 [2.689]
 [2.689]
 [2.689]] [[2.029]
 [2.117]
 [2.117]
 [2.117]
 [2.117]
 [2.117]
 [2.117]]
line 256 mcts: sample exp_bonus 3.1745703837358414
Printing some Q and Qe and total Qs values:  [[0.547]
 [0.593]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.603]] [[4.812]
 [5.202]
 [4.812]
 [4.812]
 [4.812]
 [4.812]
 [5.505]] [[0.48 ]
 [0.702]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.824]]
Printing some Q and Qe and total Qs values:  [[0.171]
 [0.171]
 [0.171]
 [0.171]
 [0.171]
 [0.171]
 [0.171]] [[-0.731]
 [-0.731]
 [-0.731]
 [-0.731]
 [-0.731]
 [-0.731]
 [-0.731]] [[0.171]
 [0.171]
 [0.171]
 [0.171]
 [0.171]
 [0.171]
 [0.171]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.366]
 [0.37 ]
 [0.358]
 [0.353]
 [0.361]
 [0.356]
 [0.363]] [[0.706]
 [1.179]
 [0.507]
 [0.538]
 [0.587]
 [0.702]
 [0.598]] [[0.366]
 [0.37 ]
 [0.358]
 [0.353]
 [0.361]
 [0.356]
 [0.363]]
Printing some Q and Qe and total Qs values:  [[0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]] [[-0.574]
 [-0.574]
 [-0.574]
 [-0.574]
 [-0.574]
 [-0.574]
 [-0.574]] [[0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7124501
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.69 ]
 [0.731]
 [0.801]
 [0.728]
 [0.664]
 [0.73 ]
 [0.729]] [[4.083]
 [4.579]
 [4.351]
 [4.706]
 [3.256]
 [3.954]
 [4.85 ]] [[0.814]
 [1.062]
 [1.126]
 [1.098]
 [0.485]
 [0.85 ]
 [1.148]]
line 256 mcts: sample exp_bonus 3.1821183004805675
Printing some Q and Qe and total Qs values:  [[0.846]
 [0.846]
 [0.846]
 [0.846]
 [0.846]
 [0.846]
 [0.846]] [[5.592]
 [5.592]
 [5.592]
 [5.592]
 [5.592]
 [5.592]
 [5.592]] [[2.336]
 [2.336]
 [2.336]
 [2.336]
 [2.336]
 [2.336]
 [2.336]]
Printing some Q and Qe and total Qs values:  [[1.066]
 [0.913]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]] [[4.979]
 [5.535]
 [5.787]
 [5.787]
 [5.787]
 [5.787]
 [5.787]] [[1.043]
 [0.923]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.8366821531762096
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.364]
 [0.391]
 [0.59 ]
 [0.579]
 [0.387]
 [0.538]
 [0.44 ]] [[2.304]
 [2.238]
 [1.925]
 [1.966]
 [2.158]
 [2.133]
 [2.445]] [[0.799]
 [0.786]
 [0.873]
 [0.891]
 [0.7  ]
 [0.976]
 [1.093]]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.564]
 [0.597]
 [0.594]
 [0.593]
 [0.546]
 [0.594]] [[0.967]
 [1.873]
 [0.777]
 [2.394]
 [0.823]
 [0.926]
 [2.394]] [[0.676]
 [1.089]
 [0.427]
 [1.497]
 [0.449]
 [0.423]
 [1.497]]
Printing some Q and Qe and total Qs values:  [[1.391]
 [1.106]
 [1.106]
 [1.106]
 [1.106]
 [1.106]
 [1.106]] [[1.727]
 [1.722]
 [1.722]
 [1.722]
 [1.722]
 [1.722]
 [1.722]] [[2.104]
 [1.531]
 [1.531]
 [1.531]
 [1.531]
 [1.531]
 [1.531]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7137329
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.371]
 [0.36 ]
 [0.371]
 [0.371]
 [0.371]
 [0.371]] [[-1.017]
 [ 0.067]
 [-0.033]
 [ 0.067]
 [ 0.067]
 [ 0.067]
 [ 0.067]] [[0.452]
 [0.371]
 [0.36 ]
 [0.371]
 [0.371]
 [0.371]
 [0.371]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.994]
 [0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]] [[1.159]
 [1.315]
 [1.315]
 [1.315]
 [1.315]
 [1.315]
 [1.315]] [[0.733]
 [0.766]
 [0.766]
 [0.766]
 [0.766]
 [0.766]
 [0.766]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Starting evaluation
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 0.7463486927911184
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
siam score:  -0.71927154
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.374]
 [0.61 ]
 [0.607]
 [0.61 ]
 [0.607]
 [0.609]] [[3.431]
 [3.925]
 [3.294]
 [2.751]
 [3.316]
 [3.089]
 [3.194]] [[0.607]
 [0.374]
 [0.61 ]
 [0.607]
 [0.61 ]
 [0.607]
 [0.609]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]] [[3.39]
 [3.39]
 [3.39]
 [3.39]
 [3.39]
 [3.39]
 [3.39]] [[0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]] [[3.565]
 [3.609]
 [3.609]
 [3.609]
 [3.609]
 [3.609]
 [3.609]] [[0.587]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]]
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.6  ]
 [0.584]
 [0.587]
 [0.586]
 [0.586]
 [0.595]] [[3.057]
 [2.865]
 [3.079]
 [3.074]
 [2.907]
 [2.731]
 [2.89 ]] [[0.585]
 [0.6  ]
 [0.584]
 [0.587]
 [0.586]
 [0.586]
 [0.595]]
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.584]
 [0.584]
 [0.584]
 [0.584]
 [0.584]
 [0.584]] [[3.023]
 [3.023]
 [3.023]
 [3.023]
 [3.023]
 [3.023]
 [3.023]] [[0.584]
 [0.584]
 [0.584]
 [0.584]
 [0.584]
 [0.584]
 [0.584]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.573]
 [0.573]
 [0.573]
 [0.58 ]
 [0.592]
 [0.634]] [[3.272]
 [2.107]
 [2.107]
 [2.107]
 [2.245]
 [1.995]
 [2.334]] [[0.652]
 [0.573]
 [0.573]
 [0.573]
 [0.58 ]
 [0.592]
 [0.634]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.598]
 [0.601]
 [0.601]
 [0.601]
 [0.572]
 [0.601]
 [0.601]] [[3.285]
 [2.441]
 [2.441]
 [2.441]
 [2.103]
 [2.441]
 [2.441]] [[0.598]
 [0.601]
 [0.601]
 [0.601]
 [0.572]
 [0.601]
 [0.601]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.598]
 [0.581]
 [0.589]
 [0.571]
 [0.584]
 [0.595]] [[4.198]
 [3.284]
 [3.731]
 [3.426]
 [3.123]
 [3.423]
 [3.357]] [[0.594]
 [0.598]
 [0.581]
 [0.589]
 [0.571]
 [0.584]
 [0.595]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]] [[3.762]
 [3.087]
 [3.087]
 [3.087]
 [3.087]
 [3.087]
 [3.087]] [[0.604]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.595]
 [0.586]
 [0.561]
 [0.586]
 [0.553]
 [0.569]
 [0.586]] [[4.108]
 [3.202]
 [3.423]
 [3.202]
 [3.231]
 [2.943]
 [3.202]] [[0.595]
 [0.586]
 [0.561]
 [0.586]
 [0.553]
 [0.569]
 [0.586]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.6  ]
 [0.518]
 [0.581]
 [0.574]
 [0.592]
 [0.586]
 [0.585]] [[4.02 ]
 [3.42 ]
 [3.716]
 [3.372]
 [3.291]
 [3.269]
 [3.157]] [[0.6  ]
 [0.518]
 [0.581]
 [0.574]
 [0.592]
 [0.586]
 [0.585]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.578]
 [0.561]
 [0.56 ]
 [0.563]
 [0.569]
 [0.576]] [[4.08 ]
 [3.685]
 [4.055]
 [3.116]
 [3.496]
 [2.839]
 [3.16 ]] [[0.586]
 [0.578]
 [0.561]
 [0.56 ]
 [0.563]
 [0.569]
 [0.576]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.606]
 [0.605]
 [0.598]
 [0.605]
 [0.605]
 [0.6  ]
 [0.605]] [[3.951]
 [2.773]
 [2.83 ]
 [2.773]
 [2.773]
 [2.948]
 [2.773]] [[0.606]
 [0.605]
 [0.598]
 [0.605]
 [0.605]
 [0.6  ]
 [0.605]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.115]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[4.234]
 [1.618]
 [1.618]
 [1.618]
 [1.618]
 [1.618]
 [1.618]] [[2.06 ]
 [1.264]
 [1.264]
 [1.264]
 [1.264]
 [1.264]
 [1.264]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.593]
 [0.589]
 [0.593]
 [0.593]
 [0.596]
 [0.593]] [[4.036]
 [2.468]
 [2.925]
 [2.468]
 [2.468]
 [2.861]
 [2.468]] [[0.594]
 [0.593]
 [0.589]
 [0.593]
 [0.593]
 [0.596]
 [0.593]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.574]
 [0.624]
 [0.6  ]
 [0.597]
 [0.597]
 [0.624]] [[3.596]
 [2.865]
 [3.408]
 [2.695]
 [2.46 ]
 [2.44 ]
 [3.408]] [[0.594]
 [0.574]
 [0.624]
 [0.6  ]
 [0.597]
 [0.597]
 [0.624]]
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.559]
 [0.575]
 [0.589]
 [0.599]
 [0.582]
 [0.635]] [[3.343]
 [2.854]
 [2.712]
 [2.589]
 [2.552]
 [2.718]
 [2.636]] [[0.604]
 [0.559]
 [0.575]
 [0.589]
 [0.599]
 [0.582]
 [0.635]]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.7236748
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.611]
 [0.504]
 [0.576]
 [0.595]
 [0.578]
 [0.612]
 [0.694]] [[2.621]
 [3.587]
 [2.622]
 [2.572]
 [2.371]
 [2.609]
 [2.593]] [[0.611]
 [0.504]
 [0.576]
 [0.595]
 [0.578]
 [0.612]
 [0.694]]
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.556]
 [0.572]
 [0.595]
 [0.575]
 [0.61 ]
 [0.689]] [[2.569]
 [2.752]
 [2.602]
 [2.571]
 [2.397]
 [2.585]
 [2.58 ]] [[0.604]
 [0.556]
 [0.572]
 [0.595]
 [0.575]
 [0.61 ]
 [0.689]]
Printing some Q and Qe and total Qs values:  [[-0.054]
 [-0.037]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]] [[4.135]
 [3.764]
 [3.5  ]
 [3.5  ]
 [3.5  ]
 [3.5  ]
 [3.5  ]] [[1.378]
 [1.175]
 [1.044]
 [1.044]
 [1.044]
 [1.044]
 [1.044]]
Printing some Q and Qe and total Qs values:  [[0.627]
 [0.617]
 [0.637]
 [0.632]
 [1.109]
 [0.599]
 [0.653]] [[-1.584]
 [ 0.519]
 [-2.178]
 [-2.137]
 [ 1.956]
 [-1.46 ]
 [-1.305]] [[0.591]
 [1.262]
 [0.406]
 [0.416]
 [2.042]
 [0.612]
 [0.698]]
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.581]
 [0.571]
 [0.564]
 [0.55 ]
 [0.576]
 [0.611]] [[2.711]
 [2.95 ]
 [2.806]
 [2.769]
 [2.583]
 [2.629]
 [2.739]] [[0.583]
 [0.581]
 [0.571]
 [0.564]
 [0.55 ]
 [0.576]
 [0.611]]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]] [[3.001]
 [3.001]
 [3.001]
 [3.001]
 [3.001]
 [3.001]
 [3.001]] [[0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]]
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.585]
 [0.562]
 [0.585]
 [0.585]
 [0.585]
 [0.585]] [[2.779]
 [2.782]
 [2.61 ]
 [2.782]
 [2.782]
 [2.782]
 [2.782]] [[0.581]
 [0.585]
 [0.562]
 [0.585]
 [0.585]
 [0.585]
 [0.585]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[-0.08 ]
 [-0.085]
 [-0.033]
 [-0.07 ]
 [-0.07 ]
 [-0.063]
 [-0.061]] [[5.042]
 [3.893]
 [4.53 ]
 [5.036]
 [5.036]
 [4.369]
 [4.205]] [[0.831]
 [0.067]
 [0.54 ]
 [0.838]
 [0.838]
 [0.404]
 [0.297]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.563]
 [0.582]
 [0.589]
 [0.572]
 [0.606]
 [0.629]] [[2.821]
 [2.822]
 [2.747]
 [2.589]
 [2.659]
 [2.704]
 [2.679]] [[0.587]
 [0.563]
 [0.582]
 [0.589]
 [0.572]
 [0.606]
 [0.629]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.605]] [[2.712]
 [2.447]
 [2.447]
 [2.447]
 [2.447]
 [2.447]
 [2.661]] [[0.604]
 [0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.605]]
siam score:  -0.7370126
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.303]
 [0.173]
 [0.173]
 [0.173]
 [0.173]
 [0.173]
 [0.173]] [[-0.896]
 [-1.512]
 [-1.512]
 [-1.512]
 [-1.512]
 [-1.512]
 [-1.512]] [[0.303]
 [0.173]
 [0.173]
 [0.173]
 [0.173]
 [0.173]
 [0.173]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.603]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]] [[3.877]
 [5.388]
 [3.877]
 [3.877]
 [3.877]
 [3.877]
 [3.877]] [[0.717]
 [1.355]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7508304
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.673267227064905
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.729]
 [0.729]
 [0.729]
 [0.729]
 [0.729]
 [0.729]
 [0.729]] [[3.629]
 [3.629]
 [3.629]
 [3.629]
 [3.629]
 [3.629]
 [3.629]] [[2.06]
 [2.06]
 [2.06]
 [2.06]
 [2.06]
 [2.06]
 [2.06]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.74219483
1740 1504
Printing some Q and Qe and total Qs values:  [[0.432]
 [0.398]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]] [[3.877]
 [5.835]
 [3.877]
 [3.877]
 [3.877]
 [3.877]
 [3.877]] [[0.981]
 [1.82 ]
 [0.981]
 [0.981]
 [0.981]
 [0.981]
 [0.981]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.195]
 [0.3  ]
 [0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]] [[3.093]
 [4.451]
 [3.138]
 [3.138]
 [3.138]
 [3.138]
 [3.138]] [[0.818]
 [1.547]
 [0.827]
 [0.827]
 [0.827]
 [0.827]
 [0.827]]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.348]
 [0.656]
 [0.642]
 [0.662]
 [0.656]
 [0.656]] [[2.702]
 [2.642]
 [2.702]
 [2.794]
 [2.795]
 [2.702]
 [2.702]] [[1.362]
 [0.686]
 [1.362]
 [1.425]
 [1.467]
 [1.362]
 [1.362]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.776 0.02  0.041 0.02  0.02  0.102 0.02 ]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.354]
 [0.469]
 [0.36 ]
 [0.368]
 [0.373]
 [0.365]
 [0.367]] [[3.367]
 [4.62 ]
 [4.275]
 [4.174]
 [4.363]
 [3.71 ]
 [3.691]] [[-0.367]
 [ 0.281]
 [-0.052]
 [-0.07 ]
 [ 0.002]
 [-0.23 ]
 [-0.233]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.401]
 [0.19 ]
 [0.212]
 [0.217]
 [0.217]
 [0.217]
 [0.217]] [[-0.966]
 [ 0.44 ]
 [-1.761]
 [-2.844]
 [-2.844]
 [-2.844]
 [-2.844]] [[0.401]
 [0.19 ]
 [0.212]
 [0.217]
 [0.217]
 [0.217]
 [0.217]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.384]
 [0.399]
 [0.384]
 [0.384]
 [0.384]
 [0.384]
 [0.384]] [[5.071]
 [5.147]
 [5.071]
 [5.071]
 [5.071]
 [5.071]
 [5.071]] [[1.363]
 [1.424]
 [1.363]
 [1.363]
 [1.363]
 [1.363]
 [1.363]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.557]
 [0.482]
 [0.485]
 [0.487]
 [0.482]
 [0.482]
 [0.483]] [[2.101]
 [2.318]
 [2.152]
 [2.077]
 [2.024]
 [2.032]
 [2.115]] [[0.159]
 [0.244]
 [0.112]
 [0.053]
 [0.004]
 [0.01 ]
 [0.079]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.6669594219030284
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
in main func line 156:  1761
Printing some Q and Qe and total Qs values:  [[0.455]
 [0.455]
 [0.439]
 [0.481]
 [0.439]
 [0.439]
 [0.482]] [[6.435]
 [4.986]
 [5.453]
 [5.064]
 [5.453]
 [5.453]
 [4.417]] [[1.796]
 [1.029]
 [1.25 ]
 [1.112]
 [1.25 ]
 [1.25 ]
 [0.77 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 3.74582568936489
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.085]
 [-0.085]
 [-0.085]
 [-0.085]
 [-0.085]
 [-0.085]
 [-0.085]] [[3.376]
 [3.376]
 [3.376]
 [3.376]
 [3.376]
 [3.376]
 [3.376]] [[0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.38 ]
 [0.38 ]
 [0.38 ]
 [0.38 ]
 [0.38 ]
 [0.38 ]
 [0.408]] [[2.389]
 [2.389]
 [2.389]
 [2.389]
 [2.389]
 [2.389]
 [2.747]] [[1.878]
 [1.878]
 [1.878]
 [1.878]
 [1.878]
 [1.878]
 [1.99 ]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.188]
 [0.172]
 [0.172]
 [0.172]
 [0.172]
 [0.172]
 [0.172]] [[-4.428]
 [-4.337]
 [-4.337]
 [-4.337]
 [-4.337]
 [-4.337]
 [-4.337]] [[0.188]
 [0.172]
 [0.172]
 [0.172]
 [0.172]
 [0.172]
 [0.172]]
from probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.367 0.163 0.061 0.041 0.224 0.061 0.082]
siam score:  -0.7100111
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.70834595
first move QE:  1.6571371949493614
line 256 mcts: sample exp_bonus 0.1615931318854486
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.234]
 [0.261]
 [0.228]
 [0.228]
 [0.228]
 [0.228]
 [0.228]] [[1.421]
 [1.903]
 [1.569]
 [1.569]
 [1.569]
 [1.569]
 [1.569]] [[0.234]
 [0.261]
 [0.228]
 [0.228]
 [0.228]
 [0.228]
 [0.228]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.765]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]] [[4.623]
 [3.069]
 [3.069]
 [3.069]
 [3.069]
 [3.069]
 [3.069]] [[0.765]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.684]
 [0.848]
 [0.851]
 [0.838]
 [0.83 ]
 [0.847]] [[2.985]
 [2.611]
 [2.236]
 [2.196]
 [2.263]
 [2.204]
 [2.147]] [[1.49 ]
 [0.901]
 [0.867]
 [0.842]
 [0.871]
 [0.817]
 [0.8  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[ 0.037]
 [-0.   ]
 [ 0.043]
 [ 0.043]
 [ 0.043]
 [ 0.038]
 [ 0.043]] [[2.881]
 [2.5  ]
 [2.85 ]
 [2.85 ]
 [2.85 ]
 [2.719]
 [2.85 ]] [[0.735]
 [0.152]
 [0.706]
 [0.706]
 [0.706]
 [0.521]
 [0.706]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
1780 1535
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.745]
 [0.777]
 [0.938]
 [0.938]
 [0.938]
 [0.938]
 [0.938]] [[2.991]
 [3.815]
 [2.612]
 [2.612]
 [2.612]
 [2.612]
 [2.612]] [[0.961]
 [1.62 ]
 [0.965]
 [0.965]
 [0.965]
 [0.965]
 [0.965]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1783 1537
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.0151248452271076
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.26 ]
 [1.122]
 [1.122]
 [1.122]
 [1.122]
 [1.122]
 [1.122]] [[2.467]
 [2.423]
 [2.423]
 [2.423]
 [2.423]
 [2.423]
 [2.423]] [[2.168]
 [1.876]
 [1.876]
 [1.876]
 [1.876]
 [1.876]
 [1.876]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
using explorer policy with actor:  1
first move QE:  1.645835171468817
Printing some Q and Qe and total Qs values:  [[0.25 ]
 [0.211]
 [0.204]
 [0.211]
 [0.211]
 [0.211]
 [0.211]] [[-1.646]
 [-0.95 ]
 [-0.447]
 [-0.95 ]
 [-0.95 ]
 [-0.95 ]
 [-0.95 ]] [[0.25 ]
 [0.211]
 [0.204]
 [0.211]
 [0.211]
 [0.211]
 [0.211]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.391]
 [0.383]
 [0.425]
 [0.425]
 [0.425]
 [0.415]
 [0.392]] [[1.132]
 [1.251]
 [1.073]
 [1.073]
 [1.073]
 [1.043]
 [0.958]] [[0.391]
 [0.383]
 [0.425]
 [0.425]
 [0.425]
 [0.415]
 [0.392]]
siam score:  -0.6894089
in main func line 156:  1786
using explorer policy with actor:  1
1787 1540
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.0000],
        [-0.3902],
        [-0.0000],
        [-0.3980],
        [-0.0000],
        [-0.4405],
        [-0.0000],
        [-0.3798],
        [-0.0000],
        [-0.5161]], dtype=torch.float64)
-0.9213435 -0.9213435
-0.0628797758985 -0.45303054971642076
-0.8037314999999999 -0.8037314999999999
-0.024259925299500003 -0.42229156595580325
-0.9360449999999999 -0.9360449999999999
-0.0727797758985 -0.5132575775310103
-0.9405 -0.9405
-0.0727797758985 -0.45261800506747224
-0.9503999999999999 -0.9503999999999999
-0.024259925299500003 -0.5403675646899334
siam score:  -0.6900288
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.512]
 [0.524]
 [0.518]
 [0.558]
 [0.646]
 [0.535]
 [0.489]] [[1.276]
 [1.555]
 [1.276]
 [1.312]
 [1.328]
 [1.216]
 [1.095]] [[0.512]
 [0.524]
 [0.518]
 [0.558]
 [0.646]
 [0.535]
 [0.489]]
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.518]
 [0.513]] [[2.315]
 [2.315]
 [2.315]
 [2.315]
 [2.315]
 [2.479]
 [2.315]] [[0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.518]
 [0.513]]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.698]
 [0.715]
 [0.698]
 [0.698]
 [0.698]
 [0.698]] [[3.516]
 [3.407]
 [3.681]
 [3.407]
 [3.407]
 [3.407]
 [3.407]] [[1.165]
 [0.987]
 [1.203]
 [0.987]
 [0.987]
 [0.987]
 [0.987]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 1.4238790488391473
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.593]
 [0.46 ]
 [0.584]
 [0.611]
 [0.567]
 [0.552]
 [0.553]] [[3.147]
 [3.51 ]
 [3.181]
 [2.865]
 [3.158]
 [3.18 ]
 [3.104]] [[0.524]
 [0.501]
 [0.53 ]
 [0.373]
 [0.481]
 [0.465]
 [0.416]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]] [[-0.446]
 [ 0.215]
 [ 0.215]
 [ 0.215]
 [ 0.215]
 [ 0.215]
 [ 0.215]] [[0.682]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.349]
 [0.23 ]
 [0.23 ]
 [0.23 ]
 [0.23 ]
 [0.23 ]
 [0.23 ]] [[ 0.335]
 [-0.771]
 [-0.771]
 [-0.771]
 [-0.771]
 [-0.771]
 [-0.771]] [[0.349]
 [0.23 ]
 [0.23 ]
 [0.23 ]
 [0.23 ]
 [0.23 ]
 [0.23 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.0642646678513614
line 256 mcts: sample exp_bonus -0.6331377572252253
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.737]
 [0.765]
 [0.737]
 [0.737]
 [0.737]
 [0.737]
 [0.737]] [[2.918]
 [3.635]
 [2.918]
 [2.918]
 [2.918]
 [2.918]
 [2.918]] [[1.554]
 [2.088]
 [1.554]
 [1.554]
 [1.554]
 [1.554]
 [1.554]]
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1800 1547
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.67861193
Printing some Q and Qe and total Qs values:  [[0.766]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]] [[4.293]
 [2.556]
 [2.556]
 [2.556]
 [2.556]
 [2.556]
 [2.556]] [[2.12 ]
 [1.698]
 [1.698]
 [1.698]
 [1.698]
 [1.698]
 [1.698]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.9952766008872334
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.6326823591231518
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.67573303
start point for exploration sampling:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.61 ]
 [0.617]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.669]] [[3.402]
 [4.637]
 [3.402]
 [3.402]
 [3.402]
 [3.402]
 [3.271]] [[0.67 ]
 [1.096]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.744]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.822]
 [0.807]
 [0.822]
 [0.822]
 [0.822]
 [0.822]
 [0.822]] [[2.704]
 [3.48 ]
 [2.704]
 [2.704]
 [2.704]
 [2.704]
 [2.704]] [[1.509]
 [1.737]
 [1.509]
 [1.509]
 [1.509]
 [1.509]
 [1.509]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.713]
 [0.727]
 [0.815]
 [0.802]
 [0.782]
 [1.015]
 [0.716]] [[1.616]
 [1.862]
 [1.624]
 [1.638]
 [1.623]
 [2.373]
 [1.655]] [[0.618]
 [0.727]
 [0.824]
 [0.803]
 [0.757]
 [1.474]
 [0.636]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.283]
 [0.277]
 [0.268]
 [0.267]
 [0.277]
 [0.277]
 [0.255]] [[-1.958]
 [-2.644]
 [-2.104]
 [-2.168]
 [-2.644]
 [-2.644]
 [-2.186]] [[0.283]
 [0.277]
 [0.268]
 [0.267]
 [0.277]
 [0.277]
 [0.255]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.695]
 [0.679]
 [0.682]
 [0.683]
 [0.679]
 [0.678]] [[3.209]
 [2.847]
 [3.37 ]
 [3.004]
 [2.911]
 [2.777]
 [2.979]] [[1.127]
 [0.797]
 [1.112]
 [0.876]
 [0.815]
 [0.718]
 [0.85 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.39 ]
 [0.433]
 [0.445]
 [0.413]
 [0.409]
 [0.391]] [[0.095]
 [2.225]
 [1.47 ]
 [1.434]
 [1.404]
 [1.405]
 [1.632]] [[0.537]
 [0.39 ]
 [0.433]
 [0.445]
 [0.413]
 [0.409]
 [0.391]]
siam score:  -0.6757707
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6769126
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6774894
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.653]
 [0.714]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.687]] [[1.927]
 [2.321]
 [1.927]
 [1.927]
 [1.927]
 [1.927]
 [3.618]] [[1.366]
 [1.645]
 [1.366]
 [1.366]
 [1.366]
 [1.366]
 [2.235]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.67493576
Printing some Q and Qe and total Qs values:  [[0.106]
 [0.076]
 [0.091]
 [0.091]
 [0.091]
 [0.091]
 [0.091]] [[4.127]
 [3.774]
 [4.256]
 [4.256]
 [4.256]
 [4.256]
 [4.256]] [[1.075]
 [0.787]
 [1.152]
 [1.152]
 [1.152]
 [1.152]
 [1.152]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1822 1562
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1823 1567
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.66561043
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6642469
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.69 ]
 [0.691]
 [0.681]
 [0.699]
 [0.669]
 [0.68 ]] [[2.075]
 [2.182]
 [2.307]
 [2.309]
 [2.303]
 [2.213]
 [1.991]] [[0.636]
 [0.619]
 [0.703]
 [0.686]
 [0.717]
 [0.597]
 [0.472]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.615303082225213
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.544]
 [0.521]
 [0.514]
 [0.511]
 [0.512]
 [0.514]] [[2.556]
 [3.495]
 [2.656]
 [2.646]
 [2.454]
 [2.063]
 [2.409]] [[0.536]
 [0.544]
 [0.521]
 [0.514]
 [0.511]
 [0.512]
 [0.514]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.366]
 [0.315]
 [0.386]
 [0.37 ]
 [0.438]
 [0.4  ]
 [0.337]] [[0.491]
 [0.739]
 [1.108]
 [1.258]
 [1.089]
 [1.029]
 [0.818]] [[0.366]
 [0.315]
 [0.386]
 [0.37 ]
 [0.438]
 [0.4  ]
 [0.337]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]] [[1.768]
 [1.768]
 [1.768]
 [1.768]
 [1.768]
 [1.768]
 [1.768]] [[0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.624]
 [0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.576]] [[2.566]
 [4.106]
 [2.566]
 [2.566]
 [2.566]
 [2.566]
 [2.566]] [[1.045]
 [1.825]
 [1.045]
 [1.045]
 [1.045]
 [1.045]
 [1.045]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6656149
siam score:  -0.6620175
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.8375494552067515
siam score:  -0.6610213
1833 1581
line 256 mcts: sample exp_bonus -5.162762984848808
Printing some Q and Qe and total Qs values:  [[0.847]
 [0.793]
 [0.793]
 [0.793]
 [0.793]
 [0.793]
 [0.793]] [[3.183]
 [2.817]
 [2.817]
 [2.817]
 [2.817]
 [2.817]
 [2.817]] [[1.338]
 [0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 10.0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 3.0044949875185485
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.694]
 [0.733]
 [0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.694]] [[3.498]
 [4.325]
 [3.498]
 [3.498]
 [3.498]
 [3.498]
 [3.498]] [[0.743]
 [1.096]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]]
line 256 mcts: sample exp_bonus 1.6964135078526557
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.129]
 [0.31 ]
 [0.121]
 [0.121]
 [0.121]
 [0.121]
 [0.121]] [[3.923]
 [3.574]
 [3.645]
 [3.645]
 [3.645]
 [3.645]
 [3.645]] [[0.297]
 [0.542]
 [0.189]
 [0.189]
 [0.189]
 [0.189]
 [0.189]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.385]
 [0.263]
 [0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.293]] [[0.585]
 [2.442]
 [1.067]
 [1.067]
 [1.067]
 [1.067]
 [0.834]] [[0.385]
 [0.263]
 [0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.293]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.45]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]] [[1.725]
 [1.961]
 [1.961]
 [1.961]
 [1.961]
 [1.961]
 [1.961]] [[0.45]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.183]
 [0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]] [[ 0.274]
 [-0.175]
 [-0.175]
 [-0.175]
 [-0.175]
 [-0.175]
 [-0.175]] [[0.183]
 [0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.459]
 [0.497]
 [0.459]
 [0.459]
 [0.459]
 [0.459]] [[-0.099]
 [ 1.16 ]
 [ 1.141]
 [ 1.16 ]
 [ 1.16 ]
 [ 1.16 ]
 [ 1.16 ]] [[0.566]
 [0.459]
 [0.497]
 [0.459]
 [0.459]
 [0.459]
 [0.459]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.727]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]] [[2.807]
 [2.532]
 [2.532]
 [2.532]
 [2.532]
 [2.532]
 [2.532]] [[1.998]
 [1.86 ]
 [1.86 ]
 [1.86 ]
 [1.86 ]
 [1.86 ]
 [1.86 ]]
siam score:  -0.6509914
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.037]
 [-0.037]
 [-0.037]
 [-0.037]
 [-0.037]
 [-0.037]
 [-0.037]] [[3.927]
 [3.927]
 [3.927]
 [3.927]
 [3.927]
 [3.927]
 [3.927]] [[0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]]
in main func line 156:  1846
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.137]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]] [[-5.978]
 [-4.447]
 [-4.447]
 [-4.447]
 [-4.447]
 [-4.447]
 [-4.447]] [[0.137]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.806]
 [0.775]
 [0.775]
 [0.775]
 [0.775]
 [0.753]] [[4.573]
 [4.86 ]
 [4.573]
 [4.573]
 [4.573]
 [4.573]
 [4.609]] [[0.912]
 [1.07 ]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.88 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10624
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]] [[-1.974]
 [-1.536]
 [-1.536]
 [-1.536]
 [-1.536]
 [-1.536]
 [-1.536]] [[0.225]
 [0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.785]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]] [[3.47 ]
 [3.714]
 [3.47 ]
 [3.47 ]
 [3.47 ]
 [3.47 ]
 [3.47 ]] [[0.568]
 [0.906]
 [0.568]
 [0.568]
 [0.568]
 [0.568]
 [0.568]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.752714414990728
using explorer policy with actor:  1
siam score:  -0.65044844
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[3.926]
 [3.397]
 [3.397]
 [3.397]
 [3.397]
 [3.397]
 [3.397]] [[1.379]
 [1.064]
 [1.064]
 [1.064]
 [1.064]
 [1.064]
 [1.064]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus -1.4916551412057328
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.795]
 [0.64 ]
 [0.64 ]
 [0.64 ]
 [0.64 ]
 [0.64 ]
 [0.64 ]] [[2.862]
 [2.337]
 [2.337]
 [2.337]
 [2.337]
 [2.337]
 [2.337]] [[1.947]
 [1.75 ]
 [1.75 ]
 [1.75 ]
 [1.75 ]
 [1.75 ]
 [1.75 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.217]
 [0.187]
 [0.187]
 [0.187]
 [0.187]
 [0.187]
 [0.187]] [[-4.118]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.217]
 [0.187]
 [0.187]
 [0.187]
 [0.187]
 [0.187]
 [0.187]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[1.286]
 [1.286]
 [1.286]
 [1.286]
 [1.286]
 [1.286]
 [1.286]] [[1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]] [[0.69]
 [0.69]
 [0.69]
 [0.69]
 [0.69]
 [0.69]
 [0.69]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.309]
 [0.312]
 [0.312]
 [0.312]
 [0.312]
 [0.312]
 [0.312]] [[5.495]
 [4.086]
 [4.086]
 [4.086]
 [4.086]
 [4.086]
 [4.086]] [[1.176]
 [0.578]
 [0.578]
 [0.578]
 [0.578]
 [0.578]
 [0.578]]
Starting evaluation
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.316]
 [0.251]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]] [[-3.521]
 [-0.38 ]
 [-3.521]
 [-3.521]
 [-3.521]
 [-3.521]
 [-3.521]] [[0.316]
 [0.251]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]]
using explorer policy with actor:  0
siam score:  -0.655007
line 256 mcts: sample exp_bonus 1.9897662656338686
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.737]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]] [[1.4  ]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[0.737]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]]
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.469]
 [0.469]
 [0.469]
 [0.469]
 [0.469]
 [0.469]] [[0.978]
 [0.766]
 [0.766]
 [0.766]
 [0.766]
 [0.766]
 [0.766]] [[0.546]
 [0.469]
 [0.469]
 [0.469]
 [0.469]
 [0.469]
 [0.469]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.822]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]] [[1.655]
 [1.935]
 [1.935]
 [1.935]
 [1.935]
 [1.935]
 [1.935]] [[0.822]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]] [[2.294]
 [2.24 ]
 [2.24 ]
 [2.24 ]
 [2.24 ]
 [2.24 ]
 [2.24 ]] [[0.72 ]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]]
Printing some Q and Qe and total Qs values:  [[0.797]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]] [[2.153]
 [1.952]
 [1.952]
 [1.952]
 [1.952]
 [1.952]
 [1.952]] [[0.797]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.281]
 [0.228]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]] [[9.312]
 [7.778]
 [8.388]
 [8.388]
 [8.388]
 [8.388]
 [8.388]] [[1.533]
 [1.078]
 [1.248]
 [1.248]
 [1.248]
 [1.248]
 [1.248]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.708]] [[2.108]
 [2.108]
 [2.108]
 [2.108]
 [2.108]
 [2.108]
 [2.108]] [[0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.708]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.715]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]] [[2.178]
 [1.82 ]
 [1.82 ]
 [1.82 ]
 [1.82 ]
 [1.82 ]
 [1.82 ]] [[0.715]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.1072423658363166
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.71 ]
 [0.72 ]
 [0.71 ]
 [0.727]
 [0.72 ]
 [0.705]] [[1.434]
 [1.94 ]
 [2.172]
 [2.07 ]
 [2.105]
 [2.184]
 [2.042]] [[0.751]
 [0.71 ]
 [0.72 ]
 [0.71 ]
 [0.727]
 [0.72 ]
 [0.705]]
Printing some Q and Qe and total Qs values:  [[0.782]
 [0.754]
 [0.691]
 [0.682]
 [0.68 ]
 [0.7  ]
 [0.714]] [[1.502]
 [1.656]
 [2.082]
 [2.128]
 [2.2  ]
 [2.129]
 [1.945]] [[0.782]
 [0.754]
 [0.691]
 [0.682]
 [0.68 ]
 [0.7  ]
 [0.714]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.802]
 [0.718]
 [0.717]
 [0.717]
 [0.718]
 [0.716]
 [0.714]] [[1.82 ]
 [2.062]
 [2.292]
 [2.263]
 [2.062]
 [2.236]
 [2.245]] [[0.802]
 [0.718]
 [0.717]
 [0.717]
 [0.718]
 [0.716]
 [0.714]]
Printing some Q and Qe and total Qs values:  [[-0.038]
 [-0.043]
 [-0.03 ]
 [-0.033]
 [-0.045]
 [-0.044]
 [-0.043]] [[5.94 ]
 [5.468]
 [5.179]
 [5.56 ]
 [5.598]
 [5.407]
 [4.998]] [[-0.048]
 [-0.215]
 [-0.286]
 [-0.165]
 [-0.177]
 [-0.238]
 [-0.374]]
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.717]
 [0.733]
 [0.717]
 [0.717]
 [0.715]
 [0.714]] [[1.691]
 [2.144]
 [2.159]
 [2.131]
 [2.204]
 [2.053]
 [2.131]] [[0.786]
 [0.717]
 [0.733]
 [0.717]
 [0.717]
 [0.715]
 [0.714]]
Printing some Q and Qe and total Qs values:  [[0.674]
 [0.601]
 [0.678]
 [0.664]
 [0.675]
 [0.672]
 [0.649]] [[1.848]
 [1.954]
 [1.855]
 [1.936]
 [1.727]
 [1.9  ]
 [1.777]] [[0.674]
 [0.601]
 [0.678]
 [0.664]
 [0.675]
 [0.672]
 [0.649]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 5.163179631503763
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]] [[3.052]
 [3.052]
 [3.052]
 [3.052]
 [3.052]
 [3.052]
 [3.052]] [[0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]
 [0.193]]
Printing some Q and Qe and total Qs values:  [[0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]] [[1.814]
 [1.814]
 [1.814]
 [1.814]
 [1.814]
 [1.814]
 [1.814]] [[0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]] [[1.919]
 [1.919]
 [1.919]
 [1.919]
 [1.919]
 [1.919]
 [1.919]] [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus -1.5900306852930428
siam score:  -0.66409934
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.3839382313813104
siam score:  -0.66514295
line 256 mcts: sample exp_bonus 4.803931750078944
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.647]
 [0.641]
 [0.647]
 [0.647]
 [0.647]
 [0.647]] [[2.177]
 [2.104]
 [2.105]
 [2.104]
 [2.104]
 [2.104]
 [2.104]] [[0.693]
 [0.647]
 [0.641]
 [0.647]
 [0.647]
 [0.647]
 [0.647]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1868 1620
Printing some Q and Qe and total Qs values:  [[0.771]
 [0.633]
 [0.686]
 [0.676]
 [0.693]
 [0.686]
 [0.679]] [[1.395]
 [2.472]
 [2.052]
 [1.988]
 [2.154]
 [2.14 ]
 [1.981]] [[0.771]
 [0.633]
 [0.686]
 [0.676]
 [0.693]
 [0.686]
 [0.679]]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.737]
 [0.737]
 [0.676]
 [0.737]
 [0.737]
 [0.737]] [[2.023]
 [1.74 ]
 [1.74 ]
 [1.988]
 [1.74 ]
 [1.74 ]
 [1.74 ]] [[0.699]
 [0.737]
 [0.737]
 [0.676]
 [0.737]
 [0.737]
 [0.737]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 2.6870202975158692
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.575]
 [0.707]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]] [[2.255]
 [3.391]
 [2.255]
 [2.255]
 [2.255]
 [2.255]
 [2.255]] [[0.861]
 [1.628]
 [0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.371]
 [0.391]
 [0.371]
 [0.371]
 [0.371]
 [0.37 ]
 [0.371]] [[2.399]
 [3.046]
 [2.399]
 [2.399]
 [2.399]
 [2.314]
 [2.399]] [[0.371]
 [0.391]
 [0.371]
 [0.371]
 [0.371]
 [0.37 ]
 [0.371]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.758]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]] [[3.625]
 [3.364]
 [3.364]
 [3.364]
 [3.364]
 [3.364]
 [3.364]] [[0.758]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]]
Printing some Q and Qe and total Qs values:  [[0.846]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]] [[3.144]
 [2.622]
 [2.622]
 [2.622]
 [2.622]
 [2.622]
 [2.622]] [[0.846]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[ 0.024]
 [ 0.385]
 [-0.001]
 [ 0.013]
 [ 0.041]
 [ 0.062]
 [ 0.077]] [[1.504]
 [2.774]
 [1.282]
 [1.239]
 [1.298]
 [1.375]
 [1.23 ]] [[-0.181]
 [ 0.96 ]
 [-0.344]
 [-0.358]
 [-0.294]
 [-0.226]
 [-0.302]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.73 ]
 [0.73 ]
 [0.73 ]
 [0.73 ]
 [0.73 ]
 [0.73 ]] [[3.198]
 [2.517]
 [2.517]
 [2.517]
 [2.517]
 [2.517]
 [2.517]] [[0.878]
 [0.73 ]
 [0.73 ]
 [0.73 ]
 [0.73 ]
 [0.73 ]
 [0.73 ]]
Printing some Q and Qe and total Qs values:  [[0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]] [[2.447]
 [2.447]
 [2.447]
 [2.447]
 [2.447]
 [2.447]
 [2.447]] [[0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.3206908098386845
Printing some Q and Qe and total Qs values:  [[0.815]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]] [[2.371]
 [2.538]
 [2.538]
 [2.538]
 [2.538]
 [2.538]
 [2.538]] [[0.815]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.951]
 [0.797]
 [0.797]
 [0.797]
 [0.797]
 [0.797]
 [0.797]] [[2.755]
 [2.552]
 [2.552]
 [2.552]
 [2.552]
 [2.552]
 [2.552]] [[0.951]
 [0.797]
 [0.797]
 [0.797]
 [0.797]
 [0.797]
 [0.797]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.0996763234184592
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]] [[2.484]
 [1.901]
 [1.901]
 [1.901]
 [1.901]
 [1.901]
 [1.901]] [[0.876]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]]
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.788]
 [0.788]
 [0.788]
 [0.788]
 [0.788]
 [0.788]] [[2.516]
 [1.898]
 [1.898]
 [1.898]
 [1.898]
 [1.898]
 [1.898]] [[0.911]
 [0.788]
 [0.788]
 [0.788]
 [0.788]
 [0.788]
 [0.788]]
Printing some Q and Qe and total Qs values:  [[0.399]
 [0.282]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]] [[-3.649]
 [ 1.649]
 [-5.399]
 [-5.399]
 [-5.399]
 [-5.399]
 [-5.399]] [[0.399]
 [0.282]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]]
rdn probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.215]
 [0.182]
 [0.191]
 [0.187]
 [0.189]
 [0.189]] [[0.958]
 [2.481]
 [1.023]
 [1.095]
 [1.29 ]
 [1.039]
 [0.763]] [[0.193]
 [0.215]
 [0.182]
 [0.191]
 [0.187]
 [0.189]
 [0.189]]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]] [[0.651]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]] [[0.571]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]]
line 256 mcts: sample exp_bonus 2.395443000819859
Printing some Q and Qe and total Qs values:  [[0.472]
 [0.238]
 [0.238]
 [0.252]
 [0.252]
 [0.264]
 [0.291]] [[2.579]
 [1.978]
 [2.143]
 [1.296]
 [1.22 ]
 [1.212]
 [1.352]] [[0.992]
 [0.324]
 [0.379]
 [0.125]
 [0.098]
 [0.12 ]
 [0.222]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.691803
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.55 ]
 [0.55 ]
 [0.55 ]
 [0.55 ]
 [0.55 ]
 [0.55 ]] [[2.093]
 [2.64 ]
 [2.64 ]
 [2.64 ]
 [2.64 ]
 [2.64 ]
 [2.64 ]] [[0.549]
 [0.55 ]
 [0.55 ]
 [0.55 ]
 [0.55 ]
 [0.55 ]
 [0.55 ]]
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.767]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]] [[2.778]
 [2.833]
 [2.778]
 [2.778]
 [2.778]
 [2.778]
 [2.778]] [[1.592]
 [1.538]
 [1.592]
 [1.592]
 [1.592]
 [1.592]
 [1.592]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
UNIT TEST: sample policy line 217 mcts : [0.918 0.02  0.    0.02  0.    0.02  0.02 ]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.696]
 [0.667]
 [0.686]
 [0.687]
 [0.682]
 [0.681]
 [0.689]] [[-0.431]
 [ 2.615]
 [ 0.056]
 [-0.423]
 [-0.216]
 [-0.09 ]
 [-0.257]] [[0.511]
 [1.725]
 [0.701]
 [0.507]
 [0.587]
 [0.638]
 [0.576]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.027]
 [-0.047]
 [-0.036]
 [-0.035]
 [-0.029]
 [-0.032]
 [-0.028]] [[2.918]
 [2.874]
 [2.934]
 [2.998]
 [3.071]
 [2.907]
 [2.832]] [[-0.508]
 [-0.562]
 [-0.52 ]
 [-0.497]
 [-0.461]
 [-0.521]
 [-0.539]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[1.158]
 [1.158]
 [1.158]
 [1.158]
 [1.158]
 [1.158]
 [1.156]] [[2.235]
 [2.235]
 [2.235]
 [2.235]
 [2.235]
 [2.235]
 [2.229]] [[0.927]
 [0.927]
 [0.927]
 [0.927]
 [0.927]
 [0.927]
 [0.92 ]]
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.225]
 [0.225]
 [0.225]
 [0.225]
 [0.225]
 [0.225]] [[2.053]
 [1.192]
 [1.192]
 [1.192]
 [1.192]
 [1.192]
 [1.192]] [[0.413]
 [0.225]
 [0.225]
 [0.225]
 [0.225]
 [0.225]
 [0.225]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]] [[4.752]
 [4.752]
 [4.752]
 [4.752]
 [4.752]
 [4.752]
 [4.752]] [[2.034]
 [2.034]
 [2.034]
 [2.034]
 [2.034]
 [2.034]
 [2.034]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.53 ]
 [0.783]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]] [[2.686]
 [1.961]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]] [[2.027]
 [1.951]
 [1.425]
 [1.425]
 [1.425]
 [1.425]
 [1.425]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[1.425]
 [1.425]
 [1.425]
 [1.425]
 [1.425]
 [1.425]
 [1.425]] [[1.586]
 [1.586]
 [1.586]
 [1.586]
 [1.586]
 [1.586]
 [1.586]] [[2.181]
 [2.181]
 [2.181]
 [2.181]
 [2.181]
 [2.181]
 [2.181]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.524]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]] [[-1.148]
 [ 0.396]
 [ 0.396]
 [ 0.396]
 [ 0.396]
 [ 0.396]
 [ 0.396]] [[0.524]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.45]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]] [[0.148]
 [1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]] [[0.45]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.3567378821114526
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1889 1637
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]] [[-0.218]
 [-0.341]
 [-0.341]
 [-0.341]
 [-0.341]
 [-0.341]
 [-0.341]] [[0.462]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.538]
 [0.47 ]
 [0.535]
 [0.53 ]
 [0.533]
 [0.518]
 [0.502]] [[2.372]
 [3.488]
 [2.365]
 [2.427]
 [2.135]
 [2.254]
 [2.331]] [[0.538]
 [0.47 ]
 [0.535]
 [0.53 ]
 [0.533]
 [0.518]
 [0.502]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6562345
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
in main func line 156:  1897
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.5817798510441503
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[-0.026]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]] [[6.627]
 [6.435]
 [6.435]
 [6.435]
 [6.435]
 [6.435]
 [6.435]] [[-0.317]
 [-0.386]
 [-0.386]
 [-0.386]
 [-0.386]
 [-0.386]
 [-0.386]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.670723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.5816449513243092
Printing some Q and Qe and total Qs values:  [[0.812]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]] [[2.702]
 [2.973]
 [2.973]
 [2.973]
 [2.973]
 [2.973]
 [2.973]] [[2.47 ]
 [2.563]
 [2.563]
 [2.563]
 [2.563]
 [2.563]
 [2.563]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.4938011884955493
Printing some Q and Qe and total Qs values:  [[0.087]
 [1.372]
 [0.087]
 [0.087]
 [0.087]
 [0.087]
 [0.087]] [[2.532]
 [1.561]
 [2.532]
 [2.532]
 [2.532]
 [2.532]
 [2.532]] [[0.235]
 [2.16 ]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1904 1650
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.66649437
Printing some Q and Qe and total Qs values:  [[0.238]
 [0.263]
 [0.233]
 [0.23 ]
 [0.245]
 [0.237]
 [0.245]] [[2.134]
 [1.789]
 [1.401]
 [1.535]
 [2.427]
 [1.485]
 [2.427]] [[0.238]
 [0.263]
 [0.233]
 [0.23 ]
 [0.245]
 [0.237]
 [0.245]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.195]
 [0.172]
 [0.174]
 [0.175]
 [0.161]
 [0.164]
 [0.17 ]] [[-1.778]
 [ 0.333]
 [-0.972]
 [-0.685]
 [-1.111]
 [-1.107]
 [-0.775]] [[0.195]
 [0.172]
 [0.174]
 [0.175]
 [0.161]
 [0.164]
 [0.17 ]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.012822748931330563
Printing some Q and Qe and total Qs values:  [[0.181]
 [0.182]
 [0.167]
 [0.186]
 [0.169]
 [0.167]
 [0.177]] [[-0.725]
 [ 0.627]
 [-0.148]
 [-0.097]
 [-0.345]
 [-0.287]
 [-0.237]] [[0.181]
 [0.182]
 [0.167]
 [0.186]
 [0.169]
 [0.167]
 [0.177]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -3.11248184175311
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.0803529361479836
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.731]] [[3.838]
 [3.838]
 [3.838]
 [3.838]
 [3.838]
 [3.838]
 [4.112]] [[1.182]
 [1.182]
 [1.182]
 [1.182]
 [1.182]
 [1.182]
 [1.297]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.171]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]] [[-0.65 ]
 [-0.585]
 [-0.585]
 [-0.585]
 [-0.585]
 [-0.585]
 [-0.585]] [[0.171]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.737]
 [0.862]
 [0.742]
 [0.742]
 [0.742]
 [0.742]
 [0.742]] [[4.602]
 [5.371]
 [4.87 ]
 [4.87 ]
 [4.87 ]
 [4.87 ]
 [4.87 ]] [[0.848]
 [1.354]
 [0.946]
 [0.946]
 [0.946]
 [0.946]
 [0.946]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.66501814
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6636819
1918 1656
line 256 mcts: sample exp_bonus 3.121235724529022
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.6735594375074845
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.494]
 [0.433]
 [0.463]
 [0.433]
 [0.433]
 [0.433]
 [0.433]] [[2.111]
 [2.351]
 [2.238]
 [2.351]
 [2.351]
 [2.351]
 [2.351]] [[0.148]
 [0.186]
 [0.171]
 [0.186]
 [0.186]
 [0.186]
 [0.186]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.405]
 [0.338]
 [0.374]
 [0.379]
 [0.35 ]
 [0.335]
 [0.352]] [[1.923]
 [2.029]
 [2.   ]
 [2.16 ]
 [2.015]
 [2.031]
 [2.183]] [[-0.259]
 [-0.323]
 [-0.269]
 [-0.153]
 [-0.307]
 [-0.327]
 [-0.192]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.299]
 [0.296]
 [0.299]
 [0.299]
 [0.299]
 [0.299]] [[ 0.264]
 [-3.135]
 [-2.402]
 [-3.135]
 [-3.135]
 [-3.135]
 [-3.135]] [[0.541]
 [0.299]
 [0.296]
 [0.299]
 [0.299]
 [0.299]
 [0.299]]
Printing some Q and Qe and total Qs values:  [[0.562]
 [0.304]
 [0.296]
 [0.304]
 [0.304]
 [0.304]
 [0.304]] [[-1.531]
 [-2.475]
 [-2.435]
 [-2.475]
 [-2.475]
 [-2.475]
 [-2.475]] [[0.562]
 [0.304]
 [0.296]
 [0.304]
 [0.304]
 [0.304]
 [0.304]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.491]
 [0.437]
 [0.439]
 [0.438]
 [0.436]
 [0.436]
 [0.435]] [[-5.441]
 [-5.164]
 [-5.097]
 [-5.097]
 [-5.058]
 [-5.053]
 [-5.067]] [[0.491]
 [0.437]
 [0.439]
 [0.438]
 [0.436]
 [0.436]
 [0.435]]
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.339]
 [0.415]
 [0.476]
 [0.476]
 [0.476]
 [0.439]] [[-6.   ]
 [-3.032]
 [-5.592]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-5.174]] [[0.467]
 [0.339]
 [0.415]
 [0.476]
 [0.476]
 [0.476]
 [0.439]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
1926 1660
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.111]
 [0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]] [[-4.712]
 [-4.758]
 [-4.758]
 [-4.758]
 [-4.758]
 [-4.758]
 [-4.758]] [[0.111]
 [0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.49 ]
 [0.141]
 [0.566]
 [0.589]
 [0.54 ]
 [0.576]
 [0.545]] [[ 0.987]
 [ 3.79 ]
 [ 0.134]
 [-0.838]
 [-0.118]
 [-0.12 ]
 [ 0.484]] [[0.991]
 [2.032]
 [0.643]
 [0.185]
 [0.493]
 [0.527]
 [0.795]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
1929 1664
first move QE:  1.567113426913325
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.235]
 [0.076]
 [0.076]
 [0.076]
 [0.076]
 [0.076]
 [0.076]] [[-1.755]
 [-1.647]
 [-1.647]
 [-1.647]
 [-1.647]
 [-1.647]
 [-1.647]] [[0.235]
 [0.076]
 [0.076]
 [0.076]
 [0.076]
 [0.076]
 [0.076]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus -1.7448891975155516
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]] [[3.097]
 [3.097]
 [3.097]
 [3.097]
 [3.097]
 [3.097]
 [3.097]] [[0.965]
 [0.965]
 [0.965]
 [0.965]
 [0.965]
 [0.965]
 [0.965]]
siam score:  -0.6576102
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.65588534
siam score:  -0.6588895
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
Printing some Q and Qe and total Qs values:  [[0.237]
 [0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]] [[ 3.392]
 [-0.456]
 [-0.456]
 [-0.456]
 [-0.456]
 [-0.456]
 [-0.456]] [[0.237]
 [0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]]
Printing some Q and Qe and total Qs values:  [[0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]] [[5.417]
 [5.417]
 [5.417]
 [5.417]
 [5.417]
 [5.417]
 [5.417]] [[0.283]
 [0.283]
 [0.283]
 [0.283]
 [0.283]
 [0.283]
 [0.283]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.357]
 [0.315]
 [0.42 ]
 [0.42 ]
 [0.42 ]
 [0.42 ]
 [0.42 ]] [[4.354]
 [5.971]
 [4.318]
 [4.318]
 [4.318]
 [4.318]
 [4.318]] [[-0.056]
 [ 0.398]
 [ 0.057]
 [ 0.057]
 [ 0.057]
 [ 0.057]
 [ 0.057]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.286 0.102 0.143 0.041 0.082 0.306 0.041]
Printing some Q and Qe and total Qs values:  [[ 0.006]
 [-0.005]
 [ 0.01 ]
 [-0.001]
 [-0.003]
 [-0.003]
 [-0.003]] [[6.173]
 [5.979]
 [5.565]
 [5.733]
 [6.156]
 [6.156]
 [6.156]] [[-0.01 ]
 [-0.097]
 [-0.206]
 [-0.171]
 [-0.033]
 [-0.033]
 [-0.033]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.506]
 [0.268]
 [0.268]
 [0.268]
 [0.268]
 [0.268]
 [0.268]] [[-3.477]
 [-1.364]
 [-1.364]
 [-1.364]
 [-1.364]
 [-1.364]
 [-1.364]] [[0.506]
 [0.268]
 [0.268]
 [0.268]
 [0.268]
 [0.268]
 [0.268]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[-0.004]
 [-0.017]
 [-0.013]
 [-0.01 ]
 [-0.017]
 [-0.003]
 [ 0.016]] [[6.615]
 [5.834]
 [6.711]
 [6.546]
 [5.834]
 [6.22 ]
 [5.911]] [[-0.077]
 [-0.364]
 [-0.064]
 [-0.113]
 [-0.364]
 [-0.207]
 [-0.272]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.419]
 [0.419]
 [0.419]
 [0.419]
 [0.419]
 [0.419]
 [0.419]] [[-0.065]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.065]
 [-0.065]] [[0.419]
 [0.419]
 [0.419]
 [0.419]
 [0.419]
 [0.419]
 [0.419]]
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.892]
 [0.892]
 [0.892]
 [0.892]
 [0.892]
 [0.728]] [[3.465]
 [3.22 ]
 [3.22 ]
 [3.22 ]
 [3.22 ]
 [3.22 ]
 [3.523]] [[1.975]
 [1.857]
 [1.857]
 [1.857]
 [1.857]
 [1.857]
 [1.792]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]] [[3.146]
 [3.146]
 [3.146]
 [3.146]
 [3.146]
 [3.146]
 [3.146]] [[2.64]
 [2.64]
 [2.64]
 [2.64]
 [2.64]
 [2.64]
 [2.64]]
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.859]
 [0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.703]] [[2.895]
 [4.042]
 [2.895]
 [2.895]
 [2.895]
 [2.895]
 [2.895]] [[0.825]
 [1.52 ]
 [0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.5660535354668603
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.126]
 [0.057]
 [0.057]
 [0.057]
 [0.057]
 [0.057]
 [0.057]] [[-2.957]
 [-2.808]
 [-2.808]
 [-2.808]
 [-2.808]
 [-2.808]
 [-2.808]] [[0.126]
 [0.057]
 [0.057]
 [0.057]
 [0.057]
 [0.057]
 [0.057]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.037]
 [-0.038]
 [-0.046]
 [-0.046]
 [-0.046]
 [-0.046]
 [-0.046]] [[6.988]
 [6.516]
 [7.805]
 [7.805]
 [7.805]
 [7.805]
 [7.805]] [[ 0.057]
 [-0.104]
 [ 0.311]
 [ 0.311]
 [ 0.311]
 [ 0.311]
 [ 0.311]]
using explorer policy with actor:  1
first move QE:  1.56442650299917
siam score:  -0.66700625
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.396291870477971
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.738381797008674
UNIT TEST: sample policy line 217 mcts : [0.306 0.163 0.082 0.143 0.204 0.061 0.041]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.618]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]] [[4.795]
 [4.843]
 [4.795]
 [4.795]
 [4.795]
 [4.795]
 [4.795]] [[0.855]
 [0.965]
 [0.855]
 [0.855]
 [0.855]
 [0.855]
 [0.855]]
Printing some Q and Qe and total Qs values:  [[0.381]
 [0.333]
 [0.37 ]
 [0.352]
 [0.358]
 [0.37 ]
 [0.385]] [[5.8  ]
 [5.121]
 [5.679]
 [5.976]
 [5.941]
 [5.913]
 [5.91 ]] [[0.332]
 [0.01 ]
 [0.27 ]
 [0.332]
 [0.333]
 [0.349]
 [0.378]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.088]
 [-0.088]
 [-0.088]
 [-0.088]
 [-0.088]
 [-0.088]
 [-0.088]] [[6.066]
 [6.066]
 [6.066]
 [6.066]
 [6.066]
 [6.066]
 [6.066]] [[1.849]
 [1.849]
 [1.849]
 [1.849]
 [1.849]
 [1.849]
 [1.849]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.108]
 [-0.104]
 [-0.111]
 [-0.111]
 [-0.113]
 [-0.115]
 [-0.114]] [[6.091]
 [5.445]
 [5.872]
 [6.011]
 [6.065]
 [5.642]
 [5.906]] [[-0.34 ]
 [-0.546]
 [-0.417]
 [-0.372]
 [-0.357]
 [-0.504]
 [-0.414]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.76 ]
 [0.763]
 [0.878]
 [0.878]
 [0.878]
 [0.772]] [[2.645]
 [3.334]
 [2.856]
 [2.645]
 [2.645]
 [2.645]
 [3.03 ]] [[1.203]
 [1.197]
 [1.044]
 [1.203]
 [1.203]
 [1.203]
 [1.12 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.5614450534439372
siam score:  -0.6551633
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]] [[5.196]
 [5.196]
 [5.196]
 [5.196]
 [5.196]
 [5.196]
 [5.196]] [[1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 3.097551681412389
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]] [[3.72]
 [3.72]
 [3.72]
 [3.72]
 [3.72]
 [3.72]
 [3.72]] [[0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.267]
 [0.105]
 [0.105]
 [0.105]
 [0.105]
 [0.105]
 [0.105]] [[-0.455]
 [-3.835]
 [-3.835]
 [-3.835]
 [-3.835]
 [-3.835]
 [-3.835]] [[0.267]
 [0.105]
 [0.105]
 [0.105]
 [0.105]
 [0.105]
 [0.105]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6544521
Printing some Q and Qe and total Qs values:  [[0.189]
 [0.235]
 [0.24 ]
 [0.218]
 [0.215]
 [0.218]
 [0.272]] [[4.76 ]
 [4.228]
 [4.193]
 [4.227]
 [4.147]
 [4.257]
 [3.939]] [[0.523]
 [0.26 ]
 [0.248]
 [0.227]
 [0.167]
 [0.246]
 [0.142]]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[ 0.037]
 [-0.014]
 [ 0.098]
 [ 0.076]
 [-0.005]
 [-0.001]
 [ 0.028]] [[5.055]
 [3.836]
 [4.634]
 [4.409]
 [4.668]
 [4.619]
 [4.349]] [[ 0.468]
 [-0.316]
 [ 0.269]
 [ 0.112]
 [ 0.196]
 [ 0.169]
 [ 0.033]]
first move QE:  1.557328490072828
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.488]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]] [[-0.638]
 [ 0.032]
 [ 0.032]
 [ 0.032]
 [ 0.032]
 [ 0.032]
 [ 0.032]] [[0.488]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.226]]
Printing some Q and Qe and total Qs values:  [[0.268]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]] [[0.85]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]] [[0.268]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.352]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]] [[7.929]
 [5.944]
 [5.944]
 [5.944]
 [5.944]
 [5.944]
 [5.944]] [[0.352]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.321]
 [0.321]
 [0.321]
 [0.321]
 [0.321]
 [0.321]
 [0.321]] [[2.121]
 [2.121]
 [2.121]
 [2.121]
 [2.121]
 [2.121]
 [2.121]] [[0.321]
 [0.321]
 [0.321]
 [0.321]
 [0.321]
 [0.321]
 [0.321]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.706]
 [0.706]
 [0.736]
 [0.706]
 [0.706]
 [0.706]] [[4.027]
 [4.027]
 [4.027]
 [4.13 ]
 [4.027]
 [4.027]
 [4.027]] [[1.715]
 [1.715]
 [1.715]
 [1.87 ]
 [1.715]
 [1.715]
 [1.715]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.66196626
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.63 ]
 [0.555]
 [0.591]
 [0.59 ]
 [0.585]
 [0.577]
 [0.587]] [[0.73 ]
 [2.628]
 [0.766]
 [0.51 ]
 [0.445]
 [0.541]
 [0.843]] [[0.63 ]
 [0.555]
 [0.591]
 [0.59 ]
 [0.585]
 [0.577]
 [0.587]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.721]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]] [[2.489]
 [1.231]
 [1.231]
 [1.231]
 [1.231]
 [1.231]
 [1.231]] [[1.925]
 [1.452]
 [1.452]
 [1.452]
 [1.452]
 [1.452]
 [1.452]]
start point for exploration sampling:  10624
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.803]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.741]] [[0.99 ]
 [1.17 ]
 [0.99 ]
 [0.99 ]
 [0.99 ]
 [0.99 ]
 [1.008]] [[1.773]
 [1.871]
 [1.773]
 [1.773]
 [1.773]
 [1.773]
 [1.782]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.072]
 [0.069]
 [0.069]
 [0.069]
 [0.069]
 [0.069]
 [0.069]] [[-3.606]
 [-3.886]
 [-3.886]
 [-3.886]
 [-3.886]
 [-3.886]
 [-3.886]] [[0.072]
 [0.069]
 [0.069]
 [0.069]
 [0.069]
 [0.069]
 [0.069]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.65491164
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.357]
 [0.043]
 [0.077]
 [0.076]
 [0.068]
 [0.08 ]
 [0.075]] [[-5.658]
 [-0.635]
 [-4.042]
 [-4.185]
 [-3.912]
 [-4.055]
 [-3.968]] [[0.357]
 [0.043]
 [0.077]
 [0.076]
 [0.068]
 [0.08 ]
 [0.075]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.056]
 [-0.061]
 [-0.061]
 [-0.061]
 [-0.061]
 [-0.061]
 [-0.061]] [[4.432]
 [4.282]
 [4.282]
 [4.282]
 [4.282]
 [4.282]
 [4.282]] [[-0.845]
 [-0.906]
 [-0.906]
 [-0.906]
 [-0.906]
 [-0.906]
 [-0.906]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.766]
 [0.731]
 [0.764]
 [0.771]
 [0.775]
 [0.731]
 [0.735]] [[0.692]
 [1.162]
 [0.504]
 [0.543]
 [0.805]
 [0.386]
 [0.705]] [[0.766]
 [0.731]
 [0.764]
 [0.771]
 [0.775]
 [0.731]
 [0.735]]
Printing some Q and Qe and total Qs values:  [[1.221]
 [0.719]
 [0.793]
 [0.773]
 [0.735]
 [0.697]
 [0.727]] [[2.178]
 [2.165]
 [1.64 ]
 [1.608]
 [1.658]
 [1.733]
 [1.739]] [[1.444]
 [0.435]
 [0.408]
 [0.358]
 [0.299]
 [0.248]
 [0.308]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.096]
 [0.077]
 [0.049]
 [0.048]
 [0.028]
 [0.05 ]
 [0.046]] [[4.122]
 [3.486]
 [3.913]
 [3.852]
 [3.455]
 [3.836]
 [3.732]] [[-0.76 ]
 [-1.009]
 [-0.923]
 [-0.945]
 [-1.119]
 [-0.948]
 [-0.99 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.539]
 [0.477]
 [0.485]
 [0.494]
 [0.491]
 [0.5  ]
 [0.487]] [[4.394]
 [3.353]
 [4.322]
 [4.659]
 [4.562]
 [4.384]
 [4.326]] [[1.019]
 [0.202]
 [0.863]
 [1.107]
 [1.035]
 [0.935]
 [0.87 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 1.5331163451965866
siam score:  -0.65561646
1981 1701
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.65429324
start point for exploration sampling:  10624
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.784]
 [0.781]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]] [[2.479]
 [3.255]
 [2.479]
 [2.479]
 [2.479]
 [2.479]
 [2.479]] [[1.383]
 [1.857]
 [1.383]
 [1.383]
 [1.383]
 [1.383]
 [1.383]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.231]
 [0.451]
 [0.113]
 [0.237]
 [0.11 ]
 [0.132]
 [0.144]] [[4.274]
 [4.054]
 [4.218]
 [3.791]
 [4.054]
 [4.145]
 [3.665]] [[1.264]
 [1.343]
 [1.097]
 [0.924]
 [0.976]
 [1.065]
 [0.733]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.111]
 [0.739]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]] [[2.636]
 [1.343]
 [0.875]
 [0.875]
 [0.875]
 [0.875]
 [0.875]] [[1.745]
 [1.644]
 [1.447]
 [1.447]
 [1.447]
 [1.447]
 [1.447]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.277]
 [0.135]
 [0.135]
 [0.135]
 [0.135]
 [0.135]
 [0.135]] [[5.966]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]] [[0.277]
 [0.135]
 [0.135]
 [0.135]
 [0.135]
 [0.135]
 [0.135]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10624
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.302]
 [0.119]
 [0.119]
 [0.119]
 [0.119]
 [0.119]
 [0.119]] [[ 3.277]
 [-2.526]
 [-2.526]
 [-2.526]
 [-2.526]
 [-2.526]
 [-2.526]] [[0.302]
 [0.119]
 [0.119]
 [0.119]
 [0.119]
 [0.119]
 [0.119]]
Printing some Q and Qe and total Qs values:  [[0.673]
 [0.753]
 [0.758]
 [0.753]
 [0.753]
 [0.626]
 [0.931]] [[2.315]
 [2.622]
 [2.8  ]
 [2.622]
 [2.622]
 [2.55 ]
 [3.083]] [[1.407]
 [1.669]
 [1.739]
 [1.669]
 [1.669]
 [1.391]
 [2.178]]
Printing some Q and Qe and total Qs values:  [[0.419]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]] [[ 1.327]
 [-0.281]
 [-0.281]
 [-0.281]
 [-0.281]
 [-0.281]
 [-0.281]] [[0.419]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]
 [0.21 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
deleting a thread, now have 3 threads
Frames:  139416 train batches done:  16336 episodes:  3693
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.093]
 [0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.085]] [[-0.849]
 [-0.524]
 [-0.524]
 [-0.524]
 [-0.524]
 [-0.524]
 [-0.524]] [[0.093]
 [0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.085]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.539710459159069
line 256 mcts: sample exp_bonus 4.0214974008054085
Printing some Q and Qe and total Qs values:  [[0.369]
 [0.406]
 [0.369]
 [0.369]
 [0.369]
 [0.369]
 [0.369]] [[3.23 ]
 [3.384]
 [3.23 ]
 [3.23 ]
 [3.23 ]
 [3.23 ]
 [3.23 ]] [[0.369]
 [0.406]
 [0.369]
 [0.369]
 [0.369]
 [0.369]
 [0.369]]
Printing some Q and Qe and total Qs values:  [[0.844]
 [0.905]
 [0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]] [[3.638]
 [2.864]
 [3.638]
 [3.638]
 [3.638]
 [3.638]
 [3.638]] [[1.817]
 [1.502]
 [1.817]
 [1.817]
 [1.817]
 [1.817]
 [1.817]]
Printing some Q and Qe and total Qs values:  [[0.348]
 [0.448]
 [0.401]
 [0.374]
 [0.38 ]
 [0.371]
 [0.366]] [[3.945]
 [3.336]
 [3.534]
 [3.737]
 [3.721]
 [3.729]
 [3.585]] [[0.348]
 [0.448]
 [0.401]
 [0.374]
 [0.38 ]
 [0.371]
 [0.366]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.18 ]
 [0.141]
 [0.141]
 [0.141]
 [0.141]
 [0.141]
 [0.141]] [[-2.184]
 [-3.302]
 [-3.302]
 [-3.302]
 [-3.302]
 [-3.302]
 [-3.302]] [[0.18 ]
 [0.141]
 [0.141]
 [0.141]
 [0.141]
 [0.141]
 [0.141]]
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.706]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]] [[3.497]
 [3.741]
 [3.497]
 [3.497]
 [3.497]
 [3.497]
 [3.497]] [[1.936]
 [2.15 ]
 [1.936]
 [1.936]
 [1.936]
 [1.936]
 [1.936]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.602]
 [0.751]
 [0.777]
 [0.602]
 [0.602]
 [0.602]
 [0.602]] [[2.389]
 [2.973]
 [2.983]
 [2.389]
 [2.389]
 [2.389]
 [2.389]] [[0.469]
 [1.248]
 [1.303]
 [0.469]
 [0.469]
 [0.469]
 [0.469]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.5389847199273408
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6521773
first move QE:  1.538975706019002
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.292]
 [0.293]
 [0.293]
 [0.293]
 [0.293]
 [0.293]
 [0.293]] [[0.545]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]] [[0.292]
 [0.293]
 [0.293]
 [0.293]
 [0.293]
 [0.293]
 [0.293]]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]] [[0.465]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]] [[0.552]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]
 [0.343]]
siam score:  -0.65274704
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.891]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]] [[3.147]
 [3.724]
 [3.147]
 [3.147]
 [3.147]
 [3.147]
 [3.147]] [[0.682]
 [1.17 ]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.487]
 [0.286]
 [0.269]
 [0.258]
 [0.265]
 [0.26 ]
 [0.258]] [[1.166]
 [2.049]
 [1.56 ]
 [1.781]
 [1.701]
 [1.64 ]
 [1.697]] [[0.487]
 [0.286]
 [0.269]
 [0.258]
 [0.265]
 [0.26 ]
 [0.258]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.466]
 [0.537]
 [0.466]
 [0.466]
 [0.466]
 [0.466]
 [0.466]] [[2.842]
 [3.192]
 [2.842]
 [2.842]
 [2.842]
 [2.842]
 [2.842]] [[0.466]
 [0.537]
 [0.466]
 [0.466]
 [0.466]
 [0.466]
 [0.466]]
Printing some Q and Qe and total Qs values:  [[0.454]
 [0.506]
 [0.457]
 [0.454]
 [0.454]
 [0.454]
 [0.44 ]] [[1.295]
 [2.399]
 [1.344]
 [1.295]
 [1.295]
 [1.295]
 [2.164]] [[0.454]
 [0.506]
 [0.457]
 [0.454]
 [0.454]
 [0.454]
 [0.44 ]]
Printing some Q and Qe and total Qs values:  [[0.524]
 [0.556]
 [0.524]
 [0.457]
 [0.524]
 [0.524]
 [0.524]] [[2.882]
 [2.575]
 [2.882]
 [2.064]
 [2.882]
 [2.882]
 [2.882]] [[0.524]
 [0.556]
 [0.524]
 [0.457]
 [0.524]
 [0.524]
 [0.524]]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.54 ]
 [0.478]
 [0.544]
 [0.502]
 [0.502]
 [0.502]] [[1.845]
 [2.098]
 [1.232]
 [2.279]
 [2.537]
 [2.537]
 [2.537]] [[0.535]
 [0.54 ]
 [0.478]
 [0.544]
 [0.502]
 [0.502]
 [0.502]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.089]
 [0.155]
 [0.194]
 [0.192]
 [0.159]
 [0.168]
 [0.158]] [[2.955]
 [2.738]
 [3.006]
 [3.027]
 [2.982]
 [2.765]
 [2.892]] [[0.089]
 [0.155]
 [0.194]
 [0.192]
 [0.159]
 [0.168]
 [0.158]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.639]
 [0.637]
 [0.639]
 [0.639]
 [0.638]
 [0.639]] [[0.231]
 [0.59 ]
 [0.495]
 [0.59 ]
 [0.59 ]
 [0.478]
 [0.59 ]] [[0.659]
 [0.639]
 [0.637]
 [0.639]
 [0.639]
 [0.638]
 [0.639]]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.736]
 [0.632]
 [0.63 ]
 [0.633]
 [0.655]
 [0.661]] [[-0.109]
 [ 0.498]
 [ 1.351]
 [ 1.275]
 [ 1.242]
 [ 1.355]
 [ 1.096]] [[0.775]
 [0.736]
 [0.632]
 [0.63 ]
 [0.633]
 [0.655]
 [0.661]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.754]
 [0.664]
 [0.664]
 [0.664]
 [0.664]
 [0.664]
 [0.664]] [[2.434]
 [1.394]
 [1.394]
 [1.394]
 [1.394]
 [1.394]
 [1.394]] [[0.754]
 [0.664]
 [0.664]
 [0.664]
 [0.664]
 [0.664]
 [0.664]]
siam score:  -0.6642449
Printing some Q and Qe and total Qs values:  [[0.233]
 [0.19 ]
 [0.162]
 [0.154]
 [0.19 ]
 [0.177]
 [0.19 ]] [[2.08 ]
 [1.935]
 [2.177]
 [2.189]
 [1.935]
 [2.226]
 [1.935]] [[-0.35 ]
 [-0.486]
 [-0.461]
 [-0.472]
 [-0.486]
 [-0.413]
 [-0.486]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.535]
 [0.585]
 [0.59 ]
 [0.597]
 [0.611]
 [0.598]] [[1.824]
 [2.933]
 [2.159]
 [2.074]
 [2.088]
 [2.02 ]
 [2.065]] [[0.612]
 [0.535]
 [0.585]
 [0.59 ]
 [0.597]
 [0.611]
 [0.598]]
Printing some Q and Qe and total Qs values:  [[-0.038]
 [-0.054]
 [-0.033]
 [-0.019]
 [-0.02 ]
 [-0.02 ]
 [-0.044]] [[5.45 ]
 [5.033]
 [4.913]
 [4.803]
 [4.764]
 [4.764]
 [5.15 ]] [[-0.571]
 [-0.741]
 [-0.739]
 [-0.748]
 [-0.764]
 [-0.764]
 [-0.683]]
siam score:  -0.6641244
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]] [[0.815]
 [1.003]
 [1.003]
 [1.003]
 [1.003]
 [1.003]
 [1.003]] [[0.703]
 [0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.66145575
Printing some Q and Qe and total Qs values:  [[0.752]
 [0.594]
 [0.653]
 [0.662]
 [0.66 ]
 [0.66 ]
 [0.641]] [[0.189]
 [2.314]
 [1.71 ]
 [1.128]
 [1.484]
 [1.583]
 [1.411]] [[0.752]
 [0.594]
 [0.653]
 [0.662]
 [0.66 ]
 [0.66 ]
 [0.641]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 1.2259371440005404
Printing some Q and Qe and total Qs values:  [[0.474]
 [0.834]
 [0.716]
 [0.716]
 [0.716]
 [0.716]
 [0.716]] [[2.378]
 [1.832]
 [0.458]
 [0.458]
 [0.458]
 [0.458]
 [0.458]] [[ 0.772]
 [ 0.873]
 [-0.058]
 [-0.058]
 [-0.058]
 [-0.058]
 [-0.058]]
