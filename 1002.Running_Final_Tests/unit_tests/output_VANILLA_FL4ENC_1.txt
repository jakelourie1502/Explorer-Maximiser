dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 25}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:32
res_block_kernel_size:3
res_block_channels:[32, 32]
res_block_ds:[False, True, False, False, False]
conv1:{'channels': 16, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
reward_support:[-1, 1, 51]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[32, 32]
reward_conv_channels:16
reward_hidden_dim:128
terminal_conv_channels:16
terminal_hidden_dim:64
value_support:[-1, 1, 51]
res_block:[32]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:2
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
resampling:False
resampling_use_max:False
resampling_assess_best_child:False
rs_start:1000
ep_to_batch_ratio:[9, 10]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
rgb_im:False
channels:1
timesteps_in_obs:1
store_prev_actions:False
env:<class 'game_play.frozen_lakeGym_Image.gridWorld'>
same_env_each_time:True
env_size:[4, 4]
observable_size:[4, 4]
game_modes:1
env_map:[['S' 'F' 'F' 'F']
 ['F' 'F' 'H' 'H']
 ['F' 'F' 'F' 'F']
 ['F' 'H' 'F' 'G']]
max_steps:30
actions_size:4
optimal_score:1
total_frames:255000
exp_gamma:0.95
atari_env:False
state_size:[4, 4]
reward_clipping:False
memory_size:100
image_size:[48, 48]
running_reward_in_obs:False
deque_length:1
PRESET_CONFIG:5
VK_ceiling:False
VK:False
use_two_heads:False
use_siam:False
exploration_type:none
rdn_beta:[0, 0.0, 1]
explorer_percentage:0.0
follow_better_policy:0.0
reward_exploration:False
train_dones:False
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(1, 16)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:True
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[['S' 'F' 'F' 'F']
 ['F' 'F' 'H' 'H']
 ['F' 'F' 'F' 'F']
 ['F' 'H' 'F' 'G']]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
actor:  0 policy actor:  0  step number:  20 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
9 27
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.2 0.4 0.2 0.2]
12 38
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
24 69
Printing some Q and Qe and total Qs values:  [[-0.   ]
 [ 0.   ]
 [ 0.001]
 [ 0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[-0.   ]
 [ 0.   ]
 [ 0.001]
 [ 0.001]]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.   ]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.   ]
 [0.   ]
 [0.001]]
45 120
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]]
Starting evaluation
siam score:  0.0
maxi score, test score, baseline:  0.026885714285714284 0.0 0.026885714285714284
probs:  [1.0]
maxi score, test score, baseline:  0.02618695652173913 0.0 0.02618695652173913
probs:  [1.0]
rdn probs:  [1.0]
maxi score, test score, baseline:  0.0251 0.0 0.0251
probs:  [1.0]
59 164
Printing some Q and Qe and total Qs values:  [[0.063]
 [0.04 ]
 [0.04 ]
 [0.011]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.063]
 [0.04 ]
 [0.04 ]
 [0.011]]
maxi score, test score, baseline:  0.022488059701492535 0.0 0.022488059701492535
probs:  [1.0]
maxi score, test score, baseline:  0.022322222222222222 0.0 0.022322222222222222
actor:  0 policy actor:  0  step number:  24 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.02501103202846975 0.0 0.02501103202846975
probs:  [1.0]
maxi score, test score, baseline:  0.02474788732394366 0.0 0.02474788732394366
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
probs:  [1.0]
maxi score, test score, baseline:  0.024575524475524475 0.0 0.024575524475524475
main train batch thing paused
add a thread
Adding thread: now have 4 threads
81 216
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
deleting a thread, now have 3 threads
Frames:  5705 train batches done:  306 episodes:  374
UNIT TEST: sample policy line 217 mcts : [0.4 0.  0.2 0.4]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
siam score:  0.0
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
siam score:  0.0
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
maxi score, test score, baseline:  0.020200502512562814 0.0 0.020200502512562814
probs:  [1.0]
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Printing some Q and Qe and total Qs values:  [[0.216]
 [0.216]
 [0.216]
 [0.216]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.216]
 [0.216]
 [0.216]
 [0.216]]
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.087]
 [0.086]
 [0.067]
 [0.117]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.087]
 [0.086]
 [0.067]
 [0.117]]
121 293
main train batch thing paused
add a thread
Adding thread: now have 5 threads
actor:  0 policy actor:  0  step number:  12 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
134 338
maxi score, test score, baseline:  0.02014008016032064 0.0 0.02014008016032064
probs:  [1.0]
maxi score, test score, baseline:  0.02014008016032064 0.0 0.02014008016032064
maxi score, test score, baseline:  0.0201 0.0 0.0201
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.15 ]
 [0.15 ]
 [0.976]
 [0.15 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.15 ]
 [0.15 ]
 [0.976]
 [0.15 ]]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
maxi score, test score, baseline:  0.0201 0.0 0.0201
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.577]
 [0.615]
 [0.577]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.577]
 [0.577]
 [0.615]
 [0.577]]
maxi score, test score, baseline:  0.0201 0.0 0.0201
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.341]
 [0.212]
 [0.208]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.74 ]
 [0.341]
 [0.212]
 [0.208]]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.827]
 [0.972]
 [0.747]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.878]
 [0.827]
 [0.972]
 [0.747]]
actor:  0 policy actor:  0  step number:  16 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  12 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
siam score:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.081]
 [0.017]
 [0.017]
 [0.017]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.081]
 [0.017]
 [0.017]
 [0.017]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
main train batch thing paused
add a thread
Adding thread: now have 6 threads
Printing some Q and Qe and total Qs values:  [[0.087]
 [0.093]
 [0.071]
 [0.063]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.087]
 [0.093]
 [0.071]
 [0.063]]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
164 421
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
actor:  0 policy actor:  0  step number:  8 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
siam score:  0.0
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
167 432
Printing some Q and Qe and total Qs values:  [[0.026]
 [0.008]
 [0.019]
 [0.008]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.026]
 [0.008]
 [0.019]
 [0.008]]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.02 ]
 [0.022]
 [0.033]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.019]
 [0.02 ]
 [0.022]
 [0.033]]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0201 0.0 0.0201
maxi score, test score, baseline:  0.0201 0.0 0.0201
actor:  0 policy actor:  0  step number:  10 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
actor:  0 policy actor:  0  step number:  15 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
rdn probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.018]
 [0.01 ]
 [0.013]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.012]
 [0.018]
 [0.01 ]
 [0.013]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
siam score:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.025]
 [0.025]
 [0.025]
 [0.025]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.025]
 [0.025]
 [0.025]
 [0.025]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[0.0105],
        [0.0000],
        [0.0106],
        [0.0132],
        [0.0000],
        [0.0149],
        [0.0120],
        [0.0132],
        [0.0105],
        [0.0132]], dtype=torch.float64)
0.0 0.010501234170074149
0.9801 0.9801
0.0 0.010626298303172368
0.0 0.01324159018030577
0.0 0.0
0.0 0.01492994215010453
0.0 0.012004258890971153
0.0 0.01324159018030577
0.0 0.010501234170074149
0.0 0.01324159018030577
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
213 569
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
216 579
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
siam score:  0.0
217 588
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
siam score:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
UNIT TEST: sample policy line 217 mcts : [0.458 0.125 0.25  0.167]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
225 598
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
232 639
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
in main func line 156:  234
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.008]
 [0.021]
 [0.006]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.012]
 [0.008]
 [0.021]
 [0.006]]
in main func line 156:  240
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.006]
 [0.01 ]
 [0.006]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.011]
 [0.006]
 [0.01 ]
 [0.006]]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.01 ]
 [0.01 ]
 [0.01 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.008]
 [0.01 ]
 [0.01 ]
 [0.01 ]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
siam score:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  14 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.049]
 [0.135]
 [0.135]
 [0.135]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.049]
 [0.135]
 [0.135]
 [0.135]]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
actor:  0 policy actor:  0  step number:  12 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
266 719
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.327]
 [0.327]
 [0.327]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.75 ]
 [0.327]
 [0.327]
 [0.327]]
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.01]
 [0.01]
 [0.01]
 [0.01]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.01]
 [0.01]
 [0.01]
 [0.01]]
in main func line 156:  276
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  12 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.054]
 [0.023]
 [0.074]
 [0.087]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.054]
 [0.023]
 [0.074]
 [0.087]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.138]
 [0.091]
 [0.174]
 [0.188]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.138]
 [0.091]
 [0.174]
 [0.188]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
282 776
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.055]
 [0.072]
 [0.625]
 [0.115]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.055]
 [0.072]
 [0.625]
 [0.115]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.349]
 [0.4  ]
 [0.413]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.368]
 [0.349]
 [0.4  ]
 [0.413]]
Printing some Q and Qe and total Qs values:  [[0.318]
 [0.035]
 [0.043]
 [0.053]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.318]
 [0.035]
 [0.043]
 [0.053]]
UNIT TEST: sample policy line 217 mcts : [0.125 0.5   0.167 0.208]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
294 802
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
295 818
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.011]
 [0.011]
 [0.011]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.011]
 [0.011]
 [0.011]
 [0.011]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.003]
 [0.003]
 [0.003]]
actor:  0 policy actor:  0  step number:  10 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.005]
 [0.008]
 [0.005]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.005]
 [0.008]
 [0.005]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.037]
 [0.037]
 [0.037]
 [0.037]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.037]
 [0.037]
 [0.037]
 [0.037]]
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.009]
 [0.007]
 [0.007]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.007]
 [0.009]
 [0.007]
 [0.007]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
Printing some Q and Qe and total Qs values:  [[0.01]
 [0.01]
 [0.01]
 [0.01]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.01]
 [0.01]
 [0.01]
 [0.01]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.028]
 [0.029]
 [0.029]
 [0.03 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.028]
 [0.029]
 [0.029]
 [0.03 ]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.056]
 [0.056]
 [0.056]
 [0.056]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.056]
 [0.056]
 [0.056]
 [0.056]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
actor:  0 policy actor:  0  step number:  25 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.025]
 [0.025]
 [0.991]
 [0.22 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.025]
 [0.025]
 [0.991]
 [0.22 ]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
330 984
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.041]
 [0.048]
 [0.055]
 [0.471]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.041]
 [0.048]
 [0.055]
 [0.471]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  14 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
334 999
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.667 0.083 0.125 0.125]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
346 1030
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.159]
 [0.159]
 [0.159]
 [0.159]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.159]
 [0.159]
 [0.159]
 [0.159]]
STARTED EXPV TRAINING ON FRAME NO.  20026
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.152]
 [0.092]
 [0.129]
 [0.13 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.152]
 [0.092]
 [0.129]
 [0.13 ]]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
actor:  0 policy actor:  0  step number:  29 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
in main func line 156:  349
rdn probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
360 1062
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.016]
 [0.   ]
 [0.006]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.016]
 [0.   ]
 [0.006]
 [0.   ]]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
374 1074
maxi score, test score, baseline:  0.0301 0.0 0.0301
374 1078
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.008]
 [0.007]
 [0.008]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.008]
 [0.007]
 [0.008]]
siam score:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
in main func line 156:  378
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
siam score:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  8 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.002]
 [0.002]]
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]]
actor:  0 policy actor:  0  step number:  12 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  14 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.802]
 [0.92 ]
 [0.951]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.682]
 [0.802]
 [0.92 ]
 [0.951]]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
actor:  0 policy actor:  0  step number:  10 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.011]
 [0.021]
 [0.012]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.012]
 [0.011]
 [0.021]
 [0.012]]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.003]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.003]
 [0.002]
 [0.002]]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0361 0.0 0.0361
probs:  [1.0]
424 1186
maxi score, test score, baseline:  0.0361 0.0 0.0361
probs:  [1.0]
maxi score, test score, baseline:  0.0361 0.0 0.0361
maxi score, test score, baseline:  0.0361 0.0 0.0361
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.   ]
 [0.   ]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.   ]
 [0.   ]
 [0.   ]]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
438 1214
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.029]
 [0.022]
 [0.029]
 [0.021]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.029]
 [0.022]
 [0.029]
 [0.021]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
453 1232
453 1233
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.004]
 [0.005]
 [0.006]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.004]
 [0.005]
 [0.006]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.004]]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.004]
 [0.005]
 [0.005]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.004]
 [0.005]
 [0.005]]
actor:  0 policy actor:  0  step number:  27 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.004]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.004]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.004]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.003]
 [0.004]
 [0.003]]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.208 0.417 0.208 0.167]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
actor:  0 policy actor:  0  step number:  14 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.003]
 [0.003]
 [0.003]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.003]
 [0.003]
 [0.003]]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.002]
 [0.003]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
487 1340
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.039]
 [0.024]
 [0.014]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.652]
 [0.039]
 [0.024]
 [0.014]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[0.484]
 [0.033]
 [0.004]
 [0.013]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.484]
 [0.033]
 [0.004]
 [0.013]]
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.214]
 [0.214]
 [0.214]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.817]
 [0.214]
 [0.214]
 [0.214]]
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.88 ]
 [0.049]
 [0.88 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.88 ]
 [0.88 ]
 [0.049]
 [0.88 ]]
Printing some Q and Qe and total Qs values:  [[0.037]
 [0.004]
 [0.659]
 [0.058]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.037]
 [0.004]
 [0.659]
 [0.058]]
506 1364
Printing some Q and Qe and total Qs values:  [[0.025]
 [0.003]
 [0.111]
 [0.039]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.025]
 [0.003]
 [0.111]
 [0.039]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
523 1400
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
actor:  0 policy actor:  0  step number:  14 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
526 1427
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.036]
 [0.036]
 [0.036]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.036]
 [0.036]
 [0.036]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.25  0.167 0.167 0.417]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
539 1483
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0201 0.0 0.0201
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.   ]
 [0.007]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.   ]
 [0.007]
 [0.   ]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.003]
 [0.012]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.003]
 [0.012]
 [0.002]]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.002]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.   ]
 [0.002]
 [0.   ]]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
Starting evaluation
maxi score, test score, baseline:  0.0201 0.0 0.0201
siam score:  0.0
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
553 1518
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
rdn probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
561 1523
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0141 0.0 0.0141
maxi score, test score, baseline:  0.0141 0.0 0.0141
probs:  [1.0]
maxi score, test score, baseline:  0.0141 0.0 0.0141
probs:  [1.0]
maxi score, test score, baseline:  0.0141 0.0 0.0141
probs:  [1.0]
maxi score, test score, baseline:  0.0141 0.0 0.0141
probs:  [1.0]
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
566 1550
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]]
UNIT TEST: sample policy line 217 mcts : [0.042 0.875 0.042 0.042]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.052]
 [0.027]
 [0.029]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.052]
 [0.027]
 [0.029]]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
probs:  [1.0]
maxi score, test score, baseline:  0.0161 0.0 0.0161
Printing some Q and Qe and total Qs values:  [[0.014]
 [0.014]
 [0.014]
 [0.014]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.014]
 [0.014]
 [0.014]
 [0.014]]
maxi score, test score, baseline:  0.0161 0.0 0.0161
maxi score, test score, baseline:  0.0161 0.0 0.0161
actor:  0 policy actor:  0  step number:  15 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
585 1618
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[0.033]
 [0.04 ]
 [0.021]
 [0.016]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.033]
 [0.04 ]
 [0.021]
 [0.016]]
actor:  0 policy actor:  0  step number:  20 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  15 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
595 1665
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
Printing some Q and Qe and total Qs values:  [[0.022]
 [0.026]
 [0.019]
 [0.017]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.022]
 [0.026]
 [0.019]
 [0.017]]
siam score:  0.0
siam score:  0.0
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.167 0.125 0.25  0.458]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.017]
 [0.017]
 [0.017]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.017]
 [0.017]
 [0.017]
 [0.017]]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.083 0.042 0.833 0.042]
607 1738
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.0201 0.0 0.0201
maxi score, test score, baseline:  0.0201 0.0 0.0201
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.018099999999999998 0.0 0.018099999999999998
actor:  0 policy actor:  0  step number:  10 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
608 1759
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.022099999999999998 0.0 0.022099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
siam score:  0.0
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.032]
 [0.473]
 [0.014]
 [0.011]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.032]
 [0.473]
 [0.014]
 [0.011]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.125 0.625 0.042 0.208]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.016]
 [0.016]
 [0.016]
 [0.016]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.016]
 [0.016]
 [0.016]
 [0.016]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
actor:  0 policy actor:  0  step number:  8 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.009]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.009]
 [0.009]
 [0.009]
 [0.009]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.25  0.333 0.167 0.25 ]
623 1821
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.062]
 [0.518]
 [0.071]
 [0.048]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.062]
 [0.518]
 [0.071]
 [0.048]]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
siam score:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.026]
 [0.225]
 [0.225]
 [0.225]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.026]
 [0.225]
 [0.225]
 [0.225]]
siam score:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.014]
 [0.018]
 [0.018]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.017]
 [0.014]
 [0.018]
 [0.018]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.03 ]
 [0.015]
 [0.015]
 [0.012]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.03 ]
 [0.015]
 [0.015]
 [0.012]]
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.01 ]
 [0.012]
 [0.013]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.01 ]
 [0.01 ]
 [0.012]
 [0.013]]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.018]
 [0.015]
 [0.012]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.018]
 [0.015]
 [0.012]]
siam score:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
636 1882
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
639 1904
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
642 1924
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.034]
 [0.034]
 [0.034]
 [0.034]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.034]
 [0.034]
 [0.034]
 [0.034]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.02 ]
 [0.009]
 [0.014]
 [0.009]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.02 ]
 [0.009]
 [0.014]
 [0.009]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
actor:  0 policy actor:  0  step number:  12 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.019]
 [0.014]
 [0.009]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.019]
 [0.014]
 [0.009]]
actor:  0 policy actor:  0  step number:  13 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.013]
 [0.011]
 [0.01 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.019]
 [0.013]
 [0.011]
 [0.01 ]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.008]
 [0.008]
 [0.009]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.011]
 [0.008]
 [0.008]
 [0.009]]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.012]
 [0.01 ]
 [0.014]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.018]
 [0.012]
 [0.01 ]
 [0.014]]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
siam score:  0.0
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
684 2063
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.013]
 [0.013]
 [0.013]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.01 ]
 [0.013]
 [0.013]
 [0.013]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.017]
 [0.017]
 [0.017]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.009]
 [0.017]
 [0.017]
 [0.017]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.017]
 [0.017]
 [0.017]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.017]
 [0.017]
 [0.017]
 [0.017]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.007]
 [0.013]
 [0.018]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.018]
 [0.007]
 [0.013]
 [0.018]]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.005]
 [0.005]
 [0.005]]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.02]
 [0.02]
 [0.02]
 [0.02]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.02]
 [0.02]
 [0.02]
 [0.02]]
actor:  0 policy actor:  0  step number:  13 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.138]
 [0.088]
 [0.019]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.138]
 [0.088]
 [0.019]]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.017]
 [0.021]
 [0.062]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.017]
 [0.021]
 [0.062]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
rdn probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0301 0.0 0.0301
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
714 2144
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.026099999999999998 0.0 0.026099999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
maxi score, test score, baseline:  0.0241 0.0 0.0241
maxi score, test score, baseline:  0.0241 0.0 0.0241
probs:  [1.0]
siam score:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.015]
 [0.694]
 [0.027]
 [0.013]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.015]
 [0.694]
 [0.027]
 [0.013]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
siam score:  0.0
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.006]
 [0.003]
 [0.03 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.006]
 [0.003]
 [0.03 ]]
maxi score, test score, baseline:  0.0281 0.0 0.0281
probs:  [1.0]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.0281 0.0 0.0281
actor:  0 policy actor:  0  step number:  16 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0301 0.0 0.0301
probs:  [1.0]
siam score:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
maxi score, test score, baseline:  0.032100000000000004 0.0 0.032100000000000004
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.034100000000000005 0.0 0.034100000000000005
probs:  [1.0]
actor:  0 policy actor:  0  step number:  10 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0361 0.0 0.0361
probs:  [1.0]
in main func line 156:  729
maxi score, test score, baseline:  0.0361 0.0 0.0361
probs:  [1.0]
maxi score, test score, baseline:  0.0361 0.0 0.0361
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.011]
 [0.012]
 [0.013]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.019]
 [0.011]
 [0.012]
 [0.013]]
actor:  0 policy actor:  0  step number:  8 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0381 0.0 0.0381
probs:  [1.0]
maxi score, test score, baseline:  0.0381 0.0 0.0381
probs:  [1.0]
maxi score, test score, baseline:  0.0381 0.0 0.0381
probs:  [1.0]
actor:  0 policy actor:  0  step number:  14 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.040100000000000004 0.0 0.040100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.040100000000000004 0.0 0.040100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.040100000000000004 0.0 0.040100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0461 0.0 0.0461
probs:  [1.0]
731 2278
maxi score, test score, baseline:  0.0461 0.0 0.0461
maxi score, test score, baseline:  0.0461 0.0 0.0461
probs:  [1.0]
maxi score, test score, baseline:  0.0461 0.0 0.0461
probs:  [1.0]
actor:  0 policy actor:  0  step number:  12 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.008]
 [0.008]
 [0.008]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.008]
 [0.008]
 [0.008]
 [0.008]]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.014]
 [0.01 ]
 [0.011]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.014]
 [0.01 ]
 [0.011]]
maxi score, test score, baseline:  0.0461 0.0 0.0461
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.007]
 [0.008]
 [0.011]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.009]
 [0.007]
 [0.008]
 [0.011]]
maxi score, test score, baseline:  0.0461 0.0 0.0461
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  14 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.006]
 [0.006]
 [0.01 ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.012]
 [0.006]
 [0.006]
 [0.01 ]]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.041]
 [0.126]
 [0.554]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.008]
 [0.041]
 [0.126]
 [0.554]]
Printing some Q and Qe and total Qs values:  [[0.204]
 [0.204]
 [0.204]
 [0.204]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.204]
 [0.204]
 [0.204]
 [0.204]]
siam score:  0.0
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.008]
 [0.01 ]
 [0.012]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.008]
 [0.01 ]
 [0.012]]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
actor:  0 policy actor:  0  step number:  16 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0541 0.0 0.0541
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.54 ]
 [0.561]
 [0.558]
 [0.558]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.54 ]
 [0.561]
 [0.558]
 [0.558]]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.604]
 [0.604]
 [0.604]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.604]
 [0.604]
 [0.604]
 [0.604]]
maxi score, test score, baseline:  0.0461 0.0 0.0461
probs:  [1.0]
maxi score, test score, baseline:  0.0461 0.0 0.0461
maxi score, test score, baseline:  0.0461 0.0 0.0461
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.005]
 [0.021]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.005]
 [0.021]
 [0.002]]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  10 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
actor:  0 policy actor:  0  step number:  8 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0521 0.0 0.0521
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.003]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.003]
 [0.002]]
siam score:  0.0
maxi score, test score, baseline:  0.0521 0.0 0.0521
maxi score, test score, baseline:  0.0521 0.0 0.0521
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
siam score:  0.0
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.001]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.001]
 [0.003]
 [0.003]]
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.001]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.001]
 [0.002]]
actor:  0 policy actor:  0  step number:  8 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
763 2433
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.003]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.003]
 [0.002]
 [0.002]]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.009]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.003]
 [0.009]
 [0.003]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]]
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0521 0.0 0.0521
probs:  [1.0]
maxi score, test score, baseline:  0.0521 0.0 0.0521
probs:  [1.0]
maxi score, test score, baseline:  0.0521 0.0 0.0521
probs:  [1.0]
maxi score, test score, baseline:  0.0521 0.0 0.0521
767 2453
maxi score, test score, baseline:  0.0521 0.0 0.0521
actor:  0 policy actor:  0  step number:  12 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
771 2469
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
actor:  0 policy actor:  0  step number:  13 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0601 0.0 0.0601
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
actor:  0 policy actor:  0  step number:  28 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.001]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.   ]
 [0.001]
 [0.   ]]
789 2527
actor:  0 policy actor:  0  step number:  24 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
792 2535
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
siam score:  0.0
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.0601 0.0 0.0601
actor:  0 policy actor:  0  step number:  20 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0621 0.0 0.0621
probs:  [1.0]
803 2597
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
803 2610
actor:  0 policy actor:  0  step number:  14 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.268]
 [0.268]
 [0.268]
 [0.268]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.268]
 [0.268]
 [0.268]
 [0.268]]
maxi score, test score, baseline:  0.0601 0.0 0.0601
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
maxi score, test score, baseline:  0.058100000000000006 0.0 0.058100000000000006
probs:  [1.0]
maxi score, test score, baseline:  0.0541 0.0 0.0541
probs:  [1.0]
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.0541 0.0 0.0541
probs:  [1.0]
810 2661
actor:  0 policy actor:  0  step number:  16 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.056100000000000004 0.0 0.056100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.0541 0.0 0.0541
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]]
actor:  0 policy actor:  0  step number:  11 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.208 0.167 0.208 0.417]
815 2681
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  8 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
Printing some Q and Qe and total Qs values:  [[0.405]
 [0.358]
 [0.812]
 [0.405]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.405]
 [0.358]
 [0.812]
 [0.405]]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.002]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.002]
 [0.   ]]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
actor:  0 policy actor:  0  step number:  7 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.050100000000000006 0.0 0.050100000000000006
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.002]
 [0.003]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.002]
 [0.003]
 [0.002]]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.004]
 [0.003]
 [0.003]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.002]
 [0.002]]
line 256 mcts: sample exp_bonus 0.0
siam score:  0.0
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.0 0.048100000000000004
probs:  [1.0]
maxi score, test score, baseline:  0.042100000000000005 0.0 0.042100000000000005
probs:  [1.0]
actor:  0 policy actor:  0  step number:  15 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0441 0.0 0.0441
maxi score, test score, baseline:  0.0441 0.0 0.0441
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.003]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.003]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.0441 0.0 0.0441
probs:  [1.0]
maxi score, test score, baseline:  0.0441 0.0 0.0441
probs:  [1.0]
siam score:  0.0
maxi score, test score, baseline:  0.0441 0.0 0.0441
probs:  [1.0]
maxi score, test score, baseline:  0.0441 0.0 0.0441
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]]
actor:  0 policy actor:  0  step number:  10 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0461 0.0 0.0461
probs:  [1.0]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]]
actor:  0 policy actor:  0  step number:  18 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  8 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
rdn probs:  [1.0]
maxi score, test score, baseline:  0.050100000000000006 0.05 0.050100000000000006
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.050100000000000006 0.05 0.050100000000000006
maxi score, test score, baseline:  0.0461 0.05 0.05
probs:  [1.0]
maxi score, test score, baseline:  0.0461 0.05 0.05
probs:  [1.0]
actor:  0 policy actor:  0  step number:  9 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
834 2806
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.003]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.003]
 [0.002]
 [0.002]]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.006]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.004]
 [0.006]
 [0.004]]
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
835 2815
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.002]
 [0.002]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20026
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.003]
 [0.003]
 [0.003]]
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
maxi score, test score, baseline:  0.0461 0.05 0.05
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  1.0  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
maxi score, test score, baseline:  0.048100000000000004 0.05 0.05
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.006]
 [0.006]
 [0.005]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.006]
 [0.006]
 [0.005]]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.006]
 [0.005]
 [0.005]] [[0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.006]
 [0.005]
 [0.005]]
