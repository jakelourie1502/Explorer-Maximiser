append_mcts_svs:False
dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 50}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
res_block_channels:[32, 32, 64, 64, 64]
res_block_ds:[False, True, False, False, False]
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
reward_support:[-1, 1, 51]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 51]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:1
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
rgb_im:True
channels:3
state_size:[6, 6]
timesteps_in_obs:2
store_prev_actions:True
env:<class 'game_play.frozen_lake_KEY.gridWorld'>
same_env_each_time:True
env_size:[7, 7]
observable_size:[7, 7]
game_modes:2
env_map:[['H' 'H' 'H' 'H' 'H' 'F' 'G']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['S' 'F' 'H' 'H' 'H' 'H' 'H']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'K' 'F']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']]
max_steps:120
actions_size:5
optimal_score:1
total_frames:305000
exp_gamma:0.95
atari_env:False
reward_clipping:False
memory_size:30
image_size:[48, 48]
deque_length:3
PRESET_CONFIG:7
VK:True
use_two_heads:True
follow_better_policy:0.5
use_siam:True
exploration_type:episodic
rdn_beta:[0.3333333333333333, 2, 6]
explorer_percentage:0.8
reward_exploration:False
train_dones:True
contrast_vector:True
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(2, 49)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:False
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[['H' 'H' 'H' 'H' 'H' 'F' 'G']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['S' 'F' 'H' 'H' 'H' 'H' 'H']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'K' 'F']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']]
Training Flag: False
Self play flag: True
add more workers flag:  True
expV_train_flag:  False
expV_train_start_flag:  305000
main train batch thing paused
add a thread
Adding thread: now have 3 threads
printing an ep nov before normalisation:  9.240452873136462
using explorer policy with actor:  1
Starting evaluation
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.0008652560857378624
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]] [[13.042]
 [13.042]
 [13.042]
 [13.042]
 [13.042]] [[1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
deleting a thread, now have 2 threads
Frames:  724 train batches done:  20 episodes:  44
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.1231656997534038
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
deleting a thread, now have 1 threads
Frames:  724 train batches done:  48 episodes:  44
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([0.4674, 0.0885, 0.1081, 0.1571, 0.1789], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.1085, 0.6953, 0.0557, 0.0052, 0.1352], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.1038, 0.1431, 0.3608, 0.1916, 0.2007], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.1705, 0.0152, 0.2026, 0.3959, 0.2157], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.1772, 0.0883, 0.2148, 0.2873, 0.2324], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
main train batch thing paused
add a thread
Adding thread: now have 2 threads
deleting a thread, now have 1 threads
Frames:  1002 train batches done:  98 episodes:  66
siam score:  -0.5251956
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.5207719
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  79.263677221752
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.61730427
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([0.7292, 0.0467, 0.0156, 0.0436, 0.1649], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0831, 0.5996, 0.1148, 0.0057, 0.1968], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0119, 0.1128, 0.5040, 0.1330, 0.2382], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.1634, 0.0099, 0.0870, 0.4512, 0.2885], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.1886, 0.0578, 0.1561, 0.2251, 0.3724], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([0.7498, 0.0769, 0.0011, 0.1005, 0.0717], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.1514, 0.6550, 0.0370, 0.0068, 0.1498], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0167, 0.1051, 0.4865, 0.1110, 0.2807], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1665, 0.0131, 0.0907, 0.4697, 0.2600], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1046, 0.1609, 0.1339, 0.2293, 0.3712], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[-0.   ]
 [-0.   ]
 [-0.   ]
 [-0.002]
 [-0.   ]] [[26.25 ]
 [26.25 ]
 [26.25 ]
 [32.269]
 [26.25 ]] [[0.645]
 [0.645]
 [0.645]
 [0.998]
 [0.645]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.938551422097476
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.8954,     0.0072,     0.0002,     0.0396,     0.0577],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0397, 0.8681, 0.0235, 0.0046, 0.0641], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0011, 0.0130, 0.8230, 0.0664, 0.0965], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0785, 0.0028, 0.1330, 0.4609, 0.3247], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.1301, 0.0290, 0.0990, 0.2459, 0.4959], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  92.94792665391455
siam score:  -0.6991007
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  52.579102516174316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[21.025]
 [21.025]
 [21.025]
 [21.025]
 [21.025]] [[21.026]
 [21.026]
 [21.026]
 [21.026]
 [21.026]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9441,     0.0018,     0.0000,     0.0230,     0.0311],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9887,     0.0013,     0.0001,     0.0097],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0007,     0.9598,     0.0048,     0.0347],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0061,     0.0005,     0.0548,     0.6503,     0.2883],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0165, 0.0311, 0.1590, 0.2312, 0.5622], grad_fn=<DivBackward0>)
siam score:  -0.71333694
UNIT TEST: sample policy line 217 mcts : [0.2 0.2 0.2 0.2 0.2]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.7153825
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.7223306
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.  0.2 0.  0.6 0.2]
actions average: 
K:  4  action  0 :  tensor([0.5420, 0.0871, 0.0006, 0.1402, 0.2302], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0010,     0.8420,     0.1419,     0.0001,     0.0150],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0666,     0.7708,     0.0393,     0.1232],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0066, 0.0007, 0.2267, 0.4953, 0.2706], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0137, 0.0288, 0.2927, 0.2179, 0.4468], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.8856,     0.0004,     0.0000,     0.0302,     0.0838],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0026,     0.9780,     0.0030,     0.0001,     0.0163],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0003,     0.8302,     0.0480,     0.1215],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0390,     0.0003,     0.0112,     0.6938,     0.2557],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0200, 0.0022, 0.1392, 0.2639, 0.5747], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.89310153325399
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.7547258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.08968605133299
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.21034873790018
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.749157
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.44564962387085
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([0.8450, 0.0085, 0.0013, 0.0345, 0.1107], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0055,     0.9446,     0.0126,     0.0008,     0.0365],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0898,     0.6737,     0.0593,     0.1772],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0231, 0.0010, 0.0841, 0.6088, 0.2830], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0760, 0.0755, 0.1294, 0.1799, 0.5391], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.04696472195417
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.036]
 [58.036]
 [58.036]
 [58.036]
 [58.036]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.425854682922363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
main train batch thing paused
add a thread
Adding thread: now have 2 threads
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.839]
 [32.602]
 [37.165]
 [51.271]
 [32.503]] [[0.132]
 [0.167]
 [0.209]
 [0.339]
 [0.166]]
printing an ep nov before normalisation:  54.934413497313365
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.354776256437866
printing an ep nov before normalisation:  34.477160924323314
main train batch thing paused
add a thread
Adding thread: now have 3 threads
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.4  ]
 [57.434]
 [63.586]
 [61.838]
 [59.686]] [[1.359]
 [1.407]
 [1.689]
 [1.609]
 [1.51 ]]
printing an ep nov before normalisation:  76.10101490732592
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
main train batch thing paused
add a thread
Adding thread: now have 4 threads
printing an ep nov before normalisation:  67.509665349605
printing an ep nov before normalisation:  43.53263236148795
main train batch thing paused
add a thread
Adding thread: now have 5 threads
line 256 mcts: sample exp_bonus 62.59749102978188
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  50.638532221113586
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  66.71682014656258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.612]
 [61.612]
 [61.612]
 [66.259]
 [61.887]] [[0.958]
 [0.958]
 [0.958]
 [1.075]
 [0.965]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.586143498162656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.6709909405562
printing an ep nov before normalisation:  48.38894880765904
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
main train batch thing paused
add a thread
Adding thread: now have 6 threads
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.547]
 [42.547]
 [42.547]
 [42.547]
 [42.547]] [[0.942]
 [0.942]
 [0.942]
 [0.942]
 [0.942]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.509]
 [32.742]
 [23.709]
 [29.157]
 [33.15 ]] [[0.836]
 [0.58 ]
 [0.344]
 [0.486]
 [0.591]]
printing an ep nov before normalisation:  67.58159001668295
printing an ep nov before normalisation:  66.38102547711611
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.121]
 [66.121]
 [66.121]
 [66.121]
 [66.121]] [[0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.495]]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  59.27433465690964
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.808641356689044
printing an ep nov before normalisation:  42.18396161145042
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.606]
 [61.606]
 [64.081]
 [61.606]
 [61.606]] [[1.238]
 [1.238]
 [1.333]
 [1.238]
 [1.238]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.202070285937225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.10979796030088
printing an ep nov before normalisation:  41.23086384036794
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.767]
 [45.077]
 [50.25 ]
 [49.088]
 [42.355]] [[0.357]
 [0.417]
 [0.51 ]
 [0.489]
 [0.368]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.802]
 [42.717]
 [56.617]
 [57.643]
 [44.945]] [[0.797]
 [0.621]
 [1.222]
 [1.266]
 [0.717]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.95620801855542
siam score:  -0.75192523
siam score:  -0.75101453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.986]
 [29.84 ]
 [29.129]
 [35.5  ]
 [24.625]] [[0.69 ]
 [0.487]
 [0.467]
 [0.648]
 [0.338]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.028]
 [28.028]
 [28.028]
 [36.086]
 [28.028]] [[0.912]
 [0.912]
 [0.912]
 [1.198]
 [0.912]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.70803389369847
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.600862402580304
printing an ep nov before normalisation:  50.55082573259403
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  93.45833254895715
siam score:  -0.7565818
printing an ep nov before normalisation:  52.06748008728027
printing an ep nov before normalisation:  65.5333096815714
actions average: 
K:  2  action  0 :  tensor([    0.8367,     0.0055,     0.0001,     0.0391,     0.1187],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0190,     0.8961,     0.0071,     0.0008,     0.0768],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0004,     0.8593,     0.0445,     0.0958],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0033, 0.0011, 0.2004, 0.3751, 0.4201], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0174, 0.0109, 0.1322, 0.3188, 0.5207], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  65.92511653900146
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  77.90712342064143
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 61.090973163956875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.31754497630211
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 23.286268674985546
using explorer policy with actor:  1
printing an ep nov before normalisation:  77.49410629272461
printing an ep nov before normalisation:  72.32178229477793
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.509658387001448
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.7822394
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.29 ]
 [39.859]
 [63.047]
 [46.   ]
 [39.653]] [[0.354]
 [0.247]
 [0.968]
 [0.438]
 [0.241]]
printing an ep nov before normalisation:  86.18922484370802
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  5.318586639814131
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.77690196
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 43.36574794764666
printing an ep nov before normalisation:  66.13722461556804
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.915692326221105
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.022932247976215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9855,     0.0013,     0.0001,     0.0042,     0.0089],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0016,     0.9517,     0.0017,     0.0003,     0.0446],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9402,     0.0292,     0.0305],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0016,     0.0005,     0.0378,     0.5593,     0.4009],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0019, 0.0108, 0.0348, 0.3456, 0.6069], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  78.28873554091473
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
printing an ep nov before normalisation:  80.08041895253432
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.099]
 [36.495]
 [50.72 ]
 [34.474]
 [50.72 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.054813385009766
printing an ep nov before normalisation:  107.52797592804995
printing an ep nov before normalisation:  42.775280769768926
printing an ep nov before normalisation:  113.87692522424668
line 256 mcts: sample exp_bonus 52.7037139859979
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.008]
 [59.008]
 [59.008]
 [59.008]
 [60.46 ]] [[1.6  ]
 [1.6  ]
 [1.6  ]
 [1.6  ]
 [1.667]]
printing an ep nov before normalisation:  42.691330909729004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.74832611184519
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.765]
 [68.745]
 [59.406]
 [55.915]
 [51.787]] [[1.183]
 [1.658]
 [1.316]
 [1.188]
 [1.037]]
printing an ep nov before normalisation:  88.51063877363428
printing an ep nov before normalisation:  46.114752978533595
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.16]
 [47.16]
 [47.16]
 [47.16]
 [47.16]] [[0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]]
printing an ep nov before normalisation:  67.2848542002662
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 44.974297520825864
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.00367451941946
printing an ep nov before normalisation:  47.63455939413013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.49058992730943
printing an ep nov before normalisation:  72.08455170622626
printing an ep nov before normalisation:  38.7537021047373
printing an ep nov before normalisation:  32.11272990450485
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.76757383
printing an ep nov before normalisation:  30.254685878753662
printing an ep nov before normalisation:  29.01481619255234
printing an ep nov before normalisation:  84.77928091872481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.484266645408034
printing an ep nov before normalisation:  30.487776498939603
printing an ep nov before normalisation:  46.202613449169505
using explorer policy with actor:  1
printing an ep nov before normalisation:  114.89884537777967
printing an ep nov before normalisation:  50.78589901382769
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.624]
 [55.635]
 [20.944]
 [55.635]
 [55.635]] [[1.333]
 [1.248]
 [0.255]
 [1.248]
 [1.248]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9387,     0.0165,     0.0000,     0.0078,     0.0370],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0094,     0.9681,     0.0001,     0.0007,     0.0217],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0007,     0.8465,     0.0969,     0.0559],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0212, 0.0012, 0.1674, 0.5250, 0.2852], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0422, 0.0683, 0.0656, 0.2850, 0.5389], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
deleting a thread, now have 5 threads
Frames:  8855 train batches done:  1026 episodes:  446
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.455]
 [23.815]
 [23.815]
 [23.815]
 [23.815]] [[1.055]
 [0.577]
 [0.577]
 [0.577]
 [0.577]]
printing an ep nov before normalisation:  23.788520076639617
printing an ep nov before normalisation:  95.39271524569435
printing an ep nov before normalisation:  76.73142819506863
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  71.86216521356187
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.542]
 [35.562]
 [29.103]
 [29.103]
 [29.103]] [[0.809]
 [1.333]
 [0.958]
 [0.958]
 [0.958]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.162]
 [49.326]
 [76.367]
 [56.538]
 [46.65 ]] [[0.051]
 [0.22 ]
 [0.781]
 [0.37 ]
 [0.165]]
printing an ep nov before normalisation:  27.287380695343018
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.32832121964901
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.87007440117311
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.76538736
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.143221244609215
using explorer policy with actor:  1
printing an ep nov before normalisation:  95.37519454956055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  80.5667476117835
printing an ep nov before normalisation:  47.49824081092429
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.71451216015474
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.869]
 [12.826]
 [13.342]
 [14.258]
 [ 9.429]] [[0.135]
 [0.148]
 [0.155]
 [0.167]
 [0.103]]
deleting a thread, now have 4 threads
Frames:  9125 train batches done:  1070 episodes:  453
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.587861631311853
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.2258451343032
printing an ep nov before normalisation:  8.396135719085578
deleting a thread, now have 3 threads
Frames:  9359 train batches done:  1094 episodes:  461
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.43394422531128
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.618]
 [85.618]
 [89.434]
 [85.618]
 [85.618]] [[0.309]
 [0.309]
 [0.333]
 [0.309]
 [0.309]]
printing an ep nov before normalisation:  38.50321107646952
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.454581275912847
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.7924532
using explorer policy with actor:  1
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.425]
 [16.792]
 [13.093]
 [17.051]
 [15.156]] [[0.23 ]
 [0.159]
 [0.06 ]
 [0.166]
 [0.115]]
siam score:  -0.78967357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[107.732]
 [107.732]
 [107.732]
 [107.732]
 [107.732]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.038]
 [21.112]
 [21.393]
 [21.112]
 [20.814]] [[0.215]
 [0.051]
 [0.052]
 [0.051]
 [0.049]]
siam score:  -0.7900127
printing an ep nov before normalisation:  42.77618455711373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  93.76673711673124
printing an ep nov before normalisation:  102.39110936380382
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.03679370880127
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.79052323
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.03800222217404
printing an ep nov before normalisation:  2.26534609942064
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.76011450140951
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  75.10187149047852
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.708]
 [81.304]
 [57.029]
 [88.835]
 [57.029]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  14.137011595125841
printing an ep nov before normalisation:  30.416202728543134
printing an ep nov before normalisation:  20.581442708721788
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.93597525409993
siam score:  -0.78694624
printing an ep nov before normalisation:  29.503280923097186
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  31.102843371173154
printing an ep nov before normalisation:  42.00501712577309
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  1.7626975846616233
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.399877239238496
printing an ep nov before normalisation:  22.72023990399481
printing an ep nov before normalisation:  110.97562670729897
printing an ep nov before normalisation:  50.06957451763015
printing an ep nov before normalisation:  35.4811498927913
actions average: 
K:  2  action  0 :  tensor([    0.9035,     0.0093,     0.0000,     0.0287,     0.0584],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0037,     0.9655,     0.0001,     0.0007,     0.0300],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0034,     0.8763,     0.0583,     0.0620],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0417, 0.0022, 0.0934, 0.5494, 0.3132], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0184, 0.0738, 0.0581, 0.2233, 0.6265], grad_fn=<DivBackward0>)
actions average: 
K:  2  action  0 :  tensor([    0.9504,     0.0061,     0.0000,     0.0097,     0.0338],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0026,     0.9080,     0.0190,     0.0005,     0.0700],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0079,     0.7203,     0.0857,     0.1861],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0028, 0.0018, 0.0408, 0.6488, 0.3058], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0198, 0.0043, 0.0451, 0.2917, 0.6391], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  30.477152148393888
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.78002137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  43.194488898049656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.4598884291694
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 0.04823289468032747
actions average: 
K:  1  action  0 :  tensor([    0.9962,     0.0006,     0.0000,     0.0006,     0.0026],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0010,     0.9383,     0.0008,     0.0045,     0.0554],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9521,     0.0089,     0.0389],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0066, 0.0117, 0.0078, 0.7811, 0.1927], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0128, 0.0021, 0.0172, 0.2372, 0.7306], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  67.33647680143757
printing an ep nov before normalisation:  21.62838039362404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.38406538347845
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.88319757129564
printing an ep nov before normalisation:  45.352373123168945
printing an ep nov before normalisation:  21.2626343219479
printing an ep nov before normalisation:  101.52474615239062
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  83.17665273472527
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.78995351284121
STARTED EXPV TRAINING ON FRAME NO.  10912
actions average: 
K:  1  action  0 :  tensor([    0.9963,     0.0001,     0.0000,     0.0023,     0.0014],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0044,     0.9926,     0.0009,     0.0001,     0.0020],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0008,     0.9944,     0.0012,     0.0037],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0198,     0.0006,     0.0112,     0.6656,     0.3028],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0067, 0.0353, 0.0812, 0.2750, 0.6018], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9459,     0.0389,     0.0000,     0.0099,     0.0052],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0005,     0.9754,     0.0098,     0.0004,     0.0139],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0046,     0.7734,     0.0746,     0.1472],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0060,     0.0007,     0.0234,     0.7316,     0.2382],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0266, 0.0160, 0.1543, 0.2641, 0.5390], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  60.78613601097767
printing an ep nov before normalisation:  32.690964658149944
printing an ep nov before normalisation:  53.694777288524044
printing an ep nov before normalisation:  36.014698394034355
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.624]
 [87.624]
 [87.624]
 [87.624]
 [87.624]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
siam score:  -0.799823
printing an ep nov before normalisation:  78.35865446146691
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.12849722027342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.93573867674939
printing an ep nov before normalisation:  62.24348149524349
printing an ep nov before normalisation:  57.8745739365516
printing an ep nov before normalisation:  18.052733496229965
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  76.6695539548096
actions average: 
K:  0  action  0 :  tensor([    0.9668,     0.0006,     0.0001,     0.0279,     0.0045],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9893,     0.0061,     0.0000,     0.0046],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0007,     0.8945,     0.0370,     0.0679],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0017,     0.0003,     0.0165,     0.5796,     0.4019],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0009, 0.0059, 0.0020, 0.3799, 0.6114], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.606]
 [44.061]
 [51.321]
 [50.644]
 [48.194]] [[0.894]
 [1.191]
 [1.525]
 [1.494]
 [1.381]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  117.32335439504058
printing an ep nov before normalisation:  25.847651958465576
printing an ep nov before normalisation:  50.539920621750134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.68897368644558
printing an ep nov before normalisation:  66.6098141664406
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.12853258642895
printing an ep nov before normalisation:  32.906794288285255
siam score:  -0.81135744
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.600335121154785
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  43.14036448403351
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[115.02 ]
 [ 78.765]
 [114.401]
 [118.619]
 [116.215]] [[1.055]
 [0.404]
 [1.044]
 [1.12 ]
 [1.077]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[91.137]
 [66.169]
 [48.364]
 [65.293]
 [66.169]] [[1.585]
 [1.029]
 [0.632]
 [1.009]
 [1.029]]
printing an ep nov before normalisation:  22.80921886822224
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.307]
 [34.428]
 [40.627]
 [34.647]
 [28.429]] [[0.495]
 [0.523]
 [0.677]
 [0.529]
 [0.374]]
printing an ep nov before normalisation:  34.414576474622876
printing an ep nov before normalisation:  39.85000626963915
printing an ep nov before normalisation:  58.52680437424606
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.38295893137817
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  65.6303300752353
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.881]
 [27.958]
 [43.209]
 [36.637]
 [29.555]] [[0.443]
 [0.361]
 [0.678]
 [0.541]
 [0.394]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.940860741737815
siam score:  -0.795894
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.84239668958026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.46975135803223
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  118.99120435350628
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  1.386001045494254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9736,     0.0001,     0.0000,     0.0125,     0.0138],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0011,     0.9527,     0.0015,     0.0001,     0.0446],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0005,     0.8817,     0.0763,     0.0415],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0085, 0.0007, 0.0532, 0.6508, 0.2869], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0163, 0.0007, 0.0258, 0.3186, 0.6387], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  46.51002728146465
printing an ep nov before normalisation:  92.2623046397557
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.08394910791785
siam score:  -0.81134295
printing an ep nov before normalisation:  78.49689424592776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.431]
 [59.931]
 [41.989]
 [49.182]
 [51.038]] [[1.114]
 [0.961]
 [0.538]
 [0.707]
 [0.751]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.564]
 [30.564]
 [30.564]
 [34.292]
 [32.012]] [[1.574]
 [1.574]
 [1.574]
 [1.96 ]
 [1.724]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.358323574066162
siam score:  -0.8157381
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9901,     0.0001,     0.0000,     0.0003,     0.0095],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0023, 0.9137, 0.0117, 0.0014, 0.0709], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0006,     0.0001,     0.7790,     0.1380,     0.0822],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0415,     0.0002,     0.0139,     0.7139,     0.2305],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0532, 0.0012, 0.0480, 0.3385, 0.5591], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  43.088854643490606
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.81320345
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.94519221417075
printing an ep nov before normalisation:  53.594973654810715
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.800122224148637
siam score:  -0.8171168
printing an ep nov before normalisation:  2.1975304315219546
using explorer policy with actor:  1
printing an ep nov before normalisation:  3.1054211764705997
printing an ep nov before normalisation:  4.002014730214398
printing an ep nov before normalisation:  105.10136510107486
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  13.136309385299683
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.29707358970023
printing an ep nov before normalisation:  37.12242481175956
printing an ep nov before normalisation:  49.436845716236206
printing an ep nov before normalisation:  35.7120418548584
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 1.774810457633461e-07
0.0 3.277467134291888e-07
0.0 1.55732276039901e-07
0.0 0.0
0.0 3.3988403777786104e-07
0.0 1.7779809098950915e-07
0.0 0.0
0.0 3.05845267954633e-07
0.0 0.0
printing an ep nov before normalisation:  36.90825625373792
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.306295827293894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  2  action  0 :  tensor([    0.9754,     0.0069,     0.0000,     0.0006,     0.0170],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9927,     0.0001,     0.0001,     0.0068],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0006,     0.0003,     0.9181,     0.0358,     0.0452],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0014,     0.0005,     0.0520,     0.5986,     0.3475],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0014, 0.0680, 0.0240, 0.1602, 0.7464], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.19619836302915417
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.49717024479013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.428122376932606
printing an ep nov before normalisation:  52.92614862273396
actions average: 
K:  3  action  0 :  tensor([    0.9354,     0.0003,     0.0001,     0.0068,     0.0574],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9941,     0.0000,     0.0000,     0.0059],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.8171,     0.0841,     0.0986],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0019, 0.0006, 0.1184, 0.5423, 0.3367], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0021, 0.0543, 0.1185, 0.2122, 0.6128], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.960819244384766
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.854301505974554
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  103.53011375838058
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.72143296995553
printing an ep nov before normalisation:  36.766222924409284
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 36.452]
 [ 36.452]
 [110.012]
 [ 35.651]
 [ 35.158]] [[0.279]
 [0.279]
 [1.352]
 [0.268]
 [0.26 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.918276402128456
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.029]
 [64.623]
 [66.626]
 [70.034]
 [68.59 ]] [[0.58 ]
 [1.715]
 [1.821]
 [2.   ]
 [1.924]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.47 ]
 [55.569]
 [24.926]
 [43.076]
 [55.569]] [[1.631]
 [1.361]
 [0.432]
 [0.982]
 [1.361]]
siam score:  -0.82455605
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.44415991585508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.401384409562922
siam score:  -0.8280676
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  11.982897397576874
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  57.6684417348268
printing an ep nov before normalisation:  33.902576199805736
line 256 mcts: sample exp_bonus 49.12748700913839
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.86393547058105
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  74.37775008412963
printing an ep nov before normalisation:  53.26537261392953
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  48.207371328014254
printing an ep nov before normalisation:  70.37142177437075
printing an ep nov before normalisation:  50.076179514996845
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.27679394508509
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
actions average: 
K:  3  action  0 :  tensor([    0.9792,     0.0002,     0.0000,     0.0056,     0.0149],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0008,     0.9721,     0.0014,     0.0008,     0.0250],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0005,     0.8716,     0.0766,     0.0512],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0017, 0.0012, 0.0151, 0.6730, 0.3090], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0064, 0.0189, 0.1658, 0.2610, 0.5479], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  70.2006202010841
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.82146615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.606885863410746
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8180273
printing an ep nov before normalisation:  48.43732366904352
printing an ep nov before normalisation:  34.09095768858854
actions average: 
K:  4  action  0 :  tensor([    0.9837,     0.0006,     0.0000,     0.0034,     0.0123],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0502, 0.8928, 0.0014, 0.0011, 0.0544], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0008,     0.0002,     0.9172,     0.0443,     0.0374],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0095,     0.0003,     0.0942,     0.6924,     0.2036],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0150, 0.0326, 0.0575, 0.2766, 0.6184], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.166]
 [35.166]
 [35.166]
 [35.166]
 [35.166]] [[0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.085]]
printing an ep nov before normalisation:  54.161739580809304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9985,     0.0000,     0.0000,     0.0003,     0.0012],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0258,     0.9565,     0.0001,     0.0004,     0.0172],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.8473,     0.0585,     0.0940],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0658, 0.0079, 0.0174, 0.6038, 0.3052], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0136, 0.0010, 0.0477, 0.3782, 0.5596], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  85.30434110321988
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.215]
 [60.268]
 [39.764]
 [56.053]
 [53.123]] [[1.481]
 [1.328]
 [0.799]
 [1.219]
 [1.143]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.021]
 [39.021]
 [73.75 ]
 [39.021]
 [39.021]] [[-0.061]
 [-0.061]
 [ 0.314]
 [-0.061]
 [-0.061]]
printing an ep nov before normalisation:  82.46724302259167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.104]
 [63.104]
 [63.104]
 [63.104]
 [63.104]] [[63.104]
 [63.104]
 [63.104]
 [63.104]
 [63.104]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.706]
 [57.706]
 [59.421]
 [57.706]
 [57.706]] [[0.961]
 [0.961]
 [1.   ]
 [0.961]
 [0.961]]
printing an ep nov before normalisation:  49.225305369974826
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.7978802215921
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  52.99874305725098
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
siam score:  -0.8266313
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.45967543921931
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.40677309036255
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  65.33312670310195
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [40.577]
 [ 0.   ]
 [40.702]
 [73.446]] [[-0.265]
 [ 0.291]
 [-0.265]
 [ 0.292]
 [ 0.741]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.318]
 [54.318]
 [61.919]
 [55.69 ]
 [55.53 ]] [[1.115]
 [1.115]
 [1.413]
 [1.169]
 [1.163]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  90.38657393499965
using explorer policy with actor:  1
printing an ep nov before normalisation:  80.41273753722318
printing an ep nov before normalisation:  102.03702630067701
printing an ep nov before normalisation:  66.85186872275479
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  74.78586113110494
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.78393899314055
printing an ep nov before normalisation:  28.3769235137397
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.85097474
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.995]
 [22.995]
 [22.995]
 [22.995]
 [22.995]] [[1.89]
 [1.89]
 [1.89]
 [1.89]
 [1.89]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8511497
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.167]
 [68.167]
 [78.24 ]
 [68.167]
 [68.167]] [[1.276]
 [1.276]
 [1.546]
 [1.276]
 [1.276]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.93215259711821
printing an ep nov before normalisation:  40.55278301239014
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.136]
 [34.136]
 [39.121]
 [36.709]
 [34.261]] [[0.646]
 [0.646]
 [0.826]
 [0.739]
 [0.651]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  103.57223923349753
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8413584
printing an ep nov before normalisation:  49.89578301285138
printing an ep nov before normalisation:  31.56727059155334
printing an ep nov before normalisation:  86.6702059507699
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.10548210144043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.91759776238004
printing an ep nov before normalisation:  52.00290792608685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.685]
 [28.982]
 [31.456]
 [34.719]
 [28.982]] [[1.273]
 [0.539]
 [0.627]
 [0.743]
 [0.539]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[107.147]
 [107.147]
 [ 95.895]
 [107.147]
 [107.147]] [[0.938]
 [0.938]
 [0.781]
 [0.938]
 [0.938]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  52.34912872314453
printing an ep nov before normalisation:  37.43009483394396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9623,     0.0002,     0.0000,     0.0091,     0.0285],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9938,     0.0002,     0.0002,     0.0056],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.8926,     0.0593,     0.0479],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0003,     0.0722,     0.5899,     0.3370],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0007, 0.0026, 0.1122, 0.2718, 0.6128], grad_fn=<DivBackward0>)
siam score:  -0.8382728
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.347]
 [38.139]
 [30.518]
 [38.139]
 [38.139]] [[1.505]
 [0.878]
 [0.63 ]
 [0.878]
 [0.878]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
line 256 mcts: sample exp_bonus 43.94189999303511
printing an ep nov before normalisation:  53.22051172439503
printing an ep nov before normalisation:  30.803545736323844
printing an ep nov before normalisation:  31.01654291152954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9976,     0.0001,     0.0000,     0.0009,     0.0014],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9954,     0.0004,     0.0000,     0.0039],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0004,     0.8140,     0.1094,     0.0762],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0021,     0.0007,     0.0553,     0.6854,     0.2566],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0072, 0.0030, 0.1196, 0.3286, 0.5416], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  14.889742587830206
printing an ep nov before normalisation:  84.16006088256836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.253]
 [26.101]
 [34.763]
 [35.63 ]
 [35.099]] [[0.357]
 [0.213]
 [0.455]
 [0.479]
 [0.464]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.246]
 [77.711]
 [77.711]
 [75.359]
 [77.711]] [[0.37 ]
 [0.588]
 [0.588]
 [0.564]
 [0.588]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.781]
 [26.557]
 [40.849]
 [29.909]
 [27.152]] [[0.967]
 [0.679]
 [1.466]
 [0.864]
 [0.712]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.57508585137373
printing an ep nov before normalisation:  72.65516377091721
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.960433959960938
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.125]
 [44.683]
 [75.783]
 [44.683]
 [44.683]] [[0.586]
 [0.6  ]
 [1.388]
 [0.6  ]
 [0.6  ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.575]
 [39.575]
 [72.429]
 [39.575]
 [39.575]] [[0.008]
 [0.008]
 [0.853]
 [0.008]
 [0.008]]
printing an ep nov before normalisation:  37.62059211730957
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  74.44179754753915
printing an ep nov before normalisation:  47.12600930603303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  145.51888007573424
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.19386720623221
printing an ep nov before normalisation:  61.71177124958839
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[2.28 ]
 [2.547]
 [2.854]
 [3.024]
 [2.666]] [[0.003]
 [0.01 ]
 [0.019]
 [0.023]
 [0.013]]
printing an ep nov before normalisation:  2.6537333149387146
printing an ep nov before normalisation:  26.6614616112395
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.331]
 [74.331]
 [60.18 ]
 [73.544]
 [80.939]] [[1.376]
 [1.376]
 [1.026]
 [1.356]
 [1.539]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.83927095
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[108.753]
 [108.753]
 [108.753]
 [108.753]
 [108.753]] [[1.895]
 [1.895]
 [1.895]
 [1.895]
 [1.895]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.8145847202801
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.912]
 [23.087]
 [31.313]
 [25.906]
 [20.66 ]] [[1.126]
 [0.151]
 [0.429]
 [0.246]
 [0.068]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.23640242094032
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.404]
 [68.485]
 [46.779]
 [70.928]
 [66.661]] [[1.569]
 [1.437]
 [0.851]
 [1.502]
 [1.387]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  61.69918448751031
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  138.2018820728781
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.83461946
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9922,     0.0003,     0.0000,     0.0018,     0.0056],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9896,     0.0015,     0.0000,     0.0088],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.9160,     0.0513,     0.0324],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0009,     0.0316,     0.6319,     0.3353],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0013, 0.0014, 0.0245, 0.3651, 0.6078], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  76.6337520524164
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.23806243984136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  89.5236873626709
printing an ep nov before normalisation:  87.09433286737581
printing an ep nov before normalisation:  30.389904975891113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  67.31633746832826
printing an ep nov before normalisation:  24.330997467041016
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.58 ]
 [45.58 ]
 [71.029]
 [52.131]
 [73.243]] [[0.4  ]
 [0.4  ]
 [0.767]
 [0.495]
 [0.799]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.863]
 [24.328]
 [31.197]
 [26.245]
 [24.06 ]] [[0.385]
 [0.166]
 [0.243]
 [0.188]
 [0.163]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.114532548665046
printing an ep nov before normalisation:  92.14223830132185
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  91.12693786621094
printing an ep nov before normalisation:  42.75328343312911
printing an ep nov before normalisation:  2.179815044109527
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.414223670959473
printing an ep nov before normalisation:  26.97956014036218
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.14224536063188
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.89569903803271
printing an ep nov before normalisation:  48.4219902172315
printing an ep nov before normalisation:  48.33326284115859
printing an ep nov before normalisation:  162.37359261461975
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.85598068384209
printing an ep nov before normalisation:  56.70655939469511
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.83270997
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  21.7279538637034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.832402
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9875,     0.0019,     0.0000,     0.0074,     0.0032],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9885,     0.0008,     0.0000,     0.0104],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9470,     0.0236,     0.0293],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0318, 0.0007, 0.0693, 0.6242, 0.2740], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0121, 0.0163, 0.1432, 0.2917, 0.5366], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  31.431575940691
printing an ep nov before normalisation:  71.04835510253906
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9979,     0.0001,     0.0000,     0.0005,     0.0015],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9849,     0.0006,     0.0003,     0.0135],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0004,     0.8972,     0.0708,     0.0315],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0020,     0.0005,     0.0308,     0.7059,     0.2608],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0009, 0.0032, 0.0899, 0.3140, 0.5920], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  79.07621383666992
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.170981290190987
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.433570587086635
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 30.204342667134636
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.805]
 [50.223]
 [56.885]
 [54.192]
 [25.805]] [[0.182]
 [0.964]
 [1.177]
 [1.091]
 [0.182]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.567930645412865
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.9572874217685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.253]
 [23.253]
 [23.253]
 [23.253]
 [23.253]] [[0.192]
 [0.192]
 [0.192]
 [0.192]
 [0.192]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.362]
 [44.545]
 [67.437]
 [34.441]
 [45.809]] [[0.074]
 [0.12 ]
 [0.215]
 [0.078]
 [0.126]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.76598587567484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.925]
 [34.925]
 [61.965]
 [34.925]
 [34.925]] [[0.274]
 [0.274]
 [0.903]
 [0.274]
 [0.274]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.91773074221532
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  78.67911809030498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.17067384126581
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.302]
 [18.577]
 [14.923]
 [14.836]
 [13.61 ]] [[0.84 ]
 [0.453]
 [0.291]
 [0.287]
 [0.233]]
printing an ep nov before normalisation:  44.33594787052037
printing an ep nov before normalisation:  26.06235039082208
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  54.85484514813483
printing an ep nov before normalisation:  28.12744429579161
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.20285297933918
printing an ep nov before normalisation:  96.0890523634332
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.24757205352123
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.086502234618344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.058507221508485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.67151131058894
siam score:  -0.8382604
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.272]
 [84.272]
 [84.272]
 [84.272]
 [84.272]] [[0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]]
printing an ep nov before normalisation:  36.74971937274962
printing an ep nov before normalisation:  32.80733774989211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.201]
 [35.933]
 [19.356]
 [21.883]
 [22.624]] [[0.566]
 [0.608]
 [0.207]
 [0.268]
 [0.286]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.12 ]
 [21.12 ]
 [35.826]
 [20.751]
 [21.12 ]] [[0.37 ]
 [0.37 ]
 [0.811]
 [0.358]
 [0.37 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  6.205192230644911
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.138785562210057
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  89.64212474820127
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.728]
 [31.223]
 [47.045]
 [65.682]
 [76.546]] [[0.769]
 [0.427]
 [0.648]
 [0.908]
 [1.06 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.88490581512451
printing an ep nov before normalisation:  32.81019032607093
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8320172
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.217]
 [35.653]
 [40.109]
 [39.902]
 [40.201]] [[1.736]
 [1.462]
 [1.805]
 [1.789]
 [1.812]]
printing an ep nov before normalisation:  32.2885062370282
printing an ep nov before normalisation:  40.95309889836288
printing an ep nov before normalisation:  62.206044623491366
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.11348517757947
siam score:  -0.8332053
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.518939881504025
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  76.34304231565037
actions average: 
K:  0  action  0 :  tensor([    0.9985,     0.0002,     0.0000,     0.0006,     0.0008],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9956,     0.0001,     0.0002,     0.0038],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0015,     0.8993,     0.0564,     0.0428],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0016,     0.0005,     0.0151,     0.7507,     0.2321],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0020, 0.0416, 0.0055, 0.4771, 0.4738], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  35.986415276444525
printing an ep nov before normalisation:  42.201674520592576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.193]
 [85.193]
 [85.193]
 [85.193]
 [85.193]] [[1.864]
 [1.864]
 [1.864]
 [1.864]
 [1.864]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.685500541377706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.830041988196065
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 40.085582453451515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.84171236
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.57945720908026
printing an ep nov before normalisation:  44.92537498474121
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 91.965]
 [ 87.546]
 [103.433]
 [ 95.15 ]
 [ 96.026]] [[1.188]
 [1.079]
 [1.473]
 [1.267]
 [1.289]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.67435748962267
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
siam score:  -0.85393125
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.212]
 [72.398]
 [60.523]
 [69.108]
 [60.478]] [[0.492]
 [1.747]
 [1.178]
 [1.589]
 [1.176]]
printing an ep nov before normalisation:  36.01031688307664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  88.45496303388789
siam score:  -0.8618638
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.785]
 [36.785]
 [36.785]
 [36.785]
 [36.785]] [[61.32]
 [61.32]
 [61.32]
 [61.32]
 [61.32]]
printing an ep nov before normalisation:  51.86102051965869
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.93 ]
 [49.461]
 [51.357]
 [55.855]
 [51.804]] [[0.206]
 [0.202]
 [0.217]
 [0.254]
 [0.221]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  74.88845266866292
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.691389606510924
printing an ep nov before normalisation:  51.23420876029297
printing an ep nov before normalisation:  38.47056593722698
printing an ep nov before normalisation:  23.990257557711647
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.387]
 [38.606]
 [61.212]
 [28.601]
 [38.606]] [[0.355]
 [0.363]
 [1.171]
 [0.006]
 [0.363]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.70836480375745
printing an ep nov before normalisation:  45.706605677590574
printing an ep nov before normalisation:  58.55842894975638
printing an ep nov before normalisation:  41.81894183468176
printing an ep nov before normalisation:  22.196219176029786
printing an ep nov before normalisation:  21.12884928201766
printing an ep nov before normalisation:  36.10852190800415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.033980505807065
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8502662
actions average: 
K:  1  action  0 :  tensor([    0.9980,     0.0001,     0.0000,     0.0005,     0.0014],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9881,     0.0005,     0.0009,     0.0102],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9961,     0.0008,     0.0031],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0005,     0.0336,     0.7529,     0.2124],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0036, 0.0035, 0.1200, 0.3743, 0.4986], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.31316614151001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.650487450063164
printing an ep nov before normalisation:  24.092337239837562
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.453879819895135
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.13981816951793
printing an ep nov before normalisation:  98.31614273754958
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.245340544059527
printing an ep nov before normalisation:  32.9710837402741
printing an ep nov before normalisation:  98.19082260131836
printing an ep nov before normalisation:  30.251547843751997
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.902]
 [28.733]
 [28.733]
 [28.733]
 [28.733]] [[0.594]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9939,     0.0001,     0.0002,     0.0038,     0.0020],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0068, 0.9543, 0.0039, 0.0011, 0.0340], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0114,     0.9204,     0.0234,     0.0449],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0041, 0.0007, 0.0157, 0.6708, 0.3087], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.1040, 0.0043, 0.0561, 0.4448, 0.3909], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  82.21293629925387
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.728]
 [79.728]
 [79.728]
 [79.728]
 [79.728]] [[0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]]
actions average: 
K:  4  action  0 :  tensor([    0.8325,     0.0211,     0.0000,     0.0379,     0.1084],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0015, 0.9815, 0.0021, 0.0012, 0.0137], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0032,     0.9117,     0.0547,     0.0304],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0035, 0.0085, 0.1538, 0.5192, 0.3150], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0057, 0.0401, 0.2433, 0.2721, 0.4388], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.248685359954834
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.366]
 [37.366]
 [37.366]
 [37.366]
 [37.366]] [[0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.404]]
siam score:  -0.84780866
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.007222324109634
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.620345487133264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.730126770960176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.93943369590683
printing an ep nov before normalisation:  47.29388667127849
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  8.530650195195904
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.56 ]
 [87.492]
 [88.337]
 [85.491]
 [87.492]] [[1.502]
 [1.746]
 [1.772]
 [1.684]
 [1.746]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  78.72877139561456
printing an ep nov before normalisation:  80.02232767638627
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 122.23144388126649
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.216]
 [64.109]
 [60.717]
 [78.884]
 [63.966]] [[0.834]
 [0.61 ]
 [0.542]
 [0.907]
 [0.607]]
printing an ep nov before normalisation:  55.71709156036377
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  65.94219054770755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9981,     0.0001,     0.0000,     0.0008,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9981,     0.0002,     0.0001,     0.0016],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9202,     0.0473,     0.0324],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0012, 0.0013, 0.0270, 0.6379, 0.3326], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0096, 0.0238, 0.0733, 0.3169, 0.5764], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  35.756324226380336
printing an ep nov before normalisation:  33.212562146296484
printing an ep nov before normalisation:  51.421478576610546
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9438,     0.0291,     0.0005,     0.0161,     0.0105],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0005,     0.9423,     0.0003,     0.0002,     0.0567],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9512,     0.0131,     0.0355],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0091, 0.0048, 0.0187, 0.4701, 0.4973], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0053, 0.0146, 0.0909, 0.2238, 0.6654], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  94.94010088489176
printing an ep nov before normalisation:  116.71037315166276
printing an ep nov before normalisation:  110.43423952190636
printing an ep nov before normalisation:  25.083766858559546
printing an ep nov before normalisation:  6.770060539270162
printing an ep nov before normalisation:  15.659663677215576
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.645]
 [31.645]
 [33.443]
 [31.645]
 [31.645]] [[0.885]
 [0.885]
 [0.959]
 [0.885]
 [0.885]]
siam score:  -0.8460729
printing an ep nov before normalisation:  69.12581403184235
printing an ep nov before normalisation:  21.728699207305908
printing an ep nov before normalisation:  36.082575208600254
printing an ep nov before normalisation:  32.310002317786434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.365]
 [69.365]
 [82.009]
 [69.365]
 [69.365]] [[0.998]
 [0.998]
 [1.27 ]
 [0.998]
 [0.998]]
printing an ep nov before normalisation:  20.76071113628247
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.321]
 [43.455]
 [28.155]
 [43.072]
 [43.703]] [[1.333]
 [1.219]
 [0.612]
 [1.204]
 [1.229]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.353]
 [55.008]
 [64.4  ]
 [72.641]
 [55.008]] [[0.905]
 [0.665]
 [0.834]
 [0.982]
 [0.665]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  17.235783146323342
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  101.4315793628031
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.783753086016354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  90.13212613639308
actions average: 
K:  3  action  0 :  tensor([    0.9908,     0.0010,     0.0000,     0.0015,     0.0066],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9995,     0.0001,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0006,     0.9106,     0.0494,     0.0395],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0244, 0.0012, 0.0294, 0.7254, 0.2196], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0580, 0.0014, 0.0022, 0.3181, 0.6202], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  26.33044179129181
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  108.34836658748547
using explorer policy with actor:  1
siam score:  -0.8454401
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.778]
 [29.778]
 [29.778]
 [29.778]
 [29.778]] [[39.694]
 [39.694]
 [39.694]
 [39.694]
 [39.694]]
printing an ep nov before normalisation:  34.175445353979235
printing an ep nov before normalisation:  44.63066101074219
printing an ep nov before normalisation:  67.1937325910984
printing an ep nov before normalisation:  49.50059583598326
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9670,     0.0004,     0.0060,     0.0262],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0003,     0.9337,     0.0310,     0.0350],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0012, 0.0006, 0.0790, 0.5915, 0.3276], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0055, 0.0008, 0.0417, 0.4597, 0.4923], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[123.711]
 [123.711]
 [102.423]
 [123.711]
 [123.711]] [[1.667]
 [1.667]
 [1.278]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.236069541757146
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.991]
 [32.991]
 [42.066]
 [32.991]
 [32.991]] [[0.777]
 [0.777]
 [1.24 ]
 [0.777]
 [0.777]]
printing an ep nov before normalisation:  19.877047290735472
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  133.42381815659763
printing an ep nov before normalisation:  29.701716966775898
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.078142166137695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  102.59160358145367
printing an ep nov before normalisation:  126.27480983062476
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  105.53976139499115
printing an ep nov before normalisation:  64.38540451498969
printing an ep nov before normalisation:  74.51485548190573
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.555]
 [16.643]
 [30.697]
 [16.643]
 [16.643]] [[0.516]
 [0.357]
 [0.93 ]
 [0.357]
 [0.357]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.88774847918106
printing an ep nov before normalisation:  33.85992234552799
siam score:  -0.8581576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  86.26778623143451
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.545]
 [27.578]
 [27.578]
 [27.578]
 [27.578]] [[0.792]
 [0.541]
 [0.541]
 [0.541]
 [0.541]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.899399280548096
printing an ep nov before normalisation:  37.47944708150191
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  87.6443526153281
printing an ep nov before normalisation:  71.24750536638602
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  89.19360123521642
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.42781560545646
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.30364592341758
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.315]
 [51.421]
 [90.678]
 [89.943]
 [90.19 ]] [[0.914]
 [0.445]
 [1.105]
 [1.092]
 [1.096]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.293]
 [61.293]
 [61.293]
 [61.293]
 [61.293]] [[1.16]
 [1.16]
 [1.16]
 [1.16]
 [1.16]]
printing an ep nov before normalisation:  60.58926412534106
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.15382368649432
printing an ep nov before normalisation:  98.90421445895545
printing an ep nov before normalisation:  41.955292453158286
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.972]
 [20.972]
 [36.843]
 [20.972]
 [20.972]] [[0.105]
 [0.105]
 [0.617]
 [0.105]
 [0.105]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.111]
 [39.937]
 [39.937]
 [39.937]
 [39.937]] [[0.802]
 [0.511]
 [0.511]
 [0.511]
 [0.511]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.351]
 [38.4  ]
 [74.783]
 [63.451]
 [62.75 ]] [[0.46 ]
 [0.127]
 [0.633]
 [0.475]
 [0.466]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9351,     0.0415,     0.0000,     0.0048,     0.0186],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9765,     0.0047,     0.0049,     0.0139],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9340,     0.0419,     0.0240],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0050,     0.0001,     0.0016,     0.7156,     0.2777],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0235, 0.0190, 0.0506, 0.2834, 0.6235], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  132.73546599378832
siam score:  -0.8584364
printing an ep nov before normalisation:  34.03691353975444
printing an ep nov before normalisation:  80.40338464085957
printing an ep nov before normalisation:  88.54965063455123
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  78.87733857068464
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.68882929114493
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.169]
 [34.148]
 [53.904]
 [57.936]
 [31.238]] [[0.298]
 [0.278]
 [0.663]
 [0.742]
 [0.221]]
printing an ep nov before normalisation:  37.59864877678201
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.86570096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.94950760355012
printing an ep nov before normalisation:  112.37824510331251
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.842]
 [60.62 ]
 [29.247]
 [25.76 ]
 [60.62 ]] [[1.667]
 [4.942]
 [1.604]
 [1.233]
 [4.942]]
printing an ep nov before normalisation:  95.98796862056076
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.126]
 [55.175]
 [65.542]
 [62.034]
 [39.8  ]] [[0.249]
 [0.481]
 [0.719]
 [0.639]
 [0.126]]
printing an ep nov before normalisation:  39.20958142159419
printing an ep nov before normalisation:  84.59733785887468
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.593]
 [47.593]
 [69.944]
 [47.593]
 [47.593]] [[0.227]
 [0.227]
 [0.855]
 [0.227]
 [0.227]]
printing an ep nov before normalisation:  31.77615495247152
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.90238152609391
printing an ep nov before normalisation:  17.94201374053955
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.6  ]
 [58.6  ]
 [43.799]
 [65.395]
 [64.747]] [[0.288]
 [0.288]
 [0.189]
 [0.333]
 [0.329]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.89668908328039
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 19.2995641207078
printing an ep nov before normalisation:  43.91291758627739
printing an ep nov before normalisation:  125.42562484741211
printing an ep nov before normalisation:  81.14810957656074
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.401]
 [44.326]
 [37.229]
 [42.087]
 [44.326]] [[1.241]
 [0.899]
 [0.681]
 [0.83 ]
 [0.899]]
printing an ep nov before normalisation:  72.53518697206658
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.351]
 [55.086]
 [68.869]
 [48.343]
 [59.103]] [[0.97 ]
 [0.815]
 [1.22 ]
 [0.617]
 [0.933]]
printing an ep nov before normalisation:  80.06696188087518
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.52724856553417
printing an ep nov before normalisation:  30.735457566112593
siam score:  -0.8521585
siam score:  -0.85124725
printing an ep nov before normalisation:  30.62215603526748
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  66.72510470941943
printing an ep nov before normalisation:  38.03541962376113
printing an ep nov before normalisation:  17.69442293454876
printing an ep nov before normalisation:  26.642275845152508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.499515875477414
deleting a thread, now have 2 threads
Frames:  24206 train batches done:  2829 episodes:  833
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.851]
 [70.854]
 [71.102]
 [79.976]
 [79.515]] [[1.329]
 [1.412]
 [1.418]
 [1.663]
 [1.65 ]]
actions average: 
K:  4  action  0 :  tensor([    0.9258,     0.0033,     0.0000,     0.0203,     0.0505],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0013,     0.9381,     0.0002,     0.0127,     0.0478],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0005,     0.9368,     0.0304,     0.0323],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0714,     0.0002,     0.0696,     0.6364,     0.2224],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0021,     0.0709,     0.3315,     0.5954],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.415]
 [36.415]
 [36.415]
 [36.415]
 [36.415]] [[0.63]
 [0.63]
 [0.63]
 [0.63]
 [0.63]]
siam score:  -0.85326934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  114.33760947991065
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.778]
 [37.189]
 [37.248]
 [27.041]
 [22.36 ]] [[0.634]
 [0.991]
 [0.994]
 [0.503]
 [0.277]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.921]
 [79.921]
 [71.178]
 [79.921]
 [79.921]] [[1.618]
 [1.618]
 [1.35 ]
 [1.618]
 [1.618]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.32164847514711
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.633 0.02  0.224 0.102 0.02 ]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  12.79951525757042
printing an ep nov before normalisation:  33.14300892061941
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.668]
 [74.557]
 [69.25 ]
 [74.889]
 [75.893]] [[0.825]
 [0.808]
 [0.728]
 [0.813]
 [0.828]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [29.109]
 [88.563]
 [ 0.   ]] [[-0.148]
 [-0.148]
 [ 0.148]
 [ 0.75 ]
 [-0.148]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[118.872]
 [118.872]
 [115.634]
 [118.856]
 [118.983]] [[1.234]
 [1.234]
 [1.181]
 [1.233]
 [1.235]]
line 256 mcts: sample exp_bonus 37.23142109165394
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  86.43517136173706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  72.48629145158007
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 41.079773144230714
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.838]
 [42.838]
 [42.838]
 [42.838]
 [42.838]] [[1.287]
 [1.287]
 [1.287]
 [1.287]
 [1.287]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.858]
 [50.858]
 [50.858]
 [50.858]
 [50.858]] [[0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  78.78280172004781
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.066]
 [74.548]
 [93.985]
 [89.978]
 [87.808]] [[0.487]
 [0.362]
 [0.529]
 [0.495]
 [0.476]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9865,     0.0008,     0.0000,     0.0017,     0.0109],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9955,     0.0000,     0.0006,     0.0039],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0056, 0.0219, 0.9046, 0.0328, 0.0350], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0006,     0.0573,     0.6770,     0.2647],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0012, 0.0045, 0.1477, 0.3553, 0.4913], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.158328820902085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.76]
 [43.76]
 [43.76]
 [43.76]
 [43.76]] [[0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.88 ]
 [61.785]
 [66.446]
 [67.751]
 [62.023]] [[0.066]
 [1.01 ]
 [1.168]
 [1.212]
 [1.018]]
printing an ep nov before normalisation:  42.74933950771585
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.704]
 [30.34 ]
 [52.391]
 [40.341]
 [33.174]] [[0.549]
 [0.273]
 [0.861]
 [0.54 ]
 [0.348]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  97.00446889198449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.139297536515826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.38814677984003
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.17099314806997
printing an ep nov before normalisation:  55.44814648965477
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.7841144763203
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  125.62611052110401
printing an ep nov before normalisation:  36.498949659218724
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.614383647092666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.1663914181614
printing an ep nov before normalisation:  66.3059089578553
printing an ep nov before normalisation:  39.94879930469943
printing an ep nov before normalisation:  46.53317150390086
printing an ep nov before normalisation:  41.209733123501294
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  75.31153256943618
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  87.89868559028052
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.972]
 [23.583]
 [28.362]
 [24.13 ]
 [23.513]] [[1.007]
 [0.41 ]
 [0.661]
 [0.439]
 [0.406]]
printing an ep nov before normalisation:  69.54733987342031
printing an ep nov before normalisation:  56.68444203744477
printing an ep nov before normalisation:  39.13183543369246
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  76.55738158400167
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.09040502006756
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.01560235827461
printing an ep nov before normalisation:  63.19815702815001
printing an ep nov before normalisation:  55.13009584659746
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.433]
 [33.172]
 [27.68 ]
 [30.101]
 [26.955]] [[0.385]
 [0.198]
 [0.135]
 [0.163]
 [0.127]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  81.82254805563107
printing an ep nov before normalisation:  31.675241932455958
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  103.73143909449472
printing an ep nov before normalisation:  22.528183026203266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.24 ]
 [56.956]
 [33.614]
 [49.963]
 [48.199]] [[0.888]
 [0.74 ]
 [0.367]
 [0.628]
 [0.6  ]]
printing an ep nov before normalisation:  47.01404126743867
printing an ep nov before normalisation:  39.8825185024109
actions average: 
K:  3  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9991,     0.0000,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9446,     0.0317,     0.0236],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0023, 0.0007, 0.1007, 0.6288, 0.2676], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0029, 0.0694, 0.0317, 0.2963, 0.5998], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  54.85848856688981
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9969,     0.0000,     0.0000,     0.0014,     0.0017],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0006,     0.9889,     0.0002,     0.0028,     0.0076],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9720,     0.0172,     0.0108],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0006,     0.0623,     0.6356,     0.3009],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0003,     0.0055,     0.0544,     0.2118,     0.7279],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.58951152141603
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.41847685056799
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8516017
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.29063415527344
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.29399036682439
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.768]
 [71.768]
 [82.523]
 [71.768]
 [71.768]] [[0.84 ]
 [0.84 ]
 [0.995]
 [0.84 ]
 [0.84 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.38479014827891
printing an ep nov before normalisation:  47.23541893700468
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.974]
 [46.544]
 [34.862]
 [35.998]
 [35.427]] [[1.361]
 [1.153]
 [0.602]
 [0.655]
 [0.628]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.85342455
printing an ep nov before normalisation:  76.49165994996352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.78119682411638
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.20145586510882
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  109.96337803592752
printing an ep nov before normalisation:  84.33929492337397
printing an ep nov before normalisation:  28.186955451965332
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.894]
 [31.894]
 [31.894]
 [31.894]
 [31.894]] [[0.344]
 [0.344]
 [0.344]
 [0.344]
 [0.344]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.91450733689615
actions average: 
K:  0  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0124, 0.9386, 0.0011, 0.0209, 0.0269], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0031,     0.0002,     0.9233,     0.0379,     0.0355],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0030,     0.0005,     0.0348,     0.5866,     0.3751],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0050, 0.0024, 0.0324, 0.3371, 0.6231], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.159]
 [31.729]
 [27.377]
 [27.964]
 [22.781]] [[0.815]
 [0.614]
 [0.479]
 [0.497]
 [0.336]]
printing an ep nov before normalisation:  47.90260655620898
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.07455940395197
printing an ep nov before normalisation:  47.66368865966797
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.696]
 [37.125]
 [45.732]
 [53.167]
 [46.222]] [[0.712]
 [0.252]
 [0.454]
 [0.629]
 [0.466]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.599]
 [30.147]
 [37.769]
 [37.885]
 [35.127]] [[0.816]
 [0.286]
 [0.493]
 [0.497]
 [0.421]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.89165844328658
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.534]
 [83.534]
 [96.672]
 [83.534]
 [83.534]] [[0.942]
 [0.942]
 [1.192]
 [0.942]
 [0.942]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.146]
 [24.146]
 [24.146]
 [24.146]
 [24.146]] [[0.838]
 [0.838]
 [0.838]
 [0.838]
 [0.838]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9773,     0.0215,     0.0000,     0.0006,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9873,     0.0024,     0.0000,     0.0103],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9726,     0.0130,     0.0144],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0007,     0.0258,     0.5624,     0.4110],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0005,     0.0005,     0.0371,     0.3210,     0.6409],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.40354015406379
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.359849850046274
using explorer policy with actor:  1
printing an ep nov before normalisation:  78.20435724988492
printing an ep nov before normalisation:  59.717922600453825
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.74514947091643
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.86665833
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  114.43091434497636
printing an ep nov before normalisation:  34.860414266305256
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.722]
 [20.008]
 [ 9.161]
 [17.599]
 [17.283]] [[0.049]
 [0.081]
 [0.033]
 [0.07 ]
 [0.069]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.52124631913828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.13762046281657
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.84616889807192
actions average: 
K:  0  action  0 :  tensor([    0.9962,     0.0000,     0.0000,     0.0003,     0.0035],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9800,     0.0071,     0.0001,     0.0125],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9189,     0.0540,     0.0269],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0003,     0.0399,     0.6292,     0.3305],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0342, 0.0389, 0.0676, 0.4302, 0.4292], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  8.244505370281843
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.296]
 [11.39 ]
 [10.096]
 [19.031]
 [15.314]] [[0.156]
 [0.092]
 [0.071]
 [0.218]
 [0.157]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  25.896066950616923
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  117.9806814940707
printing an ep nov before normalisation:  102.63141939428203
printing an ep nov before normalisation:  98.24796623538131
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.554]
 [32.88 ]
 [34.95 ]
 [36.54 ]
 [38.511]] [[1.356]
 [1.293]
 [1.488]
 [1.638]
 [1.824]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.03429844633249
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.314]
 [35.495]
 [39.691]
 [56.357]
 [34.845]] [[1.005]
 [0.823]
 [0.92 ]
 [1.307]
 [0.808]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  118.26957866121667
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.279245593662168
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.7902193069458
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.348135190729096
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.279]
 [39.279]
 [75.093]
 [39.279]
 [39.279]] [[0.537]
 [0.537]
 [1.184]
 [0.537]
 [0.537]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.843]
 [30.956]
 [19.927]
 [18.549]
 [15.045]] [[0.929]
 [1.509]
 [0.463]
 [0.332]
 [0.   ]]
printing an ep nov before normalisation:  53.607939781477754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.76 ]
 [33.229]
 [29.503]
 [31.552]
 [37.664]] [[1.068]
 [0.705]
 [0.577]
 [0.647]
 [0.858]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  58.702355132479646
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.262]
 [37.93 ]
 [27.636]
 [33.53 ]
 [37.664]] [[1.333]
 [0.85 ]
 [0.41 ]
 [0.662]
 [0.838]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8720128
printing an ep nov before normalisation:  48.7103463589885
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.69556223173641
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.718765520719053
printing an ep nov before normalisation:  56.11857617623198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9983,     0.0000,     0.0000,     0.0007,     0.0011],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9979,     0.0014,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9447,     0.0320,     0.0232],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0003,     0.0500,     0.6277,     0.3219],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0058,     0.0006,     0.1015,     0.3014,     0.5908],
       grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.38093527074039
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.224]
 [17.224]
 [27.561]
 [17.224]
 [17.224]] [[0.516]
 [0.516]
 [1.08 ]
 [0.516]
 [0.516]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.936293911431623
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.03449625969847
printing an ep nov before normalisation:  41.29995805931972
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.249]
 [39.798]
 [23.297]
 [37.475]
 [39.099]] [[0.871]
 [0.677]
 [0.249]
 [0.617]
 [0.659]]
printing an ep nov before normalisation:  33.98328715625129
printing an ep nov before normalisation:  135.46122826969037
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[100.521]
 [100.521]
 [120.879]
 [100.521]
 [100.521]] [[1.335]
 [1.335]
 [1.766]
 [1.335]
 [1.335]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  46.28388792289564
printing an ep nov before normalisation:  33.41894053291925
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  66.26059255302206
actions average: 
K:  3  action  0 :  tensor([    0.9819,     0.0001,     0.0000,     0.0074,     0.0106],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9997,     0.0001,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9343,     0.0362,     0.0295],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0067, 0.0008, 0.0749, 0.6223, 0.2953], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0005,     0.0018,     0.0477,     0.3959,     0.5541],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  108.48796094708042
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.906946605302956
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[105.926]
 [105.926]
 [105.926]
 [105.926]
 [105.926]] [[1.708]
 [1.708]
 [1.708]
 [1.708]
 [1.708]]
line 256 mcts: sample exp_bonus 103.12819475383527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  118.99266437995598
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  72.66347895509652
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.8727465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.75833949425045
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8664738
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 38.0336513516279
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8679297
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.86731076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.804]
 [81.804]
 [92.116]
 [81.804]
 [81.804]] [[0.615]
 [0.615]
 [0.735]
 [0.615]
 [0.615]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  98.51255736770392
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.05690282295436
printing an ep nov before normalisation:  82.85417184289014
printing an ep nov before normalisation:  75.95734580544031
printing an ep nov before normalisation:  116.96570578375032
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.14000442095696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  90.85280699436859
using explorer policy with actor:  1
printing an ep nov before normalisation:  73.45951128506769
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.21498675379821
printing an ep nov before normalisation:  38.32612416126206
printing an ep nov before normalisation:  29.328146747450475
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 57.04053582217993
printing an ep nov before normalisation:  28.623218936143985
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.389934694522026
printing an ep nov before normalisation:  23.809302727452565
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.30455403585
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9802,     0.0010,     0.0004,     0.0032,     0.0151],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9995,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.9378,     0.0373,     0.0247],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0041,     0.0004,     0.0373,     0.6775,     0.2807],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0045, 0.0007, 0.0647, 0.4386, 0.4915], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.407]
 [60.381]
 [68.998]
 [77.195]
 [74.094]] [[0.96 ]
 [0.758]
 [0.975]
 [1.182]
 [1.104]]
printing an ep nov before normalisation:  96.04270856088444
printing an ep nov before normalisation:  35.96860593558309
printing an ep nov before normalisation:  35.48233582751162
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.803036782776374
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.991]
 [52.991]
 [52.991]
 [52.991]
 [52.991]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.833]
 [34.833]
 [66.959]
 [34.833]
 [34.833]] [[0.026]
 [0.026]
 [0.65 ]
 [0.026]
 [0.026]]
printing an ep nov before normalisation:  36.72783374786377
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.085]
 [27.085]
 [27.085]
 [27.085]
 [27.085]] [[1.413]
 [1.413]
 [1.413]
 [1.413]
 [1.413]]
printing an ep nov before normalisation:  86.85175123160032
printing an ep nov before normalisation:  23.742432594299316
printing an ep nov before normalisation:  60.94977996230448
printing an ep nov before normalisation:  60.32973366463081
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.167]
 [25.323]
 [25.323]
 [16.476]
 [25.323]] [[1.333]
 [1.454]
 [1.454]
 [0.525]
 [1.454]]
printing an ep nov before normalisation:  65.09402470923575
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
actions average: 
K:  3  action  0 :  tensor([    0.9953,     0.0000,     0.0000,     0.0026,     0.0020],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0008,     0.9934,     0.0001,     0.0000,     0.0057],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9815,     0.0044,     0.0138],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0026,     0.0006,     0.0995,     0.6289,     0.2683],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0015, 0.0016, 0.0194, 0.3035, 0.6740], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
siam score:  -0.8697177
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.085526295608204
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.199]
 [26.266]
 [32.396]
 [27.827]
 [31.399]] [[0.569]
 [0.336]
 [0.516]
 [0.382]
 [0.487]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.89936113348968
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.56845447397144
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.342399302678892
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.245]
 [61.245]
 [61.245]
 [67.636]
 [61.505]] [[0.278]
 [0.278]
 [0.278]
 [0.333]
 [0.28 ]]
printing an ep nov before normalisation:  19.564783453269463
line 256 mcts: sample exp_bonus 49.33972009116769
printing an ep nov before normalisation:  31.159123583239108
actions average: 
K:  4  action  0 :  tensor([    0.9642,     0.0003,     0.0000,     0.0192,     0.0162],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9467,     0.0002,     0.0200,     0.0329],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0004,     0.8865,     0.0434,     0.0696],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0008,     0.0003,     0.0178,     0.6836,     0.2976],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0024, 0.0009, 0.0685, 0.3619, 0.5663], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.787]
 [35.787]
 [35.787]
 [35.787]
 [35.787]] [[1.859]
 [1.859]
 [1.859]
 [1.859]
 [1.859]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[101.046]
 [101.046]
 [101.046]
 [101.046]
 [101.046]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
printing an ep nov before normalisation:  93.61098603037262
printing an ep nov before normalisation:  87.49791034910119
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.291306972503662
printing an ep nov before normalisation:  70.45562864943597
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.647]
 [59.411]
 [75.041]
 [76.777]
 [73.099]] [[0.225]
 [0.16 ]
 [0.26 ]
 [0.271]
 [0.247]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  77.60907636488645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.151]
 [34.079]
 [39.881]
 [35.142]
 [34.079]] [[1.361]
 [1.596]
 [1.874]
 [1.647]
 [1.596]]
using explorer policy with actor:  1
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.616432973304292
rdn beta is 0 so we're just using the maxi policy
line 256 mcts: sample exp_bonus 16.42094437015958
printing an ep nov before normalisation:  38.546741008758545
printing an ep nov before normalisation:  0.0011293936225342804
printing an ep nov before normalisation:  56.16694948419744
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.800567141574852
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.978]
 [24.962]
 [20.206]
 [23.063]
 [21.164]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  5.304909401436362
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9883,     0.0000,     0.0000,     0.0066,     0.0051],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9995,     0.0000,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0015,     0.9110,     0.0302,     0.0572],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0008, 0.0007, 0.0255, 0.6119, 0.3611], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0362,     0.0502,     0.3125,     0.6008],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.77361123713435
printing an ep nov before normalisation:  64.52315019578965
printing an ep nov before normalisation:  60.07774831392068
printing an ep nov before normalisation:  52.79640074764119
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.788]
 [44.788]
 [37.629]
 [39.605]
 [50.527]] [[0.843]
 [0.843]
 [0.673]
 [0.72 ]
 [0.979]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  92.35590067588205
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.50008380051209
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.2297454926053
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.628]
 [59.628]
 [67.371]
 [59.628]
 [59.628]] [[1.541]
 [1.541]
 [1.871]
 [1.541]
 [1.541]]
printing an ep nov before normalisation:  30.39500747879167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.30999403169445
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  86.78266314638199
printing an ep nov before normalisation:  55.54092031862914
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.567]
 [32.495]
 [33.68 ]
 [29.934]
 [29.399]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  39.83674692374692
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  85.2169983603228
printing an ep nov before normalisation:  58.310346746324306
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  35.819997787475586
printing an ep nov before normalisation:  81.49269104003906
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.251]
 [40.439]
 [60.484]
 [22.524]
 [20.887]] [[0.372]
 [0.731]
 [1.322]
 [0.203]
 [0.155]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.313]
 [39.313]
 [39.313]
 [39.313]
 [39.313]] [[0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]]
siam score:  -0.8758089
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.07128014473779
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.165688711502234
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.842]
 [44.406]
 [45.92 ]
 [55.032]
 [48.14 ]] [[0.608]
 [0.458]
 [0.488]
 [0.673]
 [0.533]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.32120157260558
printing an ep nov before normalisation:  52.17262888216355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  89.98600543939601
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
printing an ep nov before normalisation:  70.70037054689911
main train batch thing paused
add a thread
Adding thread: now have 4 threads
main train batch thing paused
add a thread
Adding thread: now have 5 threads
printing an ep nov before normalisation:  54.45376575301711
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  99.09971689373309
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  78.30142841969771
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.76 ]
 [27.553]
 [27.553]
 [27.553]
 [27.553]] [[0.502]
 [0.272]
 [0.272]
 [0.272]
 [0.272]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.510628405343844
actions average: 
K:  3  action  0 :  tensor([    0.9465,     0.0010,     0.0001,     0.0242,     0.0283],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0232,     0.9612,     0.0002,     0.0040,     0.0113],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0001,     0.8992,     0.0536,     0.0470],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0006,     0.0555,     0.6336,     0.3101],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0016, 0.0473, 0.0683, 0.3638, 0.5190], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.334945952026093
siam score:  -0.85819733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.55454024022508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.734161614877316
siam score:  -0.8663802
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.894]
 [55.894]
 [75.22 ]
 [58.537]
 [55.894]] [[0.566]
 [0.566]
 [0.875]
 [0.608]
 [0.566]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.979980973189114
printing an ep nov before normalisation:  64.05847136508143
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 77.7645967146873
printing an ep nov before normalisation:  83.56315877281874
printing an ep nov before normalisation:  37.848983242523104
using explorer policy with actor:  1
printing an ep nov before normalisation:  94.72237995385959
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.71194828205291
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.13157960713299
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.442]
 [46.26 ]
 [32.949]
 [50.632]
 [42.548]] [[0.827]
 [0.603]
 [0.337]
 [0.691]
 [0.529]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  83.8191032409668
line 256 mcts: sample exp_bonus 77.8243981066015
printing an ep nov before normalisation:  39.932589159479946
siam score:  -0.8808959
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.82416338297361
printing an ep nov before normalisation:  27.76058852527172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.52755497485583
printing an ep nov before normalisation:  68.85584940583549
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.969]
 [36.969]
 [24.11 ]
 [36.969]
 [36.969]] [[1.  ]
 [1.  ]
 [0.52]
 [1.  ]
 [1.  ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.735]
 [53.086]
 [66.225]
 [31.735]
 [31.735]] [[0.271]
 [0.85 ]
 [1.206]
 [0.271]
 [0.271]]
printing an ep nov before normalisation:  92.2758172009447
using explorer policy with actor:  1
siam score:  -0.8767032
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.909]
 [61.756]
 [65.192]
 [64.625]
 [60.565]] [[0.364]
 [0.422]
 [0.474]
 [0.465]
 [0.404]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.42 ]
 [37.852]
 [47.024]
 [39.819]
 [38.269]] [[1.267]
 [1.421]
 [2.   ]
 [1.545]
 [1.447]]
printing an ep nov before normalisation:  34.01202936468398
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 39.879380487818466
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.82 ]
 [49.82 ]
 [50.858]
 [49.82 ]
 [53.194]] [[1.096]
 [1.096]
 [1.139]
 [1.096]
 [1.237]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.68157582622009
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.15998554102064
printing an ep nov before normalisation:  53.520705058402896
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  95.42009081273306
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  166.0863092346146
printing an ep nov before normalisation:  107.8357626271229
printing an ep nov before normalisation:  17.06592195088294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.757640123695133
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.9505517862233
printing an ep nov before normalisation:  37.509212937589034
printing an ep nov before normalisation:  38.356176768496226
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.20923045872855
siam score:  -0.8823117
printing an ep nov before normalisation:  96.73270243110778
line 256 mcts: sample exp_bonus 50.67658182796642
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  158.64122661943298
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  99.03475687110263
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.482756876382965
printing an ep nov before normalisation:  40.41338636167763
printing an ep nov before normalisation:  45.355824462984806
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.45557599135006
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.623]
 [53.756]
 [45.631]
 [60.492]
 [59.987]] [[0.992]
 [0.945]
 [0.74 ]
 [1.115]
 [1.103]]
printing an ep nov before normalisation:  27.511253596786293
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.952817076609016
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0007,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0020,     0.8921,     0.0001,     0.0001,     0.1057],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0002,     0.9476,     0.0214,     0.0306],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0011, 0.0006, 0.0514, 0.5917, 0.3552], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0270,     0.0005,     0.0527,     0.3532,     0.5665],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.997]
 [37.997]
 [37.997]
 [37.997]
 [37.997]] [[50.65]
 [50.65]
 [50.65]
 [50.65]
 [50.65]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 37.129451405873226
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  96.98479812860778
printing an ep nov before normalisation:  37.95856486651397
printing an ep nov before normalisation:  32.44050979614258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  80.64632282612894
printing an ep nov before normalisation:  86.27257662475807
printing an ep nov before normalisation:  26.052726595096722
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.137197494506836
printing an ep nov before normalisation:  53.11866401434904
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.247]
 [56.977]
 [69.012]
 [40.271]
 [31.942]] [[0.124]
 [0.425]
 [0.629]
 [0.141]
 [0.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.104]
 [30.35 ]
 [32.452]
 [31.058]
 [30.062]] [[0.324]
 [0.467]
 [0.525]
 [0.486]
 [0.459]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.668]
 [46.668]
 [44.199]
 [41.543]
 [46.668]] [[1.   ]
 [1.   ]
 [0.924]
 [0.842]
 [1.   ]]
printing an ep nov before normalisation:  41.18279886069638
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.568]
 [27.568]
 [27.568]
 [27.568]
 [27.568]] [[0.386]
 [0.386]
 [0.386]
 [0.386]
 [0.386]]
printing an ep nov before normalisation:  96.92562887518392
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.987]
 [60.987]
 [41.727]
 [60.987]
 [60.987]] [[1.667]
 [1.667]
 [1.141]
 [1.667]
 [1.667]]
printing an ep nov before normalisation:  70.11599567478699
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.659]
 [61.161]
 [68.667]
 [46.169]
 [37.903]] [[0.318]
 [0.549]
 [0.654]
 [0.339]
 [0.224]]
line 256 mcts: sample exp_bonus 54.31780351613489
printing an ep nov before normalisation:  26.78133368860074
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.558701848401626
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.20422124862671
printing an ep nov before normalisation:  35.77448129653931
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  76.87727154186105
printing an ep nov before normalisation:  71.89285204141129
printing an ep nov before normalisation:  27.633544021104772
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.77 ]
 [57.863]
 [66.483]
 [81.59 ]
 [85.072]] [[0.823]
 [0.516]
 [0.706]
 [1.039]
 [1.116]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.090959428731324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.26001765643149
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  66.347530909947
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  65.30113961350045
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.13342094421387
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  101.15988743048545
printing an ep nov before normalisation:  37.583345970101306
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  95.24560592337231
printing an ep nov before normalisation:  40.69904619446859
printing an ep nov before normalisation:  102.74118687505708
printing an ep nov before normalisation:  38.560076219604966
printing an ep nov before normalisation:  123.51475322259148
printing an ep nov before normalisation:  99.34161642460936
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.014]
 [70.014]
 [70.014]
 [70.014]
 [70.014]] [[1.754]
 [1.754]
 [1.754]
 [1.754]
 [1.754]]
printing an ep nov before normalisation:  30.154437422918466
printing an ep nov before normalisation:  65.34931605628465
printing an ep nov before normalisation:  26.7549713507414
actions average: 
K:  0  action  0 :  tensor([    0.9711,     0.0005,     0.0003,     0.0073,     0.0209],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9868,     0.0019,     0.0001,     0.0111],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.8834,     0.0266,     0.0899],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0232, 0.0008, 0.0358, 0.6549, 0.2853], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0245, 0.0075, 0.1176, 0.3062, 0.5443], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.238]
 [34.673]
 [38.374]
 [35.382]
 [31.389]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.787]
 [56.46 ]
 [55.787]
 [50.143]
 [52.288]] [[1.85 ]
 [1.881]
 [1.85 ]
 [1.593]
 [1.691]]
printing an ep nov before normalisation:  19.874520314170894
printing an ep nov before normalisation:  30.099120140075684
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.43 ]
 [40.851]
 [23.598]
 [23.598]
 [23.598]] [[1.129]
 [1.182]
 [0.537]
 [0.537]
 [0.537]]
siam score:  -0.87129456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.247137944543244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.74824585129673
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.02177218715601
printing an ep nov before normalisation:  33.06612062528245
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.448129890280136
line 256 mcts: sample exp_bonus 16.680919937743415
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.2012840906779
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  68.05360552665292
printing an ep nov before normalisation:  24.010279064333304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.8765404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.25233535464932
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.379]
 [43.852]
 [49.123]
 [47.606]
 [43.267]] [[1.108]
 [1.082]
 [1.333]
 [1.261]
 [1.055]]
printing an ep nov before normalisation:  124.05622804415943
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.79 ]
 [70.433]
 [71.482]
 [66.337]
 [64.998]] [[0.214]
 [0.261]
 [0.268]
 [0.232]
 [0.223]]
printing an ep nov before normalisation:  37.83344905880604
printing an ep nov before normalisation:  54.79946760997866
printing an ep nov before normalisation:  47.12566240897153
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.328]
 [26.328]
 [31.058]
 [26.328]
 [26.328]] [[0.946]
 [0.946]
 [1.333]
 [0.946]
 [0.946]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.851202216884786
printing an ep nov before normalisation:  73.78941932175113
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.403815624875065
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  67.33287058339378
printing an ep nov before normalisation:  33.31892546340519
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.156]
 [84.156]
 [84.156]
 [84.156]
 [84.156]] [[0.55]
 [0.55]
 [0.55]
 [0.55]
 [0.55]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.184 0.469 0.082 0.163 0.102]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  58.6683784741869
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  92.34837763492611
printing an ep nov before normalisation:  67.38885014399392
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.269354820251465
printing an ep nov before normalisation:  88.69462127547783
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8726978
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.899]
 [34.899]
 [74.123]
 [34.899]
 [69.766]] [[0.344]
 [0.344]
 [1.382]
 [0.344]
 [1.267]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.613]
 [26.69 ]
 [17.079]
 [21.171]
 [25.717]] [[0.286]
 [0.238]
 [0.119]
 [0.17 ]
 [0.226]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.564]
 [51.477]
 [56.391]
 [55.484]
 [60.803]] [[0.884]
 [1.35 ]
 [1.515]
 [1.484]
 [1.662]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.339]
 [18.2  ]
 [18.2  ]
 [18.2  ]
 [18.2  ]] [[0.851]
 [0.594]
 [0.594]
 [0.594]
 [0.594]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.96689517270956
printing an ep nov before normalisation:  23.468241602215862
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.471]
 [69.094]
 [82.668]
 [70.391]
 [67.471]] [[0.956]
 [0.999]
 [1.361]
 [1.033]
 [0.956]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.378489843832995
printing an ep nov before normalisation:  33.45960628733224
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.165]
 [38.17 ]
 [25.619]
 [34.366]
 [40.541]] [[1.563]
 [1.304]
 [0.759]
 [1.139]
 [1.406]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.651]
 [15.858]
 [16.255]
 [16.837]
 [15.858]] [[0.519]
 [0.305]
 [0.32 ]
 [0.342]
 [0.305]]
deleting a thread, now have 4 threads
Frames:  36145 train batches done:  4227 episodes:  1134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  67.03447664345718
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.86874205
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.355]
 [82.355]
 [82.667]
 [82.355]
 [82.355]] [[0.6  ]
 [0.6  ]
 [0.603]
 [0.6  ]
 [0.6  ]]
printing an ep nov before normalisation:  40.98658561706543
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.732892990112305
deleting a thread, now have 3 threads
Frames:  36332 train batches done:  4240 episodes:  1136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.24631631592047
actions average: 
K:  3  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9976,     0.0002,     0.0005,     0.0016],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0070,     0.9373,     0.0259,     0.0296],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0316,     0.0004,     0.0228,     0.6740,     0.2711],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0086, 0.0007, 0.0720, 0.3940, 0.5247], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
deleting a thread, now have 2 threads
Frames:  36514 train batches done:  4256 episodes:  1138
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9952,     0.0002,     0.0000,     0.0006,     0.0040],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0003,     0.0003,     0.8402,     0.0952,     0.0639],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0006,     0.0308,     0.7013,     0.2670],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0242, 0.0584, 0.1259, 0.3525, 0.4390], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
deleting a thread, now have 1 threads
Frames:  36514 train batches done:  4272 episodes:  1138
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9966,     0.0000,     0.0000,     0.0032],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9966,     0.0007,     0.0027],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0011,     0.0005,     0.0998,     0.5514,     0.3473],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0015,     0.0005,     0.0746,     0.3773,     0.5461],
       grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9722,     0.0069,     0.0003,     0.0083,     0.0122],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0065,     0.9790,     0.0002,     0.0000,     0.0142],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.9056,     0.0559,     0.0382],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0015,     0.0006,     0.0711,     0.6252,     0.3016],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0007, 0.0014, 0.0645, 0.3910, 0.5425], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  72.04728369580373
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88654935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.67735181233681
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.124454020845448
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0005,     0.9953,     0.0000,     0.0000,     0.0042],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9758,     0.0153,     0.0089],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0004,     0.0311,     0.5877,     0.3804],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0004,     0.0004,     0.0310,     0.4363,     0.5319],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  94.77567008583891
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.008584721759366
siam score:  -0.88687915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9952,     0.0000,     0.0000,     0.0005,     0.0042],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9988,     0.0000,     0.0000,     0.0011],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9995,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0051,     0.0573,     0.6592,     0.2779],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0003,     0.0016,     0.0838,     0.2770,     0.6374],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[146.904]
 [146.904]
 [148.595]
 [153.365]
 [146.904]] [[0.636]
 [0.636]
 [0.644]
 [0.667]
 [0.636]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9569,     0.0292,     0.0009,     0.0035,     0.0095],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9580,     0.0397,     0.0000,     0.0020],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9222,     0.0431,     0.0346],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0069, 0.0009, 0.0639, 0.6354, 0.2930], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0012, 0.0285, 0.0991, 0.3061, 0.5651], grad_fn=<DivBackward0>)
siam score:  -0.8639357
siam score:  -0.86434203
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  123.37400032434971
printing an ep nov before normalisation:  35.3595821325749
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8637941
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.0682080875734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0001,     0.0009],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0014, 0.9563, 0.0011, 0.0117, 0.0296], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9524,     0.0169,     0.0304],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0025, 0.0159, 0.0295, 0.7658, 0.1862], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0112, 0.0010, 0.0763, 0.3383, 0.5731], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.50696861160362
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0003,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9972,     0.0000,     0.0000,     0.0027],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9675,     0.0144,     0.0180],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0022,     0.0006,     0.0518,     0.6389,     0.3064],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0089,     0.0003,     0.0459,     0.2894,     0.6556],
       grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9970,     0.0000,     0.0000,     0.0007,     0.0023],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0327, 0.9199, 0.0050, 0.0192, 0.0232], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0005,     0.0002,     0.8902,     0.0591,     0.0500],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0021, 0.0017, 0.0432, 0.6063, 0.3468], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0008, 0.0009, 0.0702, 0.3344, 0.5937], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.692586278055543
siam score:  -0.8702403
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  84.1910171508789
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9979,     0.0000,     0.0000,     0.0004,     0.0016],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9957,     0.0005,     0.0000,     0.0036],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9085,     0.0522,     0.0391],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0259,     0.6866,     0.2871],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0002,     0.0003,     0.0606,     0.4020,     0.5368],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.7869758605957
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8743866
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.58551021695887
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.769946605437006
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.21635725076276
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  63.585398506320786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9848,     0.0003,     0.0000,     0.0028,     0.0121],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0274, 0.9341, 0.0028, 0.0144, 0.0213], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9705,     0.0129,     0.0164],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0030, 0.0008, 0.0608, 0.6072, 0.3282], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0432, 0.0111, 0.0310, 0.3323, 0.5824], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.388]
 [24.798]
 [21.941]
 [26.942]
 [21.984]] [[0.214]
 [0.153]
 [0.134]
 [0.167]
 [0.135]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 57.41340955801167
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.401]
 [29.56 ]
 [46.826]
 [41.151]
 [39.015]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  3  action  0 :  tensor([    0.9084,     0.0005,     0.0000,     0.0370,     0.0541],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0013, 0.9412, 0.0431, 0.0044, 0.0099], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0023,     0.9744,     0.0104,     0.0128],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0003,     0.1157,     0.5994,     0.2842],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0007, 0.0011, 0.0136, 0.4346, 0.5499], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.704]
 [71.63 ]
 [84.47 ]
 [82.814]
 [80.121]] [[0.381]
 [0.534]
 [0.754]
 [0.726]
 [0.679]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.29114484922502
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  79.98488002919251
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  159.15566035910172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 0.0
0.0 4.31768269436315e-11
0.0 6.227426969635234e-11
0.0 4.06858561520398e-11
0.0 8.593849215686507e-11
0.0 1.619131012762465e-11
0.0 4.234650336845181e-11
0.0 4.649812130556978e-11
0.0 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8746454
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.872887
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.66358793134059
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.483525601963816
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.056]
 [39.056]
 [39.056]
 [39.056]
 [39.056]] [[78.112]
 [78.112]
 [78.112]
 [78.112]
 [78.112]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8777319
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.908]
 [65.908]
 [75.121]
 [65.908]
 [65.908]] [[0.491]
 [0.491]
 [0.622]
 [0.491]
 [0.491]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.505]
 [51.455]
 [80.303]
 [66.743]
 [79.305]] [[0.51 ]
 [0.371]
 [0.814]
 [0.606]
 [0.799]]
siam score:  -0.8769442
printing an ep nov before normalisation:  25.453414487421878
printing an ep nov before normalisation:  28.74661684036255
printing an ep nov before normalisation:  34.93933393920734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0293,     0.9579,     0.0001,     0.0001,     0.0126],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0086, 0.0086, 0.9196, 0.0200, 0.0431], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0003,     0.0510,     0.6856,     0.2629],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0014, 0.0016, 0.0911, 0.2919, 0.6139], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.49088198610324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.929]
 [26.733]
 [26.733]
 [26.733]
 [26.733]] [[1.775]
 [1.696]
 [1.696]
 [1.696]
 [1.696]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  125.74552094467626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8801134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
main train batch thing paused
add a thread
Adding thread: now have 2 threads
UNIT TEST: sample policy line 217 mcts : [0.265 0.265 0.122 0.163 0.184]
printing an ep nov before normalisation:  54.58731745707607
printing an ep nov before normalisation:  109.42020780595101
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.132926877153544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.02  0.02  0.51  0.02  0.429]
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.958624839782715
printing an ep nov before normalisation:  75.5024705528807
printing an ep nov before normalisation:  21.55137062072754
main train batch thing paused
add a thread
Adding thread: now have 3 threads
printing an ep nov before normalisation:  102.4347512008912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[94.344]
 [81.306]
 [81.306]
 [81.029]
 [81.306]] [[0.918]
 [0.708]
 [0.708]
 [0.704]
 [0.708]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.831]
 [48.831]
 [48.831]
 [48.831]
 [48.831]] [[0.078]
 [0.078]
 [0.078]
 [0.078]
 [0.078]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.66 ]
 [47.66 ]
 [47.66 ]
 [65.185]
 [45.31 ]] [[0.064]
 [0.064]
 [0.064]
 [0.124]
 [0.056]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.417428943334954
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  11.668347970307789
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  78.1760433968067
printing an ep nov before normalisation:  41.32796764373779
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.176]
 [64.176]
 [64.176]
 [64.176]
 [64.176]] [[1.725]
 [1.725]
 [1.725]
 [1.725]
 [1.725]]
printing an ep nov before normalisation:  24.300037497828843
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  47.81702983671385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.444679260253906
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.137]
 [48.405]
 [71.288]
 [58.632]
 [55.117]] [[0.059]
 [0.066]
 [0.195]
 [0.124]
 [0.104]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  150.60737251381533
printing an ep nov before normalisation:  152.13251789489502
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  60.361137602068894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.339265444389348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.119899057305915
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.317412525650976
printing an ep nov before normalisation:  21.041258038269664
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.987220287322998
printing an ep nov before normalisation:  81.364394638555
printing an ep nov before normalisation:  37.22896871177152
printing an ep nov before normalisation:  31.291952980122108
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  24.82799180840096
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.076]
 [41.901]
 [49.076]
 [49.076]
 [49.076]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.924924226715873
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.573]
 [32.573]
 [35.771]
 [34.297]
 [32.573]] [[1.252]
 [1.252]
 [1.472]
 [1.371]
 [1.252]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.147246433928707
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.33 ]
 [17.779]
 [15.33 ]
 [18.725]
 [18.862]] [[0.961]
 [1.246]
 [0.961]
 [1.356]
 [1.372]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.79509503506295
printing an ep nov before normalisation:  78.89886988090441
printing an ep nov before normalisation:  4.424256229139445
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.1416645996473
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 51.971]
 [ 87.131]
 [131.016]
 [131.052]
 [101.201]] [[0.087]
 [0.188]
 [0.315]
 [0.315]
 [0.229]]
printing an ep nov before normalisation:  104.47769431574383
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  15.247048951375032
printing an ep nov before normalisation:  37.48838969794774
printing an ep nov before normalisation:  25.865230262003777
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.898]
 [63.898]
 [63.898]
 [63.898]
 [63.898]] [[1.313]
 [1.313]
 [1.313]
 [1.313]
 [1.313]]
printing an ep nov before normalisation:  100.87886270200576
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.787]
 [22.595]
 [35.207]
 [46.826]
 [34.486]] [[0.124]
 [0.002]
 [0.485]
 [0.93 ]
 [0.458]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  72.83722304152383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.418]
 [46.688]
 [50.564]
 [49.277]
 [47.538]] [[0.557]
 [0.621]
 [0.731]
 [0.694]
 [0.645]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.692967628999334
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.9936,     0.0017,     0.0000,     0.0003,     0.0044],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0005,     0.9267,     0.0224,     0.0504],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0084,     0.0428,     0.6586,     0.2899],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0009, 0.0083, 0.0018, 0.3646, 0.6244], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  41.827803187900116
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.99483387937541
printing an ep nov before normalisation:  38.80459795123503
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.431]
 [60.3  ]
 [52.23 ]
 [59.175]
 [57.041]] [[1.029]
 [1.218]
 [0.905]
 [1.174]
 [1.091]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8730671
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.548565853859934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 26.10425610275655
printing an ep nov before normalisation:  0.0007195868410766101
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.0401953458786
printing an ep nov before normalisation:  12.833581615734248
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.909213066101074
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.365]
 [20.079]
 [23.355]
 [23.862]
 [23.81 ]] [[0.742]
 [0.499]
 [0.626]
 [0.645]
 [0.643]]
printing an ep nov before normalisation:  68.14909389342863
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.241]
 [44.241]
 [44.241]
 [44.241]
 [44.241]] [[1.082]
 [1.082]
 [1.082]
 [1.082]
 [1.082]]
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.123924255371094
printing an ep nov before normalisation:  58.15723044388105
printing an ep nov before normalisation:  26.5008806925211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  77.15903759002686
printing an ep nov before normalisation:  49.92266803605264
printing an ep nov before normalisation:  49.571578314654836
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.8655948638916
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8853598
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.49849891662598
printing an ep nov before normalisation:  27.527510093478142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.01077939135923
printing an ep nov before normalisation:  23.543908628493494
printing an ep nov before normalisation:  17.301132678985596
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  16.979516951517887
printing an ep nov before normalisation:  43.30771047076354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.43 ]
 [68.729]
 [63.538]
 [44.815]
 [43.192]] [[0.578]
 [1.307]
 [1.129]
 [0.489]
 [0.433]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.16823031364167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.739]
 [32.721]
 [24.833]
 [33.352]
 [31.577]] [[0.868]
 [0.719]
 [0.426]
 [0.742]
 [0.676]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.73713682622002
siam score:  -0.88296616
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.29264831542969
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.515]
 [43.262]
 [28.008]
 [41.518]
 [41.527]] [[1.021]
 [0.89 ]
 [0.417]
 [0.836]
 [0.836]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.31 ]
 [22.094]
 [20.06 ]
 [23.141]
 [20.603]] [[0.551]
 [0.234]
 [0.171]
 [0.267]
 [0.188]]
actions average: 
K:  3  action  0 :  tensor([    0.9909,     0.0004,     0.0000,     0.0018,     0.0069],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9995,     0.0001,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0076,     0.9462,     0.0262,     0.0197],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0004,     0.0459,     0.7121,     0.2414],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0005,     0.0235,     0.1202,     0.2642,     0.5916],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.240241144551746
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.464]
 [44.464]
 [44.464]
 [44.464]
 [44.464]] [[59.27]
 [59.27]
 [59.27]
 [59.27]
 [59.27]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.618]
 [19.132]
 [25.418]
 [24.889]
 [22.084]] [[0.943]
 [0.898]
 [1.479]
 [1.43 ]
 [1.171]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.603838020416287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.842]
 [22.367]
 [25.068]
 [25.761]
 [22.749]] [[0.295]
 [0.607]
 [0.793]
 [0.841]
 [0.633]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.36 ]
 [23.36 ]
 [28.625]
 [23.36 ]
 [23.36 ]] [[0.609]
 [0.609]
 [0.843]
 [0.609]
 [0.609]]
printing an ep nov before normalisation:  42.91657525404069
actions average: 
K:  1  action  0 :  tensor([    0.9990,     0.0000,     0.0000,     0.0001,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0007,     0.9949,     0.0002,     0.0000,     0.0043],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0004,     0.8857,     0.0565,     0.0570],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0004,     0.0320,     0.6969,     0.2703],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0036, 0.0014, 0.1201, 0.3423, 0.5327], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.023228968431354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8838493
printing an ep nov before normalisation:  41.64757996355983
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.4971075355974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9951,     0.0003,     0.0000,     0.0011,     0.0034],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0009,     0.9450,     0.0010,     0.0220,     0.0310],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9849,     0.0004,     0.0147],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0006,     0.0525,     0.6517,     0.2949],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0002,     0.0007,     0.0833,     0.3100,     0.6059],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.24131392446033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.925224068441374
printing an ep nov before normalisation:  54.40273980074687
printing an ep nov before normalisation:  20.757164790455185
printing an ep nov before normalisation:  25.761529036929257
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.29304236563606
printing an ep nov before normalisation:  26.06539438039535
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[149.73]
 [149.73]
 [149.73]
 [149.73]
 [149.73]] [[0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  29.778952598571777
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.063]
 [36.575]
 [50.111]
 [48.936]
 [51.362]] [[0.698]
 [0.266]
 [0.62 ]
 [0.59 ]
 [0.653]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.25887517841675
printing an ep nov before normalisation:  51.601546706693334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.889991131087378
printing an ep nov before normalisation:  60.77559500874999
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.311]
 [17.311]
 [17.311]
 [17.221]
 [17.311]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
UNIT TEST: sample policy line 217 mcts : [0.082 0.612 0.143 0.143 0.02 ]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.8796942
printing an ep nov before normalisation:  48.98137633474093
printing an ep nov before normalisation:  115.16306398915339
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.413989305496216
siam score:  -0.8730191
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.527]
 [20.053]
 [28.79 ]
 [24.742]
 [23.323]] [[0.89 ]
 [0.226]
 [0.601]
 [0.427]
 [0.367]]
printing an ep nov before normalisation:  58.12226439131184
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.084]
 [25.642]
 [29.712]
 [29.697]
 [28.284]] [[0.795]
 [0.346]
 [0.521]
 [0.52 ]
 [0.46 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.919]
 [52.919]
 [52.919]
 [52.919]
 [52.919]] [[1.395]
 [1.395]
 [1.395]
 [1.395]
 [1.395]]
printing an ep nov before normalisation:  38.96058792442368
printing an ep nov before normalisation:  72.73775697130407
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.91382332163905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8655564
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.188]
 [23.188]
 [30.305]
 [23.188]
 [23.188]] [[0.948]
 [0.948]
 [1.502]
 [0.948]
 [0.948]]
printing an ep nov before normalisation:  73.7408571042555
printing an ep nov before normalisation:  25.34862518310547
printing an ep nov before normalisation:  52.979196401561964
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.801]
 [20.037]
 [27.815]
 [20.417]
 [24.376]] [[0.073]
 [0.097]
 [0.155]
 [0.1  ]
 [0.129]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.539]
 [15.408]
 [20.012]
 [19.466]
 [18.666]] [[0.181]
 [0.076]
 [0.129]
 [0.123]
 [0.114]]
printing an ep nov before normalisation:  13.928684146276835
printing an ep nov before normalisation:  20.34119173409251
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  91.73291786620885
printing an ep nov before normalisation:  31.585006002276387
printing an ep nov before normalisation:  57.667436293682435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  67.92568378803108
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.5057013461158
siam score:  -0.87239975
printing an ep nov before normalisation:  80.13958639251287
siam score:  -0.8723
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.900887246703356
printing an ep nov before normalisation:  57.34031588757205
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.48000608905819
printing an ep nov before normalisation:  72.19523051859315
printing an ep nov before normalisation:  27.92618751525879
printing an ep nov before normalisation:  38.999009542320756
printing an ep nov before normalisation:  46.63879107270219
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.8656894813024
actions average: 
K:  4  action  0 :  tensor([    0.9756,     0.0002,     0.0000,     0.0091,     0.0151],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9952,     0.0018,     0.0000,     0.0029],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9728,     0.0145,     0.0127],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0005,     0.1080,     0.6111,     0.2800],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0007, 0.0094, 0.0064, 0.3328, 0.6508], grad_fn=<DivBackward0>)
siam score:  -0.8805754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.524429790418214
printing an ep nov before normalisation:  36.92176128357368
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  54.623222570679815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88168395
printing an ep nov before normalisation:  20.500741004943848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[115.231]
 [102.793]
 [127.799]
 [129.746]
 [133.035]] [[1.571]
 [1.297]
 [1.849]
 [1.892]
 [1.964]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  64.90337625117309
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.67107124117021
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  105.92872886220206
actions average: 
K:  1  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0203, 0.9628, 0.0048, 0.0043, 0.0079], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9218,     0.0454,     0.0326],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0003,     0.0517,     0.5963,     0.3509],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0041, 0.0008, 0.0281, 0.4168, 0.5502], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  24.145530922747156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.16737832564604
printing an ep nov before normalisation:  73.18073144701138
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.779]
 [30.779]
 [57.885]
 [30.779]
 [56.138]] [[0.275]
 [0.275]
 [1.239]
 [0.275]
 [1.177]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.986]
 [81.986]
 [81.986]
 [81.986]
 [81.986]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.56976323683598
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.975]
 [24.012]
 [52.076]
 [34.749]
 [37.97 ]] [[0.517]
 [0.208]
 [0.828]
 [0.445]
 [0.517]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.979690074920654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.02979895468933
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.729]
 [25.933]
 [25.933]
 [25.933]
 [25.933]] [[0.834]
 [0.661]
 [0.661]
 [0.661]
 [0.661]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.456]
 [84.514]
 [85.031]
 [75.868]
 [76.753]] [[0.656]
 [0.923]
 [0.931]
 [0.779]
 [0.794]]
printing an ep nov before normalisation:  52.22723960876465
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.111]
 [47.111]
 [47.111]
 [61.617]
 [47.111]] [[0.254]
 [0.254]
 [0.254]
 [0.417]
 [0.254]]
printing an ep nov before normalisation:  60.674357168934044
printing an ep nov before normalisation:  22.166574001312256
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  91.17792622251348
printing an ep nov before normalisation:  33.827058759271516
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.822]
 [30.747]
 [52.234]
 [30.747]
 [30.747]] [[0.76 ]
 [0.06 ]
 [1.058]
 [0.06 ]
 [0.06 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[4.135]
 [5.202]
 [5.605]
 [4.864]
 [6.82 ]] [[0.083]
 [0.106]
 [0.115]
 [0.099]
 [0.141]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.02182069225825
printing an ep nov before normalisation:  33.31528230703735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.777]
 [29.305]
 [32.253]
 [22.722]
 [29.198]] [[0.372]
 [0.347]
 [0.397]
 [0.234]
 [0.345]]
printing an ep nov before normalisation:  25.4063805612115
printing an ep nov before normalisation:  39.72429434372857
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.7  ]
 [31.664]
 [16.656]
 [24.666]
 [20.045]] [[0.306]
 [0.408]
 [0.215]
 [0.318]
 [0.258]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  95.85481773091114
printing an ep nov before normalisation:  51.490940782596994
siam score:  -0.88463366
printing an ep nov before normalisation:  63.152398682173875
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.557329725024935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  70.76601879798986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.579]
 [63.59 ]
 [57.124]
 [47.846]
 [57.784]] [[0.92 ]
 [0.806]
 [0.723]
 [0.605]
 [0.732]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.07894081512232
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.880156771490874
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  33.66028729972469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  4.097555460083413
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.93843443283731
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.534]
 [60.534]
 [60.534]
 [60.534]
 [60.534]] [[1.247]
 [1.247]
 [1.247]
 [1.247]
 [1.247]]
printing an ep nov before normalisation:  49.234181096473215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.957406997680664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.727]
 [51.493]
 [44.184]
 [46.577]
 [51.957]] [[1.736]
 [1.585]
 [1.242]
 [1.354]
 [1.606]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.331]
 [36.069]
 [36.069]
 [36.069]
 [36.069]] [[1.169]
 [0.886]
 [0.886]
 [0.886]
 [0.886]]
printing an ep nov before normalisation:  118.87753973690859
printing an ep nov before normalisation:  49.460716508069915
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.406]
 [46.425]
 [40.535]
 [56.133]
 [55.891]] [[1.827]
 [1.549]
 [1.276]
 [2.   ]
 [1.989]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  64.3993881281545
printing an ep nov before normalisation:  22.64106709787441
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.83926567167049
actions average: 
K:  0  action  0 :  tensor([    0.9991,     0.0000,     0.0000,     0.0004,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0399, 0.9493, 0.0010, 0.0018, 0.0080], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0004,     0.9209,     0.0245,     0.0542],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0003,     0.0155,     0.5529,     0.4309],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0003,     0.0004,     0.0552,     0.2968,     0.6473],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  73.17089766500062
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.373]
 [42.272]
 [24.296]
 [36.654]
 [36.054]] [[1.423]
 [1.176]
 [0.449]
 [0.949]
 [0.925]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.475488721141094
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9890,     0.0058,     0.0004,     0.0007,     0.0040],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0154, 0.9395, 0.0019, 0.0064, 0.0368], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0006,     0.8990,     0.0484,     0.0517],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0015, 0.0016, 0.0660, 0.5176, 0.4133], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0009, 0.0012, 0.0501, 0.3766, 0.5713], grad_fn=<DivBackward0>)
siam score:  -0.8822697
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.56 ]
 [19.299]
 [31.577]
 [20.609]
 [18.273]] [[0.443]
 [0.303]
 [0.83 ]
 [0.36 ]
 [0.259]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.23242671529481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.456336990834128
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.093]
 [27.093]
 [29.213]
 [27.093]
 [27.093]] [[0.905]
 [0.905]
 [1.   ]
 [0.905]
 [0.905]]
printing an ep nov before normalisation:  84.19822311081452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  58.10672177280965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.376]
 [56.804]
 [51.958]
 [58.28 ]
 [57.165]] [[0.918]
 [0.969]
 [0.867]
 [1.   ]
 [0.976]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87994176
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.05866843697319
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.851143607091494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.76955660085662
using explorer policy with actor:  1
printing an ep nov before normalisation:  47.20435993110069
printing an ep nov before normalisation:  21.11258795870974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.991837399498564
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.316027398330306
printing an ep nov before normalisation:  38.359642028808594
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.145]
 [46.845]
 [39.145]
 [32.819]
 [39.145]] [[1.29 ]
 [1.675]
 [1.29 ]
 [0.973]
 [1.29 ]]
siam score:  -0.88108534
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.83 ]
 [33.753]
 [45.005]
 [44.742]
 [36.482]] [[0.377]
 [0.55 ]
 [0.879]
 [0.872]
 [0.63 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.33195522533765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.300459443817
printing an ep nov before normalisation:  56.09853050063406
printing an ep nov before normalisation:  33.8513988806934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.55035106822497
printing an ep nov before normalisation:  43.33275058250592
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.68353842211717
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.22596263885498
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9970,     0.0002,     0.0000,     0.0004,     0.0025],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0009,     0.9871,     0.0007,     0.0001,     0.0111],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0047,     0.8964,     0.0551,     0.0435],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0017,     0.0004,     0.0669,     0.6300,     0.3010],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0011,     0.0006,     0.0722,     0.3114,     0.6148],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.056]
 [50.004]
 [33.296]
 [37.539]
 [44.147]] [[0.365]
 [0.557]
 [0.309]
 [0.372]
 [0.47 ]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  93.84196485364168
printing an ep nov before normalisation:  34.402167522607854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  70.16839595508502
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.95 ]
 [24.95 ]
 [74.165]
 [24.95 ]
 [24.95 ]] [[0.161]
 [0.161]
 [0.921]
 [0.161]
 [0.161]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.9710797956385
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.702]
 [56.699]
 [53.365]
 [52.624]
 [52.727]] [[1.502]
 [1.542]
 [1.408]
 [1.378]
 [1.382]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.732]
 [39.458]
 [47.451]
 [85.716]
 [39.931]] [[0.077]
 [0.062]
 [0.085]
 [0.197]
 [0.063]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.31044200911111
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.55252974846685
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.205]
 [37.205]
 [37.205]
 [37.205]
 [37.205]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.88357484718247
using explorer policy with actor:  1
printing an ep nov before normalisation:  78.12377666409309
printing an ep nov before normalisation:  48.40531766317668
printing an ep nov before normalisation:  60.71809290041945
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.319]
 [18.086]
 [20.68 ]
 [18.852]
 [19.357]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.96298038677893
printing an ep nov before normalisation:  56.37063935709086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.31837711827398
siam score:  -0.8863704
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9796,     0.0066,     0.0004,     0.0048,     0.0085],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0301, 0.9546, 0.0032, 0.0035, 0.0086], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.8957,     0.0401,     0.0639],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0003,     0.0567,     0.7407,     0.2021],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0004,     0.0006,     0.0280,     0.3557,     0.6153],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  85.48981027346521
printing an ep nov before normalisation:  36.924981880496674
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  80.35679637720533
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.677]
 [58.127]
 [50.954]
 [56.124]
 [56.124]] [[0.986]
 [0.786]
 [0.619]
 [0.74 ]
 [0.74 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8889526
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8872969
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.67217375816712
printing an ep nov before normalisation:  63.41491201892376
printing an ep nov before normalisation:  31.673230182828394
printing an ep nov before normalisation:  34.892983305924346
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  3.1704644243291114e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.729]
 [21.8  ]
 [46.735]
 [26.421]
 [28.963]] [[0.046]
 [0.036]
 [0.125]
 [0.052]
 [0.061]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  76.49656752565022
printing an ep nov before normalisation:  45.78577775682247
printing an ep nov before normalisation:  44.60678577423096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.603918075561523
printing an ep nov before normalisation:  31.212745174010536
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  123.97725582122803
printing an ep nov before normalisation:  100.50875452693842
printing an ep nov before normalisation:  39.41938644056903
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  81.5545022801487
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  97.65980035552099
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.03432559967041
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  77.24333019946499
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.256059646606445
printing an ep nov before normalisation:  27.517428678016344
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.461]
 [60.461]
 [60.461]
 [77.494]
 [60.461]] [[1.054]
 [1.054]
 [1.054]
 [1.455]
 [1.054]]
printing an ep nov before normalisation:  45.65948880965586
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([0.9681, 0.0060, 0.0026, 0.0117, 0.0117], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9990,     0.0000,     0.0000,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0004,     0.0272,     0.9258,     0.0186,     0.0279],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0062,     0.0004,     0.0291,     0.6615,     0.3027],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0033, 0.0561, 0.0365, 0.3771, 0.5269], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  95.50399111192746
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.125]
 [33.473]
 [49.018]
 [50.49 ]
 [43.173]] [[0.643]
 [0.766]
 [1.206]
 [1.248]
 [1.041]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.009]
 [29.009]
 [29.009]
 [29.009]
 [29.009]] [[58.019]
 [58.019]
 [58.019]
 [58.019]
 [58.019]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.353]
 [23.15 ]
 [17.945]
 [22.923]
 [23.15 ]] [[1.138]
 [0.592]
 [0.339]
 [0.581]
 [0.592]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88698447
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 54.72042912492725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.806594748353504
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9692,     0.0001,     0.0000,     0.0113,     0.0195],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0017, 0.9402, 0.0211, 0.0167, 0.0203], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9251,     0.0282,     0.0466],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0010,     0.0002,     0.0643,     0.6504,     0.2841],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0145, 0.0361, 0.1279, 0.2002, 0.6213], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.298]
 [23.298]
 [16.616]
 [20.017]
 [23.298]] [[0.974]
 [0.974]
 [0.442]
 [0.713]
 [0.974]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.34528091727712
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.685820277090844
printing an ep nov before normalisation:  26.665414979759948
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9655,     0.0071,     0.0003,     0.0039,     0.0232],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9895,     0.0061,     0.0000,     0.0042],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0002,     0.8693,     0.0717,     0.0587],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0044,     0.0004,     0.0519,     0.5903,     0.3530],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0373, 0.0087, 0.0681, 0.2355, 0.6504], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  32.13723862859738
printing an ep nov before normalisation:  61.77477142708987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.24565208623273
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.69 ]
 [45.296]
 [66.027]
 [55.514]
 [51.018]] [[0.309]
 [0.315]
 [0.492]
 [0.402]
 [0.363]]
actions average: 
K:  0  action  0 :  tensor([0.9888, 0.0036, 0.0013, 0.0019, 0.0045], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0012,     0.9967,     0.0007,     0.0000,     0.0014],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9772,     0.0111,     0.0115],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0185,     0.0003,     0.0261,     0.6728,     0.2823],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0702,     0.0004,     0.0392,     0.3935,     0.4967],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  67.96357096022163
printing an ep nov before normalisation:  33.14601637677619
printing an ep nov before normalisation:  47.64270212449664
printing an ep nov before normalisation:  58.53994129022608
printing an ep nov before normalisation:  29.22389984996963
printing an ep nov before normalisation:  79.16260072765868
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.86485869420399
printing an ep nov before normalisation:  95.47920765248266
printing an ep nov before normalisation:  72.677457220748
actions average: 
K:  4  action  0 :  tensor([    0.9875,     0.0091,     0.0001,     0.0014,     0.0019],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9984,     0.0001,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.8317,     0.0743,     0.0938],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0086, 0.0013, 0.0065, 0.6721, 0.3114], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0001,     0.0127,     0.0651,     0.3668,     0.5552],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  81.20003223629314
using explorer policy with actor:  1
UNIT TEST: sample policy line 217 mcts : [0.49  0.122 0.143 0.102 0.143]
printing an ep nov before normalisation:  30.681102161481903
siam score:  -0.88662183
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  76.44859151502321
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9985,     0.0000,     0.0000,     0.0012],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9420,     0.0292,     0.0286],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0105,     0.0006,     0.0445,     0.5904,     0.3540],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0071, 0.0008, 0.1428, 0.4077, 0.4416], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  23.318056206293747
siam score:  -0.8916343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.494470835022621
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 0.0
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.367]
 [67.38 ]
 [67.38 ]
 [67.561]
 [67.38 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.89321244
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.305]
 [16.305]
 [16.305]
 [16.305]
 [16.305]] [[0.204]
 [0.204]
 [0.204]
 [0.204]
 [0.204]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  83.77362902136528
siam score:  -0.8929654
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  19.601372779607495
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.340584697678345
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9947,     0.0000,     0.0000,     0.0018,     0.0035],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9975,     0.0004,     0.0000,     0.0021],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0016, 0.0059, 0.9502, 0.0242, 0.0181], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0005,     0.0297,     0.6909,     0.2787],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0001,     0.0006,     0.0678,     0.3171,     0.6143],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  49.80546612636753
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  42.987934002871484
printing an ep nov before normalisation:  74.18451546274517
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.756]
 [34.756]
 [34.756]
 [34.756]
 [34.756]] [[1.35]
 [1.35]
 [1.35]
 [1.35]
 [1.35]]
printing an ep nov before normalisation:  29.44835492390209
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.754]
 [24.754]
 [24.754]
 [24.754]
 [24.754]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([0.9731, 0.0106, 0.0014, 0.0047, 0.0102], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0243,     0.9277,     0.0001,     0.0002,     0.0477],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0012,     0.0004,     0.9135,     0.0371,     0.0477],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0024, 0.0010, 0.0604, 0.6821, 0.2541], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0032, 0.0508, 0.0915, 0.3781, 0.4763], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  38.630828857421875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8943245
line 256 mcts: sample exp_bonus 68.0736748566317
printing an ep nov before normalisation:  19.900249035846766
printing an ep nov before normalisation:  37.706170473899704
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.085]
 [43.955]
 [53.697]
 [52.032]
 [51.919]] [[0.182]
 [0.214]
 [0.324]
 [0.305]
 [0.304]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.04155558172901
actions average: 
K:  1  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0005,     0.0006],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0002,     0.9466,     0.0123,     0.0407],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0011,     0.0006,     0.0809,     0.6545,     0.2629],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0024, 0.0023, 0.0532, 0.4463, 0.4957], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9811,     0.0071,     0.0000,     0.0003,     0.0114],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9899,     0.0059,     0.0000,     0.0041],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0028,     0.9547,     0.0142,     0.0283],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0025, 0.0042, 0.0426, 0.7136, 0.2372], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0018,     0.0004,     0.0032,     0.4199,     0.5748],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.44245469583879
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.187128690092976
actions average: 
K:  2  action  0 :  tensor([    0.9987,     0.0003,     0.0000,     0.0001,     0.0009],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9991,     0.0001,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9572,     0.0258,     0.0170],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0165, 0.0020, 0.0123, 0.6919, 0.2772], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0485, 0.0174, 0.0272, 0.2022, 0.7047], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.465]
 [47.34 ]
 [69.119]
 [71.255]
 [69.425]] [[1.637]
 [1.261]
 [1.841]
 [1.898]
 [1.849]]
line 256 mcts: sample exp_bonus 34.97342283592143
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  55.308847427368164
siam score:  -0.8967456
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.946]
 [17.326]
 [17.326]
 [17.326]
 [18.744]] [[0.489]
 [0.18 ]
 [0.18 ]
 [0.18 ]
 [0.212]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.823]
 [51.823]
 [38.323]
 [51.823]
 [51.823]] [[1.   ]
 [1.   ]
 [0.663]
 [1.   ]
 [1.   ]]
printing an ep nov before normalisation:  25.604958331280812
printing an ep nov before normalisation:  70.62051838030747
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.058]
 [42.058]
 [37.863]
 [42.058]
 [42.058]] [[0.391]
 [0.391]
 [0.33 ]
 [0.391]
 [0.391]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.991]
 [25.505]
 [21.656]
 [21.431]
 [20.889]] [[0.634]
 [0.436]
 [0.267]
 [0.257]
 [0.233]]
printing an ep nov before normalisation:  50.78295271002505
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.116]
 [72.116]
 [67.915]
 [73.786]
 [72.116]] [[1.667]
 [1.667]
 [1.465]
 [1.747]
 [1.667]]
printing an ep nov before normalisation:  62.33795381239885
siam score:  -0.89159125
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.752]
 [29.752]
 [29.752]
 [29.752]
 [29.752]] [[1.346]
 [1.346]
 [1.346]
 [1.346]
 [1.346]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  108.43935719992457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.852]
 [93.852]
 [93.852]
 [93.852]
 [93.852]] [[0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.84256139028107
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.08 ]
 [29.302]
 [29.302]
 [29.302]
 [29.302]] [[1.013]
 [0.846]
 [0.846]
 [0.846]
 [0.846]]
printing an ep nov before normalisation:  43.08287864236745
printing an ep nov before normalisation:  28.950807257728766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  16.94481339898531
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.63801619003708
printing an ep nov before normalisation:  26.648109290558217
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.61 ]
 [18.788]
 [99.365]
 [23.178]
 [14.659]] [[0.153]
 [0.031]
 [0.613]
 [0.063]
 [0.001]]
printing an ep nov before normalisation:  23.574969772014242
printing an ep nov before normalisation:  15.02177684616612
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.66175365447998
printing an ep nov before normalisation:  78.20204153395326
printing an ep nov before normalisation:  62.67894605264396
printing an ep nov before normalisation:  59.19861448295263
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.712]
 [29.069]
 [57.633]
 [21.212]
 [21.13 ]] [[0.175]
 [0.12 ]
 [0.551]
 [0.001]
 [0.   ]]
line 256 mcts: sample exp_bonus 22.632278183473506
printing an ep nov before normalisation:  25.843947569176645
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 62.20494182711381
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[90.851]
 [90.851]
 [94.457]
 [90.504]
 [88.428]] [[0.542]
 [0.542]
 [0.591]
 [0.538]
 [0.509]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.489]
 [59.489]
 [59.489]
 [59.489]
 [59.489]] [[0.336]
 [0.336]
 [0.336]
 [0.336]
 [0.336]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.99 ]
 [28.574]
 [30.357]
 [29.324]
 [30.582]] [[0.414]
 [0.604]
 [0.677]
 [0.635]
 [0.687]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.23 ]
 [27.835]
 [24.222]
 [24.408]
 [26.576]] [[0.537]
 [0.386]
 [0.301]
 [0.306]
 [0.357]]
printing an ep nov before normalisation:  69.18533097780345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.57 ]
 [72.458]
 [49.901]
 [60.336]
 [71.777]] [[1.171]
 [1.046]
 [0.648]
 [0.832]
 [1.034]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  68.5056843668407
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.71455625135676
printing an ep nov before normalisation:  24.981018164457296
printing an ep nov before normalisation:  40.80086132551932
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  64.89263467676784
printing an ep nov before normalisation:  48.54441534774528
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.85366249084473
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.938762103512595
printing an ep nov before normalisation:  49.811391103494955
printing an ep nov before normalisation:  72.49878319372812
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.076]
 [24.597]
 [19.199]
 [27.621]
 [20.458]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.691]
 [50.196]
 [33.318]
 [43.349]
 [50.567]] [[1.512]
 [1.358]
 [0.78 ]
 [1.124]
 [1.371]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  93.02421569824219
printing an ep nov before normalisation:  23.784519340067725
using explorer policy with actor:  1
printing an ep nov before normalisation:  64.8827740914616
actions average: 
K:  2  action  0 :  tensor([0.9646, 0.0150, 0.0063, 0.0052, 0.0089], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9984,     0.0000,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0004,     0.8970,     0.0456,     0.0569],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0058,     0.0002,     0.0306,     0.6510,     0.3124],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0171, 0.0223, 0.0895, 0.4021, 0.4690], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  50.90322004301116
printing an ep nov before normalisation:  24.47619261082163
printing an ep nov before normalisation:  75.84956842767356
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.52]
 [38.52]
 [38.52]
 [38.52]
 [38.52]] [[0.21]
 [0.21]
 [0.21]
 [0.21]
 [0.21]]
printing an ep nov before normalisation:  16.516363620758057
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  72.3280730814548
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.73172119100325
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  33.9766682645455
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.349]
 [32.349]
 [32.349]
 [32.349]
 [32.349]] [[0.985]
 [0.985]
 [0.985]
 [0.985]
 [0.985]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.25534945460828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  12.746385876474935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.90014321688742
line 256 mcts: sample exp_bonus 67.74676888929925
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([0.9794, 0.0052, 0.0016, 0.0053, 0.0084], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9985,     0.0002,     0.0000,     0.0011],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9272,     0.0434,     0.0293],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0041,     0.0883,     0.6618,     0.2452],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0206, 0.0163, 0.0217, 0.4348, 0.5066], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  57.724098113519446
printing an ep nov before normalisation:  32.460682282831534
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.38758643364502
printing an ep nov before normalisation:  64.52482691919904
printing an ep nov before normalisation:  68.54803437206904
printing an ep nov before normalisation:  32.275340432760984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.613]
 [68.613]
 [68.613]
 [68.613]
 [68.613]] [[0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]]
siam score:  -0.8919933
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.095096863302764
printing an ep nov before normalisation:  18.61013649222596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.03037091856899
printing an ep nov before normalisation:  0.7871539367988589
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.973250154621862
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.172407048175128
printing an ep nov before normalisation:  28.657027285415637
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.288]
 [41.439]
 [41.529]
 [45.357]
 [51.167]] [[0.739]
 [0.379]
 [0.38 ]
 [0.44 ]
 [0.532]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.839]
 [31.343]
 [33.872]
 [30.436]
 [33.256]] [[1.096]
 [1.391]
 [1.556]
 [1.331]
 [1.516]]
printing an ep nov before normalisation:  49.27489875073899
printing an ep nov before normalisation:  24.533065250616673
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.99025315791132
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  8.578458698743532
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.8992457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 101.18878060402074
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.49 ]
 [16.763]
 [23.073]
 [17.974]
 [17.93 ]] [[0.442]
 [0.312]
 [0.532]
 [0.355]
 [0.353]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.4377637274659
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.17470455169678
printing an ep nov before normalisation:  29.119813607474214
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.531]
 [41.531]
 [30.184]
 [42.238]
 [41.531]] [[1.63 ]
 [1.63 ]
 [1.043]
 [1.667]
 [1.63 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.357]
 [24.357]
 [74.479]
 [24.357]
 [24.357]] [[0.047]
 [0.047]
 [0.249]
 [0.047]
 [0.047]]
printing an ep nov before normalisation:  52.112186599199816
printing an ep nov before normalisation:  59.04709657867922
printing an ep nov before normalisation:  43.51472854614258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.792826958242234
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0010,     0.9759,     0.0005,     0.0042,     0.0184],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9770,     0.0107,     0.0121],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0004,     0.0388,     0.6922,     0.2682],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0007,     0.0009,     0.0012,     0.3271,     0.6702],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  28.97901530265659
printing an ep nov before normalisation:  26.807352268660274
printing an ep nov before normalisation:  13.608763224195588
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.198]
 [19.278]
 [24.621]
 [19.535]
 [18.036]] [[0.162]
 [0.141]
 [0.201]
 [0.144]
 [0.127]]
printing an ep nov before normalisation:  29.097767489714528
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.47545659525229
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.51440506437655
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.21537658479161
printing an ep nov before normalisation:  48.52614119326428
printing an ep nov before normalisation:  66.91737500019323
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.436232232264505
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.205]
 [26.82 ]
 [16.69 ]
 [16.432]
 [26.82 ]] [[2.   ]
 [2.641]
 [1.234]
 [1.198]
 [2.641]]
siam score:  -0.9043437
using explorer policy with actor:  1
printing an ep nov before normalisation:  48.66712990842179
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.55541149822729
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.21873090802706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.85 ]
 [21.489]
 [17.307]
 [21.101]
 [21.649]] [[1.02 ]
 [0.691]
 [0.475]
 [0.671]
 [0.7  ]]
printing an ep nov before normalisation:  31.775087848696202
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  87.94779004423195
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  56.276736243682954
printing an ep nov before normalisation:  37.878051250452515
printing an ep nov before normalisation:  25.801801681518555
siam score:  -0.9103319
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9881,     0.0000,     0.0000,     0.0072,     0.0047],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0271, 0.9393, 0.0046, 0.0066, 0.0223], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0054,     0.9121,     0.0369,     0.0457],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0021, 0.0037, 0.0952, 0.5713, 0.3278], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0049, 0.0071, 0.1026, 0.2778, 0.6076], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.105]
 [22.796]
 [22.796]
 [22.796]
 [22.796]] [[0.596]
 [0.376]
 [0.376]
 [0.376]
 [0.376]]
printing an ep nov before normalisation:  22.210186550178683
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.496]
 [23.496]
 [23.496]
 [23.496]
 [57.409]] [[-0.11 ]
 [-0.11 ]
 [-0.11 ]
 [-0.11 ]
 [ 0.861]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.955]
 [14.402]
 [22.607]
 [26.736]
 [15.206]] [[0.506]
 [0.472]
 [0.984]
 [1.242]
 [0.522]]
printing an ep nov before normalisation:  73.67762204772032
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.34417564868541
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.09 ]
 [18.684]
 [59.163]
 [35.325]
 [39.482]] [[0.183]
 [0.   ]
 [0.304]
 [0.125]
 [0.156]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.668]
 [43.027]
 [43.027]
 [45.271]
 [43.027]] [[0.458]
 [0.604]
 [0.604]
 [0.648]
 [0.604]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.33585292489755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.335722837370916
printing an ep nov before normalisation:  48.9894801461134
printing an ep nov before normalisation:  23.41700612456962
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.784]
 [49.547]
 [55.974]
 [57.029]
 [57.064]] [[0.259]
 [0.206]
 [0.271]
 [0.282]
 [0.282]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9770,     0.0102,     0.0001,     0.0039,     0.0089],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0006,     0.9514,     0.0008,     0.0147,     0.0326],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.8859,     0.0510,     0.0629],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0014,     0.0005,     0.0221,     0.6452,     0.3308],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0011, 0.0091, 0.1575, 0.3122, 0.5201], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.159482430804104
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  140.65135200364418
printing an ep nov before normalisation:  23.276844024658203
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 63.80819783843149
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.00307681646051
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.668612995756256
printing an ep nov before normalisation:  16.640263734175242
printing an ep nov before normalisation:  24.018514156341553
line 256 mcts: sample exp_bonus 39.947382866916215
printing an ep nov before normalisation:  55.416423966524704
printing an ep nov before normalisation:  36.6339277480097
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  91.24393151700399
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  92.69403297986685
actions average: 
K:  2  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9925,     0.0029,     0.0001,     0.0040],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9550,     0.0241,     0.0209],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0027,     0.0004,     0.0438,     0.6364,     0.3167],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0027,     0.0004,     0.0424,     0.3123,     0.6422],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  29.491398334503174
printing an ep nov before normalisation:  39.219947676007536
printing an ep nov before normalisation:  58.394228663743114
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.48448811780248
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9480,     0.0316,     0.0006,     0.0062,     0.0136],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0016,     0.9868,     0.0014,     0.0008,     0.0094],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0013,     0.9725,     0.0132,     0.0131],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0007, 0.0029, 0.0363, 0.6884, 0.2716], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0011, 0.0007, 0.0644, 0.4668, 0.4671], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  1.3684000920142125
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.73043317161413
printing an ep nov before normalisation:  19.707670043727063
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.957335869133043
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.00798785143415
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.8  ]
 [44.8  ]
 [27.452]
 [44.8  ]
 [44.8  ]] [[1.424]
 [1.424]
 [0.731]
 [1.424]
 [1.424]]
printing an ep nov before normalisation:  22.191092452600422
printing an ep nov before normalisation:  23.842983830128553
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.441426858271203
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9939,     0.0018,     0.0000,     0.0011,     0.0032],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0328, 0.9420, 0.0102, 0.0033, 0.0117], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9079,     0.0570,     0.0350],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0005,     0.0546,     0.6789,     0.2660],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0006,     0.0716,     0.4124,     0.5151],
       grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 0.8166516387154843
printing an ep nov before normalisation:  25.687069357246425
printing an ep nov before normalisation:  23.873389790208698
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.497]
 [51.641]
 [40.497]
 [40.497]
 [40.497]] [[0.913]
 [1.391]
 [0.913]
 [0.913]
 [0.913]]
printing an ep nov before normalisation:  80.00232056192382
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.12398223274799
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  139.6338040348053
line 256 mcts: sample exp_bonus 18.317996134037774
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  70.87836981456026
printing an ep nov before normalisation:  70.6860259772333
printing an ep nov before normalisation:  67.05165226733035
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 52.461793422698975
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.33236496271718
line 256 mcts: sample exp_bonus 33.69881342017796
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.120851148691486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  62.56237302496697
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.261393799997716
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.974]
 [35.818]
 [44.744]
 [44.352]
 [44.18 ]] [[0.682]
 [0.418]
 [0.707]
 [0.694]
 [0.689]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.675]
 [38.675]
 [38.675]
 [38.675]
 [38.675]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.493]
 [21.493]
 [21.493]
 [21.493]
 [21.493]] [[0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.96 ]
 [48.508]
 [42.238]
 [46.886]
 [46.486]] [[1.175]
 [1.303]
 [1.076]
 [1.244]
 [1.23 ]]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.002]
 [ 0.002]
 [33.06 ]
 [33.06 ]
 [33.06 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.68]
 [44.68]
 [44.68]
 [44.68]
 [44.68]] [[0.955]
 [0.955]
 [0.955]
 [0.955]
 [0.955]]
printing an ep nov before normalisation:  37.29661773064581
actions average: 
K:  4  action  0 :  tensor([    0.9767,     0.0031,     0.0008,     0.0073,     0.0121],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9942,     0.0005,     0.0000,     0.0051],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.9167,     0.0418,     0.0412],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0007, 0.0045, 0.0480, 0.6302, 0.3166], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0287, 0.0349, 0.2433, 0.3197, 0.3735], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.673789688661046
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.005171710506601812
printing an ep nov before normalisation:  54.52961937552186
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.99847902674128
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 15.47124582245905
printing an ep nov before normalisation:  44.78234579557931
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.509289741516113
printing an ep nov before normalisation:  18.499249807063133
printing an ep nov before normalisation:  61.15406114801128
printing an ep nov before normalisation:  16.459024204487754
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.57350024387673
actions average: 
K:  2  action  0 :  tensor([    0.9409,     0.0015,     0.0000,     0.0028,     0.0548],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9993,     0.0001,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9658,     0.0118,     0.0224],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0002,     0.0500,     0.7167,     0.2328],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0004,     0.0012,     0.1596,     0.3432,     0.4956],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.832124629645698
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.786]
 [71.109]
 [69.388]
 [71.109]
 [71.109]] [[0.389]
 [0.891]
 [0.861]
 [0.891]
 [0.891]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.73480677362347
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.005185585205094
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.374]
 [28.09 ]
 [22.144]
 [28.092]
 [28.303]] [[0.714]
 [0.437]
 [0.278]
 [0.437]
 [0.443]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.712]
 [32.363]
 [37.033]
 [34.081]
 [34.822]] [[0.603]
 [0.561]
 [0.709]
 [0.615]
 [0.639]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.845]
 [34.307]
 [34.307]
 [34.307]
 [34.307]] [[1.877]
 [1.293]
 [1.293]
 [1.293]
 [1.293]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.998]
 [30.293]
 [58.328]
 [46.334]
 [54.291]] [[0.156]
 [0.029]
 [0.489]
 [0.292]
 [0.422]]
printing an ep nov before normalisation:  30.59277055476297
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  62.49575812068737
printing an ep nov before normalisation:  38.26089938639028
printing an ep nov before normalisation:  56.41849582209433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9069521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.867]
 [12.867]
 [97.219]
 [12.867]
 [12.867]] [[0.044]
 [0.044]
 [0.506]
 [0.044]
 [0.044]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  127.8677120460273
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.876]
 [60.876]
 [60.876]
 [60.876]
 [60.876]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
printing an ep nov before normalisation:  35.83153757727828
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.037]
 [32.037]
 [62.372]
 [32.037]
 [32.037]] [[0.117]
 [0.117]
 [1.205]
 [0.117]
 [0.117]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.31952726318771
actions average: 
K:  2  action  0 :  tensor([    0.9889,     0.0089,     0.0005,     0.0008,     0.0010],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0368,     0.9318,     0.0178,     0.0002,     0.0134],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9417,     0.0234,     0.0348],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0002,     0.0477,     0.6330,     0.3187],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0168, 0.0139, 0.0277, 0.4837, 0.4579], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  62.9112699730544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.222]
 [39.592]
 [31.296]
 [27.485]
 [31.296]] [[0.594]
 [1.081]
 [0.754]
 [0.604]
 [0.754]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.53]
 [87.53]
 [87.53]
 [87.53]
 [87.53]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.503]
 [42.67 ]
 [23.503]
 [23.503]
 [23.503]] [[0.154]
 [0.469]
 [0.154]
 [0.154]
 [0.154]]
printing an ep nov before normalisation:  92.39034794180061
printing an ep nov before normalisation:  28.410832112018277
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.82835441843781
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  173.4381623713465
printing an ep nov before normalisation:  55.89178287678791
line 256 mcts: sample exp_bonus 54.54914096691561
printing an ep nov before normalisation:  57.65373859402466
printing an ep nov before normalisation:  61.71708802063052
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 49.495]
 [ 82.743]
 [124.478]
 [105.733]
 [ 90.816]] [[0.   ]
 [0.579]
 [1.305]
 [0.979]
 [0.719]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  35.10059530490948
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.99105920821059
printing an ep nov before normalisation:  34.78160172561804
printing an ep nov before normalisation:  21.10042711852281
printing an ep nov before normalisation:  15.950273251304049
printing an ep nov before normalisation:  24.920736205752558
printing an ep nov before normalisation:  21.25465862939194
printing an ep nov before normalisation:  65.96043805583511
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.03590061210625
printing an ep nov before normalisation:  20.483109928126588
printing an ep nov before normalisation:  1.087590062281123
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.826275250273678
printing an ep nov before normalisation:  170.05571858095277
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  27.753622706709255
printing an ep nov before normalisation:  26.612332164723245
printing an ep nov before normalisation:  26.040428141879246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.676069525392082
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[5.537]
 [9.512]
 [7.678]
 [4.603]
 [6.765]] [[0.117]
 [0.201]
 [0.162]
 [0.097]
 [0.143]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  180.03594546607818
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.92928618388823
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  2  action  0 :  tensor([    0.9738,     0.0219,     0.0010,     0.0004,     0.0028],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9972,     0.0001,     0.0000,     0.0024],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9335,     0.0336,     0.0328],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0015,     0.0004,     0.0003,     0.6549,     0.3428],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0006, 0.0778, 0.4034, 0.5171], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.647192040049326
printing an ep nov before normalisation:  44.72097396850586
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9082072
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.644]
 [21.644]
 [21.644]
 [21.644]
 [21.644]] [[1.198]
 [1.198]
 [1.198]
 [1.198]
 [1.198]]
UNIT TEST: sample policy line 217 mcts : [0.367 0.327 0.224 0.041 0.041]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.982097694220315
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.30253316189489
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.39272739935521
printing an ep nov before normalisation:  42.674500201391936
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.17251689696321
printing an ep nov before normalisation:  37.78451387654186
printing an ep nov before normalisation:  62.427568640725184
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 72.34464098501209
using explorer policy with actor:  1
printing an ep nov before normalisation:  55.370861284530775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.453354644320854
printing an ep nov before normalisation:  50.611004691000225
printing an ep nov before normalisation:  24.82515508106617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.75172863925644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.27571999729703
printing an ep nov before normalisation:  38.867472995827704
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.05441534993163
actions average: 
K:  0  action  0 :  tensor([    0.9856,     0.0038,     0.0000,     0.0029,     0.0076],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0034,     0.9734,     0.0006,     0.0048,     0.0178],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.9175,     0.0475,     0.0347],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0006,     0.0346,     0.6071,     0.3572],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0004,     0.0007,     0.0969,     0.4864,     0.4155],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.302372413846964
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.59583401281839
printing an ep nov before normalisation:  29.18379545211792
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.252102280830226
siam score:  -0.91712296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.921543397501324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.03716991287495
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.974]
 [22.58 ]
 [46.155]
 [46.317]
 [28.107]] [[0.285]
 [0.152]
 [0.454]
 [0.456]
 [0.222]]
printing an ep nov before normalisation:  54.20069646587457
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.37368449786109
printing an ep nov before normalisation:  45.419513316958124
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.366434144478866
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.506589505052027
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  0.025886763311717687
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.00689611037816
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.446]
 [24.493]
 [19.79 ]
 [22.895]
 [22.416]] [[0.721]
 [0.324]
 [0.153]
 [0.266]
 [0.248]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.746450807876524
line 256 mcts: sample exp_bonus 15.892664444144959
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.965]
 [57.744]
 [57.462]
 [53.793]
 [55.595]] [[1.061]
 [1.091]
 [1.08 ]
 [0.94 ]
 [1.009]]
printing an ep nov before normalisation:  42.39629783397485
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.075]
 [55.753]
 [41.552]
 [46.718]
 [46.337]] [[0.328]
 [0.333]
 [0.221]
 [0.262]
 [0.259]]
printing an ep nov before normalisation:  58.28192391622789
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 29.318]
 [ 29.318]
 [129.121]
 [ 29.318]
 [ 29.318]] [[0.268]
 [0.268]
 [1.399]
 [0.268]
 [0.268]]
printing an ep nov before normalisation:  64.30366605322759
printing an ep nov before normalisation:  48.86534868801726
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.257]
 [30.137]
 [25.436]
 [24.474]
 [24.14 ]] [[0.947]
 [1.674]
 [1.24 ]
 [1.151]
 [1.121]]
actions average: 
K:  3  action  0 :  tensor([    0.9938,     0.0019,     0.0000,     0.0018,     0.0025],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0210,     0.9704,     0.0016,     0.0003,     0.0068],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0024,     0.9620,     0.0190,     0.0165],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0247,     0.0585,     0.6315,     0.2849],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0006,     0.0028,     0.0013,     0.3090,     0.6863],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.47056943723684
printing an ep nov before normalisation:  70.16856432853768
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  68.52566808166429
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [49.913]
 [ 0.   ]
 [ 0.   ]] [[-0.905]
 [-0.905]
 [ 1.   ]
 [-0.905]
 [-0.905]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.143]
 [58.122]
 [75.89 ]
 [58.875]
 [58.122]] [[0.286]
 [0.357]
 [0.537]
 [0.364]
 [0.357]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.257]
 [47.692]
 [47.692]
 [48.193]
 [47.868]] [[0.316]
 [0.321]
 [0.321]
 [0.328]
 [0.323]]
printing an ep nov before normalisation:  37.04623006637513
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.48405623632528
printing an ep nov before normalisation:  63.78485027427253
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.979]
 [30.527]
 [24.218]
 [28.58 ]
 [29.804]] [[1.616]
 [1.257]
 [0.748]
 [1.1  ]
 [1.198]]
printing an ep nov before normalisation:  33.15359349396346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.81598320419721
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.72141126853123
printing an ep nov before normalisation:  26.91247531639479
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.58 ]
 [20.542]
 [20.542]
 [20.542]
 [20.542]] [[0.286]
 [0.182]
 [0.182]
 [0.182]
 [0.182]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.467]
 [19.495]
 [32.507]
 [23.225]
 [22.622]] [[0.589]
 [0.249]
 [0.884]
 [0.431]
 [0.402]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.997]
 [66.58 ]
 [66.58 ]
 [66.58 ]
 [66.58 ]] [[2.   ]
 [1.593]
 [1.593]
 [1.593]
 [1.593]]
printing an ep nov before normalisation:  48.83766771423644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.869]
 [54.336]
 [39.795]
 [46.772]
 [32.869]] [[0.803]
 [1.327]
 [0.972]
 [1.142]
 [0.803]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.485]
 [30.809]
 [34.377]
 [30.809]
 [30.809]] [[0.514]
 [0.377]
 [0.482]
 [0.377]
 [0.377]]
printing an ep nov before normalisation:  26.396614846693485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.39823505050413
printing an ep nov before normalisation:  20.575571180846218
printing an ep nov before normalisation:  20.854714638577324
printing an ep nov before normalisation:  20.041793725565192
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 60.12281562812572
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.295]
 [38.333]
 [30.295]
 [22.024]
 [34.186]] [[0.906]
 [1.271]
 [0.906]
 [0.531]
 [1.082]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
deleting a thread, now have 2 threads
Frames:  58764 train batches done:  6872 episodes:  1758
printing an ep nov before normalisation:  59.69170115247459
printing an ep nov before normalisation:  30.117770336794155
printing an ep nov before normalisation:  38.94561992314685
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.09043255804143
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.93733787536621
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.0183596323907409
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.61 ]
 [36.902]
 [39.61 ]
 [38.681]
 [39.61 ]] [[1.985]
 [1.777]
 [1.985]
 [1.914]
 [1.985]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.714983134343758
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.595626621824824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.882880083340876
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.72975076839692
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.766]
 [91.697]
 [94.227]
 [94.725]
 [95.127]] [[1.506]
 [1.69 ]
 [1.743]
 [1.753]
 [1.761]]
actions average: 
K:  4  action  0 :  tensor([    0.9894,     0.0046,     0.0000,     0.0015,     0.0045],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9992,     0.0005,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0019,     0.9308,     0.0357,     0.0315],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0018,     0.0958,     0.7096,     0.1925],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0113,     0.1333,     0.4185,     0.4367],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9806,     0.0024,     0.0000,     0.0083,     0.0088],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0016, 0.9488, 0.0141, 0.0095, 0.0260], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9739,     0.0134,     0.0125],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0000,     0.0005,     0.0739,     0.7033,     0.2223],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0272, 0.0018, 0.0930, 0.4161, 0.4618], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9979,     0.0006,     0.0000,     0.0003,     0.0013],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0004,     0.9863,     0.0007,     0.0000,     0.0126],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0004,     0.8986,     0.0516,     0.0494],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0817, 0.0013, 0.0691, 0.5447, 0.3032], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0193, 0.0062, 0.1695, 0.3549, 0.4502], grad_fn=<DivBackward0>)
siam score:  -0.90514773
printing an ep nov before normalisation:  23.750300776823444
line 256 mcts: sample exp_bonus 29.460927095448312
siam score:  -0.9055809
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9009423
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.56652434450957
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.23566494410081
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  150.79777098473048
printing an ep nov before normalisation:  59.32121961198806
using explorer policy with actor:  1
printing an ep nov before normalisation:  46.13934601229265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.96807669123694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.09404536528986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  116.7346642584396
line 256 mcts: sample exp_bonus 38.19696653966016
printing an ep nov before normalisation:  68.9298030690407
printing an ep nov before normalisation:  40.24442396966553
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.36313923570759
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[99.876]
 [60.883]
 [60.883]
 [60.883]
 [60.883]] [[1.097]
 [0.494]
 [0.494]
 [0.494]
 [0.494]]
printing an ep nov before normalisation:  106.99745360966709
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8917715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0175, 0.9548, 0.0038, 0.0015, 0.0224], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9746,     0.0023,     0.0231],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0019, 0.0050, 0.0692, 0.5639, 0.3601], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0019, 0.0036, 0.0507, 0.3102, 0.6337], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0444,     0.9412,     0.0007,     0.0013,     0.0124],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0006,     0.9406,     0.0323,     0.0262],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0053,     0.0005,     0.0172,     0.6719,     0.3050],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0033, 0.0015, 0.0976, 0.3500, 0.5477], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Starting evaluation
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  47.17984437047837
printing an ep nov before normalisation:  21.00964466115407
siam score:  -0.89432406
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.831]
 [28.973]
 [25.389]
 [25.57 ]
 [28.563]] [[0.47 ]
 [0.723]
 [0.633]
 [0.638]
 [0.713]]
printing an ep nov before normalisation:  21.352277922416956
printing an ep nov before normalisation:  19.44155267204999
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  68.58262813616474
actions average: 
K:  3  action  0 :  tensor([    0.9959,     0.0013,     0.0000,     0.0001,     0.0026],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0028,     0.9306,     0.0006,     0.0003,     0.0657],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0012,     0.9198,     0.0368,     0.0421],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0075, 0.0052, 0.0492, 0.6394, 0.2987], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0192, 0.0021, 0.0526, 0.2661, 0.6600], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9011043
printing an ep nov before normalisation:  32.45579753482856
siam score:  -0.90221816
printing an ep nov before normalisation:  10.465929016803699
printing an ep nov before normalisation:  50.38096831315216
siam score:  -0.903042
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9966,     0.0020,     0.0000,     0.0001,     0.0013],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9961,     0.0014,     0.0000,     0.0017],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0005,     0.9206,     0.0377,     0.0411],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0007, 0.0021, 0.0319, 0.6383, 0.3271], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0039, 0.0010, 0.0695, 0.3617, 0.5639], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.12120791982595
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.576]
 [52.366]
 [43.161]
 [43.161]
 [46.97 ]] [[1.499]
 [1.395]
 [1.098]
 [1.098]
 [1.221]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.235219423833136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.67231200080376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.49625905393533
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.18506475199283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.91000795
printing an ep nov before normalisation:  36.85020362390867
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.15983393272414
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.63164897788038
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.91107565
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.01648343544583
line 256 mcts: sample exp_bonus 68.81938851341573
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.91025996
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 94.343]
 [105.921]
 [110.689]
 [104.174]
 [104.409]] [[1.132]
 [1.398]
 [1.507]
 [1.358]
 [1.363]]
printing an ep nov before normalisation:  75.31202701440807
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  68.97666306508252
printing an ep nov before normalisation:  49.18353260937138
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  17.756823417259167
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.001]
 [ 0.001]
 [30.   ]
 [30.   ]
 [30.   ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  122.32093811035156
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.736793466569814
line 256 mcts: sample exp_bonus 0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.520904244435492
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.509876994192275
printing an ep nov before normalisation:  155.86145584465137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9493,     0.0048,     0.0002,     0.0136,     0.0321],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0023, 0.9468, 0.0247, 0.0031, 0.0231], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.9360,     0.0371,     0.0265],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0003,     0.0667,     0.6933,     0.2393],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0004,     0.0012,     0.1920,     0.3934,     0.4131],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.66934819774021
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9141159
UNIT TEST: sample policy line 217 mcts : [0.204 0.388 0.102 0.082 0.224]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.533494309430814
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.391]
 [10.625]
 [21.381]
 [21.639]
 [21.746]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.61143702996236
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9733,     0.0009,     0.0013,     0.0099,     0.0146],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0388,     0.9521,     0.0043,     0.0001,     0.0047],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9139,     0.0374,     0.0485],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0008, 0.0007, 0.0246, 0.6571, 0.3168], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0041, 0.0055, 0.0608, 0.3111, 0.6185], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.535]
 [38.397]
 [38.155]
 [32.928]
 [36.206]] [[0.56 ]
 [0.722]
 [0.714]
 [0.54 ]
 [0.649]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.296269374538888
printing an ep nov before normalisation:  25.607402359379932
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.864608276070115
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.085739144765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.179529100145864
siam score:  -0.91172075
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.595852034452314
printing an ep nov before normalisation:  18.870784631097404
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.53040055626384
printing an ep nov before normalisation:  40.78471514513716
printing an ep nov before normalisation:  29.591624982475224
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9986,     0.0003,     0.0000,     0.0002,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0046,     0.9861,     0.0004,     0.0003,     0.0085],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0004,     0.9105,     0.0411,     0.0479],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0008,     0.0311,     0.7133,     0.2543],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0013, 0.0018, 0.0935, 0.4243, 0.4792], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.092]
 [44.738]
 [35.609]
 [39.233]
 [39.233]] [[1.302]
 [1.285]
 [0.835]
 [1.014]
 [1.014]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.619]
 [19.716]
 [25.851]
 [26.252]
 [21.033]] [[0.944]
 [0.798]
 [1.27 ]
 [1.301]
 [0.899]]
printing an ep nov before normalisation:  35.5472208512453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.46966743602524
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.866]
 [21.52 ]
 [35.515]
 [44.051]
 [41.157]] [[0.498]
 [0.029]
 [0.269]
 [0.415]
 [0.366]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  78.38919294387163
printing an ep nov before normalisation:  36.162838470433506
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  64.65656110494756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.43087209898244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.74540214746568
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.60619568824768
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[112.709]
 [112.26 ]
 [112.26 ]
 [112.26 ]
 [112.26 ]] [[1.43 ]
 [1.421]
 [1.421]
 [1.421]
 [1.421]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  44.8404634694232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.041322998415904
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9742,     0.0205,     0.0002,     0.0010,     0.0041],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9979,     0.0002,     0.0001,     0.0017],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9490,     0.0176,     0.0333],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0010, 0.0302, 0.0186, 0.7577, 0.1925], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0015, 0.0501, 0.0718, 0.1748, 0.7019], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.368]
 [28.216]
 [28.067]
 [22.835]
 [25.765]] [[0.684]
 [0.451]
 [0.448]
 [0.328]
 [0.395]]
printing an ep nov before normalisation:  18.13032865524292
printing an ep nov before normalisation:  25.583833024427392
printing an ep nov before normalisation:  27.791186256876365
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.90118784
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.901246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.735 0.02  0.02  0.082 0.143]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.86149752262612
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.28197784302918
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8988612
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  16.568966368144512
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.827167401789215
printing an ep nov before normalisation:  54.81629246867955
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.006]
 [22.128]
 [47.354]
 [47.354]
 [47.354]] [[1.333]
 [1.239]
 [3.93 ]
 [3.93 ]
 [3.93 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.884]
 [33.801]
 [29.639]
 [20.741]
 [20.664]] [[0.322]
 [0.527]
 [0.431]
 [0.227]
 [0.225]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.70974747189919
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.912]
 [36.284]
 [34.233]
 [23.503]
 [32.965]] [[1.312]
 [1.592]
 [1.502]
 [1.029]
 [1.446]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.966]
 [28.422]
 [43.587]
 [53.414]
 [36.095]] [[0.627]
 [0.432]
 [0.966]
 [1.312]
 [0.702]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
actions average: 
K:  0  action  0 :  tensor([    0.9990,     0.0000,     0.0000,     0.0004,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0028,     0.9772,     0.0068,     0.0001,     0.0131],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0023,     0.9177,     0.0275,     0.0522],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0003,     0.0260,     0.7315,     0.2420],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0160, 0.0324, 0.3923, 0.5583], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  46.2167246297504
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  64.74048820049691
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.551208748516355
printing an ep nov before normalisation:  39.611296122995306
printing an ep nov before normalisation:  51.65411508633539
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  40.100145244181505
printing an ep nov before normalisation:  62.33756389023423
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.879]
 [34.879]
 [39.277]
 [41.794]
 [34.879]] [[0.762]
 [0.762]
 [0.966]
 [1.083]
 [0.762]]
actions average: 
K:  2  action  0 :  tensor([    0.9946,     0.0049,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0041,     0.9878,     0.0017,     0.0001,     0.0063],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0007,     0.8770,     0.0674,     0.0548],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0077, 0.0007, 0.0335, 0.6751, 0.2829], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0050, 0.0078, 0.0287, 0.4254, 0.5330], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.745]
 [22.499]
 [25.468]
 [37.688]
 [27.504]] [[0.411]
 [0.401]
 [0.519]
 [1.007]
 [0.601]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.304]
 [41.443]
 [59.561]
 [44.543]
 [43.81 ]] [[1.037]
 [0.495]
 [0.925]
 [0.569]
 [0.551]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  95.2598944303542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.673]
 [13.673]
 [16.983]
 [18.877]
 [15.353]] [[0.155]
 [0.155]
 [0.241]
 [0.29 ]
 [0.199]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.628]
 [27.755]
 [25.006]
 [21.668]
 [21.052]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.179040548372246
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.98 ]
 [24.436]
 [32.068]
 [23.622]
 [25.124]] [[0.693]
 [0.782]
 [1.247]
 [0.732]
 [0.824]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.422616586068344
printing an ep nov before normalisation:  27.48158199074076
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[2.91 ]
 [3.775]
 [4.023]
 [3.444]
 [5.372]] [[0.111]
 [0.144]
 [0.154]
 [0.132]
 [0.205]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.657692477717358
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 50.6297018695127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.173]
 [66.488]
 [66.104]
 [68.331]
 [65.67 ]] [[0.275]
 [0.281]
 [0.279]
 [0.288]
 [0.277]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.72]
 [ 0.  ]
 [ 0.  ]
 [ 0.  ]
 [ 0.  ]] [[ 1.667]
 [-1.508]
 [-1.508]
 [-1.508]
 [-1.508]]
printing an ep nov before normalisation:  47.053840513755944
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.555792048432643
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.97666208165622
line 256 mcts: sample exp_bonus 36.222086473054354
printing an ep nov before normalisation:  32.81293869018555
printing an ep nov before normalisation:  25.373664715767916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.94498393845224
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.65094809765456
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.61771238963374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.32052421569824
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.402]
 [21.683]
 [22.343]
 [22.482]
 [22.185]] [[1.183]
 [1.893]
 [1.981]
 [2.   ]
 [1.96 ]]
printing an ep nov before normalisation:  27.77433000055465
printing an ep nov before normalisation:  36.8751924566495
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9986,     0.0006,     0.0000,     0.0002,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0358,     0.9426,     0.0006,     0.0013,     0.0197],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0006,     0.9069,     0.0344,     0.0580],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0024, 0.0007, 0.0863, 0.6343, 0.2764], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0059, 0.0437, 0.0822, 0.2997, 0.5684], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.67 ]
 [27.031]
 [31.642]
 [40.032]
 [32.294]] [[0.675]
 [0.643]
 [0.87 ]
 [1.283]
 [0.902]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.43177358118514
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.279]
 [40.639]
 [59.615]
 [39.665]
 [38.769]] [[0.057]
 [0.07 ]
 [0.13 ]
 [0.067]
 [0.064]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 51.789830716943825
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
siam score:  -0.9132991
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.486994637383354
printing an ep nov before normalisation:  85.29673833307794
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.773853084787106
printing an ep nov before normalisation:  73.84055223555359
printing an ep nov before normalisation:  37.704407467057614
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.597]
 [38.803]
 [27.424]
 [22.134]
 [28.989]] [[0.972]
 [1.213]
 [0.685]
 [0.44 ]
 [0.758]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.95908801191344
printing an ep nov before normalisation:  82.34712508146262
printing an ep nov before normalisation:  39.35360750527303
printing an ep nov before normalisation:  32.723938425781995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.27353330428579
printing an ep nov before normalisation:  23.243519741217042
printing an ep nov before normalisation:  83.32197234598773
siam score:  -0.90105927
siam score:  -0.9012204
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.533]
 [53.511]
 [62.52 ]
 [59.031]
 [59.219]] [[0.179]
 [0.201]
 [0.267]
 [0.241]
 [0.243]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.353813802578802
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.57620371889631
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.683391254514884
siam score:  -0.90122855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 45.43836227917833
printing an ep nov before normalisation:  30.715070570321767
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9651,     0.0021,     0.0000,     0.0132,     0.0195],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9391,     0.0321,     0.0005,     0.0281],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9551,     0.0003,     0.0446],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0000,     0.0012,     0.0582,     0.7359,     0.2046],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0002,     0.0016,     0.1860,     0.3538,     0.4584],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  93.34169757594039
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.12235898246799
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.90997225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[136.876]
 [136.876]
 [139.532]
 [136.836]
 [136.876]] [[0.644]
 [0.644]
 [0.665]
 [0.644]
 [0.644]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.845434124176464
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.77324164028471
printing an ep nov before normalisation:  30.191464835454852
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.003]
 [46.509]
 [41.468]
 [41.468]
 [41.468]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  41.81682898555829
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.39340071559756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.90792084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.90945226
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.27201309168815
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.812]
 [23.812]
 [23.129]
 [23.922]
 [23.812]] [[0.915]
 [0.915]
 [0.889]
 [0.919]
 [0.915]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.108410551275114
siam score:  -0.90486693
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.90576583
printing an ep nov before normalisation:  76.71385962012373
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.52114365457561
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.90680444
printing an ep nov before normalisation:  92.1276761019853
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.97081346389748
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.539]
 [40.393]
 [41.684]
 [36.823]
 [35.539]] [[1.065]
 [1.351]
 [1.428]
 [1.141]
 [1.065]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.299]
 [61.836]
 [71.066]
 [66.59 ]
 [70.418]] [[0.221]
 [0.218]
 [0.281]
 [0.25 ]
 [0.276]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.427]
 [48.427]
 [48.427]
 [48.427]
 [48.427]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
actions average: 
K:  4  action  0 :  tensor([0.9513, 0.0286, 0.0056, 0.0051, 0.0093], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9812,     0.0005,     0.0181],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0003,     0.1460,     0.5898,     0.2636],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0011, 0.0346, 0.1584, 0.2619, 0.5439], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.37656021118164
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  11.736416816711426
printing an ep nov before normalisation:  56.54232550382264
printing an ep nov before normalisation:  21.62548542022705
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.754]
 [14.754]
 [22.529]
 [14.754]
 [14.754]] [[0.157]
 [0.157]
 [0.308]
 [0.157]
 [0.157]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  67.34209885569219
siam score:  -0.89981455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.940279317841984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9992,     0.0004,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0038,     0.9916,     0.0023,     0.0001,     0.0022],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0003,     0.9032,     0.0492,     0.0472],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0008, 0.0013, 0.0023, 0.8036, 0.1919], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0043, 0.0112, 0.0580, 0.3343, 0.5922], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.908]
 [93.908]
 [93.908]
 [93.908]
 [93.908]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.90658796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.839554989328136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.555446189929206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.316]
 [39.316]
 [39.316]
 [39.316]
 [39.316]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
printing an ep nov before normalisation:  37.956025755498935
printing an ep nov before normalisation:  26.676803741723795
actions average: 
K:  1  action  0 :  tensor([    0.9990,     0.0002,     0.0000,     0.0003,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0009,     0.9990,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0145,     0.9459,     0.0086,     0.0309],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0019, 0.0008, 0.0184, 0.6999, 0.2790], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0053, 0.0022, 0.1651, 0.3533, 0.4741], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[99.859]
 [99.859]
 [99.859]
 [99.859]
 [99.859]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
actions average: 
K:  3  action  0 :  tensor([    0.9997,     0.0001,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0039,     0.9944,     0.0002,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0005,     0.8906,     0.0368,     0.0720],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0030, 0.0009, 0.0606, 0.7744, 0.1611], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0181, 0.0422, 0.0984, 0.3816, 0.4597], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  56.84416462398471
siam score:  -0.90854937
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.60375387137871
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.9971,     0.0001,     0.0000,     0.0007,     0.0020],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0099,     0.9765,     0.0028,     0.0003,     0.0105],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9093,     0.0380,     0.0526],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0004,     0.0656,     0.7214,     0.2125],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0050, 0.0528, 0.1063, 0.3000, 0.5359], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  27.634252918647487
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9986,     0.0004,     0.0000,     0.0002,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0047, 0.8820, 0.0372, 0.0019, 0.0742], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9629,     0.0178,     0.0192],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0004,     0.0477,     0.6884,     0.2634],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0008, 0.0032, 0.0022, 0.3971, 0.5967], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  63.66166725051831
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.286]
 [15.692]
 [20.051]
 [18.878]
 [19.502]] [[0.665]
 [0.468]
 [0.598]
 [0.563]
 [0.582]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[78.837]
 [76.647]
 [76.647]
 [76.647]
 [76.647]] [[1.   ]
 [0.948]
 [0.948]
 [0.948]
 [0.948]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.7838134765625
printing an ep nov before normalisation:  39.05321338065679
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.55064735155184
printing an ep nov before normalisation:  49.77908419626746
printing an ep nov before normalisation:  27.747264482969936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.327819041720804
printing an ep nov before normalisation:  30.17547979965768
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.614]
 [27.614]
 [27.614]
 [27.85 ]
 [27.614]] [[0.797]
 [0.797]
 [0.797]
 [0.809]
 [0.797]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.870124619242794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  113.1537495159596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  81.05536091544522
printing an ep nov before normalisation:  28.243383913027007
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.0016878549587318048
printing an ep nov before normalisation:  36.10324999271563
printing an ep nov before normalisation:  38.11407973090783
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  42.86783455819126
printing an ep nov before normalisation:  119.4171919501675
siam score:  -0.8998445
printing an ep nov before normalisation:  61.19337177385628
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.69309536848355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  112.9945757124097
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.33309817216125
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.91208595
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9779,     0.0014,     0.0001,     0.0053,     0.0153],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0005,     0.9908,     0.0006,     0.0047,     0.0034],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0005,     0.9764,     0.0101,     0.0130],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0025,     0.0006,     0.0406,     0.7029,     0.2535],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0012, 0.0071, 0.1061, 0.3641, 0.5215], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.716]
 [31.843]
 [31.342]
 [28.144]
 [32.221]] [[0.905]
 [1.04 ]
 [1.023]
 [0.919]
 [1.052]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  76.69629441925228
printing an ep nov before normalisation:  65.29825860621348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.848394870758057
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  27.45384933532438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9832,     0.0063,     0.0014,     0.0007,     0.0084],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9988,     0.0002,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0004,     0.9229,     0.0317,     0.0450],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0062,     0.0004,     0.0480,     0.7722,     0.1731],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0613, 0.0032, 0.0595, 0.2830, 0.5931], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.05317613679248
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.835813527798738
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.98 ]
 [17.115]
 [19.677]
 [27.774]
 [17.379]] [[0.196]
 [0.162]
 [0.208]
 [0.352]
 [0.167]]
printing an ep nov before normalisation:  31.202419487664695
printing an ep nov before normalisation:  53.1754195690155
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9090119
printing an ep nov before normalisation:  40.810920027448496
printing an ep nov before normalisation:  53.277477834062786
printing an ep nov before normalisation:  34.13995718110716
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.798893696609213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.089173045049755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.434]
 [60.774]
 [58.434]
 [56.109]
 [58.434]] [[1.177]
 [1.266]
 [1.177]
 [1.088]
 [1.177]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9893,     0.0035,     0.0001,     0.0013,     0.0058],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9496,     0.0288,     0.0012,     0.0201],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0007,     0.9275,     0.0294,     0.0424],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0004,     0.0728,     0.7628,     0.1638],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0011,     0.1759,     0.4432,     0.3797],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  53.350580013099204
printing an ep nov before normalisation:  0.8201134412072975
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.963]
 [36.164]
 [32.963]
 [32.963]
 [32.963]] [[0.65 ]
 [0.713]
 [0.65 ]
 [0.65 ]
 [0.65 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.615]
 [21.068]
 [27.329]
 [25.587]
 [25.624]] [[0.538]
 [0.563]
 [0.906]
 [0.81 ]
 [0.812]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.767]
 [68.535]
 [59.989]
 [67.054]
 [69.696]] [[1.038]
 [1.001]
 [0.742]
 [0.956]
 [1.036]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 35.29033698923969
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.365]
 [22.627]
 [23.141]
 [27.259]
 [22.208]] [[0.543]
 [0.507]
 [0.532]
 [0.731]
 [0.487]]
printing an ep nov before normalisation:  31.366071217529463
printing an ep nov before normalisation:  39.977092024254176
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.531]
 [49.147]
 [43.679]
 [43.419]
 [42.68 ]] [[0.484]
 [0.517]
 [0.405]
 [0.4  ]
 [0.385]]
actions average: 
K:  3  action  0 :  tensor([    0.9977,     0.0000,     0.0000,     0.0008,     0.0015],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0012,     0.9820,     0.0014,     0.0006,     0.0148],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0005,     0.9076,     0.0420,     0.0499],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0007,     0.0005,     0.0782,     0.6196,     0.3010],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0017, 0.0017, 0.0714, 0.3791, 0.5461], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 50.21071657146384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.474013424293794
printing an ep nov before normalisation:  23.805841416286157
printing an ep nov before normalisation:  26.045750019047087
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9004213
printing an ep nov before normalisation:  104.57292737455514
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.58 ]
 [31.902]
 [32.937]
 [35.453]
 [35.461]] [[0.717]
 [0.546]
 [0.584]
 [0.675]
 [0.676]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.413]
 [41.413]
 [41.413]
 [41.413]
 [41.413]] [[41.413]
 [41.413]
 [41.413]
 [41.413]
 [41.413]]
printing an ep nov before normalisation:  35.10276649204616
siam score:  -0.89531827
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.043]
 [26.685]
 [28.734]
 [28.719]
 [27.597]] [[0.429]
 [0.989]
 [1.162]
 [1.161]
 [1.066]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  64.49183659186957
printing an ep nov before normalisation:  43.283869069169526
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.732]
 [20.551]
 [29.732]
 [36.967]
 [29.732]] [[0.685]
 [0.282]
 [0.685]
 [1.003]
 [0.685]]
actions average: 
K:  2  action  0 :  tensor([    0.9973,     0.0004,     0.0000,     0.0002,     0.0021],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0133, 0.9050, 0.0436, 0.0010, 0.0371], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0008,     0.8674,     0.0653,     0.0665],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0028,     0.0422,     0.6340,     0.3205],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0003,     0.0193,     0.0796,     0.3432,     0.5575],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.01206617105303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.347 0.102 0.245 0.163 0.143]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.176]
 [51.925]
 [44.367]
 [42.176]
 [42.176]] [[0.833]
 [1.126]
 [0.899]
 [0.833]
 [0.833]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  47.26811658565519
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.426]
 [54.887]
 [60.149]
 [56.164]
 [56.215]] [[0.912]
 [1.174]
 [1.388]
 [1.226]
 [1.228]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.98]
 [29.98]
 [29.98]
 [27.82]
 [29.98]] [[1.142]
 [1.142]
 [1.142]
 [1.06 ]
 [1.142]]
line 256 mcts: sample exp_bonus 42.84160643074566
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.827]
 [37.823]
 [36.827]
 [36.827]
 [36.827]] [[1.523]
 [1.584]
 [1.523]
 [1.523]
 [1.523]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.27040385375452
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.786449432373047
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.988]
 [70.33 ]
 [70.244]
 [70.724]
 [70.292]] [[0.574]
 [0.652]
 [0.65 ]
 [0.659]
 [0.651]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.319]
 [41.674]
 [30.645]
 [34.604]
 [48.66 ]] [[0.408]
 [0.235]
 [0.12 ]
 [0.161]
 [0.307]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.106868936172447
printing an ep nov before normalisation:  79.81093757599935
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.013786100058816
siam score:  -0.910829
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.76809698005069
printing an ep nov before normalisation:  24.916343688964844
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.280852694313083
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9998,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0005,     0.9227,     0.0380,     0.0388],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0004,     0.0929,     0.6520,     0.2541],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0024, 0.0009, 0.1073, 0.3614, 0.5279], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.505]
 [20.963]
 [30.324]
 [25.515]
 [25.515]] [[0.676]
 [0.707]
 [1.34 ]
 [1.015]
 [1.015]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  107.15875617561817
printing an ep nov before normalisation:  30.5673885345459
printing an ep nov before normalisation:  31.791849006441918
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.06138568780928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.647]
 [20.647]
 [56.62 ]
 [20.647]
 [20.647]] [[0.312]
 [0.312]
 [0.854]
 [0.312]
 [0.312]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.374]
 [23.347]
 [15.428]
 [14.98 ]
 [16.909]] [[0.806]
 [1.   ]
 [0.483]
 [0.454]
 [0.58 ]]
printing an ep nov before normalisation:  134.05613917128463
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.276719609703086
printing an ep nov before normalisation:  1.4960463659008383e-05
using explorer policy with actor:  1
siam score:  -0.90806174
printing an ep nov before normalisation:  13.26906614935222
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.81 ]
 [17.011]
 [16.999]
 [23.023]
 [18.953]] [[0.14 ]
 [0.32 ]
 [0.319]
 [0.577]
 [0.403]]
printing an ep nov before normalisation:  65.70437887176514
printing an ep nov before normalisation:  76.53211828393493
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.437737697123556
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.1  ]
 [52.541]
 [64.1  ]
 [76.511]
 [64.1  ]] [[1.083]
 [0.739]
 [1.083]
 [1.452]
 [1.083]]
printing an ep nov before normalisation:  35.747251439708556
using explorer policy with actor:  1
printing an ep nov before normalisation:  97.5584176900418
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.43268593001142
printing an ep nov before normalisation:  0.00015103945827377174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.06047865056357
printing an ep nov before normalisation:  42.48169143400949
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.845220179838925
printing an ep nov before normalisation:  30.437440872192383
printing an ep nov before normalisation:  26.860935818424164
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  85.02773454104498
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.666]
 [33.352]
 [48.641]
 [39.334]
 [40.279]] [[0.551]
 [0.535]
 [1.333]
 [0.847]
 [0.896]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  47.543541356771144
actions average: 
K:  4  action  0 :  tensor([0.9145, 0.0164, 0.0043, 0.0191, 0.0458], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9904,     0.0034,     0.0001,     0.0060],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0014,     0.9519,     0.0159,     0.0307],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0000,     0.0009,     0.1021,     0.6795,     0.2174],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0020,     0.1081,     0.2867,     0.6028],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.07211294000067
printing an ep nov before normalisation:  45.14974804414724
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 30.751741883562328
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.539049354877104
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.36810806749738
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.92916726170294
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 27.54 ]
 [ 68.333]
 [111.188]
 [ 80.342]
 [ 75.047]] [[0.038]
 [0.13 ]
 [0.227]
 [0.157]
 [0.145]]
printing an ep nov before normalisation:  136.0690834012511
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9086528
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.125]
 [30.763]
 [21.108]
 [22.785]
 [27.416]] [[0.561]
 [0.715]
 [0.491]
 [0.53 ]
 [0.637]]
printing an ep nov before normalisation:  61.07039471301404
printing an ep nov before normalisation:  50.15543562712096
printing an ep nov before normalisation:  87.95587346333488
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.27 ]
 [22.389]
 [31.048]
 [29.768]
 [18.337]] [[0.521]
 [0.321]
 [0.446]
 [0.427]
 [0.263]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[  0.   ]
 [  0.   ]
 [122.439]
 [  0.   ]
 [  0.   ]] [[-0.466]
 [-0.466]
 [ 1.417]
 [-0.466]
 [-0.466]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.601372843325244
printing an ep nov before normalisation:  15.456612539346205
printing an ep nov before normalisation:  22.598808489411763
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 37.48506226712213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.0419973560842
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.904]
 [35.904]
 [34.855]
 [35.904]
 [35.904]] [[1.911]
 [1.911]
 [1.831]
 [1.911]
 [1.911]]
printing an ep nov before normalisation:  33.01683434106916
printing an ep nov before normalisation:  82.21186505593798
printing an ep nov before normalisation:  37.18943735035786
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 28.743]
 [ 59.808]
 [118.506]
 [103.327]
 [ 68.649]] [[0.002]
 [0.358]
 [1.029]
 [0.856]
 [0.459]]
printing an ep nov before normalisation:  72.58660157882181
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.85974161965507
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  78.47950376625975
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.35627797991393
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.666]
 [34.293]
 [34.293]
 [34.293]
 [34.293]] [[0.247]
 [0.138]
 [0.138]
 [0.138]
 [0.138]]
printing an ep nov before normalisation:  30.007425223608422
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.77790615814465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.88965498478053
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.88492028071717
printing an ep nov before normalisation:  29.440011384862075
using explorer policy with actor:  1
printing an ep nov before normalisation:  96.94353103637695
printing an ep nov before normalisation:  23.97851264747162
printing an ep nov before normalisation:  25.2967106698365
printing an ep nov before normalisation:  31.5883812871914
printing an ep nov before normalisation:  60.34694407472779
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.197]
 [42.139]
 [34.666]
 [34.666]
 [34.666]] [[0.984]
 [1.465]
 [1.063]
 [1.063]
 [1.063]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.015]
 [51.389]
 [46.015]
 [46.015]
 [46.015]] [[1.302]
 [1.586]
 [1.302]
 [1.302]
 [1.302]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.58378514602906
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9028498
UNIT TEST: sample policy line 217 mcts : [0.143 0.204 0.143 0.306 0.204]
siam score:  -0.9045241
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.632873385606093
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.885857131622583
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.15463438324799
printing an ep nov before normalisation:  71.95999281747001
printing an ep nov before normalisation:  44.055574172513175
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  43.01665135407766
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.732]
 [20.538]
 [14.507]
 [16.835]
 [21.765]] [[0.699]
 [0.685]
 [0.266]
 [0.428]
 [0.77 ]]
printing an ep nov before normalisation:  30.469457217056842
actions average: 
K:  3  action  0 :  tensor([    0.9824,     0.0048,     0.0003,     0.0005,     0.0120],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0009,     0.9623,     0.0149,     0.0004,     0.0215],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0018,     0.9397,     0.0295,     0.0290],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0044, 0.0012, 0.0295, 0.7563, 0.2086], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0056, 0.0027, 0.1460, 0.3415, 0.5042], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.249]
 [33.448]
 [54.506]
 [59.151]
 [52.924]] [[0.682]
 [0.399]
 [0.65 ]
 [0.705]
 [0.631]]
printing an ep nov before normalisation:  32.16962223103275
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.319486143728067
printing an ep nov before normalisation:  25.410779239756017
printing an ep nov before normalisation:  32.1054536260515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.058594703674316
printing an ep nov before normalisation:  31.20132376200048
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.297]
 [37.511]
 [39.553]
 [40.961]
 [41.198]] [[1.528]
 [1.467]
 [1.624]
 [1.732]
 [1.75 ]]
printing an ep nov before normalisation:  43.4639729163965
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.480941797795325
printing an ep nov before normalisation:  19.925147710331494
printing an ep nov before normalisation:  26.958049157132496
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.0056414604187
printing an ep nov before normalisation:  74.04817921117628
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.611]
 [88.611]
 [88.611]
 [88.611]
 [88.611]] [[1.285]
 [1.285]
 [1.285]
 [1.285]
 [1.285]]
printing an ep nov before normalisation:  61.0441563133597
printing an ep nov before normalisation:  40.51538701177933
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9067043
printing an ep nov before normalisation:  48.71452604999097
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.047]
 [68.625]
 [68.625]
 [68.625]
 [68.625]] [[0.805]
 [0.983]
 [0.983]
 [0.983]
 [0.983]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.85]
 [24.85]
 [31.82]
 [24.85]
 [24.85]] [[1.083]
 [1.083]
 [1.858]
 [1.083]
 [1.083]]
printing an ep nov before normalisation:  33.532347827972785
printing an ep nov before normalisation:  36.01502135548845
printing an ep nov before normalisation:  85.90513984766325
printing an ep nov before normalisation:  28.14517283687912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.52999696135551
printing an ep nov before normalisation:  68.95388092561167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.48811942534358
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  16.746070905213788
printing an ep nov before normalisation:  30.88871366137281
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.752]
 [33.212]
 [28.971]
 [30.81 ]
 [33.123]] [[1.532]
 [1.43 ]
 [1.15 ]
 [1.271]
 [1.424]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 14.121]
 [ 44.044]
 [124.67 ]
 [ 60.247]
 [ 62.736]] [[0.013]
 [0.079]
 [0.256]
 [0.114]
 [0.12 ]]
actions average: 
K:  4  action  0 :  tensor([    0.9953,     0.0004,     0.0000,     0.0013,     0.0029],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0012,     0.9728,     0.0086,     0.0001,     0.0173],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.9356,     0.0197,     0.0444],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0005,     0.0300,     0.7175,     0.2518],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0057,     0.0908,     0.3034,     0.5998],
       grad_fn=<DivBackward0>)
siam score:  -0.90817225
printing an ep nov before normalisation:  42.18360164824129
printing an ep nov before normalisation:  26.140491831004393
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0001,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9623,     0.0186,     0.0190],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0022, 0.0009, 0.0511, 0.7321, 0.2136], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0046, 0.0254, 0.0704, 0.2611, 0.6385], grad_fn=<DivBackward0>)
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.00028198250674904557
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.07 ]
 [63.293]
 [69.082]
 [68.165]
 [66.684]] [[1.154]
 [1.292]
 [1.539]
 [1.5  ]
 [1.437]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.786809459920846
printing an ep nov before normalisation:  25.99005119060537
printing an ep nov before normalisation:  41.84403542995619
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.203017242167796
printing an ep nov before normalisation:  30.92015246117209
printing an ep nov before normalisation:  43.364967253445215
printing an ep nov before normalisation:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  58.59636284970803
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 39.83367132679871
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  2.555628526579312e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  72.92451397650508
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.497714654706954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.29121363221165
printing an ep nov before normalisation:  34.67284446819954
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.22558580648876
printing an ep nov before normalisation:  29.872564901058535
printing an ep nov before normalisation:  35.16647421936711
printing an ep nov before normalisation:  30.62939340690589
printing an ep nov before normalisation:  21.502110958099365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.07 ]
 [55.398]
 [55.398]
 [55.398]
 [55.398]] [[0.6  ]
 [0.605]
 [0.605]
 [0.605]
 [0.605]]
printing an ep nov before normalisation:  34.62727716226867
printing an ep nov before normalisation:  25.456418763942363
printing an ep nov before normalisation:  26.45850793640289
printing an ep nov before normalisation:  23.102731704711914
printing an ep nov before normalisation:  21.606357097625732
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.962832140713623
line 256 mcts: sample exp_bonus 22.649449788863386
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.626]
 [29.895]
 [25.394]
 [20.243]
 [24.054]] [[0.345]
 [0.524]
 [0.395]
 [0.248]
 [0.357]]
printing an ep nov before normalisation:  29.67577513809739
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[109.725]
 [ 98.514]
 [ 98.514]
 [ 98.514]
 [ 98.514]] [[1.656]
 [1.379]
 [1.379]
 [1.379]
 [1.379]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 26.71802838643392
printing an ep nov before normalisation:  29.87932139656475
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.697]
 [56.605]
 [50.697]
 [50.697]
 [50.697]] [[1.424]
 [1.667]
 [1.424]
 [1.424]
 [1.424]]
printing an ep nov before normalisation:  52.9611638959961
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.90168333
printing an ep nov before normalisation:  42.84298234317701
printing an ep nov before normalisation:  62.24867903395593
printing an ep nov before normalisation:  47.73082520216704
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.532]
 [44.855]
 [38.31 ]
 [38.31 ]
 [38.934]] [[1.227]
 [1.371]
 [1.087]
 [1.087]
 [1.115]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  1.762019223860989e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.3  ]
 [56.073]
 [78.093]
 [82.653]
 [77.415]] [[0.87 ]
 [0.36 ]
 [0.975]
 [1.103]
 [0.957]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.66889055519157
printing an ep nov before normalisation:  33.947109896798146
printing an ep nov before normalisation:  55.2382755279541
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.875589238160387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  64.36592105793278
printing an ep nov before normalisation:  67.14067777314341
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.909504
printing an ep nov before normalisation:  56.920976638793945
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[97.498]
 [92.827]
 [92.827]
 [92.827]
 [92.827]] [[1.178]
 [1.086]
 [1.086]
 [1.086]
 [1.086]]
printing an ep nov before normalisation:  101.74141693488708
printing an ep nov before normalisation:  42.909357228312125
printing an ep nov before normalisation:  0.00024595005925220903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.203497479211343
printing an ep nov before normalisation:  84.03755685484703
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.298]
 [45.208]
 [38.733]
 [39.424]
 [45.161]] [[1.042]
 [0.547]
 [0.414]
 [0.428]
 [0.546]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.81696947733424
printing an ep nov before normalisation:  42.483899918394954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.11890406187985
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.901]
 [63.901]
 [64.944]
 [63.901]
 [63.901]] [[0.634]
 [0.634]
 [0.651]
 [0.634]
 [0.634]]
printing an ep nov before normalisation:  29.12120080494747
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.61999201528768
printing an ep nov before normalisation:  24.275660514831543
printing an ep nov before normalisation:  24.849102267618747
printing an ep nov before normalisation:  36.08333554137956
printing an ep nov before normalisation:  24.71251062575323
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.484599545639085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.164]
 [42.164]
 [42.164]
 [60.502]
 [42.164]] [[0.426]
 [0.426]
 [0.426]
 [0.667]
 [0.426]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.58270899184599
printing an ep nov before normalisation:  135.74211690209395
printing an ep nov before normalisation:  31.479470176437722
using explorer policy with actor:  1
printing an ep nov before normalisation:  71.77519619755162
printing an ep nov before normalisation:  41.83248482304795
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.83159882306694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  11.7734153152111
line 256 mcts: sample exp_bonus 11.405465433269459
printing an ep nov before normalisation:  14.940732956150017
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.989]
 [11.795]
 [11.795]
 [11.795]
 [11.795]] [[0.166]
 [0.113]
 [0.113]
 [0.113]
 [0.113]]
UNIT TEST: sample policy line 217 mcts : [0.224 0.122 0.102 0.102 0.449]
printing an ep nov before normalisation:  22.8382186046413
printing an ep nov before normalisation:  15.342927489170023
printing an ep nov before normalisation:  45.901872918479945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  78.7721897546905
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.437]
 [63.437]
 [64.467]
 [64.898]
 [64.873]] [[0.437]
 [0.437]
 [0.45 ]
 [0.455]
 [0.454]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.71 ]
 [27.057]
 [25.053]
 [39.982]
 [35.468]] [[0.365]
 [0.356]
 [0.33 ]
 [0.526]
 [0.467]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.9  ]
 [41.644]
 [48.563]
 [36.89 ]
 [43.069]] [[0.132]
 [0.267]
 [0.34 ]
 [0.217]
 [0.282]]
printing an ep nov before normalisation:  21.495150939238663
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.467]
 [44.301]
 [45.275]
 [45.275]
 [45.275]] [[1.024]
 [0.683]
 [0.698]
 [0.698]
 [0.698]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.078]
 [36.349]
 [20.293]
 [23.582]
 [23.582]] [[0.367]
 [0.636]
 [0.254]
 [0.332]
 [0.332]]
printing an ep nov before normalisation:  55.50223685270069
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.72631166188556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.914]
 [ 0.   ]
 [68.364]
 [70.48 ]
 [61.399]] [[ 0.17 ]
 [-0.129]
 [ 0.237]
 [ 0.248]
 [ 0.2  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.34485701467407
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.481]
 [37.239]
 [31.996]
 [36.968]
 [37.239]] [[1.722]
 [1.574]
 [1.227]
 [1.556]
 [1.574]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  19.705097381919156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.973]
 [47.628]
 [49.87 ]
 [46.226]
 [47.502]] [[0.953]
 [1.204]
 [1.303]
 [1.142]
 [1.198]]
printing an ep nov before normalisation:  84.93219176660125
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.25 ]
 [31.25 ]
 [51.485]
 [31.25 ]
 [31.25 ]] [[0.209]
 [0.209]
 [0.523]
 [0.209]
 [0.209]]
printing an ep nov before normalisation:  71.78719470986954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.148275539605017
printing an ep nov before normalisation:  35.78926280345399
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.748907957680615
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.408]
 [42.408]
 [42.408]
 [42.408]
 [42.408]] [[0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.65038967339505
siam score:  -0.902504
printing an ep nov before normalisation:  32.60364786374513
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.139]
 [40.631]
 [42.139]
 [42.139]
 [42.139]] [[0.977]
 [0.923]
 [0.977]
 [0.977]
 [0.977]]
printing an ep nov before normalisation:  30.594347675825283
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.878363923378267
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  60.26986598968506
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.674]
 [35.225]
 [27.674]
 [27.648]
 [27.674]] [[0.777]
 [0.989]
 [0.777]
 [0.776]
 [0.777]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.125345609787434
printing an ep nov before normalisation:  32.003084609248134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  89.31412696838379
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.24829265273281
printing an ep nov before normalisation:  26.884163257151428
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.502]
 [25.145]
 [24.789]
 [19.141]
 [23.95 ]] [[0.881]
 [1.001]
 [0.975]
 [0.561]
 [0.914]]
using explorer policy with actor:  1
siam score:  -0.9012851
printing an ep nov before normalisation:  22.48439166310054
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.433]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[1.615]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.80649374737476
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.202]
 [59.202]
 [59.202]
 [59.202]
 [59.202]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
printing an ep nov before normalisation:  66.10323971379911
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.482]
 [32.482]
 [32.482]
 [34.282]
 [32.482]] [[1.689]
 [1.689]
 [1.689]
 [1.811]
 [1.689]]
printing an ep nov before normalisation:  32.96289322575684
using explorer policy with actor:  1
siam score:  -0.90127885
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.443]
 [28.604]
 [34.057]
 [33.686]
 [34.012]] [[1.539]
 [1.077]
 [1.598]
 [1.563]
 [1.594]]
printing an ep nov before normalisation:  21.266846656799316
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.752]
 [46.784]
 [40.752]
 [40.752]
 [40.752]] [[1.161]
 [1.333]
 [1.161]
 [1.161]
 [1.161]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.824052442378456
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.126]
 [25.038]
 [19.126]
 [19.126]
 [19.126]] [[0.755]
 [1.134]
 [0.755]
 [0.755]
 [0.755]]
printing an ep nov before normalisation:  35.96867742546336
printing an ep nov before normalisation:  12.745510261023568
line 256 mcts: sample exp_bonus 16.102521788445873
printing an ep nov before normalisation:  82.1774464189145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.199304062683588
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[90.651]
 [90.651]
 [90.651]
 [90.651]
 [90.651]] [[181.301]
 [181.301]
 [181.301]
 [181.301]
 [181.301]]
printing an ep nov before normalisation:  60.606896891706825
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.376]
 [33.376]
 [33.376]
 [33.376]
 [33.376]] [[1.125]
 [1.125]
 [1.125]
 [1.125]
 [1.125]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.208]
 [32.982]
 [40.773]
 [43.208]
 [43.208]] [[1.485]
 [0.848]
 [1.333]
 [1.485]
 [1.485]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.143]
 [35.87 ]
 [33.372]
 [32.54 ]
 [27.608]] [[0.609]
 [0.756]
 [0.658]
 [0.625]
 [0.431]]
printing an ep nov before normalisation:  34.648988733673356
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.46290729456195
siam score:  -0.90473753
deleting a thread, now have 1 threads
Frames:  77641 train batches done:  9090 episodes:  2345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8996953
siam score:  -0.8973956
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.81196767391054
printing an ep nov before normalisation:  29.227860234910782
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.384]
 [18.5  ]
 [18.4  ]
 [19.853]
 [18.911]] [[0.547]
 [0.495]
 [0.489]
 [0.574]
 [0.519]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.622]
 [22.004]
 [20.472]
 [21.243]
 [21.979]] [[0.366]
 [0.379]
 [0.327]
 [0.353]
 [0.378]]
printing an ep nov before normalisation:  11.163026749173834
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 59.782901432582115
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.6645634140136
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 1.0214710063273106e-11
0.0 1.5036641363374046e-11
0.0 1.0370395739962767e-11
0.0 1.360519807815827e-11
0.0 1.6048598241114706e-11
0.0 1.4098202712148144e-11
0.0 1.3540329045902173e-11
0.0 1.282676970779966e-11
0.0 0.0
printing an ep nov before normalisation:  30.197530146061176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.67167030322603
printing an ep nov before normalisation:  37.906130931106716
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.9946,     0.0010,     0.0000,     0.0015,     0.0029],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0025,     0.9969,     0.0001,     0.0000,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0064,     0.0033,     0.9800,     0.0003,     0.0100],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0205, 0.0192, 0.0188, 0.7049, 0.2367], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0254, 0.0272, 0.1785, 0.2212, 0.5478], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.798]
 [83.798]
 [83.798]
 [83.798]
 [83.798]] [[1.208]
 [1.208]
 [1.208]
 [1.208]
 [1.208]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  123.63383701858329
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.87995195388794
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.625707626342773
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.224300619452375
siam score:  -0.89522904
printing an ep nov before normalisation:  35.98855587628359
siam score:  -0.89708674
printing an ep nov before normalisation:  105.49871958971815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.101711238711374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.01884788505080337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.146602120403188
printing an ep nov before normalisation:  19.340836862348212
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 25.2440791563523
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 14.721367344923335
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  4.13007768429452e-06
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.89754003
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.060226358788874
printing an ep nov before normalisation:  34.584809917218
printing an ep nov before normalisation:  43.995513030466135
actions average: 
K:  2  action  0 :  tensor([    0.9548,     0.0000,     0.0392,     0.0014,     0.0045],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9473,     0.0452,     0.0008,     0.0064],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0005,     0.9151,     0.0317,     0.0526],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0008, 0.0008, 0.0511, 0.7448, 0.2026], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0029, 0.0020, 0.1423, 0.2202, 0.6326], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  27.903744397428497
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  4.820115009351866e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.013704299926758
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.847]
 [27.496]
 [27.798]
 [26.47 ]
 [29.085]] [[1.665]
 [1.541]
 [1.569]
 [1.447]
 [1.687]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.754]
 [31.754]
 [31.754]
 [31.754]
 [31.754]] [[1.297]
 [1.297]
 [1.297]
 [1.297]
 [1.297]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.313807461331933
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.49644256087483
line 256 mcts: sample exp_bonus 24.813813076726817
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.324297020695354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.24284440143768
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.03142223702052
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.39041605259351
siam score:  -0.90484774
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.983495684377637
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.919137613745306
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.9949,     0.0040,     0.0000,     0.0002,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0003,     0.9862,     0.0004,     0.0000,     0.0131],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0012,     0.8966,     0.0374,     0.0647],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0007,     0.0567,     0.7647,     0.1778],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0009, 0.0030, 0.0763, 0.3603, 0.5595], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.760079421692026
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.609]
 [67.609]
 [68.846]
 [70.041]
 [70.574]] [[1.235]
 [1.235]
 [1.27 ]
 [1.305]
 [1.32 ]]
printing an ep nov before normalisation:  32.44766372164249
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.215778827667236
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.845]
 [32.216]
 [32.216]
 [32.216]
 [32.216]] [[0.886]
 [0.745]
 [0.745]
 [0.745]
 [0.745]]
printing an ep nov before normalisation:  22.32983112335205
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.394]
 [39.84 ]
 [43.641]
 [40.493]
 [40.907]] [[0.358]
 [0.406]
 [0.481]
 [0.419]
 [0.427]]
printing an ep nov before normalisation:  0.0005872752558389038
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  144.3625067846683
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.89956826
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.64482369331339
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.5647756982043
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.134]
 [45.134]
 [45.134]
 [46.667]
 [44.771]] [[0.887]
 [0.887]
 [0.887]
 [0.933]
 [0.876]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.284]
 [28.284]
 [30.544]
 [28.284]
 [28.284]] [[1.109]
 [1.109]
 [1.267]
 [1.109]
 [1.109]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  73.1115420844331
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.87 ]
 [39.404]
 [71.928]
 [56.392]
 [61.924]] [[0.068]
 [0.048]
 [0.196]
 [0.125]
 [0.15 ]]
printing an ep nov before normalisation:  70.25478078186228
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  51.850471100316696
printing an ep nov before normalisation:  43.40276991421438
printing an ep nov before normalisation:  81.29747861940959
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.83831151917627
printing an ep nov before normalisation:  29.246649718451994
printing an ep nov before normalisation:  29.47639011716671
printing an ep nov before normalisation:  47.87233981870076
printing an ep nov before normalisation:  28.961049679023976
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.668]
 [24.517]
 [22.709]
 [22.861]
 [23.145]] [[0.849]
 [0.616]
 [0.535]
 [0.541]
 [0.554]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  81.4019222980993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.47531022877413
printing an ep nov before normalisation:  21.18444562193495
printing an ep nov before normalisation:  61.26868724822998
siam score:  -0.9013424
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.6719677895251
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.6807551647378
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.20580965533128
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.625]
 [29.625]
 [29.625]
 [26.864]
 [29.625]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 23.48743334220065
printing an ep nov before normalisation:  44.31178259414182
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 26.934953456790033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9881,     0.0072,     0.0011,     0.0005,     0.0031],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9988,     0.0004,     0.0001,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9393,     0.0322,     0.0284],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0037, 0.0022, 0.0592, 0.6073, 0.3275], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0237, 0.0925, 0.0801, 0.2431, 0.5606], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  33.82164809058833
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.08632359436096
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 0.0
0.0 -1.345816160398385e-11
0.0 -9.894689511808899e-12
0.0 -1.8595788850565846e-11
0.0 0.0
0.0 0.0
0.0 -8.121602665518037e-12
0.0 -7.97889079471573e-12
0.0 -7.490210765306247e-12
0.0 -4.514884546267509e-12
printing an ep nov before normalisation:  45.89328165291905
printing an ep nov before normalisation:  3.410048179830483e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.247]
 [49.058]
 [58.812]
 [58.259]
 [58.922]] [[0.942]
 [0.894]
 [1.281]
 [1.259]
 [1.285]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.630505218489525
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  130.93760184584403
printing an ep nov before normalisation:  36.78791267087691
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.238]
 [27.451]
 [28.909]
 [28.909]
 [28.216]] [[0.927]
 [1.024]
 [1.14 ]
 [1.14 ]
 [1.085]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.905]
 [24.419]
 [27.629]
 [27.629]
 [27.629]] [[0.969]
 [0.701]
 [0.834]
 [0.834]
 [0.834]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.16581142253425
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 69.6566291851261
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.64857475512897
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.42266264319168
printing an ep nov before normalisation:  19.011753535965692
printing an ep nov before normalisation:  96.75337225874702
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.191]
 [39.191]
 [39.191]
 [39.191]
 [39.191]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  169.17880606043136
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.359]
 [47.094]
 [46.274]
 [45.171]
 [47.183]] [[1.605]
 [1.646]
 [1.6  ]
 [1.539]
 [1.651]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.231901111134285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.87975638067277
printing an ep nov before normalisation:  35.374285134062156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.746843814849854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.23297433594387
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  72.22123307952715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.843680061072405
siam score:  -0.89331573
siam score:  -0.8911539
printing an ep nov before normalisation:  27.437461682311604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.03066571188128364
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.652477684338137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.535]
 [41.647]
 [41.315]
 [39.841]
 [40.2  ]] [[1.126]
 [1.485]
 [1.465]
 [1.379]
 [1.4  ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.359]
 [82.359]
 [82.359]
 [82.359]
 [82.359]] [[1.878]
 [1.878]
 [1.878]
 [1.878]
 [1.878]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  106.47644969752413
printing an ep nov before normalisation:  62.43338642507268
printing an ep nov before normalisation:  43.93263739087885
printing an ep nov before normalisation:  42.157925582903744
printing an ep nov before normalisation:  60.37304060799735
printing an ep nov before normalisation:  36.29491875464028
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9800,     0.0179,     0.0000,     0.0002,     0.0019],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0036,     0.9528,     0.0150,     0.0001,     0.0285],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0007,     0.0015,     0.8486,     0.0844,     0.0648],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0017, 0.0121, 0.0259, 0.8396, 0.1207], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0022, 0.0192, 0.1674, 0.3067, 0.5044], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  27.8385192913975
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.308]
 [51.003]
 [51.003]
 [50.487]
 [51.003]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.047]
 [31.315]
 [23.819]
 [20.559]
 [21.854]] [[0.954]
 [0.965]
 [0.645]
 [0.505]
 [0.561]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  48.6999714392753
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  28.591072982854612
printing an ep nov before normalisation:  85.74738453262398
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 81.6377653214806
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  140.11922258874438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.955]
 [36.3  ]
 [42.85 ]
 [31.403]
 [31.454]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.056978437635635
printing an ep nov before normalisation:  32.637715093297395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  68.84525809761371
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.895343
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  18.81980505627217
printing an ep nov before normalisation:  26.140295392977993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.164771491094946
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.331]
 [27.033]
 [25.331]
 [25.331]
 [25.331]] [[1.307]
 [1.446]
 [1.307]
 [1.307]
 [1.307]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[108.834]
 [108.834]
 [122.117]
 [108.834]
 [108.834]] [[0.946]
 [0.946]
 [1.166]
 [0.946]
 [0.946]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.91114485895448
printing an ep nov before normalisation:  25.966795810518267
printing an ep nov before normalisation:  83.03738786038302
printing an ep nov before normalisation:  26.652633081289565
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.855]
 [57.396]
 [67.854]
 [67.722]
 [67.369]] [[0.622]
 [0.611]
 [0.846]
 [0.843]
 [0.835]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 1.5955083046500064e-08
0.0 0.0
0.0 3.625718688934489e-08
0.0 0.0
0.0 1.27689930239606e-08
0.0 0.0
0.0 4.742669989373888e-09
0.0 3.625718688934489e-08
0.0 1.4854627508058504e-08
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.97722062818139
printing an ep nov before normalisation:  36.601872000216666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9090524
printing an ep nov before normalisation:  73.69553940734652
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.0006831591599620879
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.968899096375594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.05182659707306
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  12.929456233978271
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9022561
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 28.335132075306074
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.479]
 [42.479]
 [67.417]
 [42.479]
 [42.479]] [[0.516]
 [0.516]
 [1.063]
 [0.516]
 [0.516]]
printing an ep nov before normalisation:  23.746037266115884
printing an ep nov before normalisation:  30.511866977970215
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.904384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  86.65075667005748
actions average: 
K:  2  action  0 :  tensor([    0.9803,     0.0028,     0.0008,     0.0030,     0.0131],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0066,     0.9005,     0.0639,     0.0004,     0.0286],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0051,     0.8465,     0.0585,     0.0898],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0008,     0.0414,     0.7464,     0.2110],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0004,     0.0042,     0.1373,     0.2814,     0.5768],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  128.7480100135149
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.7403732511322
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 88.322783306828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.437621988209116
printing an ep nov before normalisation:  76.7082355647539
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  25.179962949407617
siam score:  -0.89681274
printing an ep nov before normalisation:  33.47474175121422
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.62640573612487
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.80049324035645
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.669]
 [52.776]
 [51.625]
 [51.487]
 [52.224]] [[0.285]
 [0.258]
 [0.247]
 [0.245]
 [0.252]]
printing an ep nov before normalisation:  95.3059917248887
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[78.219]
 [78.219]
 [78.219]
 [78.219]
 [78.219]] [[1.928]
 [1.928]
 [1.928]
 [1.928]
 [1.928]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.996]
 [46.193]
 [65.335]
 [65.373]
 [65.443]] [[1.239]
 [0.593]
 [1.329]
 [1.33 ]
 [1.333]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.369]
 [50.65 ]
 [46.648]
 [31.891]
 [48.144]] [[1.254]
 [1.472]
 [1.268]
 [0.516]
 [1.345]]
printing an ep nov before normalisation:  20.942206733508645
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.459688947136794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.80974216373589
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  17.737250083783753
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9988,     0.0002,     0.0000,     0.0006,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0008,     0.9521,     0.0115,     0.0003,     0.0352],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9691,     0.0101,     0.0206],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0009,     0.0005,     0.0161,     0.8035,     0.1790],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0042, 0.0346, 0.2587, 0.3260, 0.3764], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.041841588390106
printing an ep nov before normalisation:  37.599053752592084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.72527038287128
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.082]
 [18.082]
 [18.082]
 [18.082]
 [18.082]] [[0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]]
printing an ep nov before normalisation:  42.31825913415557
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.655]
 [19.453]
 [16.27 ]
 [28.158]
 [21.715]] [[0.627]
 [0.516]
 [0.431]
 [0.746]
 [0.576]]
printing an ep nov before normalisation:  56.96403779614541
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.92578190664431
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9851,     0.0042,     0.0002,     0.0043,     0.0062],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9994,     0.0001,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0003,     0.9132,     0.0329,     0.0536],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0018,     0.0167,     0.7131,     0.2678],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0001,     0.0080,     0.0983,     0.3154,     0.5782],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.94024278181959
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  47.321519398356585
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.882937345702793
printing an ep nov before normalisation:  39.50744367118968
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.690013756170117
printing an ep nov before normalisation:  21.458787782101382
printing an ep nov before normalisation:  46.985619368456405
printing an ep nov before normalisation:  76.18446545222055
printing an ep nov before normalisation:  73.29362603909352
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.142]
 [60.363]
 [70.472]
 [66.008]
 [62.97 ]] [[0.96 ]
 [0.792]
 [1.085]
 [0.956]
 [0.868]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  99.46701172344022
printing an ep nov before normalisation:  74.36467640087288
line 256 mcts: sample exp_bonus 62.83500226303823
printing an ep nov before normalisation:  34.43480734389091
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[106.831]
 [ 73.474]
 [ 73.474]
 [ 73.474]
 [ 73.474]] [[1.562]
 [0.838]
 [0.838]
 [0.838]
 [0.838]]
printing an ep nov before normalisation:  97.11480713974503
printing an ep nov before normalisation:  33.98756211395816
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.539]
 [15.539]
 [15.539]
 [32.006]
 [38.858]] [[-0.419]
 [-0.419]
 [-0.419]
 [ 0.862]
 [ 1.395]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  67.96814109542596
printing an ep nov before normalisation:  22.781235365540375
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8987358
printing an ep nov before normalisation:  27.911790173640572
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  94.66008938547645
actions average: 
K:  3  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0043,     0.9946,     0.0000,     0.0000,     0.0010],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0028, 0.0210, 0.8833, 0.0266, 0.0663], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0007,     0.0003,     0.0277,     0.7016,     0.2696],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0493, 0.0392, 0.0754, 0.2841, 0.5521], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.23876525866331
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  109.59436771108285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.669832775197456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.93224050560833
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.20329715196956
printing an ep nov before normalisation:  48.23777840994646
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.854029060115934
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 38.124]
 [ 63.085]
 [102.523]
 [ 63.085]
 [ 63.085]] [[0.206]
 [0.456]
 [0.851]
 [0.456]
 [0.456]]
printing an ep nov before normalisation:  0.007011822260594158
printing an ep nov before normalisation:  134.00906378513534
printing an ep nov before normalisation:  78.94612273986343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.20144557952881
siam score:  -0.8885338
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.52386569976807
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.863]
 [31.564]
 [32.338]
 [32.295]
 [32.415]] [[1.699]
 [1.67 ]
 [1.746]
 [1.742]
 [1.754]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8868228
printing an ep nov before normalisation:  95.8627627222229
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.916950525669563
siam score:  -0.8886626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9994,     0.0001,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9991,     0.0003,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0171,     0.8859,     0.0342,     0.0625],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0004,     0.0605,     0.7416,     0.1972],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0730, 0.0032, 0.0890, 0.2601, 0.5747], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 3.687628037596369e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.17395901282771
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.346]
 [19.43 ]
 [18.84 ]
 [20.692]
 [20.86 ]] [[1.209]
 [0.653]
 [0.612]
 [0.742]
 [0.754]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  64.00404114382766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.894762383683297
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.597]
 [22.597]
 [26.436]
 [22.597]
 [22.597]] [[1.183]
 [1.183]
 [1.384]
 [1.183]
 [1.183]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.152]
 [33.152]
 [33.152]
 [33.414]
 [35.224]] [[1.279]
 [1.279]
 [1.279]
 [1.299]
 [1.432]]
printing an ep nov before normalisation:  43.66367231916027
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.67793776570197
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.225507592866855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.006057147989793066
printing an ep nov before normalisation:  86.71976879814507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  24.343727035034266
printing an ep nov before normalisation:  23.563212073940793
printing an ep nov before normalisation:  16.907944679260254
printing an ep nov before normalisation:  21.03683749917989
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.679]
 [24.823]
 [26.743]
 [22.223]
 [23.956]] [[1.057]
 [1.173]
 [1.367]
 [0.909]
 [1.085]]
printing an ep nov before normalisation:  32.7452663246617
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.966]
 [42.259]
 [38.795]
 [42.427]
 [46.815]] [[1.803]
 [1.623]
 [1.49 ]
 [1.629]
 [1.798]]
UNIT TEST: sample policy line 217 mcts : [0.061 0.02  0.02  0.878 0.02 ]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.20698881149292
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.095249062914
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.197]
 [25.722]
 [19.246]
 [27.894]
 [26.188]] [[0.945]
 [1.104]
 [0.696]
 [1.241]
 [1.134]]
actions average: 
K:  2  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0006,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9994,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0005,     0.0022,     0.9076,     0.0240,     0.0656],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0003,     0.0150,     0.7795,     0.2049],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0075, 0.0039, 0.1474, 0.2703, 0.5709], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.39916594122878
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 6.9651694795806025e-09
0.0 1.525525864290763e-08
0.0 6.424905593590632e-09
0.0 2.8351399163512007e-09
0.0 1.0599578888808292e-07
0.0 6.318970141492188e-09
0.0 6.9651694795806025e-09
0.0 9.600616571317105e-09
0.0 6.2639612033150784e-09
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.181]
 [63.181]
 [76.31 ]
 [64.655]
 [69.556]] [[1.042]
 [1.042]
 [1.259]
 [1.066]
 [1.147]]
printing an ep nov before normalisation:  32.83390146853552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.29600717397937
printing an ep nov before normalisation:  21.761874205004688
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.17 ]
 [76.223]
 [75.17 ]
 [75.17 ]
 [71.397]] [[1.737]
 [1.776]
 [1.737]
 [1.737]
 [1.597]]
siam score:  -0.8955834
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  52.9514405537985
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.964133632702854
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  32.92243235055975
printing an ep nov before normalisation:  36.14907070963782
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.626]
 [21.626]
 [21.626]
 [21.626]
 [21.626]] [[1.18]
 [1.18]
 [1.18]
 [1.18]
 [1.18]]
printing an ep nov before normalisation:  38.730104750650305
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.42 ]
 [21.413]
 [21.42 ]
 [21.42 ]
 [21.42 ]] [[1.371]
 [1.37 ]
 [1.371]
 [1.371]
 [1.371]]
siam score:  -0.89686906
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.058]
 [54.437]
 [53.822]
 [54.55 ]
 [55.685]] [[1.134]
 [1.44 ]
 [1.405]
 [1.447]
 [1.511]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.52046565959114
printing an ep nov before normalisation:  16.351506590421774
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  46.621868843307595
siam score:  -0.89734876
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[104.777]
 [104.777]
 [104.777]
 [104.777]
 [104.777]] [[0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]]
actions average: 
K:  2  action  0 :  tensor([    0.9871,     0.0001,     0.0000,     0.0064,     0.0064],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0007,     0.9780,     0.0036,     0.0005,     0.0173],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0373,     0.9189,     0.0125,     0.0311],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0002,     0.0389,     0.7465,     0.2141],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0524, 0.1715, 0.2977, 0.4772], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.11377206920907
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.358886120447064
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.433]
 [33.433]
 [33.433]
 [33.433]
 [33.433]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.053]
 [67.434]
 [62.383]
 [67.682]
 [65.281]] [[1.649]
 [1.577]
 [1.352]
 [1.588]
 [1.481]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.7819399733155
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.531]
 [23.961]
 [19.69 ]
 [20.531]
 [20.531]] [[1.363]
 [1.796]
 [1.256]
 [1.363]
 [1.363]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.983630401965083
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  67.04447113660561
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.90412766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  86.29873162573635
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.333]
 [63.566]
 [58.333]
 [58.333]
 [58.333]] [[0.762]
 [0.854]
 [0.762]
 [0.762]
 [0.762]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.201]
 [14.182]
 [17.18 ]
 [17.789]
 [15.173]] [[0.371]
 [0.416]
 [0.555]
 [0.583]
 [0.462]]
printing an ep nov before normalisation:  31.038632958220607
printing an ep nov before normalisation:  39.90901644973214
siam score:  -0.9051576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.379]
 [30.379]
 [30.379]
 [30.379]
 [30.379]] [[1.138]
 [1.138]
 [1.138]
 [1.138]
 [1.138]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.255843863269355
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.664]
 [45.418]
 [53.007]
 [56.88 ]
 [49.162]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  41.565911493709564
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  0  action  0 :  tensor([    0.9968,     0.0000,     0.0000,     0.0008,     0.0024],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9995,     0.0000,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0025,     0.9316,     0.0304,     0.0354],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0005,     0.0504,     0.7216,     0.2274],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0022, 0.0461, 0.1517, 0.2825, 0.5173], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  19.43409209672254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 27.21591421160813
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.57583012708389
printing an ep nov before normalisation:  26.850901911500273
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.853]
 [20.808]
 [24.721]
 [17.756]
 [20.9  ]] [[1.255]
 [0.811]
 [0.968]
 [0.688]
 [0.815]]
printing an ep nov before normalisation:  90.47547600124759
UNIT TEST: sample policy line 217 mcts : [0.469 0.082 0.041 0.102 0.306]
printing an ep nov before normalisation:  24.69762086868286
printing an ep nov before normalisation:  30.598247051239014
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.9682034811468
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9647,     0.0000,     0.0000,     0.0114,     0.0240],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0046,     0.9864,     0.0004,     0.0052,     0.0034],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0007,     0.0010,     0.9426,     0.0198,     0.0358],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0026,     0.0006,     0.0230,     0.7575,     0.2163],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0007, 0.0511, 0.0609, 0.2652, 0.6222], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  62.871202681499675
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.262]
 [34.038]
 [34.866]
 [36.012]
 [36.359]] [[0.817]
 [0.954]
 [0.995]
 [1.051]
 [1.068]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  66.15668350684435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8944752
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.787]
 [28.801]
 [32.252]
 [20.557]
 [24.61 ]] [[1.016]
 [1.158]
 [1.401]
 [0.577]
 [0.862]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 29.11020919578848
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.034]
 [62.034]
 [62.034]
 [62.034]
 [54.199]] [[1.275]
 [1.275]
 [1.275]
 [1.275]
 [1.   ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.45 ]
 [27.957]
 [26.202]
 [25.178]
 [26.857]] [[0.761]
 [0.513]
 [0.455]
 [0.421]
 [0.477]]
printing an ep nov before normalisation:  24.78203899277463
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  47.19548959981993
printing an ep nov before normalisation:  91.84749667156031
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.9413569352955
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.43203448272777223
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.03561508024611
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.44508616355992
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.860528469085693
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  12.601230323285527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.628]
 [70.628]
 [70.628]
 [70.628]
 [70.628]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9985,     0.0000,     0.0000,     0.0006,     0.0009],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0326, 0.9196, 0.0171, 0.0009, 0.0297], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0003,     0.9258,     0.0246,     0.0493],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0015,     0.0003,     0.0497,     0.7366,     0.2119],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0188, 0.0011, 0.0828, 0.3161, 0.5812], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.014]
 [56.941]
 [56.941]
 [59.214]
 [56.941]] [[0.916]
 [1.192]
 [1.192]
 [1.283]
 [1.192]]
printing an ep nov before normalisation:  80.0859999832752
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.789]
 [69.285]
 [60.133]
 [60.133]
 [60.133]] [[1.216]
 [1.204]
 [0.989]
 [0.989]
 [0.989]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.155]
 [56.155]
 [56.155]
 [56.155]
 [56.155]] [[1.325]
 [1.325]
 [1.325]
 [1.325]
 [1.325]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.191324427630406
printing an ep nov before normalisation:  29.658731878234917
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.44372963017714
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  13.861706925579973
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.231]
 [46.231]
 [65.527]
 [21.806]
 [46.231]] [[0.453]
 [0.453]
 [0.681]
 [0.165]
 [0.453]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.8123243742303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  79.72814590150068
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.806583756932074
printing an ep nov before normalisation:  28.241952534685367
printing an ep nov before normalisation:  27.71968676792227
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.9053142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.233601375118
printing an ep nov before normalisation:  24.638767749048938
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.023]
 [33.759]
 [29.384]
 [27.749]
 [30.047]] [[0.71 ]
 [0.667]
 [0.52 ]
 [0.465]
 [0.542]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.713]
 [72.713]
 [65.14 ]
 [75.645]
 [76.144]] [[0.942]
 [0.942]
 [0.823]
 [0.988]
 [0.995]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.272674344133588
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.552144142343238
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 34.598]
 [ 34.598]
 [135.678]
 [100.929]
 [ 73.236]] [[-0.   ]
 [-0.   ]
 [ 0.315]
 [ 0.207]
 [ 0.12 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.528939962387085
UNIT TEST: sample policy line 217 mcts : [0.327 0.265 0.245 0.061 0.102]
siam score:  -0.89896584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 24.06437694363537
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.260192825250414
printing an ep nov before normalisation:  23.936089737629494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.45507036327109
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.728]
 [58.728]
 [58.728]
 [61.347]
 [58.728]] [[1.859]
 [1.859]
 [1.859]
 [2.   ]
 [1.859]]
siam score:  -0.8976941
printing an ep nov before normalisation:  16.005095544748993
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.34 ]
 [46.34 ]
 [66.492]
 [64.165]
 [46.34 ]] [[0.424]
 [0.424]
 [1.375]
 [1.266]
 [0.424]]
printing an ep nov before normalisation:  17.353496551513672
printing an ep nov before normalisation:  19.61896097270352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.55810445242011
siam score:  -0.8978792
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.42001427595095
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.079]
 [48.343]
 [37.519]
 [36.337]
 [45.845]] [[0.18 ]
 [0.143]
 [0.1  ]
 [0.096]
 [0.133]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.833287123280737
printing an ep nov before normalisation:  23.545076721000374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.167]
 [72.183]
 [59.717]
 [59.717]
 [59.717]] [[0.387]
 [1.229]
 [0.879]
 [0.879]
 [0.879]]
line 256 mcts: sample exp_bonus 33.96447737008236
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.74 ]
 [20.017]
 [13.627]
 [12.72 ]
 [17.533]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.929155915060683
printing an ep nov before normalisation:  12.252244155363124
printing an ep nov before normalisation:  38.21162150506146
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.26 ]
 [27.443]
 [25.51 ]
 [26.416]
 [25.405]] [[1.199]
 [1.137]
 [0.989]
 [1.059]
 [0.981]]
printing an ep nov before normalisation:  35.84478443441756
siam score:  -0.90483165
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.75082760472356
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.67616179258357
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.566]
 [74.697]
 [60.566]
 [60.566]
 [60.566]] [[1.108]
 [1.581]
 [1.108]
 [1.108]
 [1.108]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[111.507]
 [111.507]
 [ 99.788]
 [109.793]
 [110.765]] [[1.667]
 [1.667]
 [1.4  ]
 [1.628]
 [1.65 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.01 ]
 [20.191]
 [23.937]
 [24.53 ]
 [24.53 ]] [[1.343]
 [0.724]
 [1.064]
 [1.118]
 [1.118]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.555675021067785
printing an ep nov before normalisation:  0.0005992853496244217
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.110150057362226
printing an ep nov before normalisation:  93.6158693081089
UNIT TEST: sample policy line 217 mcts : [0.143 0.204 0.306 0.122 0.224]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.908]
 [31.177]
 [29.554]
 [30.794]
 [29.909]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8938566
printing an ep nov before normalisation:  0.00010721445050876355
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.0005492994142741736
printing an ep nov before normalisation:  22.921589089670604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  88.05300068139894
printing an ep nov before normalisation:  64.8261833190918
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0
Starting evaluation
printing an ep nov before normalisation:  70.61130913560523
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.860700118853785
printing an ep nov before normalisation:  52.76229173470325
printing an ep nov before normalisation:  50.337752410291145
printing an ep nov before normalisation:  37.84019606275881
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.54 ]
 [33.329]
 [82.29 ]
 [33.329]
 [33.329]] [[ 0.355]
 [-0.051]
 [ 0.42 ]
 [-0.051]
 [-0.051]]
printing an ep nov before normalisation:  94.78112599177045
printing an ep nov before normalisation:  22.764882633443975
printing an ep nov before normalisation:  42.365217208862305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.88297654806125
printing an ep nov before normalisation:  79.00122363897212
actions average: 
K:  2  action  0 :  tensor([    0.9986,     0.0001,     0.0000,     0.0004,     0.0009],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0007,     0.9569,     0.0228,     0.0007,     0.0189],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0008,     0.0085,     0.8856,     0.0285,     0.0766],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0016, 0.0015, 0.0208, 0.8409, 0.1351], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0282, 0.0264, 0.0479, 0.3027, 0.5948], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  31.00957715811776
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.674791406576695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.093110408704344
siam score:  -0.8912828
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.779]
 [37.488]
 [37.673]
 [37.488]
 [37.488]] [[1.673]
 [1.984]
 [2.   ]
 [1.984]
 [1.984]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.538]
 [31.763]
 [39.246]
 [39.242]
 [40.196]] [[0.622]
 [0.526]
 [0.784]
 [0.784]
 [0.816]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.331730907874935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  82.0921488148159
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -4.125670364209594e-12
0.0 -7.974566196378119e-12
0.0 -5.682527104725431e-12
0.0 -7.568053597811057e-12
0.0 0.0
0.0 -2.542866010308007e-12
0.0 -3.252100747857728e-12
0.0 -5.55278904182428e-12
0.0 -8.182147089367522e-12
0.0 -4.566779771830729e-12
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  83.63432789668525
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.793103896786015
printing an ep nov before normalisation:  37.46003123929358
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.46504831647576
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 16.856832954799962
printing an ep nov before normalisation:  27.375035285949707
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.896]
 [17.896]
 [25.433]
 [29.618]
 [17.896]] [[0.054]
 [0.054]
 [0.17 ]
 [0.234]
 [0.054]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.8381481882731
printing an ep nov before normalisation:  70.53570934530755
printing an ep nov before normalisation:  32.73066409272766
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.559]
 [30.073]
 [20.421]
 [29.087]
 [30.206]] [[1.255]
 [1.427]
 [0.764]
 [1.36 ]
 [1.436]]
printing an ep nov before normalisation:  21.40665054321289
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  75.94858169555664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.391567945666015
printing an ep nov before normalisation:  50.94120603330421
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8962439
printing an ep nov before normalisation:  96.5771635826308
printing an ep nov before normalisation:  44.211731875052635
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.435]
 [39.435]
 [39.435]
 [44.729]
 [39.435]] [[1.448]
 [1.448]
 [1.448]
 [1.642]
 [1.448]]
printing an ep nov before normalisation:  42.742127989551314
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.097]
 [40.418]
 [36.565]
 [37.154]
 [34.308]] [[0.676]
 [1.268]
 [1.023]
 [1.061]
 [0.88 ]]
actions average: 
K:  3  action  0 :  tensor([    0.9763,     0.0003,     0.0007,     0.0061,     0.0166],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0004,     0.9967,     0.0009,     0.0004,     0.0016],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0003,     0.0020,     0.8993,     0.0363,     0.0621],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0258,     0.0004,     0.0411,     0.8182,     0.1145],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0013, 0.0437, 0.0726, 0.2264, 0.6561], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.229]
 [43.229]
 [36.083]
 [43.229]
 [43.229]] [[2.   ]
 [2.   ]
 [1.669]
 [2.   ]
 [2.   ]]
printing an ep nov before normalisation:  54.78112516037592
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.89217496
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8941964
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.66453565122329
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.9041961701648
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.28816829610372
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.04873881982033
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.825]
 [46.202]
 [46.202]
 [46.202]
 [46.202]] [[1.599]
 [0.821]
 [0.821]
 [0.821]
 [0.821]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.78955279655807
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.3537244074257
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.649]
 [21.92 ]
 [22.649]
 [18.353]
 [22.001]] [[1.261]
 [1.195]
 [1.261]
 [0.876]
 [1.203]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.542]
 [18.542]
 [18.542]
 [18.542]
 [18.542]] [[1.753]
 [1.753]
 [1.753]
 [1.753]
 [1.753]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.004847298150707502
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.   ]
 [0.001]
 [0.   ]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.968]
 [33.968]
 [33.968]
 [33.968]
 [33.968]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  100.65428142668469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.561860543416806
printing an ep nov before normalisation:  22.603639416670507
UNIT TEST: sample policy line 217 mcts : [0.306 0.    0.    0.694 0.   ]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.922]
 [23.309]
 [20.922]
 [19.56 ]
 [20.922]] [[1.192]
 [1.452]
 [1.192]
 [1.044]
 [1.192]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.37340918887486
siam score:  -0.88983977
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.532743034249606
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.321]
 [24.174]
 [24.955]
 [16.713]
 [16.762]] [[0.26 ]
 [0.154]
 [0.164]
 [0.057]
 [0.058]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.795575717447505
siam score:  -0.8882857
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.497]
 [25.583]
 [28.047]
 [26.733]
 [26.712]] [[0.504]
 [0.508]
 [0.614]
 [0.558]
 [0.557]]
printing an ep nov before normalisation:  20.764501061674007
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.340255083573265
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.002]
 [0.001]
 [0.001]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.915173360375505
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.881]
 [55.662]
 [48.138]
 [60.175]
 [55.698]] [[1.248]
 [1.136]
 [0.876]
 [1.293]
 [1.138]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.89422256
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.087974428965303
printing an ep nov before normalisation:  18.422958319792127
printing an ep nov before normalisation:  31.155150324728123
siam score:  -0.89672244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.536345687770748
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.82 ]
 [19.332]
 [22.876]
 [22.062]
 [19.686]] [[0.384]
 [0.366]
 [0.493]
 [0.464]
 [0.379]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 13.71484704596821
printing an ep nov before normalisation:  55.04768944599027
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  13.635546932708108
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.195493698120117
actions average: 
K:  4  action  0 :  tensor([0.9665, 0.0107, 0.0032, 0.0018, 0.0177], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0010,     0.9982,     0.0001,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0009,     0.0097,     0.9381,     0.0244,     0.0269],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0019,     0.1009,     0.6458,     0.2510],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0055, 0.0249, 0.1401, 0.2660, 0.5636], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.425413856590563
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.164777590669075
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  47.26850885181473
printing an ep nov before normalisation:  100.21248548572602
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.259]
 [59.572]
 [59.572]
 [59.572]
 [59.572]] [[0.75 ]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
printing an ep nov before normalisation:  86.8745229986124
printing an ep nov before normalisation:  22.906936110378794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.471145129267185
printing an ep nov before normalisation:  17.822925168209267
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.45 ]
 [26.45 ]
 [26.45 ]
 [35.947]
 [26.45 ]] [[0.395]
 [0.395]
 [0.395]
 [0.726]
 [0.395]]
printing an ep nov before normalisation:  28.630778475450175
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.53591932913808
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.417313967014174
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.89425415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.833334040190667
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.03989659835204
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.71594973530022
printing an ep nov before normalisation:  52.25978009213639
printing an ep nov before normalisation:  30.506251186836806
actions average: 
K:  2  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0205,     0.9365,     0.0003,     0.0011,     0.0416],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0030,     0.8925,     0.0243,     0.0802],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0012,     0.0005,     0.0020,     0.7726,     0.2238],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0874, 0.0524, 0.0989, 0.1937, 0.5676], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  26.109155247311072
printing an ep nov before normalisation:  22.118139673413683
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  98.29869561821556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.007427356483731273
printing an ep nov before normalisation:  39.08059797626659
printing an ep nov before normalisation:  0.0021808920519106323
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.9312641072556
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.95821001615921
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.30781078338623
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.4379820687123
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 44.72686558055669
printing an ep nov before normalisation:  34.64553340972582
printing an ep nov before normalisation:  56.03247405366984
printing an ep nov before normalisation:  22.081333963776114
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.29]
 [24.29]
 [24.29]
 [24.29]
 [24.29]] [[1.867]
 [1.867]
 [1.867]
 [1.867]
 [1.867]]
printing an ep nov before normalisation:  64.6899911741059
printing an ep nov before normalisation:  41.6710308683895
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.529]
 [13.22 ]
 [13.12 ]
 [12.964]
 [13.57 ]] [[1.235]
 [1.303]
 [1.293]
 [1.278]
 [1.337]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.17014061873678
using explorer policy with actor:  1
siam score:  -0.8927514
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.746]
 [18.027]
 [14.746]
 [12.86 ]
 [17.372]] [[0.703]
 [0.86 ]
 [0.703]
 [0.613]
 [0.829]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.133]
 [14.668]
 [12.087]
 [15.023]
 [17.554]] [[0.425]
 [0.461]
 [0.287]
 [0.485]
 [0.655]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  95.4009903801812
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.88292967239687
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.527893198268423
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.35137371425729
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [35.955]
 [35.955]
 [35.955]
 [35.955]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  21.130294464827454
printing an ep nov before normalisation:  18.813425140047034
printing an ep nov before normalisation:  16.632917225495337
printing an ep nov before normalisation:  13.873984232718156
printing an ep nov before normalisation:  37.51043519265023
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 8.011024107190678e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.213]
 [72.805]
 [41.957]
 [41.874]
 [41.969]] [[0.706]
 [1.419]
 [0.592]
 [0.589]
 [0.592]]
printing an ep nov before normalisation:  48.62438041149305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9973,     0.0006,     0.0000,     0.0001,     0.0020],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0004,     0.9529,     0.0130,     0.0002,     0.0335],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9526,     0.0132,     0.0340],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0009,     0.0249,     0.7733,     0.2008],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0007, 0.0164, 0.1202, 0.2881, 0.5745], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.095]
 [26.752]
 [27.49 ]
 [23.066]
 [25.385]] [[0.727]
 [0.557]
 [0.586]
 [0.412]
 [0.503]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.85578606999597
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.89699936
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.607]
 [20.607]
 [20.607]
 [31.296]
 [20.607]] [[0.707]
 [0.707]
 [0.707]
 [1.511]
 [0.707]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
UNIT TEST: sample policy line 217 mcts : [0.755 0.02  0.041 0.143 0.041]
printing an ep nov before normalisation:  37.65668504627507
printing an ep nov before normalisation:  104.53079520609559
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.506166602697604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.195341136264414
printing an ep nov before normalisation:  22.56911896872539
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  38.898173082291265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.669668772862636
printing an ep nov before normalisation:  46.0321840702379
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.19435185224502
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.092]
 [27.418]
 [17.74 ]
 [16.486]
 [15.495]] [[0.464]
 [1.1  ]
 [0.557]
 [0.486]
 [0.431]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  19.742084561145475
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.561]
 [39.933]
 [50.68 ]
 [45.543]
 [45.959]] [[0.739]
 [0.67 ]
 [1.121]
 [0.905]
 [0.923]]
actions average: 
K:  4  action  0 :  tensor([    0.9735,     0.0048,     0.0006,     0.0017,     0.0193],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.8622,     0.1082,     0.0003,     0.0292],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9277,     0.0335,     0.0387],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0017,     0.0021,     0.8539,     0.1420],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0005,     0.0834,     0.1697,     0.1537,     0.5927],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.565]
 [33.003]
 [33.202]
 [31.45 ]
 [32.565]] [[1.49 ]
 [1.521]
 [1.534]
 [1.413]
 [1.49 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.204]
 [44.204]
 [66.63 ]
 [44.204]
 [44.204]] [[0.222]
 [0.222]
 [0.437]
 [0.222]
 [0.222]]
printing an ep nov before normalisation:  52.31994112702963
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.725]
 [44.953]
 [40.99 ]
 [50.512]
 [42.111]] [[0.28 ]
 [0.152]
 [0.118]
 [0.201]
 [0.128]]
printing an ep nov before normalisation:  0.0007563528379250783
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.86609932994195
siam score:  -0.8947851
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.456]
 [52.384]
 [52.384]
 [52.384]
 [52.384]] [[0.979]
 [0.802]
 [0.802]
 [0.802]
 [0.802]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88974214
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.201]
 [23.679]
 [25.51 ]
 [25.384]
 [25.528]] [[1.466]
 [1.291]
 [1.501]
 [1.487]
 [1.503]]
printing an ep nov before normalisation:  72.05366625758599
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.28058147686826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.0001936613625730388
siam score:  -0.8781795
line 256 mcts: sample exp_bonus 23.127777610804916
siam score:  -0.8780684
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8795894
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9672,     0.0036,     0.0001,     0.0035,     0.0255],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9964,     0.0010,     0.0007,     0.0018],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9278,     0.0274,     0.0447],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0002,     0.0207,     0.7261,     0.2528],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0005,     0.0300,     0.1792,     0.2611,     0.5292],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  95.12945135032221
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.653]
 [36.653]
 [36.653]
 [36.795]
 [36.653]] [[1.875]
 [1.875]
 [1.875]
 [1.887]
 [1.875]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  16.21461480448349
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.73676918048382
siam score:  -0.8892334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.79504347662218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  22.961115837097168
printing an ep nov before normalisation:  43.99308556613642
printing an ep nov before normalisation:  71.42309634045922
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.0105520848106
printing an ep nov before normalisation:  104.92473244751044
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.263]
 [53.576]
 [53.576]
 [53.576]
 [53.576]] [[1.1  ]
 [1.066]
 [1.066]
 [1.066]
 [1.066]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  66.6813849735027
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8896312
actions average: 
K:  2  action  0 :  tensor([    0.9980,     0.0002,     0.0000,     0.0006,     0.0012],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9937,     0.0010,     0.0000,     0.0052],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0091,     0.9121,     0.0356,     0.0431],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0050,     0.0134,     0.8312,     0.1502],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0333, 0.1063, 0.2713, 0.5878], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9897,     0.0003,     0.0074,     0.0001,     0.0025],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0007,     0.9855,     0.0001,     0.0002,     0.0135],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0006,     0.9387,     0.0261,     0.0346],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0048,     0.0429,     0.8016,     0.1505],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0005,     0.0090,     0.0898,     0.3658,     0.5349],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.687]
 [33.232]
 [33.059]
 [26.701]
 [31.304]] [[1.205]
 [1.349]
 [1.339]
 [0.981]
 [1.24 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.240253419396208
printing an ep nov before normalisation:  85.4495644592322
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.8958043392549
printing an ep nov before normalisation:  31.098418888502348
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.374444072354176
siam score:  -0.8886567
actions average: 
K:  4  action  0 :  tensor([    0.9475,     0.0326,     0.0002,     0.0026,     0.0171],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0004,     0.9506,     0.0009,     0.0015,     0.0466],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0065,     0.8889,     0.0372,     0.0673],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0012,     0.0417,     0.7909,     0.1660],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0034, 0.0916, 0.0943, 0.2124, 0.5983], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[127.392]
 [127.392]
 [126.354]
 [125.979]
 [125.971]] [[0.661]
 [0.661]
 [0.654]
 [0.651]
 [0.651]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9956,     0.0000,     0.0000,     0.0002,     0.0042],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9934,     0.0007,     0.0000,     0.0055],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9764,     0.0117,     0.0119],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0006,     0.0309,     0.6758,     0.2923],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0455, 0.0833, 0.3545, 0.5157], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.942]
 [24.942]
 [26.868]
 [24.942]
 [24.942]] [[0.795]
 [0.795]
 [0.912]
 [0.795]
 [0.795]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.0003037420057694362
siam score:  -0.88758004
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.45 ]
 [44.263]
 [35.231]
 [33.45 ]
 [33.45 ]] [[0.757]
 [1.184]
 [0.827]
 [0.757]
 [0.757]]
printing an ep nov before normalisation:  18.696727791693114
printing an ep nov before normalisation:  17.45461985506272
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.706480915739167
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.794901371002197
printing an ep nov before normalisation:  30.82759675280844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.479]
 [33.814]
 [29.716]
 [39.909]
 [41.252]] [[1.779]
 [1.406]
 [1.079]
 [1.893]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  47.28897578496158
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.77800203565174
printing an ep nov before normalisation:  60.34777029434012
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 31.597826382083856
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88756543
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.782747408651886
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.37524717496957
printing an ep nov before normalisation:  27.745725030822957
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.317]
 [25.317]
 [25.317]
 [27.964]
 [25.317]] [[1.639]
 [1.639]
 [1.639]
 [2.   ]
 [1.639]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  37.919119313106485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.109341875348754
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.67303690059522
using explorer policy with actor:  1
printing an ep nov before normalisation:  90.41467659456399
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.392422017032874
printing an ep nov before normalisation:  27.810269185610824
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.22 ]
 [33.565]
 [32.992]
 [28.728]
 [28.121]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.02338045532768
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.40245383126395
printing an ep nov before normalisation:  17.838458308816985
printing an ep nov before normalisation:  17.573046534444043
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.831]
 [18.599]
 [19.34 ]
 [27.966]
 [19.502]] [[0.363]
 [0.264]
 [0.287]
 [0.549]
 [0.292]]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.398012969130804
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.478012561798096
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.979423072020534
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.834]
 [43.298]
 [44.097]
 [41.082]
 [43.377]] [[0.531]
 [0.297]
 [0.307]
 [0.269]
 [0.298]]
printing an ep nov before normalisation:  24.120005064318367
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  140.77578353642625
siam score:  -0.8862669
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.425]
 [42.352]
 [29.394]
 [27.783]
 [29.184]] [[0.789]
 [0.558]
 [0.31 ]
 [0.279]
 [0.306]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  58.16339574513607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.961]
 [16.906]
 [18.502]
 [18.108]
 [18.082]] [[0.97 ]
 [0.863]
 [1.024]
 [0.984]
 [0.982]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.454]
 [47.454]
 [47.454]
 [47.454]
 [47.454]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
printing an ep nov before normalisation:  63.39766594087489
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.109339103646377
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.29234628160766
printing an ep nov before normalisation:  73.38048668429337
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.115838450611957
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.7030051144271
printing an ep nov before normalisation:  101.39079738047073
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.222925662994385
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.164395586085483
printing an ep nov before normalisation:  80.27495113885912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9974,     0.0001,     0.0000,     0.0002,     0.0023],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0004,     0.9637,     0.0105,     0.0002,     0.0252],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0008,     0.0009,     0.9437,     0.0218,     0.0328],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0096, 0.0069, 0.0307, 0.6695, 0.2834], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0025, 0.0054, 0.1229, 0.2331, 0.6361], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  77.73820842778507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.245 0.327 0.102 0.204 0.122]
printing an ep nov before normalisation:  65.40287152536018
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9877,     0.0016,     0.0000,     0.0036,     0.0070],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9972,     0.0003,     0.0002,     0.0023],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0009,     0.9130,     0.0288,     0.0572],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0017,     0.0214,     0.8409,     0.1357],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0006,     0.0052,     0.0724,     0.2656,     0.6563],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  26.665430269604236
printing an ep nov before normalisation:  20.82678673425237
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.57234661433898
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.921]
 [21.239]
 [29.046]
 [21.561]
 [27.   ]] [[1.485]
 [1.089]
 [1.491]
 [1.106]
 [1.386]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.710218312520965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.24639799076362
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.027428322811886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.108]
 [66.429]
 [58.85 ]
 [58.85 ]
 [58.85 ]] [[1.407]
 [1.348]
 [1.082]
 [1.082]
 [1.082]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.264]
 [27.706]
 [20.721]
 [26.483]
 [26.507]] [[1.382]
 [1.535]
 [1.097]
 [1.458]
 [1.46 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.259840661176575
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.592889724601743
siam score:  -0.88726455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.03941816380809
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.215]
 [15.215]
 [17.826]
 [15.48 ]
 [15.215]] [[0.314]
 [0.314]
 [0.417]
 [0.324]
 [0.314]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.02519850930994
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.603]
 [34.318]
 [24.917]
 [30.438]
 [27.937]] [[0.421]
 [0.437]
 [0.222]
 [0.348]
 [0.291]]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  79.17319297790527
printing an ep nov before normalisation:  78.9344596862793
siam score:  -0.885681
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9567,     0.0128,     0.0001,     0.0064,     0.0239],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9710,     0.0046,     0.0005,     0.0236],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0105,     0.8766,     0.0486,     0.0642],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0004,     0.0956,     0.7018,     0.2022],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0019, 0.0055, 0.1153, 0.2997, 0.5775], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.91476877979431
actions average: 
K:  4  action  0 :  tensor([    0.9545,     0.0126,     0.0001,     0.0142,     0.0185],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9916,     0.0051,     0.0003,     0.0031],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0003,     0.0220,     0.9036,     0.0153,     0.0588],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0022,     0.0338,     0.7806,     0.1829],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0001,     0.0047,     0.2346,     0.2296,     0.5310],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.23 ]
 [34.932]
 [27.686]
 [27.686]
 [28.417]] [[0.904]
 [1.306]
 [0.871]
 [0.871]
 [0.915]]
siam score:  -0.8899354
printing an ep nov before normalisation:  59.52031342004076
using explorer policy with actor:  1
printing an ep nov before normalisation:  2.7224928089708555e-05
printing an ep nov before normalisation:  7.9229705305653235
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0001,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0014,     0.9700,     0.0008,     0.0003,     0.0275],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0053,     0.9499,     0.0164,     0.0282],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0008,     0.0003,     0.0189,     0.8513,     0.1286],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0081, 0.0308, 0.0016, 0.2158, 0.7437], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  20.432814878870797
printing an ep nov before normalisation:  38.748820243001454
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.892079
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.07244871068431
siam score:  -0.88971406
printing an ep nov before normalisation:  32.934543355403584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.605307597951658
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88949907
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  36.11940383911133
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  11.159136147127883
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  0.00031566406946126335
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.014]
 [0.016]
 [0.015]
 [0.013]
 [0.014]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.252]
 [28.252]
 [28.252]
 [28.252]
 [28.252]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.907607669276413
siam score:  -0.88865143
printing an ep nov before normalisation:  17.57966637611389
printing an ep nov before normalisation:  16.135982673945282
printing an ep nov before normalisation:  46.81570823581327
using explorer policy with actor:  1
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.750542696628145
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 65.872]
 [113.638]
 [134.24 ]
 [131.381]
 [122.71 ]] [[0.118]
 [0.404]
 [0.528]
 [0.511]
 [0.459]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 38.02 ]
 [ 38.02 ]
 [105.589]
 [ 45.926]
 [ 38.02 ]] [[0.007]
 [0.007]
 [0.534]
 [0.069]
 [0.007]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  137.6034142544858
line 256 mcts: sample exp_bonus 29.057885121985244
printing an ep nov before normalisation:  28.42137685418578
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.648]
 [65.811]
 [78.853]
 [78.956]
 [65.811]] [[0.841]
 [0.538]
 [0.737]
 [0.739]
 [0.538]]
siam score:  -0.88907456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.357]
 [20.651]
 [15.556]
 [16.69 ]
 [20.862]] [[0.828]
 [1.017]
 [0.596]
 [0.69 ]
 [1.035]]
actions average: 
K:  1  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9987,     0.0005,     0.0003,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0008,     0.8814,     0.0508,     0.0670],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0004,     0.0157,     0.6909,     0.2924],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0005,     0.0795,     0.1826,     0.1709,     0.5665],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.831357316062416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.893948293753304
printing an ep nov before normalisation:  23.288497619066266
printing an ep nov before normalisation:  32.06049311007903
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.88374610334475
printing an ep nov before normalisation:  47.363525996821586
printing an ep nov before normalisation:  16.32251912469834
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  105.35983408876139
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.379]
 [26.379]
 [26.379]
 [26.379]
 [26.379]] [[1.491]
 [1.491]
 [1.491]
 [1.491]
 [1.491]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.11504238435595
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.88850975434416
line 256 mcts: sample exp_bonus 58.59284506927112
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.24240291127026
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.243502616882324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8883299
printing an ep nov before normalisation:  18.64337921142578
printing an ep nov before normalisation:  28.729910326567413
printing an ep nov before normalisation:  31.76825839018367
printing an ep nov before normalisation:  88.41194537964374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.854]
 [87.85 ]
 [87.85 ]
 [87.85 ]
 [87.85 ]] [[1.256]
 [1.275]
 [1.275]
 [1.275]
 [1.275]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.505656266242216
printing an ep nov before normalisation:  0.007852044564060634
printing an ep nov before normalisation:  27.51834542850609
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.61583345916615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.80533083013345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  102.66527974986228
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88966995
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.791636909297274
printing an ep nov before normalisation:  47.0415161249808
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  84.56372160725543
printing an ep nov before normalisation:  54.292238727867286
printing an ep nov before normalisation:  74.67719715247375
UNIT TEST: sample policy line 217 mcts : [0.    0.51  0.204 0.143 0.143]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.60387318534662
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9995,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9572,     0.0221,     0.0205],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0014,     0.0006,     0.0245,     0.8050,     0.1685],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0377, 0.0343, 0.1130, 0.2268, 0.5882], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.502]
 [19.587]
 [19.11 ]
 [20.283]
 [20.199]] [[1.276]
 [0.924]
 [0.881]
 [0.987]
 [0.979]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.87216758728027
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.9599091620431
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.201]
 [32.134]
 [34.201]
 [34.201]
 [34.201]] [[2.   ]
 [1.809]
 [2.   ]
 [2.   ]
 [2.   ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.063]
 [18.869]
 [18.869]
 [29.912]
 [18.869]] [[0.602]
 [0.648]
 [0.648]
 [1.268]
 [0.648]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.494]
 [28.615]
 [25.6  ]
 [27.611]
 [25.6  ]] [[1.268]
 [0.877]
 [0.706]
 [0.82 ]
 [0.706]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.133]
 [21.133]
 [21.133]
 [21.133]
 [21.133]] [[0.944]
 [0.944]
 [0.944]
 [0.944]
 [0.944]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.03547745153331
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.296]
 [26.585]
 [24.731]
 [22.636]
 [20.694]] [[0.614]
 [0.734]
 [0.637]
 [0.527]
 [0.425]]
siam score:  -0.8914119
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  58.51694231760218
printing an ep nov before normalisation:  44.06074584722203
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  101.1338276502756
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.53 ]
 [33.53 ]
 [33.53 ]
 [27.331]
 [33.53 ]] [[1.667]
 [1.667]
 [1.667]
 [1.205]
 [1.667]]
printing an ep nov before normalisation:  0.13275159255499602
printing an ep nov before normalisation:  65.45822769400682
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  24.06103456136114
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.973]
 [27.973]
 [27.973]
 [27.973]
 [27.973]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.82473755995826
printing an ep nov before normalisation:  17.511695652415348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.826]
 [28.148]
 [29.347]
 [29.347]
 [29.347]] [[1.392]
 [0.919]
 [0.972]
 [0.972]
 [0.972]]
printing an ep nov before normalisation:  26.228799854488987
printing an ep nov before normalisation:  38.286352060191504
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.56973934173584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.032812548670194
printing an ep nov before normalisation:  65.14651480203769
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.73298156261444
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.198]
 [53.907]
 [74.529]
 [38.275]
 [38.302]] [[0.237]
 [0.393]
 [0.628]
 [0.215]
 [0.215]]
printing an ep nov before normalisation:  43.670621394166
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.7021269957835
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.710243509176436
printing an ep nov before normalisation:  24.95714723088614
siam score:  -0.8887291
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.92 ]
 [75.92 ]
 [83.994]
 [76.091]
 [75.92 ]] [[0.809]
 [0.809]
 [0.929]
 [0.812]
 [0.809]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.388]
 [33.931]
 [38.681]
 [34.552]
 [37.285]] [[0.868]
 [0.712]
 [0.811]
 [0.725]
 [0.782]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.802]
 [34.19 ]
 [21.345]
 [26.123]
 [24.146]] [[0.308]
 [0.529]
 [0.226]
 [0.339]
 [0.292]]
printing an ep nov before normalisation:  22.9254412651062
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.734]
 [76.061]
 [93.512]
 [93.974]
 [88.502]] [[0.194]
 [0.184]
 [0.291]
 [0.293]
 [0.26 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9948,     0.0006,     0.0001,     0.0014,     0.0030],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9872,     0.0024,     0.0006,     0.0097],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9424,     0.0149,     0.0426],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0037,     0.0288,     0.7236,     0.2437],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0004,     0.0484,     0.1285,     0.1963,     0.6264],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.003]
 [25.047]
 [14.772]
 [21.784]
 [15.815]] [[0.34 ]
 [0.511]
 [0.22 ]
 [0.418]
 [0.249]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.19413818211696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9525,     0.0186,     0.0004,     0.0002,     0.0283],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9977,     0.0001,     0.0005,     0.0013],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9360,     0.0332,     0.0308],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0004,     0.0562,     0.7243,     0.2188],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0022, 0.0375, 0.1049, 0.2937, 0.5616], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.67001758874875
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.9048844767968
printing an ep nov before normalisation:  29.161141390242868
printing an ep nov before normalisation:  36.691907743419804
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.103]
 [38.871]
 [30.103]
 [30.103]
 [30.103]] [[1.331]
 [2.   ]
 [1.331]
 [1.331]
 [1.331]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.89004374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8888988
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.943]
 [52.535]
 [48.943]
 [48.943]
 [48.943]] [[0.493]
 [0.558]
 [0.493]
 [0.493]
 [0.493]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 43.736585844516945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.67557459675234
using explorer policy with actor:  1
printing an ep nov before normalisation:  61.36258145632835
printing an ep nov before normalisation:  102.91227443170098
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.714]
 [75.714]
 [75.714]
 [75.714]
 [75.714]] [[1.074]
 [1.074]
 [1.074]
 [1.074]
 [1.074]]
printing an ep nov before normalisation:  45.486392974853516
printing an ep nov before normalisation:  24.168955565534716
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88134605
printing an ep nov before normalisation:  75.09296570345737
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.65054914781296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.612 0.061 0.286 0.02  0.02 ]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.47509621627953
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9987,     0.0002,     0.0000,     0.0001,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9985,     0.0001,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0117,     0.8958,     0.0455,     0.0468],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0006,     0.0305,     0.7251,     0.2436],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0015, 0.0294, 0.0552, 0.3375, 0.5764], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.40015573118097336
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.271942736565396
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.634]
 [30.634]
 [31.998]
 [30.634]
 [30.634]] [[1.476]
 [1.476]
 [1.588]
 [1.476]
 [1.476]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.184]
 [30.736]
 [35.553]
 [34.662]
 [35.043]] [[0.53 ]
 [0.583]
 [0.75 ]
 [0.719]
 [0.733]]
printing an ep nov before normalisation:  16.254990100860596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  4.211752099081423e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.157]
 [19.602]
 [19.616]
 [24.291]
 [17.086]] [[0.515]
 [0.489]
 [0.49 ]
 [0.708]
 [0.371]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.4830710853019
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  29.146015644073486
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 31.503477649378567
printing an ep nov before normalisation:  22.852093026160215
siam score:  -0.8805232
line 256 mcts: sample exp_bonus 24.86249303817749
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.97 ]
 [32.178]
 [29.97 ]
 [29.97 ]
 [29.97 ]] [[0.862]
 [0.926]
 [0.862]
 [0.862]
 [0.862]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.495144681797267
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.611382379120045
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  80.5820388601008
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.02903223527468
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  64.97896618350242
printing an ep nov before normalisation:  84.48585623421948
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.75217038531762
printing an ep nov before normalisation:  41.75715446472168
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.22072556862849
printing an ep nov before normalisation:  24.06743122998274
printing an ep nov before normalisation:  92.05719105066873
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  12.244416051474044
printing an ep nov before normalisation:  12.798967682744427
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.466]
 [34.842]
 [31.268]
 [32.189]
 [29.987]] [[0.225]
 [0.308]
 [0.276]
 [0.284]
 [0.265]]
printing an ep nov before normalisation:  0.005074014852977728
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  81.32122704113125
actions average: 
K:  4  action  0 :  tensor([    0.9990,     0.0001,     0.0000,     0.0004,     0.0004],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9712,     0.0003,     0.0002,     0.0281],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9989,     0.0003,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0006,     0.0009,     0.0319,     0.8213,     0.1453],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0010, 0.0598, 0.1213, 0.0446, 0.7733], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  67.23078460873707
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  100.08294434108844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.75461196899414
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.02630525683928
printing an ep nov before normalisation:  36.85976425531496
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.01088155736135
printing an ep nov before normalisation:  18.089002902185623
printing an ep nov before normalisation:  40.92625056925088
printing an ep nov before normalisation:  74.29608675596359
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0014992423393778154
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.73125418236538
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.653032488107467
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9697,     0.0146,     0.0002,     0.0014,     0.0141],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0009,     0.9797,     0.0007,     0.0004,     0.0183],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0111,     0.8490,     0.0504,     0.0891],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0003,     0.0004,     0.8425,     0.1566],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0011, 0.0192, 0.0656, 0.2268, 0.6873], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.839]
 [24.839]
 [24.839]
 [24.839]
 [24.839]] [[0.65]
 [0.65]
 [0.65]
 [0.65]
 [0.65]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.217]
 [94.732]
 [94.305]
 [96.431]
 [96.497]] [[1.579]
 [1.912]
 [1.895]
 [1.978]
 [1.981]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.123]
 [35.745]
 [40.496]
 [38.922]
 [38.992]] [[0.925]
 [1.021]
 [1.302]
 [1.209]
 [1.213]]
printing an ep nov before normalisation:  27.642731184942654
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.772112226455505
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.03 ]
 [25.84 ]
 [26.684]
 [27.03 ]
 [27.03 ]] [[1.625]
 [1.494]
 [1.587]
 [1.625]
 [1.625]]
printing an ep nov before normalisation:  30.14264299086862
printing an ep nov before normalisation:  36.829483253235075
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.16289265950521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9913,     0.0007,     0.0002,     0.0039,     0.0039],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9760,     0.0007,     0.0000,     0.0232],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9073,     0.0507,     0.0418],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0009,     0.0005,     0.0045,     0.8304,     0.1637],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0010, 0.0384, 0.1550, 0.1886, 0.6171], grad_fn=<DivBackward0>)
siam score:  -0.88662684
printing an ep nov before normalisation:  21.352043608422655
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.65124174593524
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.704]
 [89.944]
 [89.944]
 [89.944]
 [89.944]] [[1.489]
 [1.401]
 [1.401]
 [1.401]
 [1.401]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  44.28006022958211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.204 0.347 0.102 0.224 0.122]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.929838410086905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  21.778933517554314
printing an ep nov before normalisation:  24.708149276167553
printing an ep nov before normalisation:  75.89010809345736
siam score:  -0.88908166
printing an ep nov before normalisation:  0.0
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 26.535627937078914
printing an ep nov before normalisation:  17.907413454004026
printing an ep nov before normalisation:  32.25016352505677
printing an ep nov before normalisation:  19.377702474594116
printing an ep nov before normalisation:  13.886270523071289
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.69855029797289
printing an ep nov before normalisation:  25.608666167211034
printing an ep nov before normalisation:  23.543145656585693
printing an ep nov before normalisation:  15.993301842136608
printing an ep nov before normalisation:  24.75715798896969
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[  0.   ]
 [  0.   ]
 [110.568]
 [  0.   ]
 [  0.   ]] [[-1.134]
 [-1.134]
 [ 1.303]
 [-1.134]
 [-1.134]]
printing an ep nov before normalisation:  33.47160752220531
printing an ep nov before normalisation:  27.04433034702373
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.652]
 [28.652]
 [29.614]
 [28.652]
 [28.652]] [[1.39 ]
 [1.39 ]
 [1.437]
 [1.39 ]
 [1.39 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.37422496011752
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.7733182729849
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  86.23526041828462
printing an ep nov before normalisation:  27.361661299877888
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.191282901234295
printing an ep nov before normalisation:  28.825194042349437
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.861]
 [25.736]
 [30.144]
 [30.144]
 [30.144]] [[1.679]
 [1.008]
 [1.423]
 [1.423]
 [1.423]]
printing an ep nov before normalisation:  23.744031560993225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 33.30165921530748
printing an ep nov before normalisation:  32.92328270569007
printing an ep nov before normalisation:  24.509397157036705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[119.539]
 [ 48.151]
 [ 48.151]
 [ 48.151]
 [ 48.151]] [[ 1.333]
 [-0.183]
 [-0.183]
 [-0.183]
 [-0.183]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.65595217260961
printing an ep nov before normalisation:  62.854704206043024
printing an ep nov before normalisation:  34.67080383308955
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.97 ]
 [29.369]
 [25.198]
 [25.278]
 [28.481]] [[0.821]
 [0.921]
 [0.624]
 [0.63 ]
 [0.858]]
line 256 mcts: sample exp_bonus 32.23374784615886
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.3642066366393
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.002]
 [27.141]
 [36.002]
 [38.171]
 [36.002]] [[1.368]
 [1.031]
 [1.368]
 [1.451]
 [1.368]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.29988824170483
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 98.31300796360617
printing an ep nov before normalisation:  50.166509459213025
printing an ep nov before normalisation:  31.684775624461246
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.872901559656455
printing an ep nov before normalisation:  24.928753497357338
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.226]
 [23.772]
 [23.772]
 [29.438]
 [24.915]] [[0.692]
 [0.579]
 [0.579]
 [0.841]
 [0.632]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.89059638977051
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.58347116040072
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.28795038495491
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9953,     0.0003,     0.0000,     0.0013,     0.0031],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9984,     0.0000,     0.0000,     0.0014],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0005,     0.0131,     0.9165,     0.0123,     0.0576],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0004,     0.0399,     0.7496,     0.2100],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0010, 0.0323, 0.1303, 0.1773, 0.6591], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.234165404473096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  72.21220804395196
printing an ep nov before normalisation:  78.1596920005652
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  38.817125804542144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.91569328308105
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.558]
 [25.94 ]
 [26.558]
 [23.385]
 [26.558]] [[1.113]
 [1.064]
 [1.113]
 [0.86 ]
 [1.113]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  80.13730410881307
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.736]
 [32.042]
 [35.957]
 [33.293]
 [32.736]] [[0.776]
 [0.746]
 [0.919]
 [0.801]
 [0.776]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  12.14888084823879
printing an ep nov before normalisation:  30.590604637715337
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.74419403076172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.612722240435225
siam score:  -0.8891146
printing an ep nov before normalisation:  36.02531877858286
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.16627931572501
printing an ep nov before normalisation:  32.352887511397824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9802,     0.0003,     0.0005,     0.0190],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0103,     0.8842,     0.0472,     0.0580],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0071, 0.0039, 0.0191, 0.8147, 0.1552], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0023, 0.0220, 0.1426, 0.2626, 0.5706], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  40.51410571416226
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  57.84657759871919
printing an ep nov before normalisation:  42.69451970149179
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  79.97845799497641
printing an ep nov before normalisation:  43.851868639128725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  74.14377298882245
printing an ep nov before normalisation:  17.449026107788086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.142]
 [49.142]
 [49.142]
 [49.142]
 [49.142]] [[0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.47 ]
 [29.47 ]
 [35.036]
 [29.47 ]
 [29.47 ]] [[0.688]
 [0.688]
 [0.933]
 [0.688]
 [0.688]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.027]
 [48.493]
 [57.408]
 [54.402]
 [50.971]] [[0.693]
 [0.802]
 [1.083]
 [0.989]
 [0.88 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88840127
actions average: 
K:  1  action  0 :  tensor([    0.9933,     0.0025,     0.0022,     0.0002,     0.0018],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9993,     0.0000,     0.0000,     0.0006],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0013,     0.9028,     0.0317,     0.0642],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0030,     0.0007,     0.0145,     0.7603,     0.2216],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0029, 0.0628, 0.0939, 0.1893, 0.6510], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.25681715207148
actions average: 
K:  4  action  0 :  tensor([    0.9587,     0.0089,     0.0001,     0.0157,     0.0166],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9974,     0.0004,     0.0001,     0.0021],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0051,     0.8282,     0.0912,     0.0755],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0003,     0.0603,     0.7568,     0.1826],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0200,     0.0986,     0.1783,     0.7028],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  13.149118873706136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.529]
 [38.529]
 [38.529]
 [38.529]
 [38.529]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[122.334]
 [122.334]
 [122.334]
 [122.334]
 [122.334]] [[1.302]
 [1.302]
 [1.302]
 [1.302]
 [1.302]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.989737530530824
printing an ep nov before normalisation:  25.759320451999567
line 256 mcts: sample exp_bonus 57.68471048773857
printing an ep nov before normalisation:  38.59786643320616
printing an ep nov before normalisation:  36.95657459295191
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.9996266563333
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.642144547883174
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.447]
 [23.402]
 [23.447]
 [23.447]
 [23.447]] [[1.142]
 [1.139]
 [1.142]
 [1.142]
 [1.142]]
UNIT TEST: sample policy line 217 mcts : [0.061 0.469 0.408 0.041 0.02 ]
printing an ep nov before normalisation:  30.68781058662559
printing an ep nov before normalisation:  42.146779627654475
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.867035808068746
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  74.44656528934352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.329]
 [26.329]
 [26.329]
 [26.329]
 [26.329]] [[1.973]
 [1.973]
 [1.973]
 [1.973]
 [1.973]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 23.96781087389324
printing an ep nov before normalisation:  36.29715751811816
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.999]
 [74.347]
 [62.999]
 [62.999]
 [62.999]] [[0.48 ]
 [0.611]
 [0.48 ]
 [0.48 ]
 [0.48 ]]
siam score:  -0.8908078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.53357928492272
printing an ep nov before normalisation:  0.006981994001193925
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.649978889984766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.856876850128174
printing an ep nov before normalisation:  25.47551801900923
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  1.2675386642513331e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.044]
 [30.044]
 [30.044]
 [30.044]
 [30.044]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  49.25628662109375
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.88992065
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.185]
 [37.437]
 [37.437]
 [37.437]
 [37.437]] [[0.78 ]
 [0.881]
 [0.881]
 [0.881]
 [0.881]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.25500894403989
printing an ep nov before normalisation:  26.293373107910156
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.187]
 [33.187]
 [33.187]
 [30.208]
 [34.131]] [[1.945]
 [1.945]
 [1.945]
 [1.77 ]
 [2.   ]]
printing an ep nov before normalisation:  24.617901433085493
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.306]
 [38.815]
 [34.269]
 [36.389]
 [38.335]] [[1.872]
 [1.803]
 [1.592]
 [1.69 ]
 [1.781]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.195515932153235
printing an ep nov before normalisation:  89.47598617658547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  70.06286461264517
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.059]
 [0.056]
 [0.053]
 [0.047]
 [0.052]] [[0.002]
 [0.002]
 [0.002]
 [0.001]
 [0.002]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.0444139561572
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.562250183190898
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.87339978758301
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87972915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.066964183786695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  103.09272119619551
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.564]
 [27.696]
 [24.658]
 [24.203]
 [26.48 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9838,     0.0005,     0.0002,     0.0152],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0004,     0.8833,     0.0427,     0.0736],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0676,     0.7816,     0.1503],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0015, 0.1041, 0.0637, 0.3166, 0.5141], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.143]
 [62.958]
 [24.28 ]
 [38.149]
 [54.88 ]] [[1.104]
 [0.963]
 [0.371]
 [0.584]
 [0.84 ]]
siam score:  -0.885663
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.356413432758195
siam score:  -0.8883759
printing an ep nov before normalisation:  68.89277207351437
printing an ep nov before normalisation:  31.24134308786666
printing an ep nov before normalisation:  30.822788800944974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.868]
 [30.695]
 [30.868]
 [30.868]
 [29.082]] [[1.598]
 [1.585]
 [1.598]
 [1.598]
 [1.456]]
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  46.06610457791865
printing an ep nov before normalisation:  40.95499659815539
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.78705738659845
printing an ep nov before normalisation:  15.714156113758222
printing an ep nov before normalisation:  27.76327745393201
siam score:  -0.889615
printing an ep nov before normalisation:  14.435344744739982
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  82.40645398568374
printing an ep nov before normalisation:  36.96502447128296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 41.978]
 [ 58.973]
 [116.977]
 [104.366]
 [ 39.486]] [[0.17 ]
 [0.295]
 [0.721]
 [0.628]
 [0.152]]
printing an ep nov before normalisation:  43.629835117914496
printing an ep nov before normalisation:  21.77274603469044
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0005668778157996712
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.201]
 [30.029]
 [30.95 ]
 [36.244]
 [32.281]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  24.046871202780274
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.462865910870033
printing an ep nov before normalisation:  31.817044964438164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.55900125456052
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.007]
 [0.005]
 [0.005]
 [0.006]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  18.255121916294044
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.24808875324225
printing an ep nov before normalisation:  23.04372644394863
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.49 ]
 [27.347]
 [29.348]
 [29.215]
 [28.825]] [[0.699]
 [0.831]
 [0.972]
 [0.963]
 [0.935]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.713730409317854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.013769000371518
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.831557081916934
printing an ep nov before normalisation:  63.155275043427345
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.297]
 [37.754]
 [40.297]
 [32.22 ]
 [37.479]] [[1.97 ]
 [1.78 ]
 [1.97 ]
 [1.366]
 [1.759]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.802]
 [17.655]
 [17.312]
 [17.655]
 [17.655]] [[0.896]
 [0.669]
 [0.644]
 [0.669]
 [0.669]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.432]
 [33.432]
 [33.432]
 [33.432]
 [33.432]] [[1.122]
 [1.122]
 [1.122]
 [1.122]
 [1.122]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.214]
 [12.61 ]
 [15.921]
 [16.575]
 [16.233]] [[1.022]
 [0.56 ]
 [0.892]
 [0.958]
 [0.924]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.93801398332251
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 30.7453696123832
printing an ep nov before normalisation:  27.77848172271212
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  155.21782419679303
printing an ep nov before normalisation:  53.38710821722654
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.66223567399576
printing an ep nov before normalisation:  0.0159700067661106
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.24592657426122
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.00020502539797462305
printing an ep nov before normalisation:  0.0030510499982483452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  84.13279864422451
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.876]
 [22.991]
 [23.966]
 [24.047]
 [23.434]] [[1.684]
 [1.558]
 [1.697]
 [1.709]
 [1.621]]
printing an ep nov before normalisation:  37.39029380642593
printing an ep nov before normalisation:  27.675324443562126
printing an ep nov before normalisation:  19.762237912960742
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.690747940737996
using explorer policy with actor:  1
printing an ep nov before normalisation:  67.52726559224797
printing an ep nov before normalisation:  78.44448151834636
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.040370440292328
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.071]
 [36.916]
 [27.43 ]
 [36.457]
 [36.012]] [[0.575]
 [0.635]
 [0.328]
 [0.62 ]
 [0.606]]
printing an ep nov before normalisation:  15.707061779338886
printing an ep nov before normalisation:  31.923479174778272
printing an ep nov before normalisation:  32.375359798195106
printing an ep nov before normalisation:  13.310604197163645
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.311]
 [28.863]
 [27.311]
 [22.985]
 [28.703]] [[0.84 ]
 [0.944]
 [0.84 ]
 [0.552]
 [0.933]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88345385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.8447777968592
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 26.183158028100895
printing an ep nov before normalisation:  33.5008654061852
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.8313204156827
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.404776065710813
printing an ep nov before normalisation:  23.366052409774674
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8846422
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.913]
 [60.913]
 [60.004]
 [60.913]
 [60.913]] [[2.   ]
 [2.   ]
 [1.953]
 [2.   ]
 [2.   ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.838800260320163
printing an ep nov before normalisation:  23.416217066296703
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.14734675687579
printing an ep nov before normalisation:  34.596734342926155
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.271861434063695
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.896]
 [24.136]
 [32.167]
 [21.531]
 [24.903]] [[0.413]
 [0.421]
 [0.688]
 [0.334]
 [0.446]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.57]
 [30.57]
 [30.57]
 [30.57]
 [30.57]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
printing an ep nov before normalisation:  22.33695855787895
printing an ep nov before normalisation:  88.84300606710669
printing an ep nov before normalisation:  27.534822956289894
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.91489151265043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.380792379379272
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.896]
 [49.27 ]
 [15.896]
 [63.029]
 [15.896]] [[0.32 ]
 [0.993]
 [0.32 ]
 [1.27 ]
 [0.32 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  58.9682722821836
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.027267806498244
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 42.944294893710044
printing an ep nov before normalisation:  20.895432694875527
printing an ep nov before normalisation:  2.6915080297840177e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.94043644650122
printing an ep nov before normalisation:  87.0140166816328
printing an ep nov before normalisation:  37.25361435060069
printing an ep nov before normalisation:  21.151597736587778
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.29115085820331
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.778514265154172
printing an ep nov before normalisation:  23.452488281871446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.745577812194824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.889785995172797
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.51698086677611
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.437]
 [33.437]
 [33.437]
 [33.437]
 [33.437]] [[1.332]
 [1.332]
 [1.332]
 [1.332]
 [1.332]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  3.0547312235285062e-06
printing an ep nov before normalisation:  107.34289512785003
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.967710716540736
line 256 mcts: sample exp_bonus 28.33407919672912
printing an ep nov before normalisation:  34.64322574440613
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  87.50389210351157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  25.104946506774304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.23788719637288
printing an ep nov before normalisation:  15.338387240037097
printing an ep nov before normalisation:  15.564552999938819
printing an ep nov before normalisation:  12.431338017251363
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  79.85732837638406
printing an ep nov before normalisation:  22.788517309264677
line 256 mcts: sample exp_bonus 65.07832438863986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.842]
 [33.21 ]
 [29.842]
 [29.842]
 [29.842]] [[0.708]
 [0.818]
 [0.708]
 [0.708]
 [0.708]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9973,     0.0000,     0.0016,     0.0004,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0017, 0.9232, 0.0166, 0.0031, 0.0553], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0005,     0.9416,     0.0308,     0.0270],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0002,     0.0004,     0.8226,     0.1766],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0027, 0.0442, 0.1517, 0.1838, 0.6176], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  31.620173983300734
printing an ep nov before normalisation:  22.483961582183838
printing an ep nov before normalisation:  26.47305630402044
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.262]
 [15.262]
 [18.586]
 [15.262]
 [15.262]] [[0.775]
 [0.775]
 [1.099]
 [0.775]
 [0.775]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.973]
 [23.124]
 [21.127]
 [20.016]
 [22.742]] [[0.885]
 [1.281]
 [1.17 ]
 [1.109]
 [1.26 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.789389024629216
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9724,     0.0136,     0.0002,     0.0137],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9762,     0.0107,     0.0131],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0005,     0.0256,     0.6971,     0.2763],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0027,     0.0007,     0.0766,     0.2075,     0.7125],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.55577956906056
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.34074450787888
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.218357008169
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.388]
 [21.388]
 [21.388]
 [21.388]
 [21.388]] [[0.08]
 [0.08]
 [0.08]
 [0.08]
 [0.08]]
printing an ep nov before normalisation:  37.14762709517267
printing an ep nov before normalisation:  87.35279083251953
printing an ep nov before normalisation:  105.95667638583308
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.889]
 [33.298]
 [39.964]
 [33.617]
 [34.643]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.385996582801184
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.113]
 [24.113]
 [24.113]
 [24.113]
 [24.113]] [[48.226]
 [48.226]
 [48.226]
 [48.226]
 [48.226]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  3.262770178480423e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.83448401154541
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.34113702247935
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  84.50748245643322
printing an ep nov before normalisation:  29.628762069792593
printing an ep nov before normalisation:  47.197655011046145
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[97.142]
 [97.142]
 [97.142]
 [97.142]
 [97.142]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.786]
 [35.786]
 [35.786]
 [37.398]
 [35.786]] [[1.171]
 [1.171]
 [1.171]
 [1.245]
 [1.171]]
siam score:  -0.8909596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.232]
 [71.149]
 [78.69 ]
 [75.217]
 [63.297]] [[0.54 ]
 [0.676]
 [0.849]
 [0.77 ]
 [0.496]]
printing an ep nov before normalisation:  58.93044471740723
printing an ep nov before normalisation:  34.14841502776085
printing an ep nov before normalisation:  18.30847978591919
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88886046
siam score:  -0.88714784
printing an ep nov before normalisation:  37.995038118215675
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.885364
printing an ep nov before normalisation:  28.929952616420994
printing an ep nov before normalisation:  72.87279051593444
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.96719344624762
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.49383209481993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.471932548749933
printing an ep nov before normalisation:  14.84759108073029
printing an ep nov before normalisation:  23.900570659527425
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.848869207588255
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.411]
 [26.456]
 [26.456]
 [21.347]
 [23.22 ]] [[1.85 ]
 [1.856]
 [1.856]
 [1.26 ]
 [1.479]]
printing an ep nov before normalisation:  0.00244667152092656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.928452123378257
printing an ep nov before normalisation:  18.898510932922363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.222]
 [29.888]
 [32.997]
 [16.909]
 [17.007]] [[0.494]
 [0.991]
 [1.17 ]
 [0.247]
 [0.252]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.630955611807615
printing an ep nov before normalisation:  18.605901634607825
printing an ep nov before normalisation:  37.19351288509711
printing an ep nov before normalisation:  13.586345911026001
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.6895260890395
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.778]
 [14.735]
 [11.919]
 [10.994]
 [12.284]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.287]
 [93.287]
 [62.307]
 [93.287]
 [93.287]] [[0.868]
 [0.868]
 [0.491]
 [0.868]
 [0.868]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  83.68411738549409
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9914,     0.0018,     0.0019,     0.0009,     0.0040],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9675,     0.0159,     0.0003,     0.0161],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0170,     0.8557,     0.0418,     0.0851],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0004,     0.0605,     0.6942,     0.2445],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0011, 0.0256, 0.0368, 0.2705, 0.6661], grad_fn=<DivBackward0>)
siam score:  -0.8899558
printing an ep nov before normalisation:  77.79516782177343
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.66523254978114
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[1.5]
 [1.5]
 [0. ]
 [1.5]
 [1.5]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.5]
 [1.5]
 [0. ]
 [1.5]
 [1.5]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  50.41347841230634
printing an ep nov before normalisation:  47.06693578730628
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.054]
 [54.107]
 [52.451]
 [26.781]
 [49.675]] [[0.424]
 [0.461]
 [0.441]
 [0.134]
 [0.408]]
printing an ep nov before normalisation:  69.0990983466771
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.283]
 [47.283]
 [47.283]
 [47.283]
 [47.283]] [[0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.64 ]
 [28.256]
 [28.64 ]
 [28.64 ]
 [28.64 ]] [[1.815]
 [1.771]
 [1.815]
 [1.815]
 [1.815]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.950163954004502
printing an ep nov before normalisation:  24.889080812272287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[113.243]
 [108.206]
 [108.835]
 [109.068]
 [109.422]] [[1.21 ]
 [1.111]
 [1.123]
 [1.128]
 [1.135]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.483660728833854
printing an ep nov before normalisation:  86.47427093195662
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.053]
 [35.053]
 [35.053]
 [35.053]
 [35.053]] [[0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.101]
 [75.494]
 [73.344]
 [75.494]
 [75.494]] [[0.94 ]
 [0.954]
 [0.879]
 [0.954]
 [0.954]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.258]
 [59.724]
 [59.454]
 [73.424]
 [44.524]] [[0.739]
 [0.852]
 [0.845]
 [1.199]
 [0.467]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.549]
 [43.507]
 [37.549]
 [37.549]
 [37.549]] [[1.34 ]
 [1.701]
 [1.34 ]
 [1.34 ]
 [1.34 ]]
printing an ep nov before normalisation:  54.01567464940383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 20.956362983663116
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9888,     0.0003,     0.0001,     0.0014,     0.0094],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9995,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0120,     0.9043,     0.0105,     0.0731],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0021,     0.0003,     0.0314,     0.7972,     0.1690],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0015, 0.0058, 0.0783, 0.2243, 0.6900], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.982309334877655
printing an ep nov before normalisation:  25.96902803758295
printing an ep nov before normalisation:  91.22645060221353
printing an ep nov before normalisation:  13.801119555490551
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.244]
 [29.244]
 [29.244]
 [29.244]
 [29.244]] [[0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 94.719]
 [103.579]
 [ 98.785]
 [111.859]
 [112.547]] [[1.449]
 [1.721]
 [1.574]
 [1.976]
 [1.997]]
siam score:  -0.8870485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.41104316711426
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.836]
 [58.46 ]
 [55.38 ]
 [47.641]
 [49.072]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  40.328190119695506
printing an ep nov before normalisation:  65.23339363251998
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.081]
 [30.782]
 [29.56 ]
 [29.656]
 [31.368]] [[0.206]
 [0.281]
 [0.261]
 [0.263]
 [0.29 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.236]
 [52.48 ]
 [56.872]
 [53.651]
 [53.7  ]] [[0.687]
 [0.832]
 [0.954]
 [0.864]
 [0.866]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.89242506
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.621842189455975
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.561]
 [46.995]
 [41.664]
 [46.995]
 [46.995]] [[1.081]
 [0.849]
 [0.627]
 [0.849]
 [0.849]]
printing an ep nov before normalisation:  80.06999124737538
siam score:  -0.8930729
printing an ep nov before normalisation:  35.392375796365705
printing an ep nov before normalisation:  54.50150463293631
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  47.13315509441066
actions average: 
K:  0  action  0 :  tensor([    0.9982,     0.0001,     0.0000,     0.0013,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9495,     0.0001,     0.0000,     0.0502],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0017, 0.0094, 0.8820, 0.0356, 0.0713], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0009,     0.0580,     0.7881,     0.1526],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0013, 0.0298, 0.1110, 0.3358, 0.5222], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.716353113003706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88697934
printing an ep nov before normalisation:  20.978628083112397
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.915]
 [28.328]
 [32.915]
 [32.915]
 [30.572]] [[0.883]
 [0.656]
 [0.883]
 [0.883]
 [0.767]]
siam score:  -0.88591874
printing an ep nov before normalisation:  26.89793743420497
printing an ep nov before normalisation:  55.18136352570261
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.051]
 [34.064]
 [34.064]
 [34.064]
 [34.064]] [[1.603]
 [0.998]
 [0.998]
 [0.998]
 [0.998]]
printing an ep nov before normalisation:  64.2687988186712
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[90.252]
 [90.252]
 [74.391]
 [90.252]
 [90.252]] [[2.   ]
 [2.   ]
 [1.551]
 [2.   ]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  95.66071202508589
printing an ep nov before normalisation:  153.45428717723303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.593980519991113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.419786998203826
printing an ep nov before normalisation:  33.52813009804561
siam score:  -0.8867801
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.399291594923149
printing an ep nov before normalisation:  0.0021126968027829207
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.081]
 [27.719]
 [25.872]
 [24.486]
 [27.381]] [[0.389]
 [0.465]
 [0.412]
 [0.372]
 [0.455]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.591]
 [28.351]
 [27.704]
 [23.327]
 [27.913]] [[0.167]
 [0.164]
 [0.156]
 [0.1  ]
 [0.159]]
printing an ep nov before normalisation:  19.02953843764346
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.099]
 [28.071]
 [40.157]
 [27.311]
 [28.071]] [[0.322]
 [0.55 ]
 [0.895]
 [0.528]
 [0.55 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[102.413]
 [102.344]
 [105.919]
 [107.36 ]
 [106.997]] [[1.169]
 [1.169]
 [1.218]
 [1.237]
 [1.232]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  68.4554820159051
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.792]
 [16.792]
 [16.792]
 [22.116]
 [16.792]] [[0.404]
 [0.404]
 [0.404]
 [0.682]
 [0.404]]
printing an ep nov before normalisation:  17.407450422302
printing an ep nov before normalisation:  149.29919620523054
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.63804361363182
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.04604541924623
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.17650575438563
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.110973795282014
printing an ep nov before normalisation:  69.54962204914757
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.404]
 [21.792]
 [21.792]
 [19.755]
 [21.792]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.324966430664062
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0010,     0.9931,     0.0003,     0.0005,     0.0050],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0004,     0.9995,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0007,     0.0409,     0.8156,     0.1423],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0535, 0.0229, 0.0776, 0.2819, 0.5642], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.519009715902357
siam score:  -0.8942775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.773526643610783
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  130.44703824244442
printing an ep nov before normalisation:  0.019448369951646782
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.08100567392381
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  79.58775881088687
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.433]
 [28.099]
 [24.29 ]
 [21.262]
 [27.662]] [[0.819]
 [0.865]
 [0.605]
 [0.399]
 [0.835]]
printing an ep nov before normalisation:  0.002740514274819361
printing an ep nov before normalisation:  0.0007377839312994183
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.16368952437282
siam score:  -0.8902895
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.574]
 [72.301]
 [79.589]
 [73.985]
 [73.611]] [[0.778]
 [0.99 ]
 [1.19 ]
 [1.036]
 [1.026]]
printing an ep nov before normalisation:  20.721290420279807
printing an ep nov before normalisation:  18.800740653308107
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  33.46678972244263
printing an ep nov before normalisation:  32.245840472244154
printing an ep nov before normalisation:  23.178386688232422
actions average: 
K:  2  action  0 :  tensor([    0.9984,     0.0010,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0072,     0.9743,     0.0009,     0.0003,     0.0174],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0004,     0.9741,     0.0139,     0.0116],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0003,     0.0244,     0.8553,     0.1199],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0068, 0.0054, 0.1358, 0.3241, 0.5279], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.99848494468579
actions average: 
K:  4  action  0 :  tensor([    0.9883,     0.0006,     0.0000,     0.0056,     0.0055],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9988,     0.0001,     0.0007,     0.0004],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0004,     0.8632,     0.0772,     0.0593],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0005,     0.0839,     0.7416,     0.1739],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0464, 0.0372, 0.1109, 0.3455, 0.4600], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.811511516571045
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9963,     0.0003,     0.0000,     0.0012,     0.0021],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9882,     0.0011,     0.0005,     0.0097],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0004,     0.0209,     0.8576,     0.0383,     0.0828],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0000,     0.0002,     0.0265,     0.7908,     0.1825],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0005,     0.0007,     0.1085,     0.1441,     0.7462],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  36.34579221106137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.48871326446533
printing an ep nov before normalisation:  42.06487824913324
printing an ep nov before normalisation:  21.79823875427246
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.549698521769635
siam score:  -0.8773506
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.826]
 [26.553]
 [21.826]
 [21.826]
 [21.826]] [[0.706]
 [1.031]
 [0.706]
 [0.706]
 [0.706]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.18289502834755
printing an ep nov before normalisation:  56.30072593688965
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.54962738989113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.003]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8674745
printing an ep nov before normalisation:  66.6915543832997
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.7885664882802
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.489]
 [20.041]
 [24.243]
 [17.764]
 [17.592]] [[0.995]
 [0.483]
 [0.656]
 [0.389]
 [0.382]]
printing an ep nov before normalisation:  31.173138187886543
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.0618738825504
printing an ep nov before normalisation:  85.44718969801798
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.702]
 [30.329]
 [25.148]
 [30.514]
 [30.258]] [[1.372]
 [1.268]
 [0.876]
 [1.282]
 [1.263]]
printing an ep nov before normalisation:  87.99323601052434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.50405740737915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.932952570234907
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.492]
 [21.492]
 [29.861]
 [20.76 ]
 [22.098]] [[0.156]
 [0.156]
 [0.292]
 [0.144]
 [0.166]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.889]
 [25.878]
 [29.244]
 [29.83 ]
 [27.373]] [[0.973]
 [0.856]
 [1.052]
 [1.086]
 [0.943]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  122.30914496988831
siam score:  -0.8797879
printing an ep nov before normalisation:  14.740173616569145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.70721638564162
printing an ep nov before normalisation:  40.17244417713604
printing an ep nov before normalisation:  58.01783774355785
printing an ep nov before normalisation:  70.05688413127163
printing an ep nov before normalisation:  26.468421462742526
printing an ep nov before normalisation:  25.79796453483654
printing an ep nov before normalisation:  39.90367083833394
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  95.7198636177595
actions average: 
K:  2  action  0 :  tensor([    0.9987,     0.0001,     0.0000,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9384,     0.0011,     0.0002,     0.0602],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0132, 0.0034, 0.9103, 0.0307, 0.0424], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0003,     0.0204,     0.8713,     0.1076],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0005,     0.0070,     0.1217,     0.1178,     0.7530],
       grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.29978129530813
printing an ep nov before normalisation:  111.21220432489757
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.329079353589936
printing an ep nov before normalisation:  19.4402813911438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.513642633622325
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.82 ]
 [26.921]
 [20.355]
 [19.152]
 [24.197]] [[1.149]
 [1.528]
 [0.921]
 [0.81 ]
 [1.276]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.245]
 [77.245]
 [77.245]
 [77.245]
 [77.245]] [[1.78]
 [1.78]
 [1.78]
 [1.78]
 [1.78]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9940,     0.0020,     0.0000,     0.0003,     0.0037],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9664,     0.0001,     0.0002,     0.0333],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0001,     0.9474,     0.0132,     0.0392],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0005,     0.0353,     0.8087,     0.1551],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0007, 0.0026, 0.0879, 0.3310, 0.5777], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  33.08588996419668
printing an ep nov before normalisation:  45.0464357205079
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.59863118306562
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Starting evaluation
printing an ep nov before normalisation:  35.70145375692218
printing an ep nov before normalisation:  28.598160449942064
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  5.581154995455217
rdn beta is 0 so we're just using the maxi policy
UNIT TEST: sample policy line 217 mcts : [0.041 0.163 0.02  0.755 0.02 ]
printing an ep nov before normalisation:  20.570179671947535
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[105.628]
 [ 91.599]
 [102.696]
 [115.916]
 [114.218]] [[1.198]
 [0.904]
 [1.136]
 [1.413]
 [1.378]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.021]
 [19.157]
 [18.021]
 [18.021]
 [18.021]] [[1.115]
 [1.22 ]
 [1.115]
 [1.115]
 [1.115]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.533157834669854
using explorer policy with actor:  1
siam score:  -0.8891912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.41705131530762
siam score:  -0.8884918
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.09790315265557
printing an ep nov before normalisation:  29.81520201952437
printing an ep nov before normalisation:  47.090459161161824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  70.74735164642334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.88596773
UNIT TEST: sample policy line 217 mcts : [0.367 0.184 0.163 0.204 0.082]
UNIT TEST: sample policy line 217 mcts : [0.102 0.204 0.061 0.122 0.51 ]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.187]
 [35.187]
 [31.281]
 [35.187]
 [35.187]] [[0.594]
 [0.594]
 [0.463]
 [0.594]
 [0.594]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.96850622649575
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  89.84169006347656
printing an ep nov before normalisation:  111.54871146161405
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0137,     0.9683,     0.0009,     0.0003,     0.0168],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0003,     0.9264,     0.0272,     0.0460],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0005,     0.0012,     0.7676,     0.2304],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0007, 0.0172, 0.0823, 0.2811, 0.6187], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  17.533772409766957
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 23.13213136501895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.15687908173099
line 256 mcts: sample exp_bonus 35.892048807996815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.00242788873067
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.595]
 [46.762]
 [43.509]
 [45.763]
 [45.798]] [[1.548]
 [1.622]
 [1.417]
 [1.559]
 [1.561]]
printing an ep nov before normalisation:  41.74668788909912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.06207847595215
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.300567009756765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.516068733696976
printing an ep nov before normalisation:  19.551029108211203
printing an ep nov before normalisation:  25.547555696180147
printing an ep nov before normalisation:  89.84003187394732
UNIT TEST: sample policy line 217 mcts : [0.02  0.163 0.347 0.408 0.061]
printing an ep nov before normalisation:  34.10116990315417
line 256 mcts: sample exp_bonus 26.960060765429706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.152]
 [29.14 ]
 [28.306]
 [29.14 ]
 [29.14 ]] [[1.141]
 [1.038]
 [0.995]
 [1.038]
 [1.038]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
siam score:  -0.88794297
actions average: 
K:  4  action  0 :  tensor([    0.9541,     0.0043,     0.0001,     0.0019,     0.0396],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0146,     0.9350,     0.0004,     0.0006,     0.0494],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0096,     0.9128,     0.0283,     0.0492],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0006,     0.0410,     0.7812,     0.1771],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0005,     0.0378,     0.1829,     0.1330,     0.6459],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.47]
 [29.47]
 [29.47]
 [29.47]
 [29.47]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.952]
 [36.84 ]
 [45.353]
 [42.952]
 [42.952]] [[1.857]
 [1.493]
 [2.   ]
 [1.857]
 [1.857]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  14.620717261817918
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.494]
 [52.494]
 [52.494]
 [52.494]
 [52.494]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.33647415186145
printing an ep nov before normalisation:  65.71779749574435
printing an ep nov before normalisation:  90.37852265803625
siam score:  -0.8862926
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.716]
 [22.716]
 [33.98 ]
 [22.716]
 [22.716]] [[0.162]
 [0.162]
 [0.293]
 [0.162]
 [0.162]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.70581736572348
printing an ep nov before normalisation:  28.280580353545133
printing an ep nov before normalisation:  96.46413789929157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 41.66005884118758
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.711]
 [73.426]
 [35.754]
 [22.413]
 [53.343]] [[0.247]
 [0.267]
 [0.108]
 [0.051]
 [0.182]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.987130498384825
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.507]
 [87.067]
 [56.213]
 [37.043]
 [82.778]] [[0.528]
 [0.587]
 [0.343]
 [0.191]
 [0.553]]
UNIT TEST: sample policy line 217 mcts : [0.286 0.306 0.041 0.245 0.122]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.39256509311384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.616546407456102
printing an ep nov before normalisation:  37.49822600099014
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.991]
 [23.991]
 [26.704]
 [21.111]
 [24.234]] [[1.478]
 [1.478]
 [1.645]
 [1.301]
 [1.493]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8881722
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.979]
 [34.979]
 [54.223]
 [34.979]
 [34.979]] [[0.678]
 [0.678]
 [1.186]
 [0.678]
 [0.678]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  85.06563446513387
printing an ep nov before normalisation:  26.044552939259994
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.779]
 [26.779]
 [26.779]
 [26.779]
 [10.448]] [[3.977]
 [3.977]
 [3.977]
 [3.977]
 [1.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.192958834038418
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.464232803426775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.091260444077754
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  116.48476938210267
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.768]
 [ 8.877]
 [25.014]
 [23.519]
 [20.897]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.48819820521765
printing an ep nov before normalisation:  20.69678761301735
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.821]
 [85.821]
 [85.821]
 [85.821]
 [85.821]] [[0.883]
 [0.883]
 [0.883]
 [0.883]
 [0.883]]
printing an ep nov before normalisation:  24.59517463314406
printing an ep nov before normalisation:  19.417010690646897
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  65.66535004374241
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.074]
 [40.219]
 [27.044]
 [34.715]
 [34.088]] [[0.534]
 [0.414]
 [0.211]
 [0.329]
 [0.319]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  25.373324537918183
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  85.78876032492961
printing an ep nov before normalisation:  21.373037720392237
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9576,     0.0187,     0.0003,     0.0232],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9074,     0.0481,     0.0443],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0047,     0.0005,     0.0418,     0.7207,     0.2323],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0034, 0.0390, 0.1348, 0.1703, 0.6526], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  52.73450119149571
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.72033404327708
siam score:  -0.88810676
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.92478127158351
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88593954
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.44893664914901
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  86.93743478705912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  4  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0014,     0.9397,     0.0004,     0.0003,     0.0582],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0005,     0.0006,     0.9115,     0.0123,     0.0752],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0003,     0.0378,     0.7849,     0.1768],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0029, 0.0351, 0.0664, 0.2005, 0.6952], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.854422027445075
siam score:  -0.8822569
printing an ep nov before normalisation:  61.477996045911894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.669906616210938
printing an ep nov before normalisation:  20.058445930480957
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.072]
 [32.039]
 [31.404]
 [27.871]
 [31.757]] [[0.952]
 [0.821]
 [0.793]
 [0.64 ]
 [0.808]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.542220621173882
printing an ep nov before normalisation:  85.73412369065271
printing an ep nov before normalisation:  68.4414544504538
printing an ep nov before normalisation:  34.5936380703608
printing an ep nov before normalisation:  23.94770399639203
printing an ep nov before normalisation:  72.26816605078001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.59431579516419
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.111307454813044
printing an ep nov before normalisation:  18.05003273990758
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.633]
 [68.568]
 [69.424]
 [73.006]
 [74.569]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.255]
 [26.255]
 [29.773]
 [26.255]
 [26.255]] [[0.928]
 [0.928]
 [1.165]
 [0.928]
 [0.928]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.222]
 [54.65 ]
 [47.951]
 [47.951]
 [47.951]] [[1.543]
 [1.494]
 [1.285]
 [1.285]
 [1.285]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  90.15759624362255
printing an ep nov before normalisation:  48.52007153218824
printing an ep nov before normalisation:  29.588337923366904
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.671704292297363
printing an ep nov before normalisation:  15.512521266937256
printing an ep nov before normalisation:  33.9348030090332
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.75 ]
 [22.977]
 [25.453]
 [22.627]
 [22.168]] [[0.424]
 [0.511]
 [0.607]
 [0.497]
 [0.479]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.874]
 [71.948]
 [68.044]
 [66.636]
 [75.592]] [[0.996]
 [0.911]
 [0.826]
 [0.796]
 [0.99 ]]
printing an ep nov before normalisation:  58.14987156001805
printing an ep nov before normalisation:  86.9743429635308
printing an ep nov before normalisation:  29.35417890548706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9916,     0.0000,     0.0000,     0.0031,     0.0053],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9959,     0.0000,     0.0005,     0.0034],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0002,     0.9126,     0.0278,     0.0592],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0006,     0.0283,     0.7664,     0.2041],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0022, 0.0198, 0.1117, 0.2652, 0.6011], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  34.54946295873383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.73055076599121
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.138]
 [29.571]
 [24.204]
 [24.158]
 [25.159]] [[0.955]
 [0.981]
 [0.654]
 [0.651]
 [0.712]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.46511338567553
actions average: 
K:  1  action  0 :  tensor([0.9563, 0.0167, 0.0011, 0.0014, 0.0244], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0027,     0.9699,     0.0001,     0.0009,     0.0264],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0002,     0.9389,     0.0320,     0.0288],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0013,     0.0007,     0.0564,     0.7959,     0.1457],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0170, 0.0024, 0.1395, 0.2773, 0.5637], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  28.2837744968426
printing an ep nov before normalisation:  25.37850322065964
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.70276676958981
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.414]
 [29.414]
 [29.414]
 [29.414]
 [29.414]] [[0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]]
printing an ep nov before normalisation:  20.508300637465467
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.652]
 [21.221]
 [35.359]
 [18.131]
 [18.131]] [[1.084]
 [0.627]
 [1.045]
 [0.536]
 [0.536]]
printing an ep nov before normalisation:  22.783202526283386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.411]
 [22.567]
 [17.728]
 [19.411]
 [20.88 ]] [[0.702]
 [0.945]
 [0.572]
 [0.702]
 [0.815]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.19203428608527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.793710088511073
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.966]
 [60.601]
 [27.466]
 [26.362]
 [55.183]] [[1.227]
 [1.186]
 [0.193]
 [0.16 ]
 [1.024]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.813704819109596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.99304071270114
printing an ep nov before normalisation:  32.74547274522595
printing an ep nov before normalisation:  82.25059935373591
printing an ep nov before normalisation:  46.676285473514156
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 9.062]
 [12.911]
 [ 8.101]
 [ 9.03 ]
 [13.585]] [[0.453]
 [1.157]
 [0.277]
 [0.447]
 [1.28 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88637507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8893471
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.139]
 [27.139]
 [27.139]
 [26.771]
 [27.139]] [[1.17 ]
 [1.17 ]
 [1.17 ]
 [1.146]
 [1.17 ]]
actions average: 
K:  1  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9975,     0.0001,     0.0009,     0.0014],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0336,     0.9625,     0.0010,     0.0026],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0005,     0.0013,     0.0499,     0.7107,     0.2376],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0148, 0.0554, 0.0923, 0.1640, 0.6735], grad_fn=<DivBackward0>)
siam score:  -0.88872206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.05457723710716
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.09366254105771
printing an ep nov before normalisation:  56.184186935424805
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9983,     0.0000,     0.0000,     0.0009,     0.0009],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0451, 0.9002, 0.0457, 0.0012, 0.0077], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0007,     0.0054,     0.9068,     0.0273,     0.0598],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0332, 0.0030, 0.0386, 0.7505, 0.1746], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0358, 0.0660, 0.1725, 0.1940, 0.5316], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  18.375927460204963
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.37854459017984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.749]
 [36.913]
 [74.002]
 [69.321]
 [49.671]] [[0.583]
 [0.503]
 [1.009]
 [0.945]
 [0.677]]
printing an ep nov before normalisation:  52.321389201398475
siam score:  -0.87720305
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.77809758089415
actions average: 
K:  0  action  0 :  tensor([    0.9912,     0.0012,     0.0000,     0.0003,     0.0073],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9753,     0.0092,     0.0001,     0.0154],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0007,     0.9268,     0.0305,     0.0420],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0006,     0.0489,     0.7794,     0.1709],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0012, 0.0603, 0.1183, 0.2557, 0.5645], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  18.6458158493042
printing an ep nov before normalisation:  51.72088152103206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.25455278045966
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.729]
 [37.86 ]
 [25.405]
 [21.032]
 [24.956]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.45130533327461
printing an ep nov before normalisation:  41.297301933628184
printing an ep nov before normalisation:  25.571133125406142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.487]
 [33.487]
 [33.487]
 [33.487]
 [33.487]] [[1.417]
 [1.417]
 [1.417]
 [1.417]
 [1.417]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.999]
 [21.083]
 [21.129]
 [20.786]
 [20.99 ]] [[1.054]
 [1.175]
 [1.18 ]
 [1.142]
 [1.164]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.266573205300105
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.0605551017778
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9989,     0.0001,     0.0000,     0.0004,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9958,     0.0001,     0.0001,     0.0038],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9660,     0.0198,     0.0142],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0003,     0.0260,     0.8592,     0.1139],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0026, 0.0203, 0.1157, 0.2487, 0.6128], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  28.051133155822754
printing an ep nov before normalisation:  28.355048019872253
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  16.09777923527289
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.245902040318086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.212]
 [20.748]
 [20.748]
 [26.062]
 [20.748]] [[1.086]
 [0.971]
 [0.971]
 [1.219]
 [0.971]]
printing an ep nov before normalisation:  15.244009144319898
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.908668041229248
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.811504019888055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.062917680105244
printing an ep nov before normalisation:  60.06321067222469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.89473056793213
printing an ep nov before normalisation:  42.74127502867661
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.48045227390057
printing an ep nov before normalisation:  16.42714302455951
printing an ep nov before normalisation:  18.52511783125383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.29033569751795
siam score:  -0.8832928
siam score:  -0.88268393
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.336067077858246
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.526]
 [17.048]
 [23.122]
 [28.43 ]
 [18.179]] [[0.301]
 [0.286]
 [0.473]
 [0.636]
 [0.321]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 74.787]
 [  0.   ]
 [110.362]
 [  0.   ]
 [  0.   ]] [[ 0.433]
 [-0.194]
 [ 0.731]
 [-0.194]
 [-0.194]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.83796248981731
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.49642584781628
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.86400404559751
printing an ep nov before normalisation:  37.9706853107431
actions average: 
K:  4  action  0 :  tensor([    0.9936,     0.0052,     0.0000,     0.0003,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9877,     0.0070,     0.0001,     0.0052],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0001,     0.8940,     0.0452,     0.0607],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0009,     0.0380,     0.7965,     0.1643],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0017, 0.0219, 0.0361, 0.0823, 0.8581], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.94]
 [16.94]
 [16.94]
 [16.14]
 [16.94]] [[0.44 ]
 [0.44 ]
 [0.44 ]
 [0.402]
 [0.44 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.01454808976915
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  92.29513741571448
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.446795261583624
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.725]
 [73.819]
 [75.972]
 [72.515]
 [71.665]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.005451008996715245
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  90.459345180705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.62667003770533
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.902]
 [23.966]
 [23.631]
 [22.881]
 [24.138]] [[0.828]
 [1.161]
 [1.133]
 [1.072]
 [1.175]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[91.888]
 [87.18 ]
 [69.796]
 [75.24 ]
 [87.412]] [[1.5  ]
 [1.424]
 [1.14 ]
 [1.228]
 [1.427]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.782]
 [65.571]
 [62.425]
 [47.761]
 [58.419]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0001,     0.0006],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0020, 0.9306, 0.0235, 0.0016, 0.0422], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0046,     0.9000,     0.0366,     0.0584],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0001,     0.0010,     0.8811,     0.1176],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0026, 0.0158, 0.0831, 0.2797, 0.6188], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  102.27419017396225
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.656]
 [23.261]
 [23.47 ]
 [31.989]
 [23.295]] [[0.562]
 [0.835]
 [0.842]
 [1.148]
 [0.836]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.75670481835543
printing an ep nov before normalisation:  31.2324060881764
printing an ep nov before normalisation:  27.595380516656842
printing an ep nov before normalisation:  77.7257101876395
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  130.2761234143123
printing an ep nov before normalisation:  77.69943714141846
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.69482983934504
printing an ep nov before normalisation:  36.93070180530539
printing an ep nov before normalisation:  26.43507957458496
printing an ep nov before normalisation:  31.762321411229607
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  98.83506061997744
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.94850843933947
printing an ep nov before normalisation:  37.14918736408845
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.855]
 [77.855]
 [77.855]
 [77.855]
 [77.855]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
printing an ep nov before normalisation:  94.27505563101019
printing an ep nov before normalisation:  92.59785126901843
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.98639152052906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.87312648514654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 46.90738099456659
actions average: 
K:  4  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0001,     0.0010],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0006,     0.9722,     0.0021,     0.0007,     0.0244],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0006,     0.9167,     0.0331,     0.0496],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0009,     0.0289,     0.8406,     0.1295],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0018, 0.0418, 0.1391, 0.1642, 0.6532], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  30.119784006095532
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.71692537346915
printing an ep nov before normalisation:  15.653296709060669
siam score:  -0.8827649
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.76963379188002
printing an ep nov before normalisation:  90.0536305883463
printing an ep nov before normalisation:  0.0163468685366297
siam score:  -0.88341796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.811119751792432
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.232]
 [22.909]
 [22.909]
 [26.067]
 [22.909]] [[1.09 ]
 [0.988]
 [0.988]
 [1.232]
 [0.988]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.95]
 [41.95]
 [41.95]
 [41.95]
 [41.95]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.02875240582632
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9990,     0.0002,     0.0000,     0.0003,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0042, 0.9663, 0.0010, 0.0022, 0.0263], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0005,     0.0129,     0.8984,     0.0331,     0.0550],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0004,     0.0430,     0.8738,     0.0823],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0035, 0.0082, 0.1613, 0.2379, 0.5891], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.312]
 [32.81 ]
 [30.69 ]
 [31.72 ]
 [31.76 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.42098240783742
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.588908677304822
siam score:  -0.88178706
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.616]
 [53.683]
 [29.891]
 [53.683]
 [53.683]] [[0.939]
 [0.542]
 [0.09 ]
 [0.542]
 [0.542]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.883027
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.54963506431626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8822171
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[95.203]
 [87.035]
 [87.035]
 [87.035]
 [87.035]] [[2.   ]
 [1.714]
 [1.714]
 [1.714]
 [1.714]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.120561599731445
printing an ep nov before normalisation:  21.262853971438574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8812074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.556]
 [21.556]
 [19.181]
 [21.556]
 [21.099]] [[0.098]
 [0.098]
 [0.078]
 [0.098]
 [0.094]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.078]
 [23.34 ]
 [23.34 ]
 [23.34 ]
 [23.34 ]] [[0.248]
 [0.333]
 [0.333]
 [0.333]
 [0.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.558799213133685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.08]
 [39.08]
 [39.08]
 [39.08]
 [39.08]] [[0.58]
 [0.58]
 [0.58]
 [0.58]
 [0.58]]
printing an ep nov before normalisation:  62.338924407958984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.50259093146531
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.425]
 [12.587]
 [12.587]
 [12.587]
 [12.587]] [[0.377]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  101.42415035079831
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.236]
 [33.104]
 [36.236]
 [36.332]
 [36.236]] [[1.53 ]
 [1.296]
 [1.53 ]
 [1.537]
 [1.53 ]]
UNIT TEST: sample policy line 217 mcts : [0.429 0.224 0.041 0.224 0.082]
siam score:  -0.879534
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.5436869039223
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8788974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.2466215464517
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.00600106209731166
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.07508484923676
printing an ep nov before normalisation:  44.17875528364323
printing an ep nov before normalisation:  72.3375415802002
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.909]
 [34.653]
 [31.909]
 [31.909]
 [31.909]] [[1.073]
 [1.238]
 [1.073]
 [1.073]
 [1.073]]
siam score:  -0.88432467
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.666]
 [33.525]
 [41.443]
 [39.29 ]
 [38.462]] [[0.543]
 [0.709]
 [0.979]
 [0.906]
 [0.877]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.06068203800851
line 256 mcts: sample exp_bonus 40.23176659858985
printing an ep nov before normalisation:  0.05598975985179777
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  94.6844598950802
printing an ep nov before normalisation:  68.00112316755612
printing an ep nov before normalisation:  20.555925369262695
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.748287677764893
printing an ep nov before normalisation:  18.597682952718632
printing an ep nov before normalisation:  17.23776671151937
printing an ep nov before normalisation:  0.002325207445039723
printing an ep nov before normalisation:  46.181614061119426
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.539]
 [19.718]
 [20.784]
 [20.405]
 [19.873]] [[1.196]
 [1.334]
 [1.459]
 [1.415]
 [1.352]]
siam score:  -0.8845865
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.69339000607711
printing an ep nov before normalisation:  16.373527248134863
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.412]
 [24.922]
 [34.082]
 [32.622]
 [32.454]] [[0.545]
 [0.478]
 [0.654]
 [0.626]
 [0.623]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.322]
 [20.775]
 [39.392]
 [25.968]
 [20.775]] [[0.215]
 [0.204]
 [0.569]
 [0.306]
 [0.204]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Starting evaluation
printing an ep nov before normalisation:  49.26397584494862
printing an ep nov before normalisation:  0.006917738201650536
printing an ep nov before normalisation:  36.362104945149326
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.004709092141865767
printing an ep nov before normalisation:  32.824101740931916
printing an ep nov before normalisation:  11.66037917137146
printing an ep nov before normalisation:  87.02021431125162
printing an ep nov before normalisation:  0.002538184036779967
printing an ep nov before normalisation:  47.56829032933634
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.006566304804515
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.06127528635914814
printing an ep nov before normalisation:  22.36120544163952
printing an ep nov before normalisation:  16.932806968688965
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.827783584374153
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9995,     0.0002,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0010,     0.9709,     0.0003,     0.0005,     0.0272],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0005,     0.9691,     0.0011,     0.0292],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0008,     0.0337,     0.7731,     0.1917],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0017, 0.0013, 0.0515, 0.2148, 0.7307], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.993]
 [30.393]
 [40.052]
 [34.744]
 [37.13 ]] [[1.838]
 [1.324]
 [1.977]
 [1.618]
 [1.78 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.08906716963356
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.803293965013566
siam score:  -0.87450635
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  63.2333245752323
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.52 ]
 [42.52 ]
 [43.934]
 [52.661]
 [42.52 ]] [[1.214]
 [1.214]
 [1.266]
 [1.59 ]
 [1.214]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.713]
 [21.199]
 [30.446]
 [18.496]
 [20.722]] [[0.68 ]
 [0.814]
 [1.169]
 [0.71 ]
 [0.796]]
printing an ep nov before normalisation:  111.31359100341797
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  8.153053225138744e-05
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.425431622961383
printing an ep nov before normalisation:  51.985895773988844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.490577691555707
printing an ep nov before normalisation:  15.636032551697385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.397]
 [18.397]
 [18.397]
 [18.397]
 [18.397]] [[0.941]
 [0.941]
 [0.941]
 [0.941]
 [0.941]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.30552072021792
printing an ep nov before normalisation:  22.701555486665868
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.776]
 [71.498]
 [73.776]
 [70.158]
 [73.383]] [[1.523]
 [1.435]
 [1.523]
 [1.383]
 [1.508]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.088]
 [25.407]
 [18.043]
 [25.398]
 [23.585]] [[0.287]
 [0.757]
 [0.284]
 [0.757]
 [0.64 ]]
printing an ep nov before normalisation:  28.629077355578623
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.00037387169840030765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  90.43955758123191
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  34.19647867768738
printing an ep nov before normalisation:  16.072210713004434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.11588729728608
printing an ep nov before normalisation:  28.931653451357555
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 99.30377783946022
printing an ep nov before normalisation:  43.08161764186651
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9620,     0.0207,     0.0004,     0.0016,     0.0153],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0068, 0.8670, 0.0169, 0.0012, 0.1082], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.9302,     0.0263,     0.0432],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0129,     0.0005,     0.0240,     0.8135,     0.1490],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0048, 0.0017, 0.0398, 0.3407, 0.6129], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  1.7932512491095547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.402]
 [80.402]
 [77.522]
 [84.498]
 [80.402]] [[1.56 ]
 [1.56 ]
 [1.484]
 [1.667]
 [1.56 ]]
printing an ep nov before normalisation:  37.774800405641344
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  110.82538859726225
actions average: 
K:  0  action  0 :  tensor([    0.9981,     0.0003,     0.0000,     0.0011,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0005,     0.9024,     0.0401,     0.0569],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0006,     0.0422,     0.7990,     0.1577],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0062, 0.0017, 0.0635, 0.3855, 0.5430], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  17.470824718475342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  86.65449036101258
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  112.86500624914329
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 32.19004025188685
printing an ep nov before normalisation:  146.70719924558736
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 61.171]
 [ 61.171]
 [122.554]
 [ 61.171]
 [ 61.171]] [[0.328]
 [0.328]
 [0.796]
 [0.328]
 [0.328]]
printing an ep nov before normalisation:  130.2108735751607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.638]
 [31.638]
 [41.6  ]
 [42.223]
 [31.638]] [[0.834]
 [0.834]
 [1.263]
 [1.29 ]
 [0.834]]
printing an ep nov before normalisation:  35.80865151622582
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9858,     0.0001,     0.0004,     0.0043,     0.0095],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0036,     0.9957,     0.0002,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0085,     0.9714,     0.0002,     0.0199],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0013, 0.0013, 0.0032, 0.8147, 0.1794], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0161, 0.0023, 0.0647, 0.3736, 0.5433], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  42.9039997577188
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  61.83064824898021
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0030916118873847154
printing an ep nov before normalisation:  0.00019103054711422376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.8806199
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.807763132417424
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.069]
 [21.069]
 [21.069]
 [21.069]
 [21.069]] [[1.576]
 [1.576]
 [1.576]
 [1.576]
 [1.576]]
printing an ep nov before normalisation:  78.76397951539754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.232025360890688
printing an ep nov before normalisation:  5.51956475192128e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  94.83795166015625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.71962278246099
printing an ep nov before normalisation:  96.30213943803912
printing an ep nov before normalisation:  93.00649704084901
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.076882908847384
printing an ep nov before normalisation:  24.935729077964773
printing an ep nov before normalisation:  0.0019033866855977521
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.217]
 [77.63 ]
 [79.217]
 [79.217]
 [79.828]] [[0.529]
 [0.515]
 [0.529]
 [0.529]
 [0.534]]
printing an ep nov before normalisation:  43.56169708831446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.564133186947412
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.32971940811322
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.779]
 [32.779]
 [32.779]
 [32.779]
 [32.779]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
printing an ep nov before normalisation:  41.51530243417549
printing an ep nov before normalisation:  36.02178034974519
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8824746
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.192]
 [31.617]
 [24.698]
 [34.706]
 [34.304]] [[1.048]
 [1.029]
 [0.804]
 [1.13 ]
 [1.117]]
printing an ep nov before normalisation:  38.00412153330521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.109418242904866
siam score:  -0.8818103
printing an ep nov before normalisation:  20.462114500371527
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0000,     0.0001,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9740,     0.0160,     0.0002,     0.0097],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0090,     0.8797,     0.0329,     0.0784],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0003,     0.0527,     0.7628,     0.1837],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0016, 0.0013, 0.1875, 0.2039, 0.6057], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  6.395441118911549e-05
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.03698939769857
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.413704638395558
siam score:  -0.88065964
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.30715085946241
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.373420861930615
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.103618709871746
printing an ep nov before normalisation:  29.771226007500857
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.417]
 [17.15 ]
 [16.417]
 [16.417]
 [16.417]] [[0.168]
 [0.182]
 [0.168]
 [0.168]
 [0.168]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.48629053950176
printing an ep nov before normalisation:  28.80613198450978
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.614]
 [18.727]
 [14.385]
 [20.298]
 [19.017]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  33.14259701436199
printing an ep nov before normalisation:  29.302604416460735
printing an ep nov before normalisation:  59.067379898473796
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.637]
 [19.565]
 [21.149]
 [20.124]
 [20.059]] [[0.171]
 [0.207]
 [0.236]
 [0.217]
 [0.216]]
printing an ep nov before normalisation:  25.35991599991451
siam score:  -0.8788084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.30046699767796
printing an ep nov before normalisation:  23.055008691728393
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.141]
 [70.141]
 [82.969]
 [70.141]
 [70.141]] [[0.979]
 [0.979]
 [1.32 ]
 [0.979]
 [0.979]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.979]
 [20.999]
 [21.186]
 [19.559]
 [19.943]] [[1.036]
 [1.135]
 [1.153]
 [0.995]
 [1.032]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.066]
 [20.066]
 [23.838]
 [20.066]
 [20.066]] [[0.658]
 [0.658]
 [0.894]
 [0.658]
 [0.658]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  87.68235881301075
printing an ep nov before normalisation:  20.86151293742612
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.6309752132479
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.882291
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  82.10320187946519
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[90.326]
 [86.736]
 [86.736]
 [86.736]
 [86.736]] [[1.654]
 [1.539]
 [1.539]
 [1.539]
 [1.539]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.248142787388396
printing an ep nov before normalisation:  29.37697205866705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.157072831495345
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.656]
 [27.876]
 [50.618]
 [27.876]
 [27.876]] [[ 0.199]
 [-0.088]
 [ 0.058]
 [-0.088]
 [-0.088]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.04974699938492
printing an ep nov before normalisation:  93.95265948114323
printing an ep nov before normalisation:  87.86791820318038
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.65896970590832
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.688]
 [63.429]
 [74.723]
 [68.815]
 [63.181]] [[0.185]
 [0.23 ]
 [0.307]
 [0.267]
 [0.229]]
printing an ep nov before normalisation:  30.352635383605957
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9994,     0.0001,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9991,     0.0000,     0.0001,     0.0007],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0003,     0.9073,     0.0272,     0.0651],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0004,     0.0395,     0.7952,     0.1647],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0019, 0.0319, 0.0266, 0.3330, 0.6067], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  129.29894258980286
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.484]
 [41.493]
 [44.969]
 [41.781]
 [40.596]] [[1.202]
 [1.475]
 [1.712]
 [1.495]
 [1.414]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  50.54942608959722
printing an ep nov before normalisation:  72.35380711780873
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  106.31878853431029
printing an ep nov before normalisation:  47.532774554547395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.50917901476359
printing an ep nov before normalisation:  23.098776905972514
UNIT TEST: sample policy line 217 mcts : [0.163 0.224 0.061 0.367 0.184]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.597154237640844
printing an ep nov before normalisation:  23.29653442083729
printing an ep nov before normalisation:  29.081212865568485
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.344818869649952
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.974956363772126
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 79.438]
 [ 84.478]
 [100.064]
 [106.271]
 [ 95.83 ]] [[0.165]
 [0.185]
 [0.249]
 [0.275]
 [0.232]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.865499195404354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.42578887939453
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.637958654649292
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.231]
 [29.203]
 [25.231]
 [25.231]
 [25.231]] [[0.782]
 [1.   ]
 [0.782]
 [0.782]
 [0.782]]
printing an ep nov before normalisation:  19.340724286355876
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  92.4389567789959
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88000536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.776]
 [19.441]
 [20.099]
 [19.194]
 [19.169]] [[1.03 ]
 [0.837]
 [0.892]
 [0.817]
 [0.815]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.51382153565964
printing an ep nov before normalisation:  42.97495782280175
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  111.82765453858596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.830669160534347
printing an ep nov before normalisation:  16.69976526123862
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9781,     0.0024,     0.0000,     0.0139,     0.0055],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0008,     0.9605,     0.0194,     0.0025,     0.0168],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0036, 0.0313, 0.8355, 0.0491, 0.0806], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0018, 0.0009, 0.0447, 0.7988, 0.1538], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0032, 0.0023, 0.1648, 0.2859, 0.5437], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.109415554762585
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  11.179391841991945
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  107.19422201231383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.892]
 [36.892]
 [36.892]
 [36.892]
 [36.892]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.956]
 [13.956]
 [ 0.   ]
 [ 0.   ]
 [13.956]] [[0.195]
 [0.195]
 [0.   ]
 [0.   ]
 [0.195]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.82934888382546
printing an ep nov before normalisation:  0.0037708151512561017
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.19251846434837
printing an ep nov before normalisation:  63.47951408616743
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  12.340114116668701
printing an ep nov before normalisation:  77.25757653995797
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.230482185002586
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.142]
 [51.71 ]
 [53.478]
 [52.791]
 [54.196]] [[1.308]
 [1.652]
 [1.723]
 [1.696]
 [1.752]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.873933
printing an ep nov before normalisation:  33.26306124058184
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.446]
 [19.728]
 [62.377]
 [17.564]
 [23.759]] [[0.024]
 [0.135]
 [1.247]
 [0.079]
 [0.24 ]]
printing an ep nov before normalisation:  126.78931529788214
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.52776041324894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.741844955797582
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.003963488609315391
siam score:  -0.8812671
siam score:  -0.87960315
line 256 mcts: sample exp_bonus 48.816301336845314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.77569983181839
siam score:  -0.8758314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.631]
 [20.893]
 [26.438]
 [20.468]
 [20.397]] [[0.277]
 [0.185]
 [0.274]
 [0.179]
 [0.178]]
printing an ep nov before normalisation:  17.901111131328676
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.102 0.041 0.367 0.082 0.408]
printing an ep nov before normalisation:  25.710811474680717
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  16.610850484045756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[     0.0000],
        [    -0.0000],
        [     0.0000],
        [    -0.0000],
        [     0.0000],
        [    -0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 4.9819415760948365e-11
0.0 0.0
0.0 0.0
0.0 -8.234042320972141e-12
0.0 8.856785015003572e-11
0.0 0.0
0.0 2.608599964648185e-11
0.0 2.608599964648185e-11
0.0 6.227426970924066e-12
0.0 -6.953960109879434e-12
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.24746355640644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.09884548187256
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.359141808219178
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.841698817334766
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[3.034]
 [4.887]
 [3.038]
 [1.603]
 [6.215]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  47.219457821824555
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.598]
 [24.598]
 [24.598]
 [24.598]
 [24.598]] [[32.789]
 [32.789]
 [32.789]
 [32.789]
 [32.789]]
printing an ep nov before normalisation:  25.602452524275417
siam score:  -0.87889236
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  13.404309065725549
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  51.07358203140029
line 256 mcts: sample exp_bonus 33.84789853554254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[91.813]
 [91.813]
 [91.813]
 [91.813]
 [91.813]] [[1.879]
 [1.879]
 [1.879]
 [1.879]
 [1.879]]
printing an ep nov before normalisation:  16.818265925713096
printing an ep nov before normalisation:  22.31629328845892
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.01605012328758
printing an ep nov before normalisation:  24.708038060503156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.81888405866588
siam score:  -0.88050765
printing an ep nov before normalisation:  28.976525712583058
printing an ep nov before normalisation:  29.33522003802836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.246]
 [35.572]
 [26.874]
 [23.77 ]
 [32.321]] [[0.621]
 [0.95 ]
 [0.718]
 [0.635]
 [0.863]]
printing an ep nov before normalisation:  25.49307563575508
printing an ep nov before normalisation:  33.64405691688927
siam score:  -0.88166374
printing an ep nov before normalisation:  18.971254401928924
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.51593987200806
printing an ep nov before normalisation:  24.781470161290812
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.424]
 [16.972]
 [25.823]
 [24.318]
 [21.969]] [[0.412]
 [0.211]
 [0.487]
 [0.44 ]
 [0.367]]
printing an ep nov before normalisation:  19.420410241983042
printing an ep nov before normalisation:  46.098265647888184
printing an ep nov before normalisation:  12.794022560119629
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.53796271860579
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.127580962742684
printing an ep nov before normalisation:  18.535750423295134
siam score:  -0.8756886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.317]
 [16.317]
 [31.772]
 [16.317]
 [16.317]] [[0.512]
 [0.512]
 [1.436]
 [0.512]
 [0.512]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.05624238827148
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  10.68334067496293
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  12.475252252199175
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.545905413854037
printing an ep nov before normalisation:  68.36569353906633
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.24530053138733
siam score:  -0.8755109
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.42458124926674
using explorer policy with actor:  1
printing an ep nov before normalisation:  83.15259596918166
printing an ep nov before normalisation:  24.26530584985593
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.47 ]
 [46.523]
 [70.077]
 [55.962]
 [55.962]] [[0.677]
 [0.43 ]
 [0.962]
 [0.643]
 [0.643]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9995,     0.0001,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0021, 0.9101, 0.0219, 0.0012, 0.0646], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0009,     0.9019,     0.0339,     0.0632],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0062,     0.0008,     0.0196,     0.8337,     0.1397],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0620, 0.0246, 0.1021, 0.1465, 0.6648], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9488,     0.0021,     0.0001,     0.0237,     0.0254],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9603,     0.0289,     0.0007,     0.0100],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0119,     0.9344,     0.0131,     0.0405],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0001,     0.0046,     0.8785,     0.1167],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0003,     0.0078,     0.1515,     0.1992,     0.6412],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.445]
 [51.287]
 [51.287]
 [51.287]
 [51.287]] [[1.124]
 [0.672]
 [0.672]
 [0.672]
 [0.672]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.297]
 [57.941]
 [47.236]
 [45.567]
 [44.86 ]] [[1.104]
 [0.91 ]
 [0.661]
 [0.623]
 [0.606]]
printing an ep nov before normalisation:  27.733299821610316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.355793943843686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  87.42626077138144
siam score:  -0.8762077
printing an ep nov before normalisation:  17.68585327874699
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.87440085
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.487]
 [40.367]
 [34.487]
 [34.487]
 [34.487]] [[0.506]
 [0.667]
 [0.506]
 [0.506]
 [0.506]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.693078131729013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  89.28901871441508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  80.76693566733881
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.39319859382182
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.908]
 [18.737]
 [24.255]
 [24.237]
 [22.526]] [[0.547]
 [0.4  ]
 [0.656]
 [0.655]
 [0.576]]
printing an ep nov before normalisation:  124.68307943392442
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.234]
 [15.234]
 [15.234]
 [15.967]
 [15.234]] [[0.868]
 [0.868]
 [0.868]
 [0.944]
 [0.868]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87410307
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87018096
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.7346245535545
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.515]
 [89.856]
 [79.515]
 [79.515]
 [79.076]] [[0.811]
 [0.984]
 [0.811]
 [0.811]
 [0.804]]
printing an ep nov before normalisation:  43.36293333730841
printing an ep nov before normalisation:  27.200961910252126
siam score:  -0.87201715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.23857710874313
printing an ep nov before normalisation:  32.22059774392411
actions average: 
K:  3  action  0 :  tensor([    0.9700,     0.0086,     0.0005,     0.0077,     0.0134],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9994,     0.0003,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0102,     0.8788,     0.0226,     0.0882],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0003,     0.0407,     0.8900,     0.0689],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0145, 0.0246, 0.0754, 0.2121, 0.6734], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  96.5062449148306
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8717493
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.088]
 [23.58 ]
 [25.433]
 [25.342]
 [22.715]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.333]
 [38.88 ]
 [38.88 ]
 [38.88 ]
 [38.88 ]] [[0.231]
 [0.113]
 [0.113]
 [0.113]
 [0.113]]
printing an ep nov before normalisation:  19.386816109173594
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.511847236346494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.161543661341334
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[108.332]
 [107.472]
 [ 77.486]
 [ 99.181]
 [ 99.181]] [[0.585]
 [0.578]
 [0.329]
 [0.509]
 [0.509]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.18354687801665
printing an ep nov before normalisation:  26.71875998943357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.933976980380923
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[122.757]
 [118.006]
 [119.868]
 [120.971]
 [121.392]] [[0.797]
 [0.74 ]
 [0.762]
 [0.776]
 [0.781]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.63710427172069
printing an ep nov before normalisation:  17.865632253488286
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.840816405440957
printing an ep nov before normalisation:  19.68256722903591
printing an ep nov before normalisation:  21.54546060455459
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.489718726732214
printing an ep nov before normalisation:  31.58809695027374
actions average: 
K:  1  action  0 :  tensor([    0.9967,     0.0004,     0.0013,     0.0008,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0023,     0.9033,     0.0205,     0.0003,     0.0736],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0035,     0.8898,     0.0361,     0.0702],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0089, 0.0094, 0.0558, 0.7591, 0.1669], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0322, 0.0613, 0.0895, 0.2065, 0.6104], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88263625
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.732330070450463
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.858637932098553
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.463036231241176
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.56 ]
 [33.56 ]
 [37.287]
 [33.56 ]
 [33.56 ]] [[0.846]
 [0.846]
 [1.031]
 [0.846]
 [0.846]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.55775877082281
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.712]
 [24.973]
 [24.973]
 [24.973]
 [24.973]] [[1.056]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.387]
 [50.354]
 [49.367]
 [51.396]
 [51.64 ]] [[1.187]
 [1.104]
 [1.064]
 [1.146]
 [1.156]]
printing an ep nov before normalisation:  29.552925691539784
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.6925632535584
Starting evaluation
printing an ep nov before normalisation:  8.249082128486407e-05
printing an ep nov before normalisation:  14.026676049848223
printing an ep nov before normalisation:  14.907920878374007
printing an ep nov before normalisation:  13.396803616529139
printing an ep nov before normalisation:  11.901223713300649
printing an ep nov before normalisation:  21.06297254562378
printing an ep nov before normalisation:  15.909133087718706
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.264]
 [19.4  ]
 [28.984]
 [19.241]
 [20.85 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.07721845942016
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87633073
printing an ep nov before normalisation:  14.14251104492951
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.194542109284765
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  12.965321477253793
printing an ep nov before normalisation:  27.977949417688286
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.823]
 [13.766]
 [13.766]
 [18.22 ]
 [13.766]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.86975288904981
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.82502492227314
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 11.526647000717912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.896156787872314
printing an ep nov before normalisation:  29.17062400260979
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[101.229]
 [ 69.697]
 [ 69.697]
 [ 69.697]
 [ 69.697]] [[1.143]
 [0.787]
 [0.787]
 [0.787]
 [0.787]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.936737383983157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.014150142669678
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.97224850094523
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.72313580211694
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.12472882212558
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.382]
 [21.876]
 [26.798]
 [21.527]
 [21.527]] [[1.118]
 [0.824]
 [1.146]
 [0.801]
 [0.801]]
printing an ep nov before normalisation:  20.28263290409613
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.666]
 [30.666]
 [30.666]
 [34.731]
 [29.984]] [[0.878]
 [0.878]
 [0.878]
 [1.038]
 [0.852]]
printing an ep nov before normalisation:  19.747519079007247
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.193619710810236
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.154]
 [24.154]
 [24.154]
 [24.154]
 [24.154]] [[1.061]
 [1.061]
 [1.061]
 [1.061]
 [1.061]]
printing an ep nov before normalisation:  22.885190491698292
printing an ep nov before normalisation:  24.612183783187138
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.662]
 [23.022]
 [22.006]
 [24.737]
 [24.118]] [[1.668]
 [1.316]
 [1.217]
 [1.482]
 [1.422]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.231721641268248
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.387]
 [23.275]
 [22.474]
 [17.598]
 [18.622]] [[0.795]
 [1.234]
 [1.162]
 [0.724]
 [0.816]]
printing an ep nov before normalisation:  19.700866620119584
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.907853823880313
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.19027276571217
printing an ep nov before normalisation:  0.11795599637565601
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.204 0.469 0.082 0.143 0.102]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.02135299773377
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.184]
 [30.948]
 [26.874]
 [26.684]
 [26.819]] [[0.653]
 [0.821]
 [0.639]
 [0.631]
 [0.637]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.692]
 [14.07 ]
 [25.361]
 [ 9.901]
 [12.107]] [[0.105]
 [0.126]
 [0.228]
 [0.089]
 [0.109]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.367]
 [28.958]
 [28.958]
 [28.958]
 [28.958]] [[0.333]
 [0.821]
 [0.821]
 [0.821]
 [0.821]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9960,     0.0000,     0.0001,     0.0032],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0003,     0.8890,     0.0425,     0.0681],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0005,     0.0322,     0.8187,     0.1483],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0124, 0.0011, 0.1174, 0.2484, 0.6206], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.5572925659054
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.02 ]
 [26.117]
 [22.02 ]
 [22.02 ]
 [22.02 ]] [[0.539]
 [0.707]
 [0.539]
 [0.539]
 [0.539]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.689]
 [17.545]
 [14.107]
 [18.111]
 [19.698]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  16.06545934844914
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  9.090146624400592
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  13.685991530853288
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  20.91553825398547
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.92530917655223
printing an ep nov before normalisation:  33.93290783657119
line 256 mcts: sample exp_bonus 22.92169843660433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.455]
 [52.455]
 [52.455]
 [52.455]
 [52.455]] [[0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.352]]
printing an ep nov before normalisation:  20.672459602355957
printing an ep nov before normalisation:  27.36589217130759
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  88.39914892736083
printing an ep nov before normalisation:  24.911240375602155
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.769737243652344
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.988]
 [22.409]
 [23.743]
 [24.307]
 [24.76 ]] [[0.674]
 [0.527]
 [0.603]
 [0.635]
 [0.661]]
siam score:  -0.8774725
line 256 mcts: sample exp_bonus 25.7764896568042
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.407]
 [20.407]
 [20.407]
 [20.407]
 [85.738]] [[-0.412]
 [-0.412]
 [-0.412]
 [-0.412]
 [ 0.778]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.06120491027832
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.25299173452827
printing an ep nov before normalisation:  36.962199211120605
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.037747361965884
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.021826843313507
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.15467405319214
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.587]
 [73.25 ]
 [74.587]
 [63.426]
 [74.703]] [[1.632]
 [1.603]
 [1.632]
 [1.388]
 [1.635]]
printing an ep nov before normalisation:  29.767604420153408
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.919]
 [37.615]
 [38.653]
 [57.891]
 [38.76 ]] [[1.08 ]
 [0.508]
 [0.538]
 [1.109]
 [0.542]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.23 ]
 [21.26 ]
 [20.919]
 [20.634]
 [19.535]] [[1.251]
 [0.96 ]
 [0.927]
 [0.899]
 [0.791]]
printing an ep nov before normalisation:  24.020742440517502
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8769681
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.625]
 [24.625]
 [24.625]
 [24.625]
 [24.625]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.335]
 [31.718]
 [14.972]
 [18.856]
 [25.478]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  26.496112090630284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.809554841922182
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.58101223428612
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.565039958141725
printing an ep nov before normalisation:  30.431784339281815
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.181]
 [26.181]
 [26.181]
 [26.181]
 [33.862]] [[0.864]
 [0.864]
 [0.864]
 [0.864]
 [1.392]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.26569616615997
printing an ep nov before normalisation:  15.495866685699484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.461966037750244
siam score:  -0.87941253
printing an ep nov before normalisation:  27.84423828125
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  72.54125595092773
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9984,     0.0009,     0.0000,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0010, 0.9178, 0.0448, 0.0010, 0.0354], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0098,     0.9003,     0.0281,     0.0616],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0010, 0.0010, 0.0468, 0.7724, 0.1788], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0012, 0.0015, 0.1071, 0.2622, 0.6279], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.329]
 [88.189]
 [82.329]
 [82.329]
 [82.805]] [[1.066]
 [1.211]
 [1.066]
 [1.066]
 [1.078]]
printing an ep nov before normalisation:  30.871529881165998
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.538483779463306
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.7948201041000402
printing an ep nov before normalisation:  20.907920576569243
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 18.376626662693283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.404366970062256
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87710977
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.647695636110697
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.855]
 [31.855]
 [31.855]
 [31.784]
 [31.855]] [[1.   ]
 [1.   ]
 [1.   ]
 [0.997]
 [1.   ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.57893928554671
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.489718014565078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.459187942900169
printing an ep nov before normalisation:  24.267175002769275
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.815]
 [25.069]
 [15.678]
 [19.914]
 [20.122]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[10.972]
 [ 9.803]
 [10.678]
 [ 8.127]
 [14.32 ]] [[0.444]
 [0.397]
 [0.432]
 [0.329]
 [0.58 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.7]
 [33.7]
 [33.7]
 [33.7]
 [33.7]] [[1.587]
 [1.587]
 [1.587]
 [1.587]
 [1.587]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.837]
 [29.161]
 [29.12 ]
 [29.12 ]
 [29.12 ]] [[1.979]
 [1.485]
 [1.482]
 [1.482]
 [1.482]]
siam score:  -0.8773785
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 9.77464810629149
actions average: 
K:  4  action  0 :  tensor([    0.9923,     0.0005,     0.0000,     0.0001,     0.0071],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0004,     0.9075,     0.0124,     0.0002,     0.0795],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9657,     0.0006,     0.0335],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0311,     0.0233,     0.8573,     0.0880],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0012, 0.0215, 0.0861, 0.2077, 0.6834], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88486725
printing an ep nov before normalisation:  101.9338958618362
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.039]
 [79.039]
 [79.039]
 [79.039]
 [79.039]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
printing an ep nov before normalisation:  51.10236811647006
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.866932867302744
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.8738529
printing an ep nov before normalisation:  42.63307554965986
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
siam score:  -0.8770254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.87780154
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.401]
 [54.727]
 [39.401]
 [39.401]
 [39.401]] [[0.721]
 [1.314]
 [0.721]
 [0.721]
 [0.721]]
actions average: 
K:  4  action  0 :  tensor([    0.9404,     0.0000,     0.0000,     0.0294,     0.0301],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9985,     0.0005,     0.0003,     0.0007],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0007,     0.9532,     0.0163,     0.0298],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0005,     0.0768,     0.7186,     0.2038],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0396, 0.0736, 0.0350, 0.1885, 0.6634], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.785265697830628
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.023]
 [37.291]
 [37.73 ]
 [37.291]
 [37.291]] [[1.33 ]
 [1.53 ]
 [1.556]
 [1.53 ]
 [1.53 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  14.994399886581514
printing an ep nov before normalisation:  99.42145188594945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.037496196214313
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.884964
printing an ep nov before normalisation:  99.24300729264213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9972,     0.0001,     0.0000,     0.0014,     0.0012],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0005,     0.9993,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0026, 0.0021, 0.9196, 0.0230, 0.0528], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0028,     0.0003,     0.0280,     0.7956,     0.1733],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0280, 0.0210, 0.0279, 0.2324, 0.6908], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  49.21847004438825
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.00024089291130735546
printing an ep nov before normalisation:  96.49646203743342
printing an ep nov before normalisation:  74.9302042691063
line 256 mcts: sample exp_bonus 95.05851493622136
printing an ep nov before normalisation:  19.685187862902954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 34.56026052659334
printing an ep nov before normalisation:  65.41636959376211
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.899163246154785
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.059]
 [25.059]
 [31.455]
 [25.059]
 [25.059]] [[0.569]
 [0.569]
 [0.83 ]
 [0.569]
 [0.569]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.98]
 [42.7 ]
 [38.98]
 [38.98]
 [38.98]] [[0.752]
 [0.877]
 [0.752]
 [0.752]
 [0.752]]
printing an ep nov before normalisation:  31.069547602690996
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.682853481525996
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  110.04974223440304
printing an ep nov before normalisation:  30.643139570916027
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.50539174981217
printing an ep nov before normalisation:  21.44723930139865
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.187]
 [25.036]
 [25.81 ]
 [30.33 ]
 [22.772]] [[0.525]
 [0.519]
 [0.549]
 [0.729]
 [0.429]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.12243871666683
printing an ep nov before normalisation:  27.865134444446433
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.245121955871582
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.494]
 [14.12 ]
 [11.914]
 [12.327]
 [13.794]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  16.175850212371802
printing an ep nov before normalisation:  15.179769167352875
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.788302203949975
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.827054872172017
actions average: 
K:  4  action  0 :  tensor([    0.9786,     0.0112,     0.0000,     0.0008,     0.0094],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9998,     0.0001,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0109,     0.9276,     0.0128,     0.0487],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0001,     0.0012,     0.7825,     0.2161],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0009, 0.0172, 0.0672, 0.1883, 0.7263], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  75.8782675482652
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8856721
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.435]
 [13.131]
 [22.636]
 [14.943]
 [12.903]] [[0.222]
 [0.177]
 [0.504]
 [0.239]
 [0.169]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.981]
 [19.981]
 [23.37 ]
 [15.447]
 [19.981]] [[0.556]
 [0.556]
 [0.796]
 [0.237]
 [0.556]]
printing an ep nov before normalisation:  14.471329273300611
printing an ep nov before normalisation:  16.341438438912316
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.24918051559649
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.3204330179817
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.279]
 [35.366]
 [25.204]
 [28.077]
 [33.696]] [[0.634]
 [0.853]
 [0.608]
 [0.677]
 [0.813]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.470988273620605
printing an ep nov before normalisation:  31.284464123267036
printing an ep nov before normalisation:  53.33724476577051
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
line 256 mcts: sample exp_bonus 29.491839755409725
printing an ep nov before normalisation:  27.109352655867117
printing an ep nov before normalisation:  35.97417364235081
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.87562406
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.077]
 [62.524]
 [66.077]
 [66.077]
 [66.077]] [[0.307]
 [0.275]
 [0.307]
 [0.307]
 [0.307]]
printing an ep nov before normalisation:  99.07930366681971
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.75290499915395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9974,     0.0007,     0.0001,     0.0015],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0005,     0.9132,     0.0160,     0.0702],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0012,     0.0576,     0.7812,     0.1596],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0015, 0.0407, 0.0286, 0.3198, 0.6094], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.601317519035753
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.433]
 [18.745]
 [21.469]
 [21.469]
 [23.167]] [[0.875]
 [0.572]
 [0.717]
 [0.717]
 [0.808]]
printing an ep nov before normalisation:  55.99197311739486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  13.711562129354721
printing an ep nov before normalisation:  34.878932889917785
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.281]
 [16.281]
 [16.281]
 [16.281]
 [16.281]] [[0.065]
 [0.065]
 [0.065]
 [0.065]
 [0.065]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.2561204503024
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.136756645599043
printing an ep nov before normalisation:  23.584624563574987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.013404846191406
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.354]
 [29.354]
 [29.354]
 [29.354]
 [29.354]] [[0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.934]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.173]
 [22.814]
 [27.79 ]
 [24.166]
 [22.708]] [[0.682]
 [0.375]
 [0.538]
 [0.419]
 [0.371]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.37798748034165
printing an ep nov before normalisation:  22.992107738287512
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.57 ]
 [20.975]
 [12.943]
 [ 8.568]
 [12.97 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.715]
 [25.715]
 [25.715]
 [25.715]
 [25.715]] [[1.194]
 [1.194]
 [1.194]
 [1.194]
 [1.194]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.849]
 [31.598]
 [30.849]
 [30.849]
 [30.242]] [[1.286]
 [1.333]
 [1.286]
 [1.286]
 [1.248]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.268059633556174
printing an ep nov before normalisation:  120.99439180761138
printing an ep nov before normalisation:  79.9555084254393
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87869185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.584039295454954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.55916786193848
printing an ep nov before normalisation:  75.50192608455436
printing an ep nov before normalisation:  37.18376159667969
printing an ep nov before normalisation:  45.63762095866486
siam score:  -0.87393296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.551]
 [28.866]
 [25.067]
 [25.067]
 [27.785]] [[0.441]
 [1.126]
 [0.813]
 [0.813]
 [1.037]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.142255597246542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.492497368170376
printing an ep nov before normalisation:  26.051242351531982
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.609204703507604
printing an ep nov before normalisation:  21.338722757118152
printing an ep nov before normalisation:  27.645011693200363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  97.87170046034014
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88048327
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.669820171196065
printing an ep nov before normalisation:  23.210362177820905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.33498834252274
printing an ep nov before normalisation:  19.36860546781352
printing an ep nov before normalisation:  50.28802218636768
printing an ep nov before normalisation:  29.361328155828968
siam score:  -0.8823259
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  92.15096229802712
printing an ep nov before normalisation:  69.17330645704388
printing an ep nov before normalisation:  33.42090704406082
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.002103302695104503
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  58.68625627032317
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0001,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9982,     0.0002,     0.0008,     0.0008],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0006,     0.0167,     0.9439,     0.0005,     0.0383],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0020,     0.0229,     0.8014,     0.1733],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0037, 0.0022, 0.0019, 0.2361, 0.7560], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([0.9540, 0.0037, 0.0219, 0.0029, 0.0174], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9176,     0.0498,     0.0011,     0.0315],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0008,     0.8658,     0.0933,     0.0401],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0002,     0.0012,     0.8539,     0.1446],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0007, 0.0429, 0.1664, 0.1581, 0.6320], grad_fn=<DivBackward0>)
siam score:  -0.8821236
printing an ep nov before normalisation:  49.22565692256018
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.280564350036855
line 256 mcts: sample exp_bonus 27.450895309448242
printing an ep nov before normalisation:  21.96056878683452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.037]
 [15.388]
 [16.366]
 [24.92 ]
 [18.533]] [[0.566]
 [0.483]
 [0.514]
 [0.782]
 [0.582]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.95651626586914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.978]
 [24.978]
 [28.402]
 [27.506]
 [25.041]] [[1.1  ]
 [1.1  ]
 [1.403]
 [1.324]
 [1.105]]
siam score:  -0.8792247
printing an ep nov before normalisation:  57.56220199892858
printing an ep nov before normalisation:  38.98751590591129
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.37976383523011
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.096]
 [39.096]
 [39.096]
 [39.096]
 [39.096]] [[0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.957]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.893]
 [36.893]
 [36.893]
 [36.893]
 [36.893]] [[0.88]
 [0.88]
 [0.88]
 [0.88]
 [0.88]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  91.22564891385382
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.199]
 [20.672]
 [18.431]
 [17.64 ]
 [18.401]] [[0.249]
 [0.378]
 [0.314]
 [0.291]
 [0.313]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.73445058929613
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.99423741665529
printing an ep nov before normalisation:  24.796656510582665
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.703665437148594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.045176919865070886
printing an ep nov before normalisation:  65.1413087613501
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.00035923750374422525
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  97.87072489237661
printing an ep nov before normalisation:  21.67985640811979
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.50353675095713
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.581]
 [28.581]
 [29.521]
 [27.295]
 [28.581]] [[1.548]
 [1.548]
 [1.645]
 [1.416]
 [1.548]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.931685693337812
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.485]
 [17.273]
 [17.273]
 [14.843]
 [17.273]] [[1.132]
 [1.106]
 [1.106]
 [0.806]
 [1.106]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.957]
 [13.077]
 [13.352]
 [17.901]
 [18.815]] [[0.73 ]
 [0.413]
 [0.443]
 [0.944]
 [1.044]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.006416553551766
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.592]
 [18.592]
 [31.501]
 [26.669]
 [18.592]] [[0.312]
 [0.312]
 [0.765]
 [0.596]
 [0.312]]
printing an ep nov before normalisation:  33.84613011697351
printing an ep nov before normalisation:  29.573580479189694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.723153114318848
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.65944742657314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.859]
 [19.859]
 [19.859]
 [19.859]
 [19.859]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.108]
 [25.612]
 [24.537]
 [26.007]
 [26.007]] [[1.635]
 [1.376]
 [1.264]
 [1.417]
 [1.417]]
printing an ep nov before normalisation:  77.45824408560846
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.394]
 [27.394]
 [27.394]
 [27.394]
 [27.394]] [[1.98]
 [1.98]
 [1.98]
 [1.98]
 [1.98]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.906]
 [17.338]
 [17.338]
 [17.338]
 [17.338]] [[1.584]
 [1.16 ]
 [1.16 ]
 [1.16 ]
 [1.16 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  92.94180966205445
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.21626035431896
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.40829776219701
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.594]
 [22.945]
 [25.362]
 [23.594]
 [23.594]] [[1.426]
 [1.341]
 [1.657]
 [1.426]
 [1.426]]
line 256 mcts: sample exp_bonus 21.032361604322663
printing an ep nov before normalisation:  24.748092584425414
using explorer policy with actor:  1
siam score:  -0.8725706
printing an ep nov before normalisation:  23.59108787331575
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.565332614379894
printing an ep nov before normalisation:  23.21667507759389
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  14.521985054016113
printing an ep nov before normalisation:  18.25573583046214
printing an ep nov before normalisation:  22.375693321228027
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.704701084253486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 30.972]
 [104.924]
 [ 30.972]
 [ 30.972]
 [ 30.972]] [[-0.685]
 [ 2.   ]
 [-0.685]
 [-0.685]
 [-0.685]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.188260208044326
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[10.067]
 [12.523]
 [12.348]
 [11.892]
 [11.671]] [[0.234]
 [0.351]
 [0.342]
 [0.321]
 [0.31 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [14.211]
 [43.687]
 [ 0.   ]
 [ 0.   ]] [[-0.   ]
 [ 0.281]
 [ 0.863]
 [-0.   ]
 [-0.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  23.099280104369587
printing an ep nov before normalisation:  63.89416575626854
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.07458000635487
using explorer policy with actor:  1
printing an ep nov before normalisation:  25.399740077693274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  96.62456540258228
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.43567321132387
printing an ep nov before normalisation:  45.48114071639597
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  100.8893068882236
printing an ep nov before normalisation:  85.19103636873797
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.792]
 [20.585]
 [19.792]
 [19.792]
 [18.555]] [[0.882]
 [0.945]
 [0.882]
 [0.882]
 [0.783]]
printing an ep nov before normalisation:  20.9803541532975
printing an ep nov before normalisation:  43.832616226426865
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.107438863860864
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.55865325157308
printing an ep nov before normalisation:  20.832286869467495
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.218]
 [20.218]
 [20.218]
 [20.218]
 [20.218]] [[1.043]
 [1.043]
 [1.043]
 [1.043]
 [1.043]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.055156527401806
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.001]
 [24.358]
 [21.106]
 [19.97 ]
 [22.927]] [[1.071]
 [1.534]
 [1.33 ]
 [1.258]
 [1.444]]
siam score:  -0.87823194
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.244496677021605
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.663]
 [15.3  ]
 [17.795]
 [17.795]
 [17.795]] [[1.663]
 [1.154]
 [1.531]
 [1.531]
 [1.531]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88601977
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.6  ]
 [25.991]
 [26.727]
 [26.282]
 [27.07 ]] [[1.063]
 [1.366]
 [1.432]
 [1.392]
 [1.463]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88961226
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9990,     0.0000,     0.0000,     0.0001,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9993,     0.0002,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0060,     0.0002,     0.9921,     0.0002,     0.0015],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0007,     0.0443,     0.6730,     0.2815],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0018, 0.0016, 0.0762, 0.2411, 0.6793], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.285057070725927
printing an ep nov before normalisation:  20.187515670124164
printing an ep nov before normalisation:  113.16383624321453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
using explorer policy with actor:  1
printing an ep nov before normalisation:  79.43811086957152
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  36.36782757156482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  2.7631488011239626e-06
printing an ep nov before normalisation:  37.486109856422715
printing an ep nov before normalisation:  2.677098507319897e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.401]
 [20.515]
 [57.34 ]
 [17.114]
 [41.264]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 33.48478049251885
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.07]
 [56.07]
 [56.07]
 [56.07]
 [56.07]] [[0.164]
 [0.164]
 [0.164]
 [0.164]
 [0.164]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  77.34652399656771
printing an ep nov before normalisation:  28.536958963873815
printing an ep nov before normalisation:  18.064401772027207
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.567759185649397
siam score:  -0.88270986
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88055664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.778]
 [27.507]
 [16.671]
 [25.924]
 [27.295]] [[1.398]
 [1.618]
 [0.978]
 [1.525]
 [1.605]]
printing an ep nov before normalisation:  66.20183197640395
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 91.957]
 [ 83.549]
 [106.383]
 [123.709]
 [118.772]] [[0.964]
 [0.713]
 [1.395]
 [1.913]
 [1.765]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  105.38562721995572
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 37.06432183249551
printing an ep nov before normalisation:  45.29031493600221
printing an ep nov before normalisation:  48.40340492576398
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9972,     0.0000,     0.0023,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9962,     0.0003,     0.0005,     0.0027],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9539,     0.0257,     0.0202],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0006,     0.0509,     0.7847,     0.1635],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0014, 0.0015, 0.1328, 0.3062, 0.5581], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8833641
printing an ep nov before normalisation:  20.421817859704102
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  15.886187553405762
printing an ep nov before normalisation:  139.7637720955813
using explorer policy with actor:  1
printing an ep nov before normalisation:  124.33469275357024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.93366960272186
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  83.05562828651108
printing an ep nov before normalisation:  33.682427296534044
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.507]
 [24.974]
 [21.507]
 [23.689]
 [25.126]] [[0.698]
 [0.914]
 [0.698]
 [0.834]
 [0.924]]
printing an ep nov before normalisation:  63.44469079062647
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 12.778936441274258
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[117.305]
 [117.305]
 [117.305]
 [117.305]
 [117.305]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  47.993634739572045
siam score:  -0.87675905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.299]
 [32.31 ]
 [31.513]
 [25.582]
 [32.663]] [[0.255]
 [1.275]
 [1.217]
 [0.785]
 [1.301]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.078]
 [25.295]
 [24.399]
 [23.671]
 [21.078]] [[0.406]
 [0.581]
 [0.544]
 [0.514]
 [0.406]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8772479
printing an ep nov before normalisation:  31.055443286895752
printing an ep nov before normalisation:  49.58435368958437
printing an ep nov before normalisation:  97.77543192193887
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.95311737060547
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.66928699999372
printing an ep nov before normalisation:  61.06606799011075
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.13531278784278
printing an ep nov before normalisation:  64.19127974047932
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.77544690421275
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8753491
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.556]
 [15.865]
 [14.556]
 [14.556]
 [14.387]] [[1.323]
 [1.502]
 [1.323]
 [1.323]
 [1.3  ]]
printing an ep nov before normalisation:  25.873542777306962
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.567]
 [29.567]
 [29.567]
 [27.828]
 [29.567]] [[1.609]
 [1.609]
 [1.609]
 [1.468]
 [1.609]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.775263165317742
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.113]
 [28.658]
 [33.113]
 [26.747]
 [30.804]] [[1.845]
 [1.597]
 [1.845]
 [1.49 ]
 [1.716]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.797]
 [22.797]
 [22.797]
 [25.323]
 [22.797]] [[1.495]
 [1.495]
 [1.495]
 [1.661]
 [1.495]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  81.32854182184373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.26241315909232
printing an ep nov before normalisation:  23.99305171201311
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  66.07060329493804
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.08544004264884
line 256 mcts: sample exp_bonus 79.25905990700487
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.219]
 [39.219]
 [39.219]
 [39.219]
 [39.219]] [[0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]]
printing an ep nov before normalisation:  56.78432570442769
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.885135650634766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.76074981689453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.4071299748899
siam score:  -0.87856585
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.77962865952094
using explorer policy with actor:  1
printing an ep nov before normalisation:  55.37486860931775
siam score:  -0.87939227
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.275]
 [29.55 ]
 [26.064]
 [26.013]
 [30.094]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[114.778]
 [118.837]
 [143.855]
 [134.475]
 [145.182]] [[0.936]
 [0.982]
 [1.266]
 [1.159]
 [1.281]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.1624982739774
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  89.68414306640625
printing an ep nov before normalisation:  117.66139932102243
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.527820727290084
printing an ep nov before normalisation:  30.855836868286133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.77781456763048
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.1940047311889
printing an ep nov before normalisation:  40.26511315124022
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.882952
printing an ep nov before normalisation:  31.13669843572269
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.407]
 [76.034]
 [78.23 ]
 [83.75 ]
 [83.99 ]] [[1.97 ]
 [1.643]
 [1.74 ]
 [1.985]
 [1.996]]
printing an ep nov before normalisation:  19.623658657073975
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9936,     0.0044,     0.0000,     0.0003,     0.0017],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0004,     0.9990,     0.0000,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0014,     0.8853,     0.0580,     0.0553],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0005,     0.0515,     0.7740,     0.1738],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0023, 0.0289, 0.1179, 0.1241, 0.7268], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  33.41073215038202
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  120.49167736898312
printing an ep nov before normalisation:  120.22253113936355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.77034287735439
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.103309412008716
printing an ep nov before normalisation:  22.219181060791016
printing an ep nov before normalisation:  65.26889827363108
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.22629186886591
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  103.07395723130968
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 98.621]
 [ 98.493]
 [103.077]
 [103.077]
 [103.077]] [[1.509]
 [1.505]
 [1.644]
 [1.644]
 [1.644]]
using explorer policy with actor:  1
siam score:  -0.8817955
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.797657012939453
printing an ep nov before normalisation:  38.52769943705373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.669608116149902
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.55288595737213
printing an ep nov before normalisation:  119.21312309799741
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.875725796397514
printing an ep nov before normalisation:  38.79129409790039
siam score:  -0.8779965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.877733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.136776532833604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.04827624888343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.03305522993744
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.178]
 [26.008]
 [24.582]
 [24.193]
 [25.909]] [[0.794]
 [1.056]
 [0.924]
 [0.888]
 [1.047]]
printing an ep nov before normalisation:  29.353017497592177
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.20148098057692
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.577442808984667
actions average: 
K:  0  action  0 :  tensor([    0.9541,     0.0000,     0.0091,     0.0009,     0.0358],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9969,     0.0002,     0.0007,     0.0020],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0007,     0.8558,     0.0538,     0.0894],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0004,     0.0472,     0.7930,     0.1591],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0018, 0.0774, 0.0564, 0.2557, 0.6087], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.64090782419389
printing an ep nov before normalisation:  73.36012534506162
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.762513876744485
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.062080754575746
printing an ep nov before normalisation:  35.85216552150263
printing an ep nov before normalisation:  28.80941267564553
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.609]
 [37.273]
 [38.525]
 [38.525]
 [38.525]] [[1.647]
 [1.887]
 [2.   ]
 [2.   ]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.669787406921387
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.191]
 [82.224]
 [82.224]
 [82.224]
 [82.224]] [[1.397]
 [1.909]
 [1.909]
 [1.909]
 [1.909]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.07414499658793261
printing an ep nov before normalisation:  26.75393809755502
printing an ep nov before normalisation:  34.95636404512456
printing an ep nov before normalisation:  21.05445031107687
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  111.85454950280948
printing an ep nov before normalisation:  30.9964220380513
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.169952392578125
printing an ep nov before normalisation:  24.94218448693418
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  104.31003998968353
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8740512
printing an ep nov before normalisation:  0.0026562324813994564
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.040915233834404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.764228170820353
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9987,     0.0001,     0.0002,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0005,     0.9099,     0.0453,     0.0443],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0013,     0.0766,     0.7936,     0.1283],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0012, 0.0080, 0.0328, 0.2508, 0.7072], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9992,     0.0000,     0.0005,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9760,     0.0012,     0.0012,     0.0214],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9155,     0.0481,     0.0364],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0005,     0.0282,     0.8356,     0.1355],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0222, 0.0446, 0.2334, 0.6986], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  81.42468692950733
printing an ep nov before normalisation:  77.99704332457311
UNIT TEST: sample policy line 217 mcts : [0.633 0.143 0.041 0.122 0.061]
printing an ep nov before normalisation:  20.394933223724365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.241127014160156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.466222214616646
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  135.26474826551117
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  70.92911728529903
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.691]
 [44.691]
 [71.549]
 [44.691]
 [44.691]] [[0.55]
 [0.55]
 [1.16]
 [0.55]
 [0.55]]
printing an ep nov before normalisation:  34.54704216048269
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.625]
 [41.625]
 [41.625]
 [45.522]
 [41.625]] [[1.247]
 [1.247]
 [1.247]
 [1.423]
 [1.247]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.042147062497946
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.29851300232249
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.30373287200928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  99.54979480224428
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.038]
 [30.038]
 [30.038]
 [28.492]
 [31.327]] [[1.112]
 [1.112]
 [1.112]
 [1.021]
 [1.188]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.198]
 [59.613]
 [59.613]
 [59.613]
 [59.613]] [[1.099]
 [0.86 ]
 [0.86 ]
 [0.86 ]
 [0.86 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.232378922122344
printing an ep nov before normalisation:  54.19942634997624
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.534986906802704
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.62 ]
 [57.782]
 [64.245]
 [64.577]
 [65.18 ]] [[0.389]
 [0.376]
 [0.478]
 [0.483]
 [0.493]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  68.13441693199975
siam score:  -0.8827507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.74608707033525
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  136.34487792064462
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.377284998045127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.542074602451414
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.638]
 [22.906]
 [28.531]
 [20.137]
 [22.658]] [[0.345]
 [0.415]
 [0.727]
 [0.262]
 [0.402]]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.944701194763184
siam score:  -0.88944227
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.170368777602455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.78749219128656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.62476825200219
printing an ep nov before normalisation:  35.33385753631592
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.13477730422308
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.005251445352414
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.036]
 [35.294]
 [20.587]
 [20.587]
 [20.587]] [[0.813]
 [1.359]
 [0.576]
 [0.576]
 [0.576]]
printing an ep nov before normalisation:  20.11813206434559
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.45655793407793
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.08189777029621
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.124060547262175
printing an ep nov before normalisation:  43.12002822828093
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 67.70565302153052
printing an ep nov before normalisation:  38.15988580459349
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.473869486473994
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.951]
 [19.241]
 [19.241]
 [70.383]
 [19.241]] [[ 0.644]
 [-0.203]
 [-0.203]
 [ 0.766]
 [-0.203]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87611735
printing an ep nov before normalisation:  29.233374075068745
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.567]
 [17.501]
 [12.567]
 [12.567]
 [12.567]] [[0.424]
 [0.725]
 [0.424]
 [0.424]
 [0.424]]
printing an ep nov before normalisation:  25.683441544721717
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.83606415450481
printing an ep nov before normalisation:  32.53157510281861
printing an ep nov before normalisation:  27.8456922742389
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  96.50922262545986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.508148163028565
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  107.39462844506674
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.567280292510986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  34.0683474720185
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.15 ]
 [54.592]
 [69.234]
 [68.984]
 [62.616]] [[1.057]
 [1.036]
 [1.601]
 [1.592]
 [1.346]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  94.10281721765152
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  104.30470773908534
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0022,     0.9670,     0.0003,     0.0002,     0.0303],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0018,     0.9062,     0.0351,     0.0568],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0058,     0.0012,     0.0004,     0.7877,     0.2049],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0111, 0.1171, 0.1241, 0.2249, 0.5227], grad_fn=<DivBackward0>)
siam score:  -0.8805454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.954643635701526
actions average: 
K:  4  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0001,     0.0009],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9509,     0.0006,     0.0007,     0.0477],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0333,     0.0002,     0.9071,     0.0272,     0.0322],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0029,     0.0009,     0.0006,     0.8661,     0.1294],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0047, 0.0564, 0.1431, 0.0609, 0.7349], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.35182604684971
printing an ep nov before normalisation:  122.22083640328233
siam score:  -0.88504744
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0001,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0021,     0.9497,     0.0147,     0.0008,     0.0327],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0026,     0.9487,     0.0138,     0.0348],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0003,     0.0379,     0.8354,     0.1260],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0019, 0.0823, 0.2429, 0.6718], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  6.219335318746744e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9990,     0.0001,     0.0000,     0.0005,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0324, 0.0032, 0.8765, 0.0231, 0.0649], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0011,     0.0314,     0.7640,     0.2031],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0027, 0.0558, 0.0777, 0.1104, 0.7533], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.88717136910894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.795]
 [19.854]
 [23.142]
 [20.529]
 [18.07 ]] [[0.664]
 [0.561]
 [0.736]
 [0.597]
 [0.466]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.21 ]
 [19.725]
 [16.868]
 [24.994]
 [15.499]] [[0.329]
 [0.485]
 [0.358]
 [0.72 ]
 [0.297]]
printing an ep nov before normalisation:  28.729315997170975
printing an ep nov before normalisation:  60.822269016869996
printing an ep nov before normalisation:  43.503300766846515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  25.56637122444158
printing an ep nov before normalisation:  43.35023791070867
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.204]
 [17.701]
 [18.389]
 [26.634]
 [25.167]] [[0.424]
 [0.357]
 [0.388]
 [0.755]
 [0.69 ]]
printing an ep nov before normalisation:  13.549071674944697
UNIT TEST: sample policy line 217 mcts : [0.592 0.041 0.245 0.061 0.061]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  127.67519520047055
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
siam score:  -0.8753635
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  9.107287723963964e-06
line 256 mcts: sample exp_bonus 0.0004586108090620656
printing an ep nov before normalisation:  29.64805039198763
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  19.29685936552052
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.172286591606515
printing an ep nov before normalisation:  41.926568064863325
printing an ep nov before normalisation:  65.46208330460941
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.386]
 [20.777]
 [19.173]
 [31.074]
 [22.723]] [[0.627]
 [0.466]
 [0.394]
 [0.926]
 [0.553]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8775576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.163 0.02  0.02  0.755 0.041]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.50124616203375
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.474]
 [86.474]
 [86.474]
 [86.474]
 [86.474]] [[172.948]
 [172.948]
 [172.948]
 [172.948]
 [172.948]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.0012957436365468311
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.746]
 [55.012]
 [59.915]
 [73.389]
 [59.915]] [[1.556]
 [1.031]
 [1.155]
 [1.496]
 [1.155]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 26.25297139174203
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9995,     0.0001,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0004,     0.9097,     0.0232,     0.0667],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0027,     0.0006,     0.0007,     0.8431,     0.1529],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0099, 0.0052, 0.1355, 0.2324, 0.6169], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.30309980115193
printing an ep nov before normalisation:  32.89440218668376
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.475]
 [42.586]
 [52.567]
 [53.68 ]
 [53.337]] [[0.809]
 [0.813]
 [1.229]
 [1.275]
 [1.261]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  121.46291814020405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  66.18322829803921
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.002822637557983
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.318]
 [14.318]
 [14.318]
 [14.318]
 [14.318]] [[0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]]
printing an ep nov before normalisation:  34.61131243217714
printing an ep nov before normalisation:  27.404292640251448
printing an ep nov before normalisation:  35.597879461409796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.586]
 [35.118]
 [33.952]
 [32.3  ]
 [32.097]] [[1.503]
 [1.614]
 [1.53 ]
 [1.409]
 [1.395]]
printing an ep nov before normalisation:  25.84536887493505
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.541]
 [32.771]
 [32.771]
 [32.771]
 [32.771]] [[1.769]
 [1.605]
 [1.605]
 [1.605]
 [1.605]]
printing an ep nov before normalisation:  38.83973893631244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.706776312535386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.87655814046978
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.20217343449641
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.715]
 [27.037]
 [27.683]
 [27.965]
 [27.599]] [[0.256]
 [0.245]
 [0.256]
 [0.261]
 [0.254]]
printing an ep nov before normalisation:  26.95221969256307
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.418]
 [40.867]
 [57.829]
 [70.248]
 [69.933]] [[1.167]
 [0.49 ]
 [0.939]
 [1.268]
 [1.26 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 24.943027486677128
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 74.251]
 [ 74.251]
 [115.121]
 [ 74.251]
 [ 74.251]] [[0.301]
 [0.301]
 [0.577]
 [0.301]
 [0.301]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9988,     0.0000,     0.0007,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0004,     0.9637,     0.0024,     0.0017,     0.0318],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0073,     0.9326,     0.0150,     0.0449],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0001,     0.0008,     0.8053,     0.1936],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0008, 0.0159, 0.0890, 0.2425, 0.6518], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  30.98475210381604
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.56041020431302
printing an ep nov before normalisation:  35.925052877440244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  77.92237682256015
printing an ep nov before normalisation:  72.74379128406103
printing an ep nov before normalisation:  130.41802598340334
siam score:  -0.8824593
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.023196065906184
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.502]
 [15.796]
 [15.796]
 [15.796]
 [12.718]] [[0.327]
 [0.427]
 [0.427]
 [0.427]
 [0.294]]
printing an ep nov before normalisation:  21.01041351039293
printing an ep nov before normalisation:  31.622485664857503
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0001,     0.0011],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9992,     0.0002,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0164,     0.0225,     0.9457,     0.0001,     0.0153],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0040,     0.0004,     0.0008,     0.8767,     0.1181],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0015, 0.0022, 0.0988, 0.2879, 0.6096], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[141.611]
 [ 90.599]
 [143.475]
 [141.611]
 [141.611]] [[1.562]
 [0.733]
 [1.592]
 [1.562]
 [1.562]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.67084503173828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.28524321452395
printing an ep nov before normalisation:  47.71705870928689
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.41270399093628
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.404]
 [56.623]
 [43.05 ]
 [30.404]
 [31.548]] [[0.244]
 [0.643]
 [0.436]
 [0.244]
 [0.261]]
printing an ep nov before normalisation:  30.196055333685848
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8891498
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[92.723]
 [75.857]
 [90.034]
 [89.819]
 [89.8  ]] [[1.352]
 [0.948]
 [1.288]
 [1.283]
 [1.282]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.942]
 [72.26 ]
 [80.133]
 [86.448]
 [86.591]] [[1.305]
 [0.874]
 [1.091]
 [1.264]
 [1.268]]
printing an ep nov before normalisation:  49.62074040149517
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.713]
 [34.713]
 [34.713]
 [34.713]
 [38.155]] [[1.381]
 [1.381]
 [1.381]
 [1.381]
 [1.667]]
printing an ep nov before normalisation:  29.246943404943845
siam score:  -0.89033544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9924,     0.0011,     0.0047,     0.0001,     0.0016],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9994,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0102,     0.9342,     0.0151,     0.0403],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0009, 0.0009, 0.0115, 0.8166, 0.1701], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0010, 0.0044, 0.0688, 0.1981, 0.7276], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  128.37805473250629
printing an ep nov before normalisation:  60.85405946452764
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.74648316707415
printing an ep nov before normalisation:  81.9557347797813
printing an ep nov before normalisation:  64.83077049255371
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  100.53251734549795
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.677]
 [40.672]
 [44.862]
 [41.933]
 [41.226]] [[0.286]
 [1.246]
 [1.483]
 [1.317]
 [1.277]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.855]
 [31.473]
 [31.407]
 [31.021]
 [30.97 ]] [[1.225]
 [1.369]
 [1.363]
 [1.328]
 [1.324]]
using explorer policy with actor:  1
siam score:  -0.8825092
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.319]
 [24.319]
 [24.319]
 [24.319]
 [24.319]] [[48.638]
 [48.638]
 [48.638]
 [48.638]
 [48.638]]
printing an ep nov before normalisation:  30.304955865567837
printing an ep nov before normalisation:  22.50554228760544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.517878134452257
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  103.95187258003617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  112.6582458927433
printing an ep nov before normalisation:  30.8113956451416
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.158]
 [31.013]
 [50.422]
 [43.795]
 [48.388]] [[1.017]
 [0.642]
 [1.043]
 [0.906]
 [1.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.31118718657733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  97.89398489477674
printing an ep nov before normalisation:  88.51892857565959
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.37256311252969
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.72876013777437
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.191]
 [25.398]
 [77.668]
 [25.398]
 [25.398]] [[ 0.557]
 [-0.111]
 [ 0.705]
 [-0.111]
 [-0.111]]
printing an ep nov before normalisation:  34.46236537687319
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.057978222167954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8877232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.70849279028065
printing an ep nov before normalisation:  43.35203940929336
siam score:  -0.8905447
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.53906027497897
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.11629804359266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  59.54949827547632
printing an ep nov before normalisation:  61.023565934203084
printing an ep nov before normalisation:  54.189546453675526
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  74.74518087910724
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  92.087322473526
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.85 ]
 [21.85 ]
 [29.789]
 [21.85 ]
 [21.85 ]] [[0.591]
 [0.591]
 [1.   ]
 [0.591]
 [0.591]]
actions average: 
K:  2  action  0 :  tensor([    0.9616,     0.0008,     0.0290,     0.0009,     0.0078],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9601,     0.0000,     0.0002,     0.0394],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0092,     0.9474,     0.0007,     0.0426],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0007,     0.0012,     0.0100,     0.7931,     0.1950],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0046, 0.0373, 0.0305, 0.2343, 0.6932], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  41.35948049078182
printing an ep nov before normalisation:  25.96716238609453
printing an ep nov before normalisation:  30.049515861421828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9991,     0.0000,     0.0000,     0.0002,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0087,     0.9742,     0.0004,     0.0002,     0.0166],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9283,     0.0149,     0.0566],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0103, 0.0064, 0.0299, 0.8256, 0.1278], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0669, 0.0233, 0.0514, 0.0652, 0.7932], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  87.21352561406843
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.007047033390108481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.332257678771825
printing an ep nov before normalisation:  41.39348782347204
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.40331306275376
printing an ep nov before normalisation:  17.808730460277374
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  45.53408674366085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.05 ]
 [28.05 ]
 [31.138]
 [28.05 ]
 [28.05 ]] [[1.622]
 [1.622]
 [2.   ]
 [1.622]
 [1.622]]
printing an ep nov before normalisation:  30.3284132586545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8779581
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.112871928993737
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.21099033495669
actions average: 
K:  4  action  0 :  tensor([    0.9756,     0.0023,     0.0000,     0.0059,     0.0162],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9899,     0.0008,     0.0008,     0.0084],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.8413,     0.0380,     0.1203],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0013,     0.0197,     0.9168,     0.0621],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0010, 0.0678, 0.0363, 0.0898, 0.8051], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  51.87766858539522
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.014]
 [27.014]
 [27.014]
 [34.724]
 [27.014]] [[0.736]
 [0.736]
 [0.736]
 [1.127]
 [0.736]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  102.66148795636586
using explorer policy with actor:  1
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.312415846589786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  43.691424502861956
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.98]
 [25.98]
 [25.98]
 [25.98]
 [25.98]] [[0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8836174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8816294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  16.191890064004067
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.008287020662085
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.005]
 [37.953]
 [37.225]
 [32.645]
 [38.801]] [[0.805]
 [1.078]
 [1.045]
 [0.835]
 [1.117]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  16.262167176781
siam score:  -0.8790085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9923,     0.0001,     0.0045,     0.0003,     0.0029],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0022, 0.9725, 0.0022, 0.0040, 0.0190], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9121,     0.0466,     0.0411],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0008,     0.0003,     0.0196,     0.8533,     0.1259],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0005,     0.0326,     0.1348,     0.2038,     0.6282],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  10.030559436488103
printing an ep nov before normalisation:  20.655187269053208
line 256 mcts: sample exp_bonus 21.82700945558998
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.017]
 [29.017]
 [29.017]
 [29.017]
 [29.017]] [[1.318]
 [1.318]
 [1.318]
 [1.318]
 [1.318]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.456]
 [14.758]
 [14.126]
 [14.031]
 [14.126]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  106.1663730206883
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 21.846207976341248
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[113.744]
 [ 93.558]
 [119.815]
 [125.678]
 [110.041]] [[1.369]
 [0.907]
 [1.509]
 [1.643]
 [1.285]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[113.744]
 [ 93.558]
 [119.815]
 [123.554]
 [110.041]] [[1.369]
 [0.907]
 [1.509]
 [1.594]
 [1.285]]
printing an ep nov before normalisation:  19.068101578204832
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.13105930822541
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8805157
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[94.625]
 [94.625]
 [94.625]
 [94.625]
 [94.625]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.998]
 [21.998]
 [21.998]
 [34.586]
 [21.998]] [[0.295]
 [0.295]
 [0.295]
 [0.56 ]
 [0.295]]
siam score:  -0.880031
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.23256032164339
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.49265604017794
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.98407573650126
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9964,     0.0002,     0.0000,     0.0002,     0.0031],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9998,     0.0001,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9979,     0.0003,     0.0018],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0021,     0.0007,     0.0005,     0.8458,     0.1509],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0052, 0.0224, 0.0180, 0.2411, 0.7133], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.11619950940093
printing an ep nov before normalisation:  62.53998509487765
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0012,     0.9852,     0.0007,     0.0002,     0.0127],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9566,     0.0225,     0.0208],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0009,     0.0005,     0.0510,     0.7065,     0.2411],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0129, 0.0337, 0.0584, 0.1883, 0.7067], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  35.98156792565591
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.97128726226993
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.84 ]
 [26.463]
 [21.979]
 [16.632]
 [20.83 ]] [[0.101]
 [0.188]
 [0.143]
 [0.089]
 [0.131]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  111.34389555719832
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.789]
 [67.707]
 [84.384]
 [84.598]
 [86.662]] [[0.691]
 [0.519]
 [0.803]
 [0.807]
 [0.842]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  87.17227993421086
printing an ep nov before normalisation:  30.824237477904788
printing an ep nov before normalisation:  21.31603304301637
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.05919752983477
printing an ep nov before normalisation:  76.84901013885384
siam score:  -0.8845383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.105081807812745
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.74303911709515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.8889911
actions average: 
K:  3  action  0 :  tensor([    0.9960,     0.0004,     0.0002,     0.0009,     0.0025],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9979,     0.0001,     0.0006,     0.0012],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0003,     0.0161,     0.9184,     0.0044,     0.0607],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0005,     0.0145,     0.7894,     0.1951],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0007, 0.0469, 0.0424, 0.2139, 0.6960], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0107,     0.9877,     0.0007,     0.0002,     0.0007],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0260, 0.0018, 0.9322, 0.0130, 0.0270], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0234,     0.0006,     0.0144,     0.8465,     0.1151],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0543, 0.0220, 0.0347, 0.2768, 0.6123], grad_fn=<DivBackward0>)
siam score:  -0.89043695
printing an ep nov before normalisation:  61.43040652738512
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.324]
 [17.324]
 [17.324]
 [30.287]
 [17.324]] [[0.614]
 [0.614]
 [0.614]
 [1.456]
 [0.614]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.427717551790344
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  69.16765949380033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  107.73577984110578
printing an ep nov before normalisation:  37.83241267584238
printing an ep nov before normalisation:  55.6664571232662
printing an ep nov before normalisation:  54.01480864362898
printing an ep nov before normalisation:  27.26677894592285
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.540283097399815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  90.52942255996935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.88 ]
 [14.308]
 [13.275]
 [13.381]
 [13.381]] [[0.286]
 [0.267]
 [0.232]
 [0.236]
 [0.236]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  23.999621868133545
actions average: 
K:  0  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0002,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9736,     0.0009,     0.0001,     0.0252],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0009, 0.0175, 0.8865, 0.0387, 0.0564], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0009,     0.0004,     0.0012,     0.8423,     0.1552],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0028, 0.0255, 0.0245, 0.2904, 0.6569], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.697]
 [60.626]
 [59.14 ]
 [58.141]
 [34.697]] [[0.162]
 [0.942]
 [0.897]
 [0.867]
 [0.162]]
printing an ep nov before normalisation:  29.082355229053466
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  53.517472743988044
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [57.612]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[-0.794]
 [ 0.736]
 [-0.794]
 [-0.794]
 [-0.794]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.56842681129473
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.37769311726421
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  28.209969878188982
line 256 mcts: sample exp_bonus 23.00651561299283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  91.04235056670203
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  63.040309837135325
actions average: 
K:  2  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9992,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0070,     0.9348,     0.0197,     0.0384],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0011,     0.0003,     0.0670,     0.7049,     0.2267],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0154, 0.0032, 0.0986, 0.1123, 0.7705], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.668388974169943
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.771]
 [27.821]
 [27.19 ]
 [25.268]
 [49.315]] [[1.006]
 [1.333]
 [1.282]
 [1.127]
 [3.066]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0011,     0.9436,     0.0009,     0.0052,     0.0492],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9491,     0.0270,     0.0238],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0001,     0.0003,     0.9466,     0.0529],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0283, 0.0564, 0.0825, 0.1953, 0.6375], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.585]
 [78.876]
 [78.876]
 [78.876]
 [78.876]] [[1.097]
 [0.969]
 [0.969]
 [0.969]
 [0.969]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.881219
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.643]
 [42.451]
 [32.287]
 [29.98 ]
 [41.705]] [[0.423]
 [0.692]
 [0.413]
 [0.35 ]
 [0.672]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.454401969909668
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  28.939861621338988
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  26.315425983068724
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.43211802187919
printing an ep nov before normalisation:  34.767327033730396
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.303]
 [23.841]
 [23.374]
 [26.492]
 [23.995]] [[0.245]
 [0.176]
 [0.168]
 [0.217]
 [0.178]]
printing an ep nov before normalisation:  35.64565354669938
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  101.6043092182567
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.895593488352795
printing an ep nov before normalisation:  84.93437661875043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.199]
 [83.199]
 [83.199]
 [83.199]
 [83.199]] [[1.625]
 [1.625]
 [1.625]
 [1.625]
 [1.625]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.13307134135702
printing an ep nov before normalisation:  74.20134175498478
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.70288026022936
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.562]
 [32.562]
 [32.562]
 [45.423]
 [32.562]] [[0.745]
 [0.745]
 [0.745]
 [1.17 ]
 [0.745]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 20.539817094802856
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.329895159057074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.743888309018956
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.55040489104911
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  78.4889874744159
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.36111214703689
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.461]
 [75.461]
 [75.461]
 [75.268]
 [75.461]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  23.776339858310394
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  107.69318748854451
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.573]
 [17.27 ]
 [17.573]
 [17.573]
 [17.573]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8814319
printing an ep nov before normalisation:  13.960987710830974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.112]
 [35.018]
 [28.001]
 [33.173]
 [32.773]] [[0.107]
 [0.266]
 [0.213]
 [0.252]
 [0.249]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.1050044148046
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  81.20425769260952
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.749]
 [42.749]
 [58.419]
 [42.749]
 [42.749]] [[0.55 ]
 [0.55 ]
 [0.934]
 [0.55 ]
 [0.55 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.875533
printing an ep nov before normalisation:  25.953741322639605
printing an ep nov before normalisation:  73.6335712812889
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.150426990869164
printing an ep nov before normalisation:  93.40243242104026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.01160399258603
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.18339653773999
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9977,     0.0004,     0.0013,     0.0001,     0.0006],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9669,     0.0090,     0.0006,     0.0233],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0013, 0.0014, 0.9481, 0.0112, 0.0380], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0006,     0.0005,     0.8752,     0.1234],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0020, 0.0020, 0.1563, 0.2674, 0.5723], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.596143176079643
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  70.38189040289984
printing an ep nov before normalisation:  1.1912047455098218e-05
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.515633454397765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.764]
 [57.67 ]
 [23.764]
 [23.764]
 [23.764]] [[-0.022]
 [ 0.875]
 [-0.022]
 [-0.022]
 [-0.022]]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.850758351971766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.370731814796358
printing an ep nov before normalisation:  17.614794624870363
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  49.20384271738446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.50387828037213
printing an ep nov before normalisation:  54.311703798056506
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.458]
 [18.412]
 [15.164]
 [18.412]
 [18.412]] [[1.219]
 [0.572]
 [0.411]
 [0.572]
 [0.572]]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  22.674439287922876
UNIT TEST: sample policy line 217 mcts : [0.245 0.306 0.163 0.163 0.122]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.523]
 [21.589]
 [28.279]
 [23.039]
 [23.021]] [[0.499]
 [0.82 ]
 [1.174]
 [0.897]
 [0.896]]
printing an ep nov before normalisation:  28.16145541984473
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.601794784587405
printing an ep nov before normalisation:  90.14726931890634
printing an ep nov before normalisation:  23.17206382751465
printing an ep nov before normalisation:  65.38801301026652
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.02390085354591065
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.8853969
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.02  0.714 0.02  0.224 0.02 ]
printing an ep nov before normalisation:  30.631837003260934
line 256 mcts: sample exp_bonus 41.22337086154375
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.391]
 [30.353]
 [68.201]
 [30.353]
 [30.353]] [[ 0.79 ]
 [-0.241]
 [ 0.758]
 [-0.241]
 [-0.241]]
line 256 mcts: sample exp_bonus 65.10479456696362
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.02732609424965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 95.29917524278306
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.153373213683686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.440019227823832
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.50445150586418
printing an ep nov before normalisation:  15.954368114471436
printing an ep nov before normalisation:  14.335047818181234
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.537]
 [ 0.001]
 [18.537]
 [18.537]
 [ 0.   ]] [[2.]
 [0.]
 [2.]
 [2.]
 [0.]]
siam score:  -0.8791822
printing an ep nov before normalisation:  84.4768264426756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  33.39395069670519
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8841934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.43164134222192
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.091]
 [30.282]
 [24.091]
 [24.091]
 [24.091]] [[0.448]
 [0.667]
 [0.448]
 [0.448]
 [0.448]]
printing an ep nov before normalisation:  19.601051552456408
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  95.35457016217016
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.0608153531336
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.381]
 [21.381]
 [24.229]
 [21.381]
 [21.381]] [[0.832]
 [0.832]
 [1.026]
 [0.832]
 [0.832]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.473]
 [20.02 ]
 [15.721]
 [38.51 ]
 [24.581]] [[0.275]
 [0.264]
 [0.156]
 [0.728]
 [0.378]]
line 256 mcts: sample exp_bonus 21.943258380737856
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.66854052531794
printing an ep nov before normalisation:  29.734615193704826
printing an ep nov before normalisation:  22.403290919597506
actions average: 
K:  0  action  0 :  tensor([    0.9987,     0.0001,     0.0000,     0.0008,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0168, 0.0033, 0.8802, 0.0239, 0.0758], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0008,     0.0144,     0.8450,     0.1391],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0015, 0.0503, 0.2257, 0.7215], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8784436
printing an ep nov before normalisation:  41.780984502099905
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.665]
 [23.665]
 [25.744]
 [23.665]
 [23.665]] [[0.572]
 [0.572]
 [0.701]
 [0.572]
 [0.572]]
actions average: 
K:  4  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0007,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9990,     0.0002,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0083,     0.9011,     0.0331,     0.0573],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0557,     0.0007,     0.0153,     0.7572,     0.1711],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0035, 0.0334, 0.0878, 0.2511, 0.6241], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9974,     0.0002,     0.0000,     0.0008,     0.0016],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0017,     0.9928,     0.0002,     0.0001,     0.0053],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9193,     0.0313,     0.0494],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0002,     0.0259,     0.8707,     0.1030],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0162, 0.0680, 0.0238, 0.2222, 0.6698], grad_fn=<DivBackward0>)
siam score:  -0.8777139
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.086]
 [23.086]
 [23.086]
 [23.086]
 [23.086]] [[1.167]
 [1.167]
 [1.167]
 [1.167]
 [1.167]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.344]
 [18.344]
 [18.344]
 [18.344]
 [18.344]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  61.91306965679196
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.572]
 [26.902]
 [21.274]
 [22.001]
 [26.707]] [[0.32 ]
 [0.556]
 [0.307]
 [0.339]
 [0.547]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.453]
 [35.705]
 [35.705]
 [35.705]
 [35.705]] [[0.632]
 [0.579]
 [0.579]
 [0.579]
 [0.579]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.628]
 [29.628]
 [29.628]
 [29.628]
 [29.628]] [[1.467]
 [1.467]
 [1.467]
 [1.467]
 [1.467]]
actions average: 
K:  2  action  0 :  tensor([    0.9991,     0.0000,     0.0003,     0.0003,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9663,     0.0183,     0.0001,     0.0148],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0011,     0.7931,     0.0707,     0.1350],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0008, 0.0008, 0.0013, 0.7452, 0.2519], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0019, 0.0104, 0.0547, 0.2483, 0.6847], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  34.75691231669617
printing an ep nov before normalisation:  51.220499002586635
siam score:  -0.87788284
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.45166327069781
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.328]
 [44.076]
 [32.328]
 [39.998]
 [43.918]] [[0.53 ]
 [0.908]
 [0.53 ]
 [0.777]
 [0.903]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  37.838386465563914
printing an ep nov before normalisation:  78.92470689342518
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [13.416]
 [ 9.39 ]
 [ 0.   ]] [[-0.375]
 [-0.375]
 [ 0.83 ]
 [ 0.468]
 [-0.375]]
printing an ep nov before normalisation:  24.183893696207893
printing an ep nov before normalisation:  30.968455335677238
printing an ep nov before normalisation:  44.66089002084288
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.723348101851702
printing an ep nov before normalisation:  15.968382358551025
printing an ep nov before normalisation:  34.702396392822266
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.214644690824722
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.063]
 [27.063]
 [27.063]
 [22.155]
 [27.063]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.3098958486329
printing an ep nov before normalisation:  39.627572208459775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.858214598761407
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.56042971558563
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.41065100581753
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.197]
 [17.197]
 [19.592]
 [17.197]
 [17.197]] [[0.752]
 [0.752]
 [0.952]
 [0.752]
 [0.752]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [51.175]
 [51.175]
 [51.175]] [[0.   ]
 [0.   ]
 [0.796]
 [0.796]
 [0.796]]
actions average: 
K:  4  action  0 :  tensor([    0.9642,     0.0008,     0.0000,     0.0023,     0.0327],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9920,     0.0015,     0.0020,     0.0044],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0146,     0.9189,     0.0034,     0.0631],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0006,     0.0382,     0.7995,     0.1614],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0041, 0.0410, 0.0913, 0.1234, 0.7402], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  76.2249991675411
printing an ep nov before normalisation:  25.23562078252912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.236]
 [32.035]
 [32.035]
 [32.035]
 [32.035]] [[1.251]
 [0.996]
 [0.996]
 [0.996]
 [0.996]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.34327942651774
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.484]
 [39.79 ]
 [53.6  ]
 [59.734]
 [38.244]] [[1.083]
 [0.531]
 [0.867]
 [1.016]
 [0.494]]
printing an ep nov before normalisation:  21.99217650564757
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8819158
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.62618290426628
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.170215518050966
printing an ep nov before normalisation:  24.14683234803491
printing an ep nov before normalisation:  81.54871374106195
printing an ep nov before normalisation:  25.365885696453265
printing an ep nov before normalisation:  21.271121351724346
printing an ep nov before normalisation:  65.02672672271729
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.45638246132588
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.464]
 [43.464]
 [37.308]
 [43.464]
 [43.464]] [[1.149]
 [1.149]
 [0.907]
 [1.149]
 [1.149]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.71965636863354
printing an ep nov before normalisation:  23.576500972328283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.8728547
printing an ep nov before normalisation:  26.97048001288212
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.876216
printing an ep nov before normalisation:  26.57151899112509
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.723268759386315
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.336]
 [22.336]
 [24.856]
 [22.298]
 [22.336]] [[1.048]
 [1.048]
 [1.247]
 [1.045]
 [1.048]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87743574
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.626]
 [49.1  ]
 [43.523]
 [43.242]
 [41.187]] [[0.472]
 [0.326]
 [0.261]
 [0.257]
 [0.233]]
printing an ep nov before normalisation:  34.078023415829165
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  119.65595746975553
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  99.40237391022815
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  118.83371404303217
actions average: 
K:  4  action  0 :  tensor([    0.9980,     0.0003,     0.0000,     0.0005,     0.0012],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9988,     0.0000,     0.0003,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0018,     0.9286,     0.0101,     0.0594],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0006,     0.0016,     0.0433,     0.8087,     0.1458],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0013, 0.0099, 0.0393, 0.1144, 0.8351], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.35869067173093
printing an ep nov before normalisation:  76.30468471953063
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.78308680618069
printing an ep nov before normalisation:  29.207715442827762
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.183027996828365
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.553]
 [13.092]
 [11.846]
 [10.739]
 [10.838]] [[0.323]
 [0.401]
 [0.337]
 [0.281]
 [0.286]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  15.474172830581665
printing an ep nov before normalisation:  12.12814849591681
printing an ep nov before normalisation:  91.38828705636267
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.727345253155487
printing an ep nov before normalisation:  64.07814090309161
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9953,     0.0002,     0.0031,     0.0006,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9245,     0.0030,     0.0051,     0.0672],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0009,     0.0090,     0.9433,     0.0010,     0.0459],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0004,     0.0008,     0.8317,     0.1666],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0046, 0.0034, 0.0234, 0.3853, 0.5833], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  2.266244791826466e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  21.43002510688134
siam score:  -0.8759197
printing an ep nov before normalisation:  6.59522484860291
siam score:  -0.87752265
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.444]
 [28.251]
 [39.345]
 [40.543]
 [29.56 ]] [[0.167]
 [0.111]
 [0.187]
 [0.195]
 [0.12 ]]
printing an ep nov before normalisation:  49.31009960549517
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8820298
using explorer policy with actor:  1
printing an ep nov before normalisation:  65.06101175975438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  106.32373820513453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  86.88909332142258
printing an ep nov before normalisation:  30.969765933080446
printing an ep nov before normalisation:  36.585961297796565
printing an ep nov before normalisation:  18.912003841407767
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.898783007757885
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.436]
 [39.76 ]
 [37.331]
 [35.005]
 [37.349]] [[1.085]
 [1.353]
 [1.202]
 [1.058]
 [1.203]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.934775204520587
printing an ep nov before normalisation:  29.694966565690866
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.038]
 [0.038]
 [0.038]
 [0.038]
 [0.038]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.937]
 [34.26 ]
 [34.26 ]
 [34.598]
 [34.26 ]] [[1.444]
 [1.972]
 [1.972]
 [2.   ]
 [1.972]]
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  11.63828828307348
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[5.239]
 [6.23 ]
 [4.185]
 [6.004]
 [3.954]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.205]
 [35.354]
 [40.997]
 [39.435]
 [39.223]] [[0.699]
 [0.945]
 [1.279]
 [1.187]
 [1.174]]
printing an ep nov before normalisation:  10.762704169753112
printing an ep nov before normalisation:  20.342206504924526
printing an ep nov before normalisation:  36.39085487752651
printing an ep nov before normalisation:  16.049621834576495
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.310213088989258
printing an ep nov before normalisation:  31.315341248181337
printing an ep nov before normalisation:  21.342755565357407
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  10.723378575608386
printing an ep nov before normalisation:  42.11580083672191
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.600370985012407
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.776]
 [36.776]
 [36.776]
 [49.53 ]
 [39.88 ]] [[0.613]
 [0.613]
 [0.613]
 [0.943]
 [0.693]]
printing an ep nov before normalisation:  31.662095947758818
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.910446984992163
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.4  ]
 [15.686]
 [21.79 ]
 [16.376]
 [17.475]] [[0.784]
 [0.504]
 [0.7  ]
 [0.526]
 [0.561]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.927]
 [16.931]
 [16.784]
 [16.252]
 [16.477]] [[0.859]
 [0.772]
 [0.759]
 [0.713]
 [0.733]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.273]
 [16.273]
 [16.273]
 [16.273]
 [16.273]] [[0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.697]
 [18.386]
 [18.697]
 [18.697]
 [18.697]] [[1.244]
 [1.211]
 [1.244]
 [1.244]
 [1.244]]
printing an ep nov before normalisation:  63.4825925927271
printing an ep nov before normalisation:  25.490246773687495
printing an ep nov before normalisation:  17.210504643489855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0002,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0003,     0.8734,     0.0503,     0.0760],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0045, 0.0010, 0.0206, 0.7969, 0.1769], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0027, 0.0340, 0.0012, 0.3305, 0.6316], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.981]
 [42.681]
 [36.981]
 [36.981]
 [45.955]] [[0.989]
 [1.217]
 [0.989]
 [0.989]
 [1.348]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.28399090665265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  72.90385447362215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.196]
 [69.196]
 [ 1.982]
 [ 1.879]
 [ 1.976]] [[0.324]
 [0.324]
 [0.009]
 [0.009]
 [0.009]]
siam score:  -0.88538146
printing an ep nov before normalisation:  34.23681995492372
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.666]
 [71.747]
 [71.747]
 [53.035]
 [71.747]] [[0.949]
 [0.914]
 [0.914]
 [0.571]
 [0.914]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.563]
 [45.473]
 [44.565]
 [36.846]
 [42.508]] [[0.646]
 [0.712]
 [0.68 ]
 [0.413]
 [0.609]]
printing an ep nov before normalisation:  26.118497848510742
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.41877909221311
siam score:  -0.882897
printing an ep nov before normalisation:  80.33093683677637
printing an ep nov before normalisation:  22.507398271549004
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.383]
 [20.383]
 [24.489]
 [20.383]
 [20.383]] [[0.384]
 [0.384]
 [0.583]
 [0.384]
 [0.384]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.06429737250325
printing an ep nov before normalisation:  58.18037645233373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.81776237487793
printing an ep nov before normalisation:  31.008995612865004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  103.46330917991357
printing an ep nov before normalisation:  90.65301731034536
printing an ep nov before normalisation:  1.9789806060543924e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  15.887355046230287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  13.774730150947441
printing an ep nov before normalisation:  20.858486762031248
printing an ep nov before normalisation:  34.126655027901485
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.0005444182795599772
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  11.845235171743813
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 20.649280953593692
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  0  action  0 :  tensor([    0.9835,     0.0048,     0.0000,     0.0064,     0.0053],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9752,     0.0091,     0.0023,     0.0132],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0006,     0.0131,     0.8727,     0.0207,     0.0929],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0004,     0.0141,     0.8363,     0.1488],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0031, 0.0381, 0.0657, 0.2886, 0.6046], grad_fn=<DivBackward0>)
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.87303734
printing an ep nov before normalisation:  27.543825230386762
printing an ep nov before normalisation:  108.32272245342588
printing an ep nov before normalisation:  61.25812203600973
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9420,     0.0004,     0.0486,     0.0047,     0.0044],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0045, 0.9440, 0.0127, 0.0015, 0.0373], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0178, 0.0059, 0.9192, 0.0208, 0.0363], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0379,     0.0005,     0.0198,     0.8486,     0.0932],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0759, 0.0606, 0.0750, 0.1922, 0.5963], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.71 ]
 [57.483]
 [32.883]
 [47.003]
 [48.227]] [[0.382]
 [0.372]
 [0.165]
 [0.284]
 [0.294]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.904804945884614
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8710995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.90606117248535
UNIT TEST: sample policy line 217 mcts : [0.776 0.02  0.041 0.041 0.122]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.158]
 [26.158]
 [26.158]
 [26.158]
 [26.158]] [[0.125]
 [0.125]
 [0.125]
 [0.125]
 [0.125]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.834]
 [41.834]
 [82.985]
 [41.834]
 [41.834]] [[0.172]
 [0.172]
 [0.468]
 [0.172]
 [0.172]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.09953449277317
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.9 ]
 [20.78]
 [17.9 ]
 [17.9 ]
 [17.9 ]] [[0.402]
 [0.533]
 [0.402]
 [0.402]
 [0.402]]
actions average: 
K:  0  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0007,     0.9780,     0.0001,     0.0004,     0.0206],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0002,     0.9174,     0.0426,     0.0398],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0003,     0.0002,     0.8386,     0.1606],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0024, 0.0380, 0.0901, 0.1630, 0.7065], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  22.272063954950237
printing an ep nov before normalisation:  91.74662102748009
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  19.700443984189217
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.077]
 [58.843]
 [45.077]
 [45.077]
 [56.155]] [[0.767]
 [1.002]
 [0.767]
 [0.767]
 [0.956]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.137]
 [44.983]
 [19.137]
 [19.137]
 [19.137]] [[0.316]
 [1.078]
 [0.316]
 [0.316]
 [0.316]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8787831
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.306]
 [71.316]
 [67.276]
 [70.148]
 [70.148]] [[2.   ]
 [1.848]
 [1.725]
 [1.812]
 [1.812]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[91.162]
 [91.162]
 [91.162]
 [91.162]
 [91.162]] [[1.727]
 [1.727]
 [1.727]
 [1.727]
 [1.727]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 62.46466095431911
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 60.52191523611401
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  110.43755649562917
printing an ep nov before normalisation:  99.49537257356958
printing an ep nov before normalisation:  70.787868659166
printing an ep nov before normalisation:  97.4162485189818
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 79.45737825738188
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.92 ]
 [71.953]
 [46.92 ]
 [46.92 ]
 [46.92 ]] [[0.796]
 [1.459]
 [0.796]
 [0.796]
 [0.796]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  85.29002618805943
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.66 ]
 [74.424]
 [67.66 ]
 [67.66 ]
 [67.66 ]] [[1.573]
 [1.75 ]
 [1.573]
 [1.573]
 [1.573]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.976]
 [55.392]
 [53.563]
 [73.031]
 [60.913]] [[1.49 ]
 [1.29 ]
 [1.247]
 [1.701]
 [1.419]]
printing an ep nov before normalisation:  48.209776878356934
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.337]
 [88.337]
 [88.337]
 [88.337]
 [88.337]] [[1.974]
 [1.974]
 [1.974]
 [1.974]
 [1.974]]
printing an ep nov before normalisation:  25.524911880493164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  63.08254617468422
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.015453974487286
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9968,     0.0001,     0.0018,     0.0003,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9996,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0004,     0.9480,     0.0135,     0.0380],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0005,     0.0004,     0.0098,     0.8314,     0.1578],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0066, 0.0044, 0.0483, 0.3816, 0.5590], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.45 ]
 [11.174]
 [14.64 ]
 [11.749]
 [11.285]] [[0.161]
 [0.153]
 [0.246]
 [0.169]
 [0.156]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.764]
 [51.635]
 [57.231]
 [57.092]
 [56.301]] [[0.158]
 [0.21 ]
 [0.243]
 [0.242]
 [0.237]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.51310382490944
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.796]
 [34.057]
 [49.133]
 [51.971]
 [49.032]] [[0.28 ]
 [0.102]
 [0.246]
 [0.272]
 [0.245]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.559]
 [15.276]
 [22.281]
 [29.653]
 [30.42 ]] [[0.077]
 [0.057]
 [0.083]
 [0.111]
 [0.114]]
using explorer policy with actor:  1
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.59647315392502
printing an ep nov before normalisation:  92.82385835952506
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[10.884]
 [17.848]
 [13.516]
 [11.588]
 [11.145]] [[0.113]
 [0.25 ]
 [0.165]
 [0.127]
 [0.118]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8843689
printing an ep nov before normalisation:  15.05054784370132
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.041]
 [60.041]
 [60.041]
 [83.646]
 [60.041]] [[1.15 ]
 [1.15 ]
 [1.15 ]
 [1.603]
 [1.15 ]]
printing an ep nov before normalisation:  31.291334202252955
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[108.345]
 [ 89.665]
 [109.713]
 [108.345]
 [108.345]] [[0.902]
 [0.668]
 [0.919]
 [0.902]
 [0.902]]
actions average: 
K:  4  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0005,     0.9623,     0.0016,     0.0005,     0.0352],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0009,     0.0006,     0.8424,     0.0596,     0.0965],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0002,     0.0431,     0.8748,     0.0815],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0016, 0.0059, 0.0619, 0.2467, 0.6840], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.901]
 [19.36 ]
 [19.518]
 [19.403]
 [20.218]] [[0.456]
 [0.204]
 [0.207]
 [0.205]
 [0.221]]
printing an ep nov before normalisation:  45.820595043806094
printing an ep nov before normalisation:  56.61715104390545
printing an ep nov before normalisation:  37.786102294921875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  49.3507427671033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.248]
 [69.284]
 [48.72 ]
 [48.72 ]
 [48.72 ]] [[0.345]
 [0.646]
 [0.399]
 [0.399]
 [0.399]]
siam score:  -0.8793962
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.724578030028706
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9952,     0.0003,     0.0025,     0.0002,     0.0018],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0003,     0.9712,     0.0040,     0.0005,     0.0241],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0029,     0.8939,     0.0258,     0.0774],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0011,     0.0004,     0.0159,     0.8114,     0.1713],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0006,     0.0014,     0.1211,     0.1835,     0.6934],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.075]
 [84.937]
 [52.075]
 [52.075]
 [61.806]] [[0.672]
 [1.248]
 [0.672]
 [0.672]
 [0.842]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.94425455042879
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.575]
 [70.575]
 [70.575]
 [78.741]
 [70.575]] [[1.405]
 [1.405]
 [1.405]
 [1.668]
 [1.405]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  91.16938327074709
printing an ep nov before normalisation:  31.53080608254369
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.49609667896861
printing an ep nov before normalisation:  35.502972562309594
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.378]
 [37.018]
 [31.987]
 [38.826]
 [40.042]] [[0.981]
 [1.41 ]
 [1.127]
 [1.511]
 [1.58 ]]
printing an ep nov before normalisation:  21.580813386565186
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.87616193
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.864304486372244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  94.96772590997526
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.02904905734102
printing an ep nov before normalisation:  18.311641155240224
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  80.57383840828942
printing an ep nov before normalisation:  84.78550568872495
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.362]
 [93.541]
 [93.541]
 [93.541]
 [93.541]] [[1.489]
 [1.569]
 [1.569]
 [1.569]
 [1.569]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  68.7713605162048
siam score:  -0.87456846
line 256 mcts: sample exp_bonus 83.59928839186311
siam score:  -0.87641555
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.524]
 [78.712]
 [62.524]
 [62.524]
 [64.039]] [[1.107]
 [1.477]
 [1.107]
 [1.107]
 [1.142]]
line 256 mcts: sample exp_bonus 24.424834572707784
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.846253395080566
printing an ep nov before normalisation:  64.90437542336073
printing an ep nov before normalisation:  40.420427017724236
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.119]
 [28.576]
 [32.337]
 [32.798]
 [32.896]] [[0.227]
 [0.189]
 [0.246]
 [0.253]
 [0.254]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  89.87806556852435
printing an ep nov before normalisation:  22.752227858382845
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.123]
 [18.301]
 [25.088]
 [23.588]
 [26.75 ]] [[0.415]
 [0.423]
 [0.741]
 [0.671]
 [0.818]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  140.19382452989277
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.125]
 [41.03 ]
 [45.431]
 [45.823]
 [48.992]] [[0.708]
 [0.898]
 [1.04 ]
 [1.053]
 [1.155]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.373]
 [62.595]
 [62.595]
 [62.595]
 [62.595]] [[1.549]
 [1.317]
 [1.317]
 [1.317]
 [1.317]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.397]
 [51.397]
 [45.895]
 [51.397]
 [51.397]] [[0.965]
 [0.965]
 [0.862]
 [0.965]
 [0.965]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.612]
 [66.124]
 [64.834]
 [38.344]
 [55.337]] [[0.744]
 [1.074]
 [1.04 ]
 [0.34 ]
 [0.789]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.53241807945157
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.534]
 [29.534]
 [29.534]
 [29.534]
 [29.534]] [[29.534]
 [29.534]
 [29.534]
 [29.534]
 [29.534]]
printing an ep nov before normalisation:  23.42243194580078
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.384]
 [50.384]
 [50.384]
 [50.384]
 [50.384]] [[0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]]
actions average: 
K:  2  action  0 :  tensor([    0.9953,     0.0001,     0.0002,     0.0012,     0.0032],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0035, 0.9787, 0.0021, 0.0063, 0.0094], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9941,     0.0023,     0.0035],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0014,     0.0000,     0.0010,     0.8504,     0.1472],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0208, 0.0092, 0.0644, 0.3260, 0.5797], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9979,     0.0001,     0.0000,     0.0008,     0.0011],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9927,     0.0007,     0.0014,     0.0050],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0004,     0.9812,     0.0005,     0.0178],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0016, 0.0012, 0.0176, 0.9243, 0.0553], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0027, 0.0254, 0.1007, 0.2684, 0.6028], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.317]
 [62.28 ]
 [76.36 ]
 [75.89 ]
 [75.371]] [[1.138]
 [0.721]
 [1.111]
 [1.098]
 [1.084]]
printing an ep nov before normalisation:  43.262025149258946
siam score:  -0.8816547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.929]
 [79.744]
 [76.364]
 [76.364]
 [76.364]] [[1.024]
 [1.105]
 [1.058]
 [1.058]
 [1.058]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  16.187302532614808
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87354714
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  75.85522704401282
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.145]
 [34.145]
 [54.206]
 [34.145]
 [34.145]] [[0.376]
 [0.376]
 [0.762]
 [0.376]
 [0.376]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.629]
 [14.629]
 [14.629]
 [14.629]
 [14.629]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  86.52546827958767
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.153]
 [47.666]
 [55.068]
 [46.95 ]
 [58.205]] [[0.871]
 [0.701]
 [0.93 ]
 [0.679]
 [1.027]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.984497489548144
using explorer policy with actor:  1
siam score:  -0.8668525
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.149841039035834
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.519287254541922
printing an ep nov before normalisation:  40.004259804059735
printing an ep nov before normalisation:  61.51719248994114
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  100.68985310360804
printing an ep nov before normalisation:  74.20113921158269
printing an ep nov before normalisation:  59.32022356682053
printing an ep nov before normalisation:  39.96156739399894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.021]
 [57.021]
 [88.314]
 [57.021]
 [57.021]] [[0.411]
 [0.411]
 [0.824]
 [0.411]
 [0.411]]
printing an ep nov before normalisation:  21.339043573611427
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9994,     0.0001,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9517,     0.0240,     0.0240],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0008,     0.0003,     0.0178,     0.7949,     0.1862],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0014, 0.0019, 0.1197, 0.3432, 0.5338], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  59.266538996213356
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.593]
 [63.834]
 [22.593]
 [22.593]
 [22.593]] [[-0.165]
 [ 0.891]
 [-0.165]
 [-0.165]
 [-0.165]]
UNIT TEST: sample policy line 217 mcts : [0.041 0.694 0.163 0.082 0.02 ]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.246]
 [32.777]
 [40.246]
 [49.624]
 [41.184]] [[0.752]
 [0.546]
 [0.752]
 [1.011]
 [0.778]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.026624315592564
printing an ep nov before normalisation:  86.10519161156051
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.30376896092514
line 256 mcts: sample exp_bonus 21.1126147527156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.59156370162964
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.90639474946658
printing an ep nov before normalisation:  20.658970092290197
printing an ep nov before normalisation:  69.69419961496378
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.053]
 [22.525]
 [18.928]
 [22.722]
 [22.525]] [[1.309]
 [1.001]
 [0.757]
 [1.015]
 [1.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.819823138614147
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0020542235233733663
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  64.3504810333252
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.866]
 [51.866]
 [51.866]
 [64.615]
 [51.866]] [[1.157]
 [1.157]
 [1.157]
 [1.561]
 [1.157]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.983]
 [22.983]
 [27.881]
 [22.983]
 [22.983]] [[0.991]
 [0.991]
 [1.42 ]
 [0.991]
 [0.991]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[2.431]
 [2.584]
 [2.74 ]
 [2.668]
 [1.352]] [[0.314]
 [0.333]
 [0.353]
 [0.344]
 [0.174]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88587576
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.736]
 [67.736]
 [66.845]
 [65.616]
 [67.736]] [[2.   ]
 [2.   ]
 [1.97 ]
 [1.928]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9992,     0.0000,     0.0007,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0040,     0.9800,     0.0008,     0.0004,     0.0147],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0132,     0.0007,     0.8924,     0.0161,     0.0775],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0443, 0.0007, 0.0305, 0.7272, 0.1972], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0978, 0.0069, 0.1007, 0.2128, 0.5819], grad_fn=<DivBackward0>)
siam score:  -0.88196516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  92.43659100206666
printing an ep nov before normalisation:  47.809877401794886
using explorer policy with actor:  1
printing an ep nov before normalisation:  76.87038881626052
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.78590066280516
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.408 0.122 0.204 0.082 0.184]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.188]
 [31.188]
 [31.188]
 [31.188]
 [31.188]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.904]
 [27.999]
 [25.999]
 [27.506]
 [28.394]] [[1.681]
 [1.791]
 [1.59 ]
 [1.742]
 [1.831]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  91.01050928479624
siam score:  -0.8861349
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.092]
 [35.092]
 [35.092]
 [38.308]
 [35.092]] [[1.72 ]
 [1.72 ]
 [1.72 ]
 [1.948]
 [1.72 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8836618
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.775]
 [85.719]
 [86.29 ]
 [78.918]
 [85.838]] [[1.464]
 [1.963]
 [1.981]
 [1.75 ]
 [1.967]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  79.90232105209819
line 256 mcts: sample exp_bonus 48.35585573775089
siam score:  -0.8824394
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  40.67211862961183
siam score:  -0.88072324
printing an ep nov before normalisation:  50.95737729123392
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  54.413103591636876
printing an ep nov before normalisation:  57.74071027193135
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.369]
 [34.281]
 [34.281]
 [34.281]
 [34.281]] [[1.187]
 [0.013]
 [0.013]
 [0.013]
 [0.013]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  66.45939756504816
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.324648568747477
printing an ep nov before normalisation:  55.255694983266636
printing an ep nov before normalisation:  29.842353731876678
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.931]
 [24.931]
 [24.931]
 [39.185]
 [24.931]] [[0.41 ]
 [0.41 ]
 [0.41 ]
 [0.857]
 [0.41 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  97.33531954408852
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  17.51872796401699
printing an ep nov before normalisation:  56.375081547601404
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.127]
 [17.012]
 [23.086]
 [21.258]
 [21.816]] [[1.165]
 [0.573]
 [1.161]
 [0.984]
 [1.038]]
printing an ep nov before normalisation:  17.708374552926834
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.394]
 [73.076]
 [73.614]
 [35.394]
 [35.394]] [[0.03 ]
 [1.096]
 [1.111]
 [0.03 ]
 [0.03 ]]
printing an ep nov before normalisation:  40.52569160124959
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  19.069125591194165
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  31.480392103875605
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.156636714935303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.112012726320188
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  18.465084161241364
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8799226
printing an ep nov before normalisation:  20.16567168435042
printing an ep nov before normalisation:  29.39179051593464
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  20.414767601089743
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.011]
 [18.683]
 [18.683]
 [17.085]
 [18.683]] [[0.42 ]
 [0.407]
 [0.407]
 [0.342]
 [0.407]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.578]
 [76.931]
 [51.671]
 [59.336]
 [59.808]] [[0.936]
 [0.984]
 [0.474]
 [0.629]
 [0.638]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  77.42548120178242
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.87930864
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9967,     0.0002,     0.0000,     0.0007,     0.0024],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.8983,     0.0029,     0.0008,     0.0979],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0009,     0.8301,     0.0473,     0.1216],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0006,     0.0327,     0.7038,     0.2624],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0078,     0.0332,     0.1701,     0.7887],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.414]
 [20.941]
 [14.616]
 [15.552]
 [15.8  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.82620311488218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.605]
 [20.039]
 [27.066]
 [21.112]
 [22.081]] [[0.151]
 [0.143]
 [0.245]
 [0.158]
 [0.172]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.23721774592784
siam score:  -0.8804168
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.41396875580144
printing an ep nov before normalisation:  41.71103135702003
printing an ep nov before normalisation:  27.22313872045365
printing an ep nov before normalisation:  32.12175400983211
printing an ep nov before normalisation:  30.13215408412673
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9941,     0.0001,     0.0053,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0006,     0.9976,     0.0002,     0.0002,     0.0014],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0065,     0.9091,     0.0256,     0.0587],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0005,     0.0062,     0.8287,     0.1644],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0141, 0.0077, 0.0660, 0.2457, 0.6665], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  50.78184470406412
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9981,     0.0001,     0.0006,     0.0011],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0131,     0.8387,     0.0539,     0.0942],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0070, 0.0015, 0.0175, 0.8691, 0.1049], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0037, 0.0556, 0.0534, 0.1346, 0.7526], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9987,     0.0010,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9455,     0.0191,     0.0008,     0.0345],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0019,     0.8860,     0.0453,     0.0668],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0093, 0.0013, 0.0253, 0.7670, 0.1971], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0332, 0.0024, 0.0312, 0.2730, 0.6602], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([0.9108, 0.0257, 0.0011, 0.0204, 0.0420], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9717,     0.0132,     0.0012,     0.0137],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0106, 0.0021, 0.9072, 0.0325, 0.0477], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0012, 0.0324, 0.0374, 0.7871, 0.1419], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0017, 0.0208, 0.0868, 0.3703, 0.5203], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.48280838622205
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.861]
 [69.015]
 [69.581]
 [55.655]
 [66.737]] [[0.658]
 [1.086]
 [1.101]
 [0.732]
 [1.026]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.591819636280164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.632639516032004
printing an ep nov before normalisation:  31.945637294224333
siam score:  -0.87726563
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9775,     0.0028,     0.0007,     0.0187],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9024,     0.0313,     0.0663],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0002,     0.0265,     0.7598,     0.2131],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0025, 0.0195, 0.0953, 0.2049, 0.6778], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  43.086795700759566
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 23.11065342566241
siam score:  -0.8809436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  67.10724344933297
printing an ep nov before normalisation:  29.645707607269287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  41.61952592884865
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.453]
 [52.453]
 [52.453]
 [52.453]
 [52.453]] [[1.526]
 [1.526]
 [1.526]
 [1.526]
 [1.526]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.113]
 [34.71 ]
 [34.71 ]
 [42.679]
 [34.71 ]] [[0.288]
 [0.495]
 [0.495]
 [0.667]
 [0.495]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  32.686307102296354
printing an ep nov before normalisation:  71.44037190452929
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.320360858757184
printing an ep nov before normalisation:  0.056043955038376225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  21.0963773727417
printing an ep nov before normalisation:  86.45162806030011
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  73.98426364164976
printing an ep nov before normalisation:  32.55246684116274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88184524
printing an ep nov before normalisation:  15.772834155307738
printing an ep nov before normalisation:  16.977221036675733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.414]
 [67.74 ]
 [66.554]
 [46.912]
 [66.357]] [[1.31 ]
 [1.498]
 [1.456]
 [0.766]
 [1.449]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.220012544131372
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.014345823174721772
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.163124656231574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  51.77915037537809
printing an ep nov before normalisation:  35.07667426928137
printing an ep nov before normalisation:  34.31180890991378
siam score:  -0.8806744
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.53872274068589
printing an ep nov before normalisation:  35.914569315379886
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.850159671711765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.77813706456858
using explorer policy with actor:  1
printing an ep nov before normalisation:  17.893941617089162
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9967,     0.0027,     0.0000,     0.0003,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9931,     0.0036,     0.0003,     0.0026],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0013,     0.9001,     0.0499,     0.0487],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0008,     0.0004,     0.0012,     0.8207,     0.1770],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0016, 0.0091, 0.0829, 0.1830, 0.7234], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9617,     0.0007,     0.0032,     0.0010,     0.0335],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9970,     0.0018,     0.0001,     0.0010],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0007,     0.0003,     0.9548,     0.0133,     0.0310],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0015,     0.0471,     0.7873,     0.1636],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0155, 0.0442, 0.0654, 0.2925, 0.5823], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.816]
 [12.719]
 [14.814]
 [15.81 ]
 [14.372]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  12.671005720520988
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.664]
 [64.497]
 [53.54 ]
 [51.221]
 [24.664]] [[-0.007]
 [ 1.158]
 [ 0.838]
 [ 0.77 ]
 [-0.007]]
actions average: 
K:  4  action  0 :  tensor([    0.9943,     0.0007,     0.0020,     0.0003,     0.0027],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9798,     0.0003,     0.0006,     0.0191],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0132,     0.9385,     0.0066,     0.0415],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0017,     0.0002,     0.0394,     0.8131,     0.1456],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0139, 0.0489, 0.0613, 0.2717, 0.6041], grad_fn=<DivBackward0>)
siam score:  -0.88585436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9941,     0.0038,     0.0000,     0.0002,     0.0019],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0038,     0.9668,     0.0011,     0.0004,     0.0279],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0004,     0.9393,     0.0290,     0.0313],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0002,     0.0337,     0.8119,     0.1541],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0008, 0.0025, 0.0284, 0.2499, 0.7184], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.974]
 [81.658]
 [83.646]
 [82.793]
 [82.867]] [[0.413]
 [0.642]
 [0.667]
 [0.656]
 [0.657]]
siam score:  -0.88290906
actions average: 
K:  4  action  0 :  tensor([    0.9628,     0.0183,     0.0001,     0.0031,     0.0157],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0008,     0.9770,     0.0007,     0.0002,     0.0213],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0004,     0.8963,     0.0347,     0.0686],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0172,     0.0463,     0.8057,     0.1306],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0024, 0.0376, 0.0534, 0.2622, 0.6444], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 76.75521443223501
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  73.17391684285715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  52.072315891095506
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.234302759170532
printing an ep nov before normalisation:  40.4193391787608
printing an ep nov before normalisation:  21.56015396118164
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87150985
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  62.08222530559658
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.97580040069082
siam score:  -0.88271606
printing an ep nov before normalisation:  95.98303785046045
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.139]
 [36.139]
 [37.084]
 [36.139]
 [36.139]] [[1.337]
 [1.337]
 [1.415]
 [1.337]
 [1.337]]
printing an ep nov before normalisation:  52.505938601535306
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  54.388438066195064
printing an ep nov before normalisation:  28.62293166782791
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.795307548593236
printing an ep nov before normalisation:  45.40689342446346
printing an ep nov before normalisation:  56.15013687612918
printing an ep nov before normalisation:  53.036605309662576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.211]
 [23.553]
 [16.905]
 [16.512]
 [20.293]] [[0.322]
 [0.533]
 [0.271]
 [0.255]
 [0.404]]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  15.959446047634119
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.704]
 [15.153]
 [20.181]
 [14.191]
 [14.563]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.271]
 [21.994]
 [22.883]
 [21.049]
 [21.76 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  15.72446842010892
printing an ep nov before normalisation:  57.261532401117975
siam score:  -0.8788449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  69.31347741740606
printing an ep nov before normalisation:  28.812397236386744
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.04382371902466
actions average: 
K:  1  action  0 :  tensor([    0.9991,     0.0001,     0.0000,     0.0002,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9792,     0.0000,     0.0001,     0.0206],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0010,     0.9274,     0.0228,     0.0483],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0005,     0.0003,     0.7958,     0.2032],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0005,     0.0013,     0.1703,     0.1800,     0.6479],
       grad_fn=<DivBackward0>)
siam score:  -0.87859505
printing an ep nov before normalisation:  35.6394256947894
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.338111981086584
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.20338602152489
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.096748473799625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.434218626135106
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.761362469515866
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.41458222566411
printing an ep nov before normalisation:  28.717161380282757
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.834225407928995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.9987,     0.0001,     0.0000,     0.0001,     0.0011],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0018,     0.9920,     0.0023,     0.0001,     0.0038],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0002,     0.9221,     0.0160,     0.0615],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0006,     0.0664,     0.7640,     0.1689],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0928, 0.0048, 0.2985, 0.6032], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.919]
 [53.042]
 [69.993]
 [78.124]
 [78.346]] [[1.636]
 [0.639]
 [1.319]
 [1.645]
 [1.654]]
siam score:  -0.8824187
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8811259
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  84.9929212078485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.968]
 [37.368]
 [31.024]
 [26.864]
 [31.914]] [[0.136]
 [0.25 ]
 [0.18 ]
 [0.135]
 [0.19 ]]
siam score:  -0.8833034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  58.026051463877344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8804945
printing an ep nov before normalisation:  26.598330227076886
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.32651715103623
printing an ep nov before normalisation:  32.52485703356664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.41733524724407
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.984]
 [16.629]
 [15.949]
 [15.872]
 [15.841]] [[0.348]
 [0.277]
 [0.256]
 [0.254]
 [0.253]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
siam score:  -0.8816788
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.132]
 [45.132]
 [45.132]
 [45.132]
 [45.132]] [[1.999]
 [1.999]
 [1.999]
 [1.999]
 [1.999]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.533452033996582
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  56.08529566229166
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.531]
 [25.459]
 [25.762]
 [20.623]
 [24.969]] [[0.268]
 [0.235]
 [0.24 ]
 [0.157]
 [0.227]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 41.942878128120405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  45.727291107177734
printing an ep nov before normalisation:  31.067512737534724
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.154]
 [74.291]
 [64.34 ]
 [62.045]
 [68.242]] [[0.229]
 [0.274]
 [0.237]
 [0.229]
 [0.252]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8790277
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  44.24260442680981
printing an ep nov before normalisation:  61.69508617992177
printing an ep nov before normalisation:  102.60234607932176
siam score:  -0.8768375
printing an ep nov before normalisation:  58.77769505096101
printing an ep nov before normalisation:  72.85759509489299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.11606717143576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.896]
 [53.896]
 [53.896]
 [53.896]
 [53.896]] [[0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.946]
 [16.643]
 [22.427]
 [29.092]
 [30.541]] [[0.374]
 [0.147]
 [0.288]
 [0.451]
 [0.487]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.384360055431113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.145880896838307
printing an ep nov before normalisation:  15.969157341193013
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.385]
 [80.385]
 [80.385]
 [80.385]
 [80.385]] [[0.698]
 [0.698]
 [0.698]
 [0.698]
 [0.698]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.63575935300435
siam score:  -0.8766242
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.081076708252024
printing an ep nov before normalisation:  24.757245204235666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.00025944306543124185
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.207]
 [16.029]
 [20.207]
 [14.78 ]
 [20.207]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.22324869333802
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.9950,     0.0000,     0.0031,     0.0001,     0.0017],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9992,     0.0001,     0.0001,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0003,     0.9592,     0.0215,     0.0190],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0004,     0.0190,     0.7740,     0.2062],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0026, 0.0160, 0.1805, 0.1672, 0.6337], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  91.73887856293287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9881,     0.0065,     0.0000,     0.0006,     0.0047],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9722,     0.0001,     0.0010,     0.0266],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0049,     0.0000,     0.9391,     0.0155,     0.0405],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0002,     0.0221,     0.8067,     0.1708],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0016, 0.0796, 0.0146, 0.2441, 0.6601], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.376]
 [38.376]
 [38.376]
 [50.569]
 [38.376]] [[0.645]
 [0.645]
 [0.645]
 [1.035]
 [0.645]]
printing an ep nov before normalisation:  33.25432930064452
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.542]
 [42.544]
 [44.64 ]
 [42.542]
 [42.542]] [[1.603]
 [1.603]
 [1.753]
 [1.603]
 [1.603]]
siam score:  -0.8790804
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.958]
 [52.958]
 [52.958]
 [52.958]
 [52.958]] [[1.438]
 [1.438]
 [1.438]
 [1.438]
 [1.438]]
siam score:  -0.8797094
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.05971304121628
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0012,     0.9783,     0.0003,     0.0006,     0.0196],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0003,     0.8524,     0.0475,     0.0996],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0014,     0.0003,     0.0187,     0.8197,     0.1599],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0156, 0.0281, 0.0467, 0.2418, 0.6677], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  72.1573872540363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.534967947676964
actions average: 
K:  0  action  0 :  tensor([    0.9887,     0.0001,     0.0003,     0.0009,     0.0100],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9774,     0.0118,     0.0002,     0.0104],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0024,     0.0003,     0.9427,     0.0148,     0.0398],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0007,     0.0009,     0.8370,     0.1613],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0015, 0.0598, 0.0617, 0.2429, 0.6340], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.861]
 [29.795]
 [29.795]
 [29.795]
 [29.795]] [[1.667]
 [0.956]
 [0.956]
 [0.956]
 [0.956]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.908047353705165
siam score:  -0.8836963
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.51997470855713
printing an ep nov before normalisation:  55.76005935668945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.8902473449707
printing an ep nov before normalisation:  55.281844943777024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.443235766901715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.612]
 [29.503]
 [28.838]
 [27.66 ]
 [27.434]] [[0.182]
 [0.222]
 [0.213]
 [0.196]
 [0.193]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  90.13293860139159
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.596778665411534
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87887144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.55491154122767
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [    -0.0000],
        [     0.0000]], dtype=torch.float64)
0.0 1.5291792883991817e-11
0.0 9.142208757051221e-12
0.0 9.704407022037564e-12
0.0 1.8344961937951925e-11
0.0 1.0673117882973027e-11
0.0 1.4478767696523934e-11
0.0 5.064109014629975e-12
0.0 0.0
0.0 -3.135336490843932e-12
0.0 3.8099744151105985e-12
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.847]
 [16.531]
 [64.356]
 [73.667]
 [16.531]] [[ 0.725]
 [-0.229]
 [ 0.429]
 [ 0.557]
 [-0.229]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  65.8259839163484
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.451]
 [29.35 ]
 [37.504]
 [35.61 ]
 [37.18 ]] [[0.649]
 [0.369]
 [0.65 ]
 [0.585]
 [0.639]]
printing an ep nov before normalisation:  31.09430160729106
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.993651253725847
printing an ep nov before normalisation:  29.911437034606934
printing an ep nov before normalisation:  22.03177177088665
printing an ep nov before normalisation:  41.782429384852136
siam score:  -0.8781463
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  14.616010202740648
printing an ep nov before normalisation:  0.00046307866170991474
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.095040095206045
printing an ep nov before normalisation:  17.126293597654737
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 27.134616528924358
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  17.721990206459218
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87005645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.401]
 [32.401]
 [32.401]
 [32.401]
 [32.401]] [[1.246]
 [1.246]
 [1.246]
 [1.246]
 [1.246]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.813]
 [55.479]
 [50.175]
 [52.443]
 [57.923]] [[0.921]
 [0.768]
 [0.617]
 [0.681]
 [0.838]]
siam score:  -0.8730411
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.721212585398664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  27.011792797831344
printing an ep nov before normalisation:  31.43113777497519
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  87.32957565683903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.04729700088501
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.94409903450677
printing an ep nov before normalisation:  54.593205365565616
siam score:  -0.8881491
printing an ep nov before normalisation:  17.40691913658905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8858882
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.03318293324383603
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.34259434231163
printing an ep nov before normalisation:  42.022134199115506
actions average: 
K:  2  action  0 :  tensor([    0.9969,     0.0004,     0.0000,     0.0011,     0.0016],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9976,     0.0002,     0.0006,     0.0016],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9334,     0.0361,     0.0304],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0013,     0.0024,     0.8456,     0.1505],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0009, 0.0032, 0.0728, 0.2371, 0.6859], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.5335471893856
printing an ep nov before normalisation:  89.6277785218051
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.653]
 [26.031]
 [24.746]
 [26.031]
 [26.031]] [[0.836]
 [0.602]
 [0.556]
 [0.602]
 [0.602]]
actions average: 
K:  3  action  0 :  tensor([    0.9895,     0.0005,     0.0000,     0.0024,     0.0075],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0009,     0.9816,     0.0028,     0.0019,     0.0128],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9726,     0.0005,     0.0268],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0029, 0.0009, 0.0916, 0.6703, 0.2343], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0254, 0.0621, 0.1748, 0.0959, 0.6417], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88066435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  38.672025667387246
printing an ep nov before normalisation:  52.58862155963407
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.978]
 [75.824]
 [94.891]
 [87.765]
 [78.684]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.414157465581763
printing an ep nov before normalisation:  64.37339489970472
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.92725527916584
printing an ep nov before normalisation:  1.123611241382605e-05
printing an ep nov before normalisation:  13.420847790442206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9900,     0.0006,     0.0000,     0.0061,     0.0034],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9992,     0.0001,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0004,     0.9988,     0.0002,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0008,     0.0034,     0.0238,     0.7872,     0.1849],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0014, 0.0015, 0.0486, 0.1987, 0.7498], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 18.85129417118728
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9698,     0.0142,     0.0018,     0.0005,     0.0137],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0004,     0.9683,     0.0147,     0.0003,     0.0163],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9699,     0.0143,     0.0156],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0016,     0.0002,     0.0004,     0.8921,     0.1056],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0025, 0.0047, 0.1010, 0.1454, 0.7464], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  93.40463661083949
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.00022316745315720254
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 28.107401477064318
printing an ep nov before normalisation:  38.57347140832246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.855524475992617
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.744]
 [31.973]
 [24.744]
 [24.744]
 [24.744]] [[0.42 ]
 [0.849]
 [0.42 ]
 [0.42 ]
 [0.42 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  50.52093373151615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  57.650245570819024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.852045691387225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  30.204124304709982
printing an ep nov before normalisation:  26.754231996219776
printing an ep nov before normalisation:  16.36594486436482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  0.0006333467078028272
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.88532746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.01970051564523
printing an ep nov before normalisation:  44.47495597617237
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.001]
 [23.001]
 [23.001]
 [23.001]
 [23.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  88.42300415039062
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.8846376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  1  action  0 :  tensor([    0.9939,     0.0001,     0.0048,     0.0001,     0.0011],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0004,     0.9791,     0.0003,     0.0005,     0.0197],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0005,     0.9628,     0.0095,     0.0272],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0129,     0.0002,     0.0004,     0.8717,     0.1148],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0018, 0.0014, 0.0201, 0.2963, 0.6803], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  19.36238526970825
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.122 0.163 0.265 0.143 0.306]
using explorer policy with actor:  1
printing an ep nov before normalisation:  88.70938884723897
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.004887981773113
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  76.01220008297774
printing an ep nov before normalisation:  92.75222607052415
printing an ep nov before normalisation:  1.089146280719433e-05
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.844115543831585
printing an ep nov before normalisation:  57.66207696054008
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  60.63767708248713
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.45 ]
 [19.209]
 [23.031]
 [23.272]
 [22.059]] [[1.126]
 [0.966]
 [1.459]
 [1.49 ]
 [1.333]]
printing an ep nov before normalisation:  45.31224915647012
printing an ep nov before normalisation:  26.245932579040527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  29.027184355155264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
printing an ep nov before normalisation:  40.10590832167184
printing an ep nov before normalisation:  48.618061608382675
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9938,     0.0004,     0.0003,     0.0025,     0.0031],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0004,     0.9981,     0.0002,     0.0005,     0.0008],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9987,     0.0004,     0.0008],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0015,     0.0005,     0.0157,     0.8451,     0.1372],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0034, 0.0287, 0.1053, 0.2232, 0.6394], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  18.016113344936336
printing an ep nov before normalisation:  81.67936158287222
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  48.7084655314201
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  36.28859519958496
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 91.263]
 [106.785]
 [ 91.263]
 [ 91.263]
 [ 91.263]] [[0.788]
 [1.   ]
 [0.788]
 [0.788]
 [0.788]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.787142723637388
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.8786104
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.8781612
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.628]
 [14.628]
 [14.628]
 [14.628]
 [14.628]] [[0.065]
 [0.065]
 [0.065]
 [0.065]
 [0.065]]
siam score:  -0.8791025
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  23.19467067718506
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.3456162668679
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  39.99277869143827
actions average: 
K:  4  action  0 :  tensor([    0.9975,     0.0001,     0.0000,     0.0013,     0.0011],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9948,     0.0023,     0.0001,     0.0027],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0016,     0.0004,     0.9157,     0.0387,     0.0436],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0004,     0.0162,     0.8360,     0.1469],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0030, 0.0485, 0.0526, 0.1615, 0.7345], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  104.4082026541111
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.89033386280789
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.89517813536248
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.684]
 [56.066]
 [36.684]
 [36.684]
 [36.684]] [[0.77 ]
 [1.414]
 [0.77 ]
 [0.77 ]
 [0.77 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  19.906962333411222
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.881406
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.295]
 [60.295]
 [60.295]
 [60.295]
 [60.295]] [[100.513]
 [100.513]
 [100.513]
 [100.513]
 [100.513]]
printing an ep nov before normalisation:  67.60567986696712
printing an ep nov before normalisation:  28.2311408045921
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.88094354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.599]
 [59.607]
 [51.67 ]
 [61.599]
 [61.599]] [[1.057]
 [1.   ]
 [0.774]
 [1.057]
 [1.057]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  53.02343492619525
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  28.164799284181363
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.144]
 [29.936]
 [32.343]
 [31.245]
 [32.24 ]] [[0.619]
 [0.335]
 [0.386]
 [0.363]
 [0.384]]
printing an ep nov before normalisation:  21.85835247337156
siam score:  -0.87726516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.929]
 [33.943]
 [34.657]
 [33.943]
 [33.943]] [[0.645]
 [0.354]
 [0.369]
 [0.354]
 [0.354]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.184399476946396
printing an ep nov before normalisation:  59.22786395785714
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.61428331021291
printing an ep nov before normalisation:  40.648456867084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.102]
 [42.102]
 [42.102]
 [56.37 ]
 [42.102]] [[0.939]
 [0.939]
 [0.939]
 [1.463]
 [0.939]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.925]
 [37.925]
 [37.925]
 [46.283]
 [37.925]] [[0.998]
 [0.998]
 [0.998]
 [1.383]
 [0.998]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.51270294189453
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.584410298137836
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.02 ]
 [77.02 ]
 [75.621]
 [75.056]
 [77.02 ]] [[1.065]
 [1.065]
 [1.037]
 [1.025]
 [1.065]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.75042963027954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.96592285874165
printing an ep nov before normalisation:  34.288862824623756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  22.065795633666493
printing an ep nov before normalisation:  29.678826332092285
printing an ep nov before normalisation:  59.78821682980341
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.087]
 [25.172]
 [25.26 ]
 [28.21 ]
 [27.087]] [[1.328]
 [1.155]
 [1.163]
 [1.43 ]
 [1.328]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.03719436233235
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.873]
 [38.58 ]
 [36.873]
 [36.873]
 [36.873]] [[0.834]
 [0.9  ]
 [0.834]
 [0.834]
 [0.834]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.78 ]
 [49.9  ]
 [32.958]
 [41.358]
 [47.849]] [[0.864]
 [0.832]
 [0.55 ]
 [0.69 ]
 [0.798]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  42.80433651653312
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.028]
 [68.028]
 [52.385]
 [69.359]
 [68.028]] [[1.741]
 [1.741]
 [1.24 ]
 [1.784]
 [1.741]]
actions average: 
K:  1  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0019, 0.9366, 0.0018, 0.0022, 0.0574], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0076,     0.8941,     0.0397,     0.0583],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0123,     0.0004,     0.0023,     0.8584,     0.1266],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0127, 0.0106, 0.1134, 0.1894, 0.6740], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.87805283
printing an ep nov before normalisation:  56.295683480392015
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.009]
 [47.065]
 [45.657]
 [41.152]
 [39.55 ]] [[0.928]
 [1.079]
 [1.026]
 [0.859]
 [0.8  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  82.98358631707954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  46.40992789672138
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  71.77055641513638
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  24.590947966124194
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.568]
 [63.568]
 [63.568]
 [63.568]
 [63.568]] [[0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.854]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.697]
 [19.697]
 [19.697]
 [25.298]
 [19.697]] [[0.512]
 [0.512]
 [0.512]
 [0.761]
 [0.512]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.892144246416823
siam score:  -0.88414794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.032]
 [44.949]
 [27.736]
 [23.901]
 [24.856]] [[0.144]
 [0.596]
 [0.257]
 [0.181]
 [0.2  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  25.810335709214424
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.63686690038944
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  3  action  0 :  tensor([    0.9799,     0.0041,     0.0000,     0.0079,     0.0081],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9345,     0.0009,     0.0008,     0.0637],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9379,     0.0349,     0.0271],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0006,     0.0185,     0.7223,     0.2582],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0009, 0.0031, 0.1132, 0.1958, 0.6870], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.704]
 [43.704]
 [43.704]
 [46.006]
 [43.704]] [[0.906]
 [0.906]
 [0.906]
 [1.001]
 [0.906]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
line 256 mcts: sample exp_bonus 18.415135657500773
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.344]
 [31.736]
 [40.344]
 [40.344]
 [39.971]] [[0.649]
 [0.469]
 [0.649]
 [0.649]
 [0.642]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.578017146144084
actions average: 
K:  1  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0006,     0.9458,     0.0171,     0.0005,     0.0361],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0003,     0.9302,     0.0286,     0.0406],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0238,     0.0005,     0.0002,     0.8222,     0.1533],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0501, 0.0368, 0.0410, 0.1622, 0.7098], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([    0.9822,     0.0011,     0.0001,     0.0089,     0.0077],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9386,     0.0355,     0.0005,     0.0251],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0007,     0.0000,     0.9338,     0.0208,     0.0446],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0009,     0.0216,     0.8299,     0.1476],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0008, 0.1143, 0.1303, 0.1969, 0.5578], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  91.19878066862952
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.906962198628285
siam score:  -0.875263
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.361]
 [16.361]
 [16.361]
 [19.565]
 [16.361]] [[0.663]
 [0.663]
 [0.663]
 [0.793]
 [0.663]]
printing an ep nov before normalisation:  54.63944921103539
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10912
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
actions average: 
K:  2  action  0 :  tensor([0.9556, 0.0015, 0.0010, 0.0045, 0.0374], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9329,     0.0142,     0.0004,     0.0523],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0143,     0.9360,     0.0153,     0.0344],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0004,     0.0261,     0.7539,     0.2195],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0003,     0.0025,     0.0665,     0.2330,     0.6977],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.679]
 [35.135]
 [35.135]
 [35.135]
 [35.135]] [[1.645]
 [1.102]
 [1.102]
 [1.102]
 [1.102]]
line 256 mcts: sample exp_bonus 63.82725576597214
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9997,     0.0001,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0091,     0.9720,     0.0076,     0.0003,     0.0109],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9615,     0.0159,     0.0226],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0002,     0.0684,     0.8122,     0.1190],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0033, 0.0565, 0.0094, 0.2265, 0.7043], grad_fn=<DivBackward0>)
siam score:  -0.87848973
printing an ep nov before normalisation:  77.38074200581418
printing an ep nov before normalisation:  32.21954897271567
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  55.64162236880732
printing an ep nov before normalisation:  21.81856870651245
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
siam score:  -0.87874633
printing an ep nov before normalisation:  99.25985822272136
printing an ep nov before normalisation:  45.38883482994894
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.211]
 [21.211]
 [26.912]
 [21.211]
 [21.211]] [[0.462]
 [0.462]
 [0.661]
 [0.462]
 [0.462]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.754]
 [60.208]
 [60.208]
 [60.208]
 [60.208]] [[0.863]
 [0.798]
 [0.798]
 [0.798]
 [0.798]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  11.784954071044922
siam score:  -0.88055986
printing an ep nov before normalisation:  41.53328384883846
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8822221
siam score:  -0.882563
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  87.47329227099084
printing an ep nov before normalisation:  44.339123041893686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  35.67637189430057
maxi score, test score, baseline:  0.0001 0.0 