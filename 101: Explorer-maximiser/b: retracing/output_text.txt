Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [ 0.02155004 -0.07963443  0.00850402 -0.02999256 -0.01413476 -0.04650432]
then printing the same exp r:  [-0.3181757926940918, -0.31818050146102905, -0.3181377947330475, -0.3182251751422882, -0.31813234090805054, -0.3181682527065277]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.05955624 -0.0264101  -0.06221782 -0.07653428 -0.05123472 -0.09889703
  0.05656309  0.06252857]
then printing the same exp r:  [0.31000229716300964, 0.3422118127346039, 0.003864722093567252, -0.04500630125403404, 0.31000229716300964, 0.027467936277389526, 0.3422118127346039, -0.09738587588071823]
line 148 mcts, printing v robin and v batman and node v :  -0.0529 -0.0191 -0.0191
policy robin / batman :  tensor([0.1191, 0.3340, 0.2038, 0.1612, 0.1819]) tensor([0.1553, 0.2029, 0.2251, 0.2144, 0.2023])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.0604293   0.09880202  0.09184755  0.01338559  0.05832112 -0.07373948
  0.04298136  0.06875952 -0.0062583  -0.09241631  0.02752428  0.03834598
 -0.0667866 ]
then printing the same exp r:  [-0.9684979915618896, -0.9663731455802917, -0.9265228509902954, -0.921648383140564, -0.9265228509902954, -0.9285456538200378, -0.9252997636795044, -0.9224619269371033, -0.9627261757850647, -0.9684979915618896, -0.9684979915618896, -0.9081147909164429, -0.5921923518180847]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.00704571 -0.0351841   0.00821243 -0.01166151  0.02910248 -0.02952088
 -0.00702437  0.01929933 -0.06974981 -0.04073878  0.05576481  0.05511094]
then printing the same exp r:  [-0.5593075156211853, -0.4587917923927307, -0.5517855286598206, -0.5073530673980713, -0.4366001486778259, -0.4140172600746155, -0.36230942606925964, -0.3102499544620514, -0.26811012625694275, 0.2756061255931854, 0.3723600208759308, 0.13091398775577545]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.05450263 -0.03380905 -0.0348869  -0.08978078]
then printing the same exp r:  [-0.3039925694465637, -0.15806595981121063, -0.2178250253200531, 0.6511507630348206]
10 : 0.0
[[3182. 1334.  302.    0.    0.    0.    0.    0.    0.    0.    0.    0.]
 [1585.  900.  230.    4.    5.    0.    0.    0.    0.    0.    0.    0.]
 [ 953.  663.  184.   44.   10.    2.    2.    0.    0.    0.    0.    0.]
 [ 692.  443.  133.   13.    1.    1.    0.    0.    0.    0.    0.    0.]]
Test reward:  0.0
LR:  0.00036
replay buffer size:  10683
training steps:  9
Average siam loss:  -0.749551520180211
Average value from last batch of unclaimed novelty:  tensor(-0.0431, dtype=torch.float64)
Average value from last batch of predicted nov:  -0.005237853208796762
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.26450118 0.38143693 0.74791593 1.08498541 0.91325439]
then printing the same exp r:  [-0.12098819017410278, -0.3626261055469513, -0.3295147716999054, 0.18269047141075134, 0.92947918176651]
line 148 mcts, printing v robin and v batman and node v :  -0.0002 0.0045 0.0045
policy robin / batman :  tensor([0.1867, 0.2245, 0.2099, 0.1973, 0.1815]) tensor([0.2078, 0.2315, 0.1936, 0.1603, 0.2068])
Checking the total Q and that Qe samples 0.0037606668159480233 0.0
line 148 mcts, printing v robin and v batman and node v :  -0.0001 0.0031 0.0031
policy robin / batman :  tensor([0.1911, 0.2164, 0.2038, 0.1916, 0.1972]) tensor([0.1982, 0.2340, 0.1980, 0.1761, 0.1937])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.02957446 0.25103336 0.49299829 0.71153032 0.91505504 0.84859237]
then printing the same exp r:  [-0.21355225145816803, -0.23942923545837402, -0.21355225145816803, -0.19633755087852478, 0.07570565491914749, 0.8491640090942383]
line 148 mcts, printing v robin and v batman and node v :  0.0002 0.0011 0.0011
policy robin / batman :  tensor([0.1402, 0.2747, 0.2269, 0.1985, 0.1597]) tensor([0.1849, 0.2160, 0.1907, 0.1984, 0.2100])
Checking the total Q and that Qe samples 0.0011781433280485113 0.0
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-1.04994483 -0.93222125 -0.76178494 -0.60694273 -0.4231096  -0.26641036
 -0.0864232   0.07589591]
then printing the same exp r:  [-0.1283290833234787, -0.179852694272995, -0.21056200563907623, -0.18996386229991913, -0.16097307205200195, -0.18267817795276642, -0.16319206357002258, 0.12716253101825714]
Checking the total Q and that Qe samples 0.000723263647291022 0.0
20 : 0.0
[[4852. 2342.  671.    0.    0.    0.    0.    0.    0.    0.    0.    0.]
 [2150. 1307.  438.    4.    7.    0.    0.    0.    0.    0.    0.    0.]
 [1269.  855.  261.   61.   17.    4.    3.    0.    0.    0.    0.    0.]
 [ 879.  580.  188.   15.    3.    1.    1.    0.    0.    0.    0.    0.]]
Test reward:  0.0
LR:  0.0007599999999999999
replay buffer size:  15908
training steps:  19
Average siam loss:  -0.6996420681071057
Average value from last batch of unclaimed novelty:  tensor(0.0054, dtype=torch.float64)
Average value from last batch of predicted nov:  0.096023785972258
line 148 mcts, printing v robin and v batman and node v :  0.0006 0.0014 0.0014
policy robin / batman :  tensor([0.1588, 0.3098, 0.1817, 0.1869, 0.1628]) tensor([0.2105, 0.2071, 0.1760, 0.1911, 0.2153])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.76605998 0.61668449 0.40745966]
then printing the same exp r:  [-0.020186619833111763, 0.21545396745204926, 0.592475414276123]
Checking the total Q and that Qe samples 0.0006999071903250297 0.0
Checking the total Q and that Qe samples 0.0007709000391218806 0.0
30 : 0.0
[[6140. 3229. 1137.    0.    0.    0.    0.    0.    0.    0.    0.    0.]
 [2467. 1572.  576.    9.    9.    1.    0.    0.    0.    0.    0.    0.]
 [1371.  942.  297.   82.   28.   11.    6.    1.    0.    0.    0.    0.]
 [ 934.  630.  207.   18.    3.    2.    2.    0.    0.    0.    0.    0.]]
Test reward:  0.0
LR:  0.001
replay buffer size:  19674
training steps:  29
Average siam loss:  -0.7223296260384611
Average value from last batch of unclaimed novelty:  tensor(0.0242, dtype=torch.float64)
Average value from last batch of predicted nov:  0.019115733070389572
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-2.26276548 -2.26883226 -2.0673825  -1.87888911 -1.62780675 -1.28659461
 -1.01188673 -0.73440402 -0.51327005 -0.26678548 -0.03869556  0.19169831
  0.25429491]
then printing the same exp r:  [-0.2280365377664566, -0.2280365377664566, -0.2280365377664566, -0.27006104588508606, -0.3576546311378479, -0.2877037823200226, -0.2877037823200226, -0.2877037823200226, -0.25166910886764526, -0.23078472912311554, -0.23078472912311554, -0.06066025421023369, 0.31906354427337646]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.82184852 0.73746499 0.65347254]
then printing the same exp r:  [-0.06922748684883118, 0.09144158661365509, 0.8252732753753662]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.82184852 0.73746499 0.65347254]
then printing the same exp r:  [-0.06922748684883118, 0.09144158661365509, 0.8252732753753662]
line 148 mcts, printing v robin and v batman and node v :  0.0002 0.0003 0.0003
policy robin / batman :  tensor([0.1661, 0.2677, 0.1915, 0.1968, 0.1779]) tensor([0.2037, 0.2056, 0.1937, 0.1966, 0.2004])
40 : 0.0
[[7250. 4007. 1632.    0.    0.    0.    1.    0.    0.    0.    0.    0.]
 [2727. 1792.  689.   10.   11.    1.    1.    0.    0.    0.    0.    0.]
 [1451. 1003.  334.  111.   46.   21.   16.    9.    0.    0.    0.    0.]
 [ 968.  656.  220.   20.    7.    3.    2.    0.    0.    0.    0.    0.]]
Test reward:  0.0
LR:  0.001
replay buffer size:  22988
training steps:  39
Average siam loss:  -0.6856280009724331
Average value from last batch of unclaimed novelty:  tensor(0.0405, dtype=torch.float64)
Average value from last batch of predicted nov:  0.04279140695920604
Checking the total Q and that Qe samples 0.0005988546648994088 0.0
line 148 mcts, printing v robin and v batman and node v :  0.0001 0.0 0.0001
policy robin / batman :  tensor([0.1094, 0.3977, 0.1654, 0.1715, 0.1560]) tensor([0.2092, 0.1721, 0.2087, 0.2250, 0.1850])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.08553301 0.15723479 0.16885267]
then printing the same exp r:  [-0.0913219004869461, -0.010029650293290615, 0.19145825505256653]
line 148 mcts, printing v robin and v batman and node v :  0.0006 0.0006 0.0006
policy robin / batman :  tensor([0.1761, 0.2728, 0.1949, 0.1816, 0.1746]) tensor([0.2034, 0.2093, 0.2056, 0.1850, 0.1967])
50 : 0.0
[[8286. 4803. 2125.    0.    0.    0.    1.    0.    0.    0.    0.    0.]
 [2910. 1995.  795.   14.   16.    1.    1.    0.    0.    0.    0.    0.]
 [1553. 1092.  382.  146.   73.   38.   31.   23.    0.    0.    0.    0.]
 [1008.  695.  237.   21.    7.    3.    2.    0.    0.    0.    0.    0.]]
Test reward:  0.0
LR:  0.001
replay buffer size:  26258
training steps:  49
Average siam loss:  -0.6845797578527709
Average value from last batch of unclaimed novelty:  tensor(0.0439, dtype=torch.float64)
Average value from last batch of predicted nov:  0.03997118437605394
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.16375516  0.01019219  0.25188843  0.23566557]
then printing the same exp r:  [-0.21189062297344208, -0.24159328639507294, 0.018767187371850014, 0.2754460275173187]
Checking the total Q and that Qe samples 0.00024917229552100023 0.0
Checking the total Q and that Qe samples 9.995969772571699e-05 0.0
line 148 mcts, printing v robin and v batman and node v :  0.0 0.0 0.0
policy robin / batman :  tensor([0.1670, 0.2814, 0.1771, 0.1965, 0.1780]) tensor([0.2039, 0.2176, 0.2018, 0.1900, 0.1866])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.98321419 1.05958908 0.8618359 ]
then printing the same exp r:  [-0.10221707820892334, 0.2084560990333557, 0.9070413112640381]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.76746717 0.94779828 1.05958908 0.8618359 ]
then printing the same exp r:  [-0.20799483358860016, -0.10221707820892334, 0.2084560990333557, 0.9070413112640381]
line 148 mcts, printing v robin and v batman and node v :  0.0004 0.0004 0.0004
policy robin / batman :  tensor([0.1638, 0.2984, 0.1812, 0.1845, 0.1721]) tensor([0.1944, 0.2144, 0.2018, 0.1900, 0.1993])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.6434786  0.74074449 0.62292276]
then printing the same exp r:  [-0.14055518805980682, 0.12530399858951569, 0.6800149083137512]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.25445037 -0.09788312  0.08641752  0.28722301  0.33000926]
then printing the same exp r:  [-0.1644207388162613, -0.18528935313224792, -0.19993259012699127, -0.039885006844997406, 0.3388426899909973]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.40268385 0.50736668 0.3492881 ]
then printing the same exp r:  [-0.20136959850788116, 0.16320349276065826, 0.4556162655353546]
60 : 0.0
[[9284. 5539. 2640.    0.    0.    0.    1.    0.    0.    0.    1.    0.]
 [3087. 2150.  876.   17.   17.    2.    2.    1.    1.    2.    1.    0.]
 [1614. 1167.  441.  192.  108.   70.   56.   45.    0.    0.    0.    0.]
 [1025.  725.  247.   25.    7.    3.    3.    0.    0.    0.    0.    0.]]
Test reward:  0.0
LR:  0.001
replay buffer size:  29349
training steps:  59
Average siam loss:  -0.6708531255892063
Average value from last batch of unclaimed novelty:  tensor(0.0175, dtype=torch.float64)
Average value from last batch of predicted nov:  0.05215014679865363
Checking the total Q and that Qe samples 0.0005380725983734583 0.0
line 148 mcts, printing v robin and v batman and node v :  0.0003 0.0004 0.0004
policy robin / batman :  tensor([0.1786, 0.2635, 0.1902, 0.1874, 0.1803]) tensor([0.2059, 0.2089, 0.2069, 0.1884, 0.1898])
Checking the total Q and that Qe samples 0.00019901307141408325 0.0
line 148 mcts, printing v robin and v batman and node v :  0.0 0.0 0.0
policy robin / batman :  tensor([0.1511, 0.4074, 0.1505, 0.1339, 0.1571]) tensor([0.2052, 0.2094, 0.1961, 0.1828, 0.2064])
line 148 mcts, printing v robin and v batman and node v :  0.0007 0.0006 0.0007
policy robin / batman :  tensor([0.1720, 0.2699, 0.1893, 0.1953, 0.1735]) tensor([0.2006, 0.2088, 0.2025, 0.1950, 0.1931])
line 148 mcts, printing v robin and v batman and node v :  0.0006 0.0007 0.0007
policy robin / batman :  tensor([0.1609, 0.3132, 0.1827, 0.1785, 0.1647]) tensor([0.1949, 0.2081, 0.2060, 0.1921, 0.1989])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.19996845 0.71984975 1.03261539 1.23122033 1.47685203 1.55284819
 1.45550011 1.31202365 1.06963177 0.90447446 0.6757191 ]
then printing the same exp r:  [-0.29475483298301697, -0.30549442768096924, -0.18817448616027832, -0.23319512605667114, -0.06107847020030022, 0.037810105830430984, 0.15817847847938538, 0.25564464926719666, 0.1759616732597351, 0.23789146542549133, 0.7616445422172546]
Checking the total Q and that Qe samples 0.0005999106589268194 0.0
Checking the total Q and that Qe samples 0.00042716591122330083 0.0
70 : 0.0033333333333333335
[[10275.  6254.  3134.     0.     0.     0.     1.     0.     0.     0.
      1.     0.]
 [ 3290.  2338.   957.    20.    19.     2.     4.     3.     3.     6.
      3.     2.]
 [ 1691.  1270.   520.   257.   166.   129.   114.    88.     0.     0.
      0.     0.]
 [ 1051.   740.   255.    26.     8.     5.     6.     0.     0.     0.
      0.     0.]]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-2.54953125 -2.61199976 -2.62141009 -2.70918483 -2.68674644 -2.81121568
 -2.75095571 -2.27494287 -1.72669498 -2.1527688  -2.53505292 -2.07868968
 -1.84690454 -1.67928293 -1.72086972 -1.35627874 -1.49348156 -1.3394241
 -1.14601784 -0.97955931 -0.74624632 -0.59481661 -0.54523709 -0.31096012
 -0.09217872  0.06678297]
then printing the same exp r:  [-0.22684314846992493, -0.30027538537979126, -0.2022629678249359, -0.313362717628479, -0.313362717628479, -0.2915322780609131, -0.313362717628479, -0.2915322780609131, -0.22684314846992493, -0.2022629678249359, -0.2915322780609131, -0.313362717628479, -0.2915322780609131, -0.2915322780609131, -0.2698226869106293, -0.20209646224975586, -0.16914314031600952, -0.2069357931613922, -0.1780344694852829, -0.24320752918720245, -0.16914314031600952, -0.0555877685546875, -0.23978441953659058, -0.22192241251468658, -0.15989278256893158, 0.07815754413604736]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-1.85551016 -1.83769133 -1.56472159 -1.28899458 -1.07517158 -0.88376893
 -0.67602834 -0.48059394 -0.25860527 -0.03929504  0.12020083]
then printing the same exp r:  [-0.313362717628479, -0.2915322780609131, -0.2915322780609131, -0.22684314846992493, -0.2022629678249359, -0.22684314846992493, -0.2022629678249359, -0.22684314846992493, -0.22192241251468658, -0.15989278256893158, 0.132114976644516]
Test reward:  0.0
LR:  0.001
replay buffer size:  32638
training steps:  69
Average siam loss:  -0.6402329866141685
Average value from last batch of unclaimed novelty:  tensor(0.0364, dtype=torch.float64)
Average value from last batch of predicted nov:  0.06524031650657974
Checking the total Q and that Qe samples -0.12137908091849872 -0.12179123565638066
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.35680169 0.62818647 0.8564542  0.99503844 1.21202513 1.2257483
 1.16773626 1.1510013  0.98879918 0.83406278 0.63712013]
then printing the same exp r:  [-0.22684314846992493, -0.22192241251468658, -0.1299331933259964, -0.2069357931613922, -0.0014804902020841837, 0.06021774560213089, 0.028530273586511612, 0.1738283932209015, 0.16472427546977997, 0.20536752045154572, 0.6542556881904602]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.78351812 -0.50621802 -0.22328154  0.11036548  0.17109837  0.35206995]
then printing the same exp r:  [-0.3145049214363098, -0.2880497872829437, -0.3359023928642273, -0.059618085622787476, -0.1792433112859726, 0.3864262104034424]
Checking the total Q and that Qe samples 0.00039701499398797754 0.0
Checking the total Q and that Qe samples 0.0005261741732560294 0.0
line 148 mcts, printing v robin and v batman and node v :  0.0007 0.0035 0.0035
policy robin / batman :  tensor([0.0585, 0.7219, 0.0653, 0.0704, 0.0837]) tensor([0.2273, 0.2314, 0.1421, 0.2160, 0.1833])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.61097013 -0.50124797 -0.21666231]
then printing the same exp r:  [-0.27653196454048157, -0.28964877128601074, -0.05495081841945648]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.87150161 -0.77000214 -0.50124797 -0.21666231]
then printing the same exp r:  [-0.2693345248699188, -0.27653196454048157, -0.28964877128601074, -0.05495081841945648]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.61814206 -0.24487576  0.19795657  0.53594263]
then printing the same exp r:  [-0.42821916937828064, -0.44530582427978516, -0.33598649501800537, 0.591556191444397]
Checking the total Q and that Qe samples 0.000747753106484796 0.0
Checking the total Q and that Qe samples 0.2469468596676657 0.23760376201070044
Checking the total Q and that Qe samples 0.9222722240744959 0.32676952807357396
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.86404349 1.35431406 1.48314711 1.69734374 1.81211009 2.03666601
 1.79970281 1.42344214 1.05555153 0.74753972 0.52965564]
then printing the same exp r:  [-0.35229602456092834, -0.11515310406684875, -0.1992153525352478, -0.09762145578861237, -0.20625178515911102, 0.003335947170853615, 0.3944394886493683, 0.3822688162326813, 0.3186739385128021, 0.22543498873710632, 0.8023056983947754]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [1.70252696 2.2646886  2.17323241 2.60467788 3.22034092 3.24953367
 2.88791776 2.53481983 2.24175013 1.96132155 1.51274277 1.15877119
 0.86319079 0.63815699]
then printing the same exp r:  [-0.35229602456092834, -0.16074255108833313, -0.14505745470523834, -0.09762145578861237, 0.003335947170853615, 0.3944394886493683, 0.3822688162326813, 0.3186739385128021, 0.04887287691235542, 0.4683901071548462, 0.3692518174648285, 0.3072851598262787, 0.23375289142131805, 0.9119030237197876]
line 148 mcts, printing v robin and v batman and node v :  0.0153 0.0315 0.0315
policy robin / batman :  tensor([0.1241, 0.4226, 0.1642, 0.1483, 0.1408]) tensor([0.1664, 0.2392, 0.2005, 0.1838, 0.2101])
line 148 mcts, printing v robin and v batman and node v :  0.0069 0.009 0.009
policy robin / batman :  tensor([0.1680, 0.3126, 0.1828, 0.1800, 0.1566]) tensor([0.1866, 0.2273, 0.1902, 0.1945, 0.2014])
80 : 0.14
[[11307.  7023.  3473.     0.     0.     0.     1.     1.     1.     1.
      1.     0.]
 [ 3578.  2648.  1060.    34.    32.    27.    62.    61.    66.    65.
     56.    49.]
 [ 1858.  1556.   757.   471.   365.   307.   240.   137.     3.     1.
      2.     0.]
 [ 1090.   789.   267.    29.    12.    15.    17.     0.     0.     0.
      0.     0.]]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [ 0.52936226  0.50788431  0.44322792  0.84694643  0.95178954  0.58805734
  0.37098038  0.11112283  0.12118374  0.13407484  0.09618838  0.20770286
  0.15130856 -0.21352052 -0.30348516 -0.3569996  -0.42895001 -0.36602885]
then printing the same exp r:  [-0.2696336507797241, -0.2531990110874176, -0.18638992309570312, -0.19254834949970245, -0.14608383178710938, 0.020583251491189003, 0.020583251491189003, 0.061643678694963455, -0.011667019687592983, 0.0392407551407814, -0.11054288595914841, 0.058492306619882584, 0.10892444849014282, 0.08780786395072937, 0.050448931753635406, 0.0683443546295166, -0.06725399196147919, -0.09902610629796982]
Test reward:  0.28
LR:  0.001
replay buffer size:  37462
training steps:  79
Average siam loss:  -0.6797532711870737
Average value from last batch of unclaimed novelty:  tensor(1.2782, dtype=torch.float64)
Average value from last batch of predicted nov:  0.34828972777118355
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.37474512 -0.11052824  0.08814342  0.3433376   0.64873513  0.59040335
  0.74245085  0.68830668  0.70692629  0.60697646]
then printing the same exp r:  [-0.2680021822452545, -0.19978810846805573, -0.25430384278297424, -0.3019294738769531, -0.19254834949970245, -0.14608383178710938, 0.061643678694963455, -0.011667019687592983, 0.10709049552679062, 0.8838075399398804]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-2.84633132 -2.84636551 -2.879569   -2.86722418 -2.92296874 -2.99098831
 -2.88991814 -2.83363097 -1.91025029 -2.12792918 -1.74005271 -1.48979523
 -1.18587612 -0.94210892 -0.69587944 -0.44716278 -0.4795856  -0.27036663
 -0.16274318 -0.07797905  0.11918032]
then printing the same exp r:  [-0.2792951464653015, -0.2792951464653015, -0.2680021822452545, -0.19978810846805573, -0.1880761682987213, -0.2531990110874176, -0.2751697897911072, -0.22952698171138763, -0.25645947456359863, -0.28412526845932007, -0.2822917103767395, -0.3189675509929657, -0.2557457387447357, -0.2557457387447357, -0.2557457387447357, -0.22952698171138763, -0.21406327188014984, -0.11035443097352982, -0.08640799671411514, -0.19794704020023346, 0.3910841643810272]
line 148 mcts, printing v robin and v batman and node v :  0.7921 0.7627 0.7921
policy robin / batman :  tensor([0.0379, 0.8332, 0.0510, 0.0320, 0.0459]) tensor([0.0448, 0.7726, 0.0442, 0.0566, 0.0818])
Checking the total Q and that Qe samples 0.13507394878027235 0.006638075755189133
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-1.69579101 -1.29438382 -0.97937417 -0.54728812 -0.29159505 -0.07285792
  0.23285129  0.33209516  0.25333153  0.34464536]
then printing the same exp r:  [-0.41853639483451843, -0.32808423042297363, -0.44197872281074524, -0.2612212300300598, -0.3235335648059845, -0.3064451515674591, -0.0968918427824974, 0.08211813122034073, -0.08875492960214615, 0.4552266299724579]
line 148 mcts, printing v robin and v batman and node v :  0.0079 0.0216 0.0216
policy robin / batman :  tensor([0.1370, 0.3943, 0.1741, 0.1510, 0.1436]) tensor([0.1864, 0.2040, 0.2253, 0.1879, 0.1964])
line 148 mcts, printing v robin and v batman and node v :  0.578 0.4096 0.578
policy robin / batman :  tensor([0.0732, 0.6850, 0.1022, 0.0627, 0.0770]) tensor([0.0840, 0.2135, 0.1093, 0.3647, 0.2286])
Checking the total Q and that Qe samples -0.25782920804476106 -0.38110459450333817
Checking the total Q and that Qe samples 0.7157384132100061 0.0
Checking the total Q and that Qe samples -0.26618709869531304 -0.283586092877388
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.36653445 -0.31262852 -0.13487169]
then printing the same exp r:  [-0.2462775558233261, -0.18091468513011932, 0.05626596510410309]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-1.54378031 -1.30961279 -0.9753322  -0.73890649 -0.46795758 -0.31243661
 -0.30283345 -0.11422032  0.00335705  0.17416913  0.12391127]
then printing the same exp r:  [-0.270053893327713, -0.3475089967250824, -0.2462775558233261, -0.2784126102924347, -0.1602478176355362, -0.19582466781139374, -0.19167205691337585, -0.11873110383749008, -0.17077817022800446, 0.05201714485883713, 0.31766289472579956]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-2.16885621 -1.93593663 -1.54473958 -1.36191568 -1.14030224 -0.83405
 -0.75218408 -0.50797322 -0.19533381 -0.05221255  0.16217667]
then printing the same exp r:  [-0.2891748547554016, -0.41075196862220764, -0.19842733442783356, -0.23537015914916992, -0.31777045130729675, -0.22114689648151398, -0.25180867314338684, -0.31777045130729675, -0.14509433507919312, -0.21491661667823792, 0.30141481757164]
90 : 0.056666666666666664
[[12515.  7614.  3662.     0.     0.     0.     8.     7.    14.     4.
      2.     0.]
 [ 4050.  3060.  1220.    48.    52.    55.   245.   277.   243.   149.
    110.    94.]
 [ 2172.  2076.  1230.   928.   777.   636.   445.   167.    10.     4.
      7.     0.]
 [ 1151.   859.   308.    48.    37.    29.    27.     0.     0.     0.
      0.     0.]]
Checking the total Q and that Qe samples 0.2183532862523489 0.0
Test reward:  0.94
LR:  0.001
replay buffer size:  44340
training steps:  89
Average siam loss:  -0.6567833919382465
Average value from last batch of unclaimed novelty:  tensor(0.7071, dtype=torch.float64)
Average value from last batch of predicted nov:  0.32588632351312186
Checking the total Q and that Qe samples 0.37896376507950175 0.2589382033548571
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.9827649  -0.75484779  0.02167864  0.30183548  0.64201928  0.82961147
  0.99466046  0.83028924  0.91019924  1.09480623  1.11781113  1.23608578
  1.25068665  0.83740877  0.48147057  0.26188965 -0.07850692 -0.1665926 ]
then printing the same exp r:  [-0.3437095284461975, -0.43315133452415466, -0.34690821170806885, -0.37626829743385315, -0.300508588552475, -0.12891048192977905, 0.08620061725378036, 0.08225953578948975, -0.17541305720806122, -0.011946250684559345, -0.10698363184928894, -0.002115151146426797, 0.1628672331571579, 0.364396870136261, 0.22444425523281097, 0.34304192662239075, 0.08729267865419388, 0.10832464694976807]
Checking the total Q and that Qe samples 0.7106900488602927 0.520490048883807
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-3.52991566 -3.27546529 -3.20791821 -2.9779645  -3.24613825 -3.30458548
 -3.28174035 -3.0899883  -2.85313445 -2.99535069 -2.93788605 -2.55237162
 -2.00185652 -1.57683647 -0.93642164 -0.92169965 -1.05551048 -0.49511305
 -0.24274938 -0.02235269  0.5721261   1.32786572  1.64178709  1.78728128
  1.72307509  1.91589295  1.68414781  1.70327455  1.55761211  1.2089487
  0.70173574]
then printing the same exp r:  [-0.41099974513053894, -0.3437095284461975, -0.5054338574409485, -0.43315133452415466, -0.3728778660297394, -0.26219236850738525, -0.42035868763923645, -0.39431649446487427, -0.2851391136646271, -0.2139713615179062, -0.39634108543395996, -0.2668970227241516, -0.2668970227241516, -0.3453337550163269, -0.2619820535182953, -0.23168036341667175, -0.220059335231781, -0.32433515787124634, -0.2619820535182953, -0.32433515787124634, -0.37626829743385315, -0.300508588552475, -0.12891048192977905, 0.08225953578948975, -0.17541305720806122, -0.011946250684559345, -0.002115151146426797, 0.1628672331571579, 0.364396870136261, 0.519424557685852, 0.9854239821434021]
line 148 mcts, printing v robin and v batman and node v :  0.0663 0.0879 0.0879
policy robin / batman :  tensor([0.1147, 0.4614, 0.1395, 0.1371, 0.1472]) tensor([0.1374, 0.3247, 0.1482, 0.1807, 0.2090])
line 148 mcts, printing v robin and v batman and node v :  0.62 0.2728 0.62
policy robin / batman :  tensor([0.0330, 0.7383, 0.0408, 0.1065, 0.0814]) tensor([0.0309, 0.5116, 0.0335, 0.1967, 0.2273])
Checking the total Q and that Qe samples 0.8000377699568435 0.23490921576877724
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.32627797 0.5834664  0.63147766 0.90211161 0.93827351 0.93981865
 0.94266608 0.95284392]
then printing the same exp r:  [-0.2538926899433136, -0.04211766645312309, -0.2566474676132202, -0.027049656957387924, 0.007932367734611034, 0.006645685527473688, -0.0006559590110555291, 0.9544686079025269]
Checking the total Q and that Qe samples 0.7791627094870053 0.25674282987076075
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-1.95107383 -2.31227453 -2.04758252 -1.83427416 -1.55357616 -1.26259398
 -1.02790982 -0.91224803 -0.68799312 -0.45944333 -0.20690652 -0.05335141]
then printing the same exp r:  [-0.24743764102458954, -0.27601584792137146, -0.23399101197719574, -0.2992260158061981, -0.30667486786842346, -0.24743764102458954, -0.27601584792137146, -0.23346953094005585, -0.23549921810626984, -0.2571776509284973, -0.15564507246017456, 0.10380968451499939]
Checking the total Q and that Qe samples 0.6230039672444535 0.0
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.9032815  -1.0404327  -0.84956292 -0.61452205 -0.33908494 -0.18640702
 -0.4403401  -0.27888516 -0.1520644  -0.00272712  0.05578231]
then printing the same exp r:  [-0.2402515709400177, -0.20137919485569, -0.2436223179101944, -0.28164440393447876, -0.1561030149459839, -0.05473921075463295, -0.16590282320976257, -0.12963777780532837, -0.15087328851222992, -0.05853697657585144, 0.3789457678794861]
Checking the total Q and that Qe samples 0.4323487450480461 0.0
100 : 0.08
[[13517.  8056.  3757.     0.     0.     0.    20.    17.    23.     6.
     12.     0.]
 [ 4521.  3597.  1341.    82.    85.   112.   577.   613.   454.   264.
    196.   148.]
 [ 2509.  2854.  1978.  1722.  1561.  1234.   755.   212.    22.    11.
     14.     0.]
 [ 1182.   915.   350.    76.    62.    53.    39.     0.     0.     0.
      0.     0.]]
Test reward:  1.0
LR:  0.001
replay buffer size:  52947
training steps:  99
Average siam loss:  -0.6884639709103535
Average value from last batch of unclaimed novelty:  tensor(0.1417, dtype=torch.float64)
Average value from last batch of predicted nov:  0.18186795460888378
Checking the total Q and that Qe samples -0.08572122833989843 -0.20156230734854585
Checking the total Q and that Qe samples 1.7602505249343834 0.0
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.5461784  -0.78621512 -0.60081324 -0.40221923 -0.43194351 -0.39181211]
then printing the same exp r:  [-0.24002426862716675, -0.19334344565868378, -0.20466282963752747, 0.02566145732998848, -0.044494468718767166, 0.10323019325733185]
line 148 mcts, printing v robin and v batman and node v :  0.0258 0.0557 0.0557
policy robin / batman :  tensor([0.1338, 0.4147, 0.1813, 0.1299, 0.1403]) tensor([0.1773, 0.2083, 0.2626, 0.1605, 0.1914])
Checking the total Q and that Qe samples 1.2804170029026734 0.4414681774141852
Checking the total Q and that Qe samples 0.9054395926343296 0.0
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-3.09254357 -2.61841653 -2.04644415 -1.51484763 -0.93172808 -0.48995166]
then printing the same exp r:  [-0.6782548427581787, -0.598421037197113, -0.5522676706314087, -0.598421037197113, -0.4511878192424774, -0.313100665807724]
Checking the total Q and that Qe samples 0.7790114338874252 0.0
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-3.08143045 -2.86612639 -2.8225525  -3.00443963 -2.33325012 -2.06097843
 -1.75766964 -1.44803318 -1.12659952 -1.01603305 -0.57458018 -0.29124067
  0.03320821  0.13222439]
then printing the same exp r:  [-0.43994447588920593, -0.3722494840621948, -0.3429519832134247, -0.3448103666305542, -0.2958398759365082, -0.3241267502307892, -0.3273907005786896, -0.3360602557659149, -0.3241267502307892, -0.4517158269882202, -0.2891433537006378, -0.3273907005786896, -0.09868074953556061, 0.34615999460220337]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-2.22750458 -2.15767554 -2.13618513 -2.41935947 -2.54939739 -2.27850657
 -2.3077837  -2.30511903 -2.26867841 -2.04578753 -1.77061217 -1.3715147
 -1.06124163 -0.62024542 -0.35739321 -0.12846189  0.1150691   0.36106
  0.27907836]
then printing the same exp r:  [-0.47234734892845154, -0.26688534021377563, -0.22146907448768616, -0.23185133934020996, -0.26688534021377563, -0.22146907448768616, -0.25370660424232483, -0.16296084225177765, -0.25370660424232483, -0.2958398759365082, -0.4169824421405792, -0.3241267502307892, -0.4517158269882202, -0.4712978005409241, -0.23254135251045227, -0.24482858180999756, -0.24482858180999756, 0.08562871068716049, 0.4944973289966583]
Checking the total Q and that Qe samples 0.22144787305271893 0.0
line 148 mcts, printing v robin and v batman and node v :  0.1934 0.683 0.683
policy robin / batman :  tensor([0.2104, 0.4568, 0.1019, 0.1147, 0.1162]) tensor([0.3810, 0.1682, 0.1915, 0.1035, 0.1557])
Checking the total Q and that Qe samples 0.8507093085229294 0.32240405100481845
line 148 mcts, printing v robin and v batman and node v :  0.6854 0.7747 0.7747
policy robin / batman :  tensor([0.1123, 0.4496, 0.1827, 0.1322, 0.1233]) tensor([0.1570, 0.3274, 0.2067, 0.1461, 0.1628])
line 148 mcts, printing v robin and v batman and node v :  0.2318 0.4375 0.4375
policy robin / batman :  tensor([0.0645, 0.5930, 0.0697, 0.1136, 0.1592]) tensor([0.0567, 0.6126, 0.0652, 0.0998, 0.1657])
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.33040255 0.59919583 0.83148059 0.93528136 1.38570489 1.60214538
 1.77362428 1.59590239 1.79887841 1.8778518  1.7920765  1.09564514
 1.67033981 1.80487331 1.53800634 1.41235667 1.35198378 1.45915627
 0.99401397 0.81747533 0.74688283 0.663738   0.54744414]
then printing the same exp r:  [0.07361708581447601, -0.1019032746553421, -0.012314320541918278, -0.1019032746553421, -0.07811447232961655, 0.04098062589764595, 0.08557131886482239, 0.08758006244897842, 0.08758006244897842, 0.015297667123377323, 0.28509801626205444, 0.14118508994579315, 0.18818339705467224, 0.28509801626205444, 0.14118508994579315, 0.07463911920785904, -0.09351608902215958, 0.09520577639341354, 0.18657918274402618, 0.07884982973337173, 0.09068910032510757, 0.12299828976392746, 0.957473874092102]
110 : 0.14666666666666667
[[14542.  8568.  3927.     0.     0.     0.    31.    23.    31.    10.
     20.     0.]
 [ 4908.  4060.  1429.   118.   121.   145.   821.   859.   715.   510.
    337.   228.]
 [ 2773.  3567.  2737.  2467.  2179.  1665.  1028.   242.    34.    18.
     19.     0.]
 [ 1209.   962.   381.   105.    84.    67.    49.     0.     0.     0.
      0.     0.]]
Checking the total Q and that Qe samples 0.8669741837584755 0.0
Test reward:  1.0
LR:  0.001
replay buffer size:  60989
training steps:  109
Average siam loss:  -0.5406127838225671
Average value from last batch of unclaimed novelty:  tensor(-0.0068, dtype=torch.float64)
Average value from last batch of predicted nov:  0.15740952653262763
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.1300705  0.35179051 0.56710064 0.60877592 0.44240799 0.53604292
 0.61790212 0.55171792 0.38664506]
then printing the same exp r:  [-0.2204061597585678, -0.21175669133663177, -0.03594698756933212, -0.08577172458171844, -0.08916615694761276, -0.07644462585449219, 0.07242563366889954, 0.17064577341079712, 0.6621505618095398]
Checking the total Q and that Qe samples 0.694318781940476 0.0
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-3.33753006 -3.07090299 -2.78053392 -2.84034539 -2.66031667 -2.01967519
 -1.68341886 -1.49925943 -1.28281435 -0.8802489  -0.95362263 -0.80711663
 -0.47151089 -0.13210132 -0.09194795]
then printing the same exp r:  [-0.3736795485019684, -0.28903594613075256, -0.2795964479446411, -0.3546432852745056, -0.35715770721435547, -0.35665708780288696, -0.2011636644601822, -0.23158910870552063, -0.4155231714248657, -0.24126097559928894, -0.1561385542154312, -0.3437584340572357, -0.34417229890823364, -0.04148773476481438, 0.22862328588962555]
Checking the total Q and that Qe samples 0.20081628144760405 0.0
Checking the total Q and that Qe samples 0.8719990943988476 0.22489224425359705
Checking the total Q and that Qe samples 0.6410641931034752 0.0
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.70897092 -0.43683992 -0.24814529 -0.39339131 -0.15717696 -0.19252712
  0.04571617 -0.02355829]
then printing the same exp r:  [-0.2792923152446747, -0.19310715794563293, -0.15330369770526886, -0.24018800258636475, 0.03376251086592674, -0.24018800258636475, 0.06973623484373093, 0.28750374913215637]
