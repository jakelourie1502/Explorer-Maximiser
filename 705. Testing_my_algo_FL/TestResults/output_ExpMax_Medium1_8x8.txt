[['S' 'H' 'F' 'F' 'F' 'F' 'H' 'F']
 ['F' 'F' 'F' 'H' 'F' 'F' 'F' 'F']
 ['F' 'F' 'H' 'F' 'H' 'F' 'F' 'F']
 ['F' 'F' 'H' 'F' 'H' 'H' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['H' 'H' 'H' 'F' 'F' 'F' 'H' 'H']
 ['F' 'F' 'F' 'F' 'H' 'H' 'H' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F' 'G']]
Adding thread: now have 13 threads
Starting evaluation
siam score:  -0.0033825282
deleting a thread, now have 12 threads
Frames:  1516 train batches done:  12 episodes:  177
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 184, frames: 1548, time: 69.44680976867676
training steps:  13
RDN obj mus: [-0.015261591635718651, 0.0012523041286412585, 0, 0, 0]
RDN obj sigmas: [0.020960353333814713, 0.005490424626454579, 1, 1, 1]
184 : 0.0
LR:  1.2e-05
replay buffer size:  4048
Time Taken :  1.0  mins 9.44667100906372  seconds
[[[410. 146.  11.   6.   2.   0.   0.   0.]
  [287.  80.  19.   6.   0.   0.   0.   0.]
  [125.  52.  11.   0.   0.   0.   0.   0.]
  [ 69.  40.  10.   0.   0.   0.   0.   0.]
  [ 38.  29.   5.   5.   2.   0.   0.   0.]
  [  4.   6.   1.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
siam score:  -0.2873949
deleting a thread, now have 11 threads
Frames:  1725 train batches done:  42 episodes:  202
siam score:  -0.5605258
deleting a thread, now have 10 threads
Frames:  1900 train batches done:  64 episodes:  225
siam score:  -0.60005563
deleting a thread, now have 9 threads
Frames:  2053 train batches done:  91 episodes:  246
first move QE:  -0.3322339209485494
deleting a thread, now have 8 threads
Frames:  2175 train batches done:  120 episodes:  265
siam score:  -0.52067256
siam score:  -0.4919022
siam score:  -0.44478482
siam score:  -0.35504645
first move QE:  -0.33334919473514746
siam score:  -0.5599926
siam score:  -0.41371003
siam score:  -0.5842806
siam score:  -0.58341056
siam score:  -0.58731323
siam score:  -0.61441237
siam score:  -0.59939003
first move QE:  -0.23958596141069935
first move QE:  -0.23958596141069935
siam score:  -0.64401686
siam score:  -0.6601847
siam score:  -0.65142286
siam score:  -0.6521571
siam score:  -0.6766727
siam score:  -0.6767719
siam score:  -0.6747208
siam score:  -0.61285347
siam score:  -0.65654236
UNIT TEST: sample policy line 217 mcts : [0.208 0.25  0.25  0.125 0.167]
siam score:  -0.5906462
siam score:  -0.606592
siam score:  -0.6163025
siam score:  -0.5895088
Sims:  25 1 epoch:  9066 pick best:  False frame count:  9066
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 1332, frames: 10046, time: 3012.0336997509003
training steps:  1174
RDN obj mus: [-0.8978424544811249, -0.920877883040905, -0.9062935184836388, -0.8555555802604463, -0.876886534690857]
RDN obj sigmas: [0.051689607120724235, 0.04288429550897559, 0.04232255827738506, 0.048324031720045436, 0.028139607279812996]
1332 : 0.0
LR:  0.001
replay buffer size:  12779
Time Taken :  50.0  mins 12.03366208076477  seconds
[[[3012. 1081.   73.   23.   32.   18.    5.    0.]
  [1734.  546.  148.   37.   14.   13.   10.    6.]
  [ 662.  364.  112.    0.    1.    0.    3.   10.]
  [ 257.  195.   50.    0.    0.    1.    2.   11.]
  [ 124.  100.   18.    5.    2.    0.    0.    0.]
  [  17.   23.    5.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.]]]
siam score:  -0.57651633
siam score:  -0.6741741
siam score:  -0.6544918
siam score:  -0.6626529
siam score:  -0.6348469
first move QE:  -0.14120247809156866
siam score:  -0.6393336
siam score:  -0.6403016
first move QE:  -0.1436933399282171
first move QE:  -0.1425174790788066
first move QE:  -0.14205806265737878
siam score:  -0.68737274
siam score:  -0.69317746
siam score:  -0.7057372
siam score:  -0.70961976
siam score:  -0.7159434
UNIT TEST: sample policy line 217 mcts : [0.375 0.167 0.125 0.125 0.208]
siam score:  -0.67445695
siam score:  -0.6582001
siam score:  -0.68495196
UNIT TEST: sample policy line 217 mcts : [0.208 0.5   0.083 0.125 0.083]
siam score:  -0.69322234
siam score:  -0.68730736
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 5.124653448749839e-12
0.0 3.6975347681144535e-12
0.0 5.124653448749839e-12
0.0 5.124653448749839e-12
0.0 0.0
0.0 0.0
0.0 8.800565200607874e-12
0.0 1.0941243218741632e-11
0.0 5.124653448749839e-12
0.0 0.0
line 193 mcts: sample exp_bonus -0.029104466913267967
siam score:  -0.7078741
first move QE:  -0.1323648855099693
siam score:  -0.68322676
line 193 mcts: sample exp_bonus -0.4382091656327247
siam score:  -0.7015079
siam score:  -0.7109759
siam score:  -0.682446
siam score:  -0.71506643
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 2806, frames: 20080, time: 6987.375062704086
training steps:  2349
RDN obj mus: [-0.9106122595965862, -0.9450156358540058, -0.9251628944694996, -0.837392653141703, -0.7981197834014893]
RDN obj sigmas: [0.03719670509586471, 0.034874117535202684, 0.05223997738656981, 0.05801328963490263, 0.12743582414779334]
2806 : 0.0
LR:  0.001
replay buffer size:  22988
Time Taken :  116.0  mins 27.374932050704956  seconds
[[[5965. 2242.  137.   48.   48.   29.    9.    5.]
  [3318. 1080.  336.   99.   15.   20.   13.    7.]
  [1291.  726.  243.    0.    2.    1.    4.   10.]
  [ 545.  391.  127.    3.    3.    3.    2.   11.]
  [ 201.  166.   45.   19.   10.    4.    0.    0.]
  [  31.   32.   11.    8.    8.    2.    0.    0.]
  [   0.    0.    0.    0.    2.    2.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.]]]
first move QE:  -0.1273111981968385
UNIT TEST: sample policy line 217 mcts : [0.333 0.167 0.042 0.042 0.417]
siam score:  -0.67580324
siam score:  -0.65886444
siam score:  -0.68550164
siam score:  -0.6654089
siam score:  -0.6666755
siam score:  -0.6991913
first move QE:  -0.12563521301089284
line 193 mcts: sample exp_bonus -0.24276539087295532
siam score:  -0.63252586
siam score:  -0.6438843
line 193 mcts: sample exp_bonus 0.01309146840358153
first move QE:  -0.12357144991716076
siam score:  -0.70097506
siam score:  -0.6723126
siam score:  -0.6713245
siam score:  -0.6835693
siam score:  -0.6948025
first move QE:  -0.11885594015312423
siam score:  -0.67339116
first move QE:  -0.11972391982864622
siam score:  -0.69182277
siam score:  -0.6277303
siam score:  -0.61574084
Sims:  25 1 epoch:  27677 pick best:  False frame count:  27677
siam score:  -0.6874978
siam score:  -0.691913
siam score:  -0.70803976
siam score:  -0.6939241
line 193 mcts: sample exp_bonus -0.017551079392433167
siam score:  -0.6712978
siam score:  -0.6435138
line 193 mcts: sample exp_bonus 0.0009183928841957821
siam score:  -0.67712283
UNIT TEST: sample policy line 217 mcts : [0.167 0.167 0.417 0.125 0.125]
siam score:  -0.68312407
siam score:  -0.6847232
siam score:  -0.6840155
line 193 mcts: sample exp_bonus -0.0011843772255815566
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 4257, frames: 30122, time: 10936.058361768723
training steps:  3531
RDN obj mus: [-0.953548706895113, -0.9554800254940987, -0.9376899098217487, -0.8389109736378781, -0.7862608432769775]
RDN obj sigmas: [0.028113858819401687, 0.031464295703007635, 0.04692224823327018, 0.06107222646977574, 0.11612434198777925]
4257 : 0.0
LR:  0.001
replay buffer size:  33265
Time Taken :  182.0  mins 16.058231115341187  seconds
[[[9112. 3464.  228.   72.   60.   30.    9.    5.]
  [4938. 1618.  497.  144.   24.   24.   17.   11.]
  [1935. 1049.  345.    0.    3.    1.    7.   12.]
  [ 772.  518.  168.    5.    5.    4.    6.   14.]
  [ 286.  220.   69.   30.   12.    6.    1.    0.]
  [  47.   47.   16.   13.    9.    2.    0.    0.]
  [   0.    0.    2.    3.    3.    2.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.]]]
first move QE:  -0.11147697329746946
first move QE:  -0.11147697329746946
siam score:  -0.6859009
siam score:  -0.6655381
siam score:  -0.66650796
first move QE:  -0.09964259859080477
siam score:  -0.6764654
siam score:  -0.64347875
line 193 mcts: sample exp_bonus 0.21340401691382932
siam score:  -0.6719573
first move QE:  -0.0666503625557523
line 193 mcts: sample exp_bonus 3.011515244102478
siam score:  -0.69585526
line 193 mcts: sample exp_bonus 1.4795126415491104
start point for exploration sampling:  30000
start point for exploration sampling:  30000
siam score:  -0.62248397
line 193 mcts: sample exp_bonus 2.5940930277175367
siam score:  -0.69633013
siam score:  -0.6839586
siam score:  -0.67398226
siam score:  -0.6869183
first move QE:  -0.00444859154632156
start point for exploration sampling:  30000
siam score:  -0.6960896
start point for exploration sampling:  30000
siam score:  -0.68834853
siam score:  -0.689525
line 193 mcts: sample exp_bonus 3.8554634680368007
line 193 mcts: sample exp_bonus 0.48848076122879974
start point for exploration sampling:  30000
siam score:  -0.6936746
Starting evaluation
siam score:  -0.6916155
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 5059, frames: 40128, time: 14107.65743470192
training steps:  4428
RDN obj mus: [-0.9543015426516533, -0.9669368672072888, -0.9551482356727123, -0.9387491976618767, -0.9120387296378305]
RDN obj sigmas: [0.025734043624457463, 0.021835312759610887, 0.025173201636053334, 0.05110201638475555, 0.08135836317490834]
5059 : 0.0
LR:  0.001
replay buffer size:  43426
Time Taken :  235.0  mins 7.657357215881348  seconds
[[[13307.  4080.   426.   187.   151.    79.    20.    27.]
  [ 6167.  1972.   625.   181.    41.    46.    26.    18.]
  [ 2448.  1302.   381.     4.     4.     6.    22.    40.]
  [ 1033.   700.   192.    17.    13.     8.    18.    33.]
  [  410.   350.   153.   111.    91.    21.    15.    12.]
  [   65.    63.    31.    46.    51.    17.     6.     1.]
  [    0.     0.     2.    18.     8.     4.     0.     0.]
  [    0.     0.     0.    15.     5.     0.     0.     0.]]]
siam score:  -0.6939071
line 193 mcts: sample exp_bonus 3.40838459212104
start point for exploration sampling:  30000
siam score:  -0.7105768
start point for exploration sampling:  30000
line 193 mcts: sample exp_bonus 1.206899510322213
siam score:  -0.6938176
siam score:  -0.70071965
start point for exploration sampling:  30000
siam score:  -0.7108323
siam score:  -0.7027546
UNIT TEST: sample policy line 217 mcts : [0.167 0.417 0.    0.    0.417]
siam score:  -0.6987369
first move QE:  0.08623244220318206
siam score:  -0.6923449
siam score:  -0.68609345
siam score:  -0.6988793
line 193 mcts: sample exp_bonus 2.244837609672546
first move QE:  0.1275272301731375
line 193 mcts: sample exp_bonus 7.323200728604197
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 5499, frames: 50301, time: 16076.96347784996
training steps:  4944
RDN obj mus: [-0.9175671261191368, -0.9478010260045528, -0.9311774027049542, -0.9174120625436306, -0.9067985826969147]
RDN obj sigmas: [0.056756538847146966, 0.030000878197692656, 0.034124852867748454, 0.05263413089599844, 0.06914291647914068]
5499 : 0.0
LR:  0.001
replay buffer size:  53856
Time Taken :  267.0  mins 56.96334218978882  seconds
[[[14562.  4263.   565.   329.   393.   274.    43.    56.]
  [ 7272.  2311.   707.   198.   103.   138.    67.    65.]
  [ 3712.  1617.   399.    11.     8.    18.    28.    75.]
  [ 1796.   963.   224.    57.    34.    29.    29.    51.]
  [  793.   763.   491.   481.   350.   196.    43.    38.]
  [   76.    84.    63.   293.   253.   109.    18.     5.]
  [    0.     3.    26.    99.    32.    12.     0.     0.]
  [   14.    17.    50.    44.    21.    31.     0.     0.]]]
line 193 mcts: sample exp_bonus 6.590436760051236
UNIT TEST: sample policy line 217 mcts : [0.042 0.25  0.292 0.042 0.375]
start point for exploration sampling:  30000
UNIT TEST: sample policy line 217 mcts : [0.792 0.208 0.    0.    0.   ]
siam score:  -0.6903837
UNIT TEST: sample policy line 217 mcts : [0.042 0.    0.375 0.    0.583]
line 193 mcts: sample exp_bonus 6.019599862910016
siam score:  -0.69667023
siam score:  -0.69597304
siam score:  -0.6987796
first move QE:  0.15882876789556272
line 193 mcts: sample exp_bonus 5.733979559588432
siam score:  -0.7250406
siam score:  -0.70921415
siam score:  -0.7078344
siam score:  -0.70979226
line 193 mcts: sample exp_bonus 7.241385978102684
line 193 mcts: sample exp_bonus 0.9122403415751252
siam score:  -0.7356601
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 5858, frames: 60243, time: 17755.890187740326
training steps:  5367
RDN obj mus: [-0.9406747903943062, -0.9495345532894135, -0.9443577029585838, -0.9477740507364273, -0.936657379078865]
RDN obj sigmas: [0.02461703131526714, 0.023042200785451793, 0.026107255738901467, 0.023705467347596678, 0.03312915438806688]
5858 : 0.0
LR:  0.001
replay buffer size:  64024
Time Taken :  295.0  mins 55.890055894851685  seconds
[[[15388.  4402.   785.   788.  1013.   644.   104.   450.]
  [ 8006.  2569.   851.   223.   247.   475.   256.   403.]
  [ 4244.  1778.   417.    19.    14.   185.   198.   391.]
  [ 2252.  1149.   240.    77.    44.    49.    87.   187.]
  [ 1053.  1045.   756.   896.   534.   309.    92.    76.]
  [   88.    91.    72.   487.   355.   178.    25.     6.]
  [    0.     3.    26.   124.    43.    14.     0.     0.]
  [   14.    17.    50.    44.    21.    31.     0.     0.]]]
siam score:  -0.7442177
siam score:  -0.74337506
start point for exploration sampling:  30000
line 193 mcts: sample exp_bonus 4.876414865112305
siam score:  -0.7359114
line 193 mcts: sample exp_bonus 4.795660517958243
siam score:  -0.7534727
siam score:  -0.76005584
line 193 mcts: sample exp_bonus 4.385575777861833
start point for exploration sampling:  30000
start point for exploration sampling:  30000
siam score:  -0.7712535
siam score:  -0.7787877
siam score:  -0.7795334
siam score:  -0.78610456
UNIT TEST: sample policy line 217 mcts : [0.417 0.208 0.167 0.083 0.125]
UNIT TEST: sample policy line 217 mcts : [0.292 0.042 0.333 0.125 0.208]
Starting evaluation
siam score:  -0.7930826
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 6194, frames: 70254, time: 19354.70035481453
training steps:  5843
RDN obj mus: [-0.9518048492431641, -0.9651304178059101, -0.9621247039020061, -0.9472061889469624, -0.9363911185264587]
RDN obj sigmas: [0.020350713644058584, 0.017494817357207468, 0.018559634677796723, 0.02602353613358749, 0.03448590463213927]
6194 : 0.0
LR:  0.001
replay buffer size:  74250
Time Taken :  322.0  mins 34.7002170085907  seconds
[[[16360.  4558.  1026.  1062.  1765.  1087.   143.   837.]
  [ 8588.  2874.  1014.   243.   396.   726.   480.   936.]
  [ 4559.  1921.   439.    20.    22.   351.   610.  1161.]
  [ 2450.  1269.   258.    90.    47.    61.   292.  1054.]
  [ 1118.  1134.   824.   964.   593.   395.   181.   348.]
  [   89.    93.    73.   507.   372.   211.    32.    13.]
  [    0.     3.    26.   129.    43.    15.     0.     0.]
  [   14.    17.    57.    54.    25.    31.     0.     0.]]]
line 193 mcts: sample exp_bonus 6.30303280090064
siam score:  -0.7896702
line 193 mcts: sample exp_bonus 2.4813571736478806
first move QE:  0.2405788638331879
siam score:  -0.81074256
siam score:  -0.81696975
siam score:  -0.81730896
siam score:  -0.81790876
siam score:  -0.8145006
start point for exploration sampling:  30000
siam score:  -0.81800425
siam score:  -0.8218642
siam score:  -0.82079345
line 193 mcts: sample exp_bonus 4.430958563172817
start point for exploration sampling:  30000
line 193 mcts: sample exp_bonus 3.9390474022066595
siam score:  -0.83410203
UNIT TEST: sample policy line 217 mcts : [0.083 0.292 0.125 0.042 0.458]
siam score:  -0.840831
siam score:  -0.8404272
siam score:  -0.8484946
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0, '0.17': 0, '0.33': 0, '0.5': 0}
Episodes: 6616, frames: 80094, time: 21460.66323184967
training steps:  6471
RDN obj mus: [-0.9541778540790081, -0.9703113300025463, -0.9695826731741428, -0.9584752243816853, -0.9429738051593304]
RDN obj sigmas: [0.02308858930789485, 0.017528738740491476, 0.018734330419824204, 0.0362956524343916, 0.04909160577898754]
6616 : 0.0
LR:  0.001
replay buffer size:  84288
Time Taken :  357.0  mins 40.66309213638306  seconds
[[[17169.  4748.  1343.  1475.  2657.  1454.   163.  1126.]
  [ 9251.  3163.  1251.   295.   686.  1108.   670.  1185.]
  [ 4844.  2033.   467.    29.    38.   547.   959.  1637.]
  [ 2685.  1397.   276.   244.    53.    77.   475.  1424.]
  [ 1246.  1266.   905.  1108.   672.   482.   295.   512.]
  [  100.   102.    80.   607.   427.   230.    34.    21.]
  [    0.     3.    27.   160.    52.    16.     0.     0.]
  [   14.    17.    57.    58.    26.    32.     0.     0.]]]
