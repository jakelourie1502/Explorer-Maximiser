[['S' 'H' 'F' 'F' 'F' 'F' 'H' 'F']
 ['F' 'F' 'F' 'H' 'F' 'F' 'F' 'F']
 ['F' 'F' 'H' 'F' 'H' 'F' 'F' 'F']
 ['F' 'F' 'H' 'F' 'H' 'H' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['H' 'H' 'H' 'F' 'F' 'F' 'H' 'H']
 ['F' 'F' 'F' 'F' 'H' 'H' 'H' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F' 'G']]
UNIT TEST: sample policy line 217 mcts : [0.2 0.2 0.2 0.2 0.2]
Starting evaluation
Adding thread: now have 13 threads
siam score:  0.0038101368
UNIT TEST: sample policy line 217 mcts : [0.2 0.2 0.2 0.2 0.2]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0}
Episodes: 167, frames: 1429, time: 64.60861706733704
training steps:  10
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
167 : 0.0
LR:  9e-06
replay buffer size:  3929
Time Taken :  1.0  mins 4.608518838882446  seconds
[[[405. 133.  15.  10.   2.   0.   0.   0.]
  [280.  96.  29.  10.   0.   0.   0.   0.]
  [109.  65.  10.   0.   0.   0.   0.   0.]
  [ 32.  18.   6.   0.   0.   0.   0.   0.]
  [ 17.  10.   1.   1.   2.   1.   0.   0.]
  [  5.   2.   0.   0.   2.   0.   0.   0.]
  [  0.   0.   0.   0.   1.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
deleting a thread, now have 12 threads
Frames:  1431 train batches done:  14 episodes:  168
deleting a thread, now have 11 threads
Frames:  1600 train batches done:  48 episodes:  193
siam score:  -0.4389936
siam score:  -0.5669977
siam score:  -0.60871404
siam score:  -0.6335946
siam score:  -0.636195
deleting a thread, now have 10 threads
Frames:  1745 train batches done:  83 episodes:  216
siam score:  -0.63582927
siam score:  -0.6510901
siam score:  -0.6668085
deleting a thread, now have 9 threads
Frames:  1843 train batches done:  118 episodes:  237
deleting a thread, now have 8 threads
Frames:  1995 train batches done:  153 episodes:  256
siam score:  -0.65744805
siam score:  -0.55191916
siam score:  -0.49532944
siam score:  -0.5347663
siam score:  -0.473917
siam score:  -0.6248322
siam score:  -0.7108734
siam score:  -0.7136496
siam score:  -0.7131648
siam score:  -0.7186551
siam score:  -0.72297496
siam score:  -0.71300375
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.6769507
UNIT TEST: sample policy line 217 mcts : [0.083 0.375 0.167 0.167 0.208]
siam score:  -0.69905734
siam score:  -0.7235658
siam score:  -0.7253775
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.72401965
siam score:  -0.72355837
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.7267227
siam score:  -0.6747823
siam score:  -0.69115186
siam score:  -0.7005279
siam score:  -0.73448426
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0}
Episodes: 1296, frames: 10039, time: 2395.204066991806
training steps:  1170
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1296 : 0.0
LR:  0.001
replay buffer size:  12723
Time Taken :  39.0  mins 55.20392179489136  seconds
[[[2393.  955.   67.   26.    5.    5.    2.    0.]
  [1719.  545.  154.   50.    0.    0.    0.    0.]
  [ 922.  414.  122.    0.    0.    0.    0.    0.]
  [ 485.  245.   60.    1.    0.    0.    0.    0.]
  [ 251.  142.   43.    8.    8.    3.    0.    0.]
  [  57.   40.    9.    2.    6.    2.    0.    0.]
  [   0.    0.    0.    1.    1.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.]]]
siam score:  -0.7381956
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.73458695
siam score:  -0.73904914
siam score:  -0.73826516
siam score:  -0.73739356
siam score:  -0.711006
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 1.980981276725402e-08
0.0 0.0
0.0 2.340331922526508e-08
0.0 0.0
0.0 2.1271809362365372e-08
0.0 0.0
0.0 2.340331922526508e-08
0.0 0.0
0.0 1.4126247757078895e-08
siam score:  -0.69913054
siam score:  -0.73967355
siam score:  -0.7430456
UNIT TEST: sample policy line 217 mcts : [0.125 0.208 0.375 0.167 0.125]
siam score:  -0.722148
UNIT TEST: sample policy line 217 mcts : [0.125 0.292 0.333 0.125 0.125]
siam score:  -0.7210022
line 193 mcts: sample exp_bonus 0.0
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.7408188
siam score:  -0.7428728
siam score:  -0.74234086
siam score:  -0.739657
siam score:  -0.72988313
UNIT TEST: sample policy line 217 mcts : [0.125 0.417 0.167 0.167 0.125]
siam score:  -0.7149237
siam score:  -0.71612495
siam score:  -0.714376
UNIT TEST: sample policy line 217 mcts : [0.083 0.167 0.167 0.25  0.333]
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.7306794
siam score:  -0.7355093
siam score:  -0.718026
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.7246854
siam score:  -0.72788256
siam score:  -0.71908003
siam score:  -0.69568133
siam score:  -0.7031026
siam score:  -0.7047286
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0}
Episodes: 2521, frames: 20102, time: 5753.237844944
training steps:  2350
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2521 : 0.0
LR:  0.001
replay buffer size:  22957
Time Taken :  95.0  mins 53.23769497871399  seconds
[[[4787. 1875.  107.   40.   12.   11.    3.    0.]
  [3363. 1073.  288.   87.    3.    2.    0.    0.]
  [1895.  880.  221.    0.    1.    2.    0.    0.]
  [1056.  550.  110.    5.    1.    0.    0.    0.]
  [ 541.  309.   89.   22.   10.    3.    0.    0.]
  [ 123.   78.   21.    3.    6.    2.    0.    0.]
  [   0.    0.    0.    1.    1.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.]]]
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.71409684
siam score:  -0.7154412
siam score:  -0.72061926
siam score:  -0.6995969
siam score:  -0.7021708
siam score:  -0.7221865
siam score:  -0.71167296
UNIT TEST: sample policy line 217 mcts : [0.208 0.208 0.125 0.167 0.292]
siam score:  -0.71727186
siam score:  -0.7229805
siam score:  -0.7197772
siam score:  -0.6857994
siam score:  -0.70681
siam score:  -0.7235922
siam score:  -0.7239804
UNIT TEST: sample policy line 217 mcts : [0.125 0.292 0.208 0.167 0.208]
siam score:  -0.7156253
siam score:  -0.71201617
siam score:  -0.7045982
siam score:  -0.72271764
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.7183104
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.71695113
siam score:  -0.71897036
siam score:  -0.72542554
siam score:  -0.71833056
siam score:  -0.69665253
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.72178483
line 193 mcts: sample exp_bonus 0.0
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.68876326
Starting evaluation
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0}
Episodes: 3731, frames: 30097, time: 9113.29322385788
training steps:  3523
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3731 : 0.0
LR:  0.001
replay buffer size:  33110
Time Taken :  151.0  mins 53.293073892593384  seconds
[[[7213. 2777.  177.   65.   20.   12.    4.    0.]
  [5019. 1633.  460.  118.    4.    2.    0.    0.]
  [2796. 1330.  335.    2.    3.    2.    0.    0.]
  [1568.  814.  170.   14.    1.    0.    0.    0.]
  [ 809.  453.  132.   44.   17.    4.    0.    0.]
  [ 179.  112.   30.    9.    8.    3.    0.    0.]
  [   0.    1.    5.    7.    2.    0.    0.    0.]
  [   0.    0.    4.    7.    1.    0.    0.    0.]]]
siam score:  -0.7043996
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.6999021
siam score:  -0.71422875
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.70688
siam score:  -0.7025849
siam score:  -0.6904022
siam score:  -0.7103702
siam score:  -0.68164045
siam score:  -0.68379974
UNIT TEST: sample policy line 217 mcts : [0.208 0.125 0.25  0.167 0.25 ]
siam score:  -0.70030016
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.70775986
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.70122087
siam score:  -0.70991075
siam score:  -0.7216693
siam score:  -0.6999762
Starting evaluation
siam score:  -0.7075026
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0}
Episodes: 4932, frames: 40095, time: 12540.413182020187
training steps:  4696
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4932 : 0.0
LR:  0.001
replay buffer size:  43279
Time Taken :  209.0  mins 0.4130899906158447  seconds
[[[9587. 3675.  212.   80.   21.   12.    4.    0.]
  [6696. 2177.  612.  145.    4.    2.    0.    0.]
  [3789. 1763.  453.    2.    3.    2.    0.    0.]
  [2141. 1084.  224.   16.    1.    0.    0.    0.]
  [1100.  610.  172.   56.   21.    5.    0.    0.]
  [ 240.  145.   38.   11.   12.    4.    1.    0.]
  [   0.    5.    7.    9.    3.    0.    0.    0.]
  [   0.    3.    7.    8.    1.    0.    0.    0.]]]
UNIT TEST: sample policy line 217 mcts : [0.25  0.167 0.25  0.125 0.208]
siam score:  -0.71576494
siam score:  -0.70276624
siam score:  -0.70490295
UNIT TEST: sample policy line 217 mcts : [0.125 0.417 0.167 0.167 0.125]
siam score:  -0.69688165
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 0.0
0.0 0.0
0.0 0.0
0.0 4.7916590828194895e-11
0.0 4.4954238414640756e-11
0.0 3.745105383901679e-11
0.0 4.4954238414640756e-11
0.0 0.0
0.0 0.0
siam score:  -0.6870478
siam score:  -0.70895594
siam score:  -0.7149445
siam score:  -0.71131945
siam score:  -0.7046013
siam score:  -0.7225973
siam score:  -0.71329904
siam score:  -0.70938146
siam score:  -0.70877814
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.7042833
siam score:  -0.7009887
siam score:  -0.6942227
siam score:  -0.7228712
siam score:  -0.7233081
siam score:  -0.7068821
siam score:  -0.7083204
siam score:  -0.707149
UNIT TEST: sample policy line 217 mcts : [0.125 0.167 0.167 0.417 0.125]
siam score:  -0.6950176
siam score:  -0.6786586
siam score:  -0.6772714
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.68847024
siam score:  -0.6743328
Starting evaluation
line 193 mcts: sample exp_bonus 0.0
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0}
Episodes: 6167, frames: 50087, time: 16108.68104505539
training steps:  5867
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6167 : 0.0
LR:  0.001
replay buffer size:  53454
Time Taken :  268.0  mins 28.68099880218506  seconds
[[[12312.  4615.   247.    94.    29.    16.     5.     0.]
  [ 8250.  2684.   730.   177.     8.     4.     0.     0.]
  [ 4723.  2187.   576.     2.     3.     2.     0.     0.]
  [ 2678.  1324.   276.    16.     3.     0.     0.     0.]
  [ 1340.   732.   197.    63.    24.     5.     0.     0.]
  [  288.   175.    44.    14.    12.     4.     1.     0.]
  [    0.     7.    10.    12.     4.     0.     0.     0.]
  [    0.     3.    10.    12.     2.     0.     0.     0.]]]
siam score:  -0.6422463
siam score:  -0.664209
siam score:  -0.670288
siam score:  -0.67192197
siam score:  -0.65382934
siam score:  -0.6365113
siam score:  -0.6578279
siam score:  -0.66126937
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.65806943
siam score:  -0.6598058
siam score:  -0.6632016
siam score:  -0.6577204
siam score:  -0.6616423
siam score:  -0.66780365
siam score:  -0.66734385
siam score:  -0.66826063
siam score:  -0.6738369
siam score:  -0.65771896
siam score:  -0.6463198
siam score:  -0.6465228
siam score:  -0.6579664
siam score:  -0.66188264
siam score:  -0.66907763
Sims:  25 1 epoch:  59365 pick best:  False frame count:  59365
siam score:  -0.66040593
line 193 mcts: sample exp_bonus 0.0
Starting evaluation
siam score:  -0.66111654
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0}
Episodes: 7386, frames: 60039, time: 19412.436514139175
training steps:  7034
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7386 : 0.0
LR:  0.001
replay buffer size:  63606
Time Taken :  323.0  mins 32.4363648891449  seconds
[[[14749.  5514.   304.   110.    41.    26.     5.     0.]
  [ 9932.  3271.   888.   223.    14.     5.     0.     0.]
  [ 5632.  2629.   684.     2.     4.     2.     0.     0.]
  [ 3223.  1587.   342.    18.     4.     0.     0.     0.]
  [ 1546.   852.   235.    69.    28.     9.     0.     0.]
  [  345.   206.    53.    17.    15.     6.     1.     0.]
  [    0.     7.    10.    13.     4.     1.     0.     0.]
  [    0.     3.    10.    12.     2.     0.     0.     0.]]]
siam score:  -0.65237105
siam score:  -0.6748711
siam score:  -0.6586737
siam score:  -0.66948026
siam score:  -0.66331106
siam score:  -0.65672034
siam score:  -0.6577854
line 193 mcts: sample exp_bonus 0.0
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.66701615
siam score:  -0.6639172
siam score:  -0.66477364
siam score:  -0.65722895
siam score:  -0.6574057
siam score:  -0.6560974
siam score:  -0.66723955
line 193 mcts: sample exp_bonus 0.0
UNIT TEST: sample policy line 217 mcts : [0.208 0.167 0.167 0.333 0.125]
siam score:  -0.6656962
siam score:  -0.6610922
siam score:  -0.6579803
siam score:  -0.6643158
UNIT TEST: sample policy line 217 mcts : [0.125 0.125 0.458 0.167 0.125]
UNIT TEST: sample policy line 217 mcts : [0.125 0.375 0.208 0.167 0.125]
siam score:  -0.6734816
siam score:  -0.6763971
siam score:  -0.6721175
siam score:  -0.66349274
line 193 mcts: sample exp_bonus 0.0
line 193 mcts: sample exp_bonus 0.0
siam score:  -0.6617482
siam score:  -0.6655882
siam score:  -0.66134614
siam score:  -0.6631636
Starting evaluation
siam score:  -0.666698
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
Scores:  {'0.0': 0}
Episodes: 8588, frames: 70030, time: 22462.357155799866
training steps:  8202
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8588 : 0.0
LR:  0.001
replay buffer size:  73766
Time Taken :  374.0  mins 22.357011795043945  seconds
[[[17250.  6424.   334.   117.    43.    27.     6.     0.]
  [11706.  3809.  1007.   247.    14.     7.     1.     0.]
  [ 6625.  3069.   817.     5.     5.     2.     0.     0.]
  [ 3751.  1820.   389.    24.     5.     0.     0.     0.]
  [ 1779.   975.   272.    77.    31.     9.     0.     0.]
  [  390.   237.    61.    19.    17.     7.     1.     0.]
  [    0.     7.    10.    13.     5.     1.     0.     0.]
  [    0.     3.    10.    12.     2.     0.     0.     0.]]]
